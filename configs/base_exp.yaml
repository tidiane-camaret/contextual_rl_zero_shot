defaults:
  - env: carl_mountain_car
  - override hydra/launcher: slurm
  - _self_ # this indicates that the current config overrides the configs placed above it
           # however, this is already the default behavior, so this line is not necessary


hydra:
  callbacks:
    log_job_return:
      _target_: hydra.experimental.callbacks.LogJobReturnCallback
  job:
    chdir: True

  sweeper:    # only invoked if --multirun is used, e.g. `python launchers/train_ae.py --multirun`
    params:
      seed: range(10)
      context.mode: learned_jrpl
  run:
    dir: results/hydra/single_run/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: results/hydra/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

train:
  total_timesteps: 10000

wandb:
  track: False
  project_name: meta_rl
  entity: 

seed: 0

context:
  name: power
  mode: learned_jrpl #explicit # hidden, learned_iida
  lower_bound_coeff: 0.2 # lower bound = lower_bound_coeff * context_default
  upper_bound_coeff: 2.0 # upper bound = upper_bound_coeff * context_default

context_encoder:
  nb_input_transitions: 20
  hidden_sizes: [4, 2]
  latent_context_dim: 2

sac_params:
  autotune_entropy: True