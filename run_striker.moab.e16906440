+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ module load devel/python/3.9.7
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ module load devel/conda
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Lmod has detected the following error: Cannot load module "tools/conda/latest"
because these module(s) are loaded:
   devel/python

While processing the following module(s):
    Module fullname     Module Filename
    ---------------     ---------------
    tools/conda/latest  /opt/bwhpc/modulefiles/development/common/tools/conda/latest.lua

Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 1
+ module load mpi/openmpi/4.1-gnu-9.2
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ export CPATH=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/include
+ CPATH=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/include
+ source miniconda3/etc/profile.d/conda.sh
++ export CONDA_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda
++ CONDA_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/python
++ '[' -z x ']'
+ conda activate tid_env
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate tid_env
+ '[' -n '' ']'
+ local ask_conda
++ PS1=
++ __conda_exe shell.posix activate tid_env
++ /home/fr/fr_fr/fr_tn110/miniconda3/bin/conda shell.posix activate tid_env
+ ask_conda='. "/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/xgboost_deactivate.sh"
. "/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/mpivars.deactivate.sh"
PS1='\''(tid_env) '\''
export PATH='\''/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric'\''
export CONDA_PREFIX='\''/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''tid_env'\''
export CONDA_PROMPT_MODIFIER='\''(tid_env) '\''
export CONDA_PREFIX_1='\''/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest'\''
export CONDA_EXE='\''/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/fr/fr_fr/fr_tn110/miniconda3/bin/python'\'''
+ eval '. "/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/xgboost_deactivate.sh"
. "/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/mpivars.deactivate.sh"
PS1='\''(tid_env) '\''
export PATH='\''/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric'\''
export CONDA_PREFIX='\''/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''tid_env'\''
export CONDA_PROMPT_MODIFIER='\''(tid_env) '\''
export CONDA_PREFIX_1='\''/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest'\''
export CONDA_EXE='\''/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/fr/fr_fr/fr_tn110/miniconda3/bin/python'\'''
++ . /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/xgboost_deactivate.sh
+++ '[' 1 = 1 ']'
+++ unset OCL_ICD_FILENAMES_RESET
+++ unset OCL_ICD_FILENAMES
++ . /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/etc/conda/deactivate.d/mpivars.deactivate.sh
+++ '[' '' '!=' 1 ']'
++++ echo /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/mpi.jar
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/mpi.jar:\?||'
+++ export CLASSPATH=
+++ CLASSPATH=
++++ echo /opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/libfabric
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/libfabric:\?||'
+++ export LD_LIBRARY_PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:
+++ LD_LIBRARY_PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:
++++ echo /opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:\?||'
+++ export LD_LIBRARY_PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:
+++ LD_LIBRARY_PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/lib64:/opt/bwhpc/common/compiler/gnu/9.2.0/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/lib::/home/fr/fr_fr/fr_tn110/.mujoco/mujoco210/bin:/usr/lib/nvidia:
++++ echo /opt/bwhpc/common/compiler/gnu/9.2.0/share/man:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/share/man:/usr/share/lmod/lmod/share/man::/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/share/man
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/share/man:\?||'
+++ export MANPATH=/opt/bwhpc/common/compiler/gnu/9.2.0/share/man:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/share/man:/usr/share/lmod/lmod/share/man::
+++ MANPATH=/opt/bwhpc/common/compiler/gnu/9.2.0/share/man:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/share/man:/usr/share/lmod/lmod/share/man::
++++ echo /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/libfabric
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/libfabric:\?||'
+++ export LIBRARY_PATH=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:
+++ LIBRARY_PATH=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib:
++++ echo /opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric
++++ sed 's|/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric:||'
+++ export PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric
+++ PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric
++++ which fi_info
+++ FIP=/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ echo /opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ grep -q 'compilers_and_libraries.*mpi'
+++ echo /opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ grep -q /mpi/
++++ echo /opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
++++ rev
++++ cut -f1 '-d '
++++ rev
++++ sed 's|/libfabric/bin/fi_info||'
+++ export I_MPI_ROOT=/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ I_MPI_ROOT=/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ echo /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/lib/libfabric/prov:/usr/lib64/libfabric
+++ grep -q /opt/bwhpc/intel/oneapi/2022.1/intelpython/latest
+++ [[ /opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info != '' ]]
+++ echo /opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info
+++ grep -q 'compilers_and_libraries.*mpi'
+++ export FI_PROVIDER_PATH=/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info/libfabric/lib/prov:/usr/lib64/libfabric
+++ FI_PROVIDER_PATH=/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin/fi_info/libfabric/lib/prov:/usr/lib64/libfabric
++ PS1='(tid_env) '
++ export PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric
++ PATH=/opt/bwhpc/common/compiler/gnu/9.2.0/bin:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-9.2/bin:/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/condabin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/opt/moab/bin:/opt/VirtualGL/bin:/bin:/usr/local/bin:/usr/local/sbin:/home/fr/fr_fr/fr_tn110/.local/bin:/home/fr/fr_fr/fr_tn110/bin:/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest/bin/libfabric
++ export CONDA_PREFIX=/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env
++ CONDA_PREFIX=/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=tid_env
++ CONDA_DEFAULT_ENV=tid_env
++ export 'CONDA_PROMPT_MODIFIER=(tid_env) '
++ CONDA_PROMPT_MODIFIER='(tid_env) '
++ export CONDA_PREFIX_1=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest
++ CONDA_PREFIX_1=/opt/bwhpc/intel/oneapi/2022.1/intelpython/latest
++ export CONDA_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda
++ CONDA_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/home/fr/fr_fr/fr_tn110/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ mpirun python dev/automl/meta_rl/scripts/orig_impl/striker_baselines.py --context explicit
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-pr1s5nmz
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Tracking run with wandb version 0.13.5
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-1mez24fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-15t9fds4
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-1jxiownk
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-c23holdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Tracking run with wandb version 0.13.5
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-q658kpqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-15smaiuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-37wdxx29
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-2fbip4iu
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_012622-2din8w6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-jazz-32
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2fbip4iu
wandb: Syncing run volcanic-bird-27
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/pr1s5nmz
wandb: Syncing run azure-valley-27
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1mez24fw
wandb: Syncing run misunderstood-monkey-27
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: Syncing run colorful-cherry-27
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/q658kpqh
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/15t9fds4
wandb: Syncing run glowing-blaze-23
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2din8w6f
wandb: Syncing run spring-surf-24
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1jxiownk
wandb: Syncing run different-firefly-23
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/c23holdz
wandb: Syncing run wise-totem-24
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/15smaiuw
wandb: Syncing run pretty-dust-31
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/37wdxx29
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1113/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1113/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1113/rollout/ep_rew_mean â–‚â–â–‚â–ƒâ–ƒâ–…â–„â–†â–†â–†â–†â–ˆ
wandb:                   PPO_1113/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1113/train/approx_kl â–‚â–…â–â–ˆâ–ˆâ–†â–„â–…â–ˆâ–‡â–†
wandb:        PPO_1113/train/clip_fraction â–‚â–…â–â–†â–†â–†â–†â–‡â–ˆâ–‡â–†
wandb:           PPO_1113/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1113/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1113/train/explained_variance â–‚â–â–„â–ˆâ–‡â–‡â–…â–…â–â–„â–†
wandb:        PPO_1113/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1113/train/loss â–ƒâ–‚â–â–‚â–‚â–‚â–ˆâ–…â–„â–„â–„
wandb: PPO_1113/train/policy_gradient_loss â–‡â–ƒâ–ˆâ–ƒâ–â–…â–†â–ƒâ–†â–†â–ˆ
wandb:                  PPO_1113/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1113/train/value_loss â–â–„â–„â–ƒâ–†â–†â–ˆâ–‡â–†â–„â–ˆ
wandb:                PPO_1123/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1123/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1123/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:                   PPO_1123/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1123/train/approx_kl â–â–„â–‚â–†â–ƒâ–ƒâ–„â–‡â–ˆâ–‡â–‡
wandb:        PPO_1123/train/clip_fraction â–â–…â–â–„â–„â–„â–…â–‡â–ˆâ–‡â–‡
wandb:           PPO_1123/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1123/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1123/train/explained_variance â–ƒâ–â–…â–ˆâ–â–â–ƒâ–…â–†â–ƒâ–ƒ
wandb:        PPO_1123/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1123/train/loss â–‚â–†â–†â–ˆâ–…â–‚â–â–‡â–ƒâ–â–‚
wandb: PPO_1123/train/policy_gradient_loss â–‡â–â–…â–†â–…â–„â–„â–ƒâ–‚â–†â–ˆ
wandb:                  PPO_1123/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1123/train/value_loss â–‡â–„â–ˆâ–„â–„â–…â–…â–„â–‚â–„â–
wandb:                PPO_1134/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1134/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1134/rollout/ep_rew_mean â–‚â–â–ƒâ–ƒâ–„â–…â–…â–†â–…â–…â–ˆâ–†
wandb:                   PPO_1134/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1134/train/approx_kl â–‚â–ˆâ–‚â–†â–…â–†â–‡â–‡â–â–ˆâ–…
wandb:        PPO_1134/train/clip_fraction â–ƒâ–‡â–ƒâ–ˆâ–‡â–ˆâ–‡â–ˆâ–â–ˆâ–ˆ
wandb:           PPO_1134/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1134/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1134/train/explained_variance â–‡â–†â–‡â–‡â–„â–ˆâ–‡â–†â–â–ƒâ–„
wandb:        PPO_1134/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1134/train/loss â–„â–†â–„â–ˆâ–‚â–‚â–ƒâ–‚â–„â–„â–
wandb: PPO_1134/train/policy_gradient_loss â–‡â–…â–‡â–…â–â–‡â–‡â–ˆâ–…â–†â–†
wandb:                  PPO_1134/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1134/train/value_loss â–†â–ƒâ–…â–‚â–‚â–â–â–â–ˆâ–…â–…
wandb:                PPO_1144/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1144/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1144/rollout/ep_rew_mean â–â–‚â–…â–„â–ƒâ–…â–ƒâ–…â–‚â–ˆâ–…â–„
wandb:                   PPO_1144/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1144/train/approx_kl â–ƒâ–‡â–â–„â–„â–‚â–„â–‡â–‚â–‚â–ˆ
wandb:        PPO_1144/train/clip_fraction â–…â–ˆâ–‚â–…â–…â–…â–â–†â–â–„â–…
wandb:           PPO_1144/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1144/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1144/train/explained_variance â–‚â–„â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:        PPO_1144/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1144/train/loss â–‚â–‚â–ƒâ–‡â–â–â–ƒâ–ˆâ–ƒâ–‚â–…
wandb: PPO_1144/train/policy_gradient_loss â–â–ƒâ–ƒâ–„â–„â–ˆâ–‚â–â–„â–ƒâ–…
wandb:                  PPO_1144/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1144/train/value_loss â–„â–â–ˆâ–ˆâ–‚â–ƒâ–…â–‚â–„â–…â–„
wandb:                PPO_1153/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1153/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1153/rollout/ep_rew_mean â–†â–ˆâ–â–„â–†â–‚â–…â–…â–ƒâ–…â–†â–†
wandb:                   PPO_1153/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1153/train/approx_kl â–â–ƒâ–‚â–ƒâ–ˆâ–â–„â–„â–ƒâ–…â–†
wandb:        PPO_1153/train/clip_fraction â–†â–„â–ƒâ–„â–†â–â–‡â–‡â–‚â–…â–ˆ
wandb:           PPO_1153/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1153/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1153/train/explained_variance â–â–ƒâ–†â–„â–…â–…â–„â–‡â–‡â–‡â–ˆ
wandb:        PPO_1153/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1153/train/loss â–‚â–â–‚â–‚â–â–ˆâ–â–â–ˆâ–ƒâ–„
wandb: PPO_1153/train/policy_gradient_loss â–‡â–†â–ˆâ–ˆâ–‡â–†â–‡â–‡â–â–‡â–†
wandb:                  PPO_1153/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1153/train/value_loss â–…â–…â–ƒâ–†â–…â–ˆâ–†â–â–…â–†â–‚
wandb:                PPO_1163/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1163/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1163/rollout/ep_rew_mean â–…â–†â–‚â–â–ƒâ–ƒâ–…â–…â–ƒâ–†â–†â–ˆ
wandb:                   PPO_1163/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1163/train/approx_kl â–â–†â–ƒâ–‚â–ƒâ–ƒâ–‡â–…â–„â–‡â–ˆ
wandb:        PPO_1163/train/clip_fraction â–‚â–…â–‚â–â–…â–ƒâ–„â–„â–…â–ˆâ–‡
wandb:           PPO_1163/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1163/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–ˆ
wandb:   PPO_1163/train/explained_variance â–…â–„â–„â–â–†â–†â–„â–‚â–ˆâ–†â–…
wandb:        PPO_1163/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1163/train/loss â–‡â–ˆâ–†â–‡â–ˆâ–‚â–ƒâ–…â–„â–‚â–
wandb: PPO_1163/train/policy_gradient_loss â–â–‚â–â–…â–†â–ˆâ–„â–‚â–‡â–ƒâ–ƒ
wandb:                  PPO_1163/train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1163/train/value_loss â–ƒâ–ƒâ–„â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–‚â–
wandb:                PPO_1173/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1173/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1173/rollout/ep_rew_mean â–ƒâ–â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‡â–„â–ˆ
wandb:                   PPO_1173/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1173/train/approx_kl â–ƒâ–ƒâ–„â–…â–ƒâ–…â–…â–ˆâ–â–†â–ˆ
wandb:        PPO_1173/train/clip_fraction â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–…â–ˆâ–â–†â–†
wandb:           PPO_1173/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1173/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1173/train/explained_variance â–…â–†â–„â–†â–†â–†â–…â–‡â–„â–ˆâ–
wandb:        PPO_1173/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1173/train/loss â–‡â–„â–‚â–‚â–‚â–ˆâ–â–â–ƒâ–‚â–‚
wandb: PPO_1173/train/policy_gradient_loss â–…â–„â–„â–â–†â–ƒâ–†â–†â–‚â–ˆâ–†
wandb:                  PPO_1173/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1173/train/value_loss â–†â–…â–„â–†â–„â–‡â–†â–â–†â–â–ˆ
wandb:                PPO_1183/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1183/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1183/rollout/ep_rew_mean â–†â–ƒâ–â–†â–…â–„â–†â–†â–…â–„â–ˆâ–ˆ
wandb:                   PPO_1183/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1183/train/approx_kl â–‚â–‚â–â–ƒâ–„â–„â–„â–†â–…â–ˆâ–…
wandb:        PPO_1183/train/clip_fraction â–†â–…â–â–‡â–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–†
wandb:           PPO_1183/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1183/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1183/train/explained_variance â–…â–†â–â–…â–‚â–†â–ˆâ–‡â–‡â–†â–…
wandb:        PPO_1183/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1183/train/loss â–„â–„â–„â–†â–…â–â–ƒâ–ƒâ–‚â–ƒâ–ˆ
wandb: PPO_1183/train/policy_gradient_loss â–…â–ƒâ–â–ˆâ–†â–†â–„â–…â–â–ˆâ–‚
wandb:                  PPO_1183/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1183/train/value_loss â–…â–…â–ˆâ–„â–ƒâ–ƒâ–â–‚â–â–ƒâ–ƒ
wandb:                PPO_1193/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1193/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1193/rollout/ep_rew_mean â–ƒâ–„â–â–…â–…â–„â–…â–…â–†â–…â–„â–ˆ
wandb:                   PPO_1193/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1193/train/approx_kl â–…â–ˆâ–…â–ƒâ–ƒâ–„â–„â–â–…â–ƒâ–
wandb:        PPO_1193/train/clip_fraction â–„â–ˆâ–†â–†â–â–‡â–…â–„â–†â–†â–…
wandb:           PPO_1193/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1193/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1193/train/explained_variance â–‡â–ƒâ–‡â–†â–â–…â–ˆâ–‡â–‡â–ˆâ–‡
wandb:        PPO_1193/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1193/train/loss â–‚â–„â–ƒâ–â–ˆâ–â–‚â–†â–‚â–…â–
wandb: PPO_1193/train/policy_gradient_loss â–â–„â–„â–…â–â–ˆâ–…â–‚â–„â–…â–…
wandb:                  PPO_1193/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1193/train/value_loss â–‚â–†â–„â–„â–ˆâ–…â–â–‚â–‚â–â–ƒ
wandb:                    global_mean_eval â–â–ƒâ–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–‚â–„â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–‚â–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–‚â–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_12 â–â–ƒâ–…â–…â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–ƒâ–„â–†â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–‚â–„â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–‚â–„â–†â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–‚â–„â–…â–…â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–ƒâ–„â–…â–…â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_2 â–â–ƒâ–„â–†â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–‚â–„â–…â–…â–…â–†â–†â–‡â–ˆ
wandb:                      mean_reward_21 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–„â–†â–…â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_23 â–â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–‚â–„â–†â–†â–‡â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–ƒâ–„â–…â–…â–†â–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_27 â–â–ƒâ–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–„â–†â–…â–‡â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–…â–†â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–‚â–„â–…â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–ƒâ–„â–†â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–‚â–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_33 â–â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–…â–†â–†â–‡â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–„â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–ƒâ–…â–†â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–‚â–„â–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_9 â–â–ƒâ–„â–†â–…â–‡â–‡â–‡â–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–†â–…â–…
wandb:                        std_reward_1 â–ƒâ–â–‚â–‚â–ˆâ–‡â–†â–„â–„â–…
wandb:                       std_reward_10 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–†â–…â–…
wandb:                       std_reward_11 â–‚â–â–‚â–ƒâ–ˆâ–†â–‡â–…â–†â–…
wandb:                       std_reward_12 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–…â–…
wandb:                       std_reward_13 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–…â–…
wandb:                       std_reward_14 â–‚â–â–‚â–ƒâ–ˆâ–ˆâ–ˆâ–†â–…â–†
wandb:                       std_reward_15 â–ƒâ–â–‚â–ƒâ–ˆâ–‡â–ˆâ–‡â–…â–†
wandb:                       std_reward_16 â–‚â–â–‚â–ƒâ–ˆâ–‡â–‡â–…â–…â–…
wandb:                       std_reward_17 â–‚â–â–‚â–ƒâ–ˆâ–†â–…â–„â–…â–„
wandb:                       std_reward_18 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–†â–…â–†
wandb:                       std_reward_19 â–‚â–â–‚â–‚â–ˆâ–†â–†â–…â–…â–…
wandb:                        std_reward_2 â–‚â–â–‚â–‚â–ˆâ–ˆâ–†â–…â–…â–†
wandb:                       std_reward_20 â–‚â–â–‚â–ƒâ–‡â–ˆâ–†â–…â–…â–„
wandb:                       std_reward_21 â–‚â–â–‚â–ƒâ–‡â–ˆâ–†â–…â–…â–…
wandb:                       std_reward_22 â–ƒâ–â–‚â–ƒâ–ˆâ–‡â–†â–†â–†â–‡
wandb:                       std_reward_23 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–…â–…
wandb:                       std_reward_24 â–‚â–â–‚â–„â–‡â–†â–ˆâ–†â–‡â–†
wandb:                       std_reward_25 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–†â–†
wandb:                       std_reward_26 â–‚â–â–‚â–ƒâ–ˆâ–‡â–‡â–„â–…â–„
wandb:                       std_reward_27 â–‚â–â–‚â–ƒâ–ˆâ–‡â–‡â–…â–…â–…
wandb:                       std_reward_28 â–‚â–â–‚â–ƒâ–ˆâ–†â–‡â–„â–…â–…
wandb:                       std_reward_29 â–‚â–â–‚â–„â–ˆâ–…â–†â–„â–…â–…
wandb:                        std_reward_3 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–…â–…
wandb:                       std_reward_30 â–ƒâ–â–‚â–„â–ˆâ–‡â–‡â–…â–…â–†
wandb:                       std_reward_31 â–‚â–â–‚â–ƒâ–ˆâ–†â–…â–†â–…â–…
wandb:                       std_reward_32 â–‚â–â–‚â–ƒâ–ˆâ–ˆâ–‡â–…â–†â–…
wandb:                       std_reward_33 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–†â–„â–†
wandb:                       std_reward_34 â–‚â–â–‚â–ƒâ–ˆâ–‡â–ˆâ–…â–†â–†
wandb:                       std_reward_35 â–‚â–â–‚â–‚â–ˆâ–†â–…â–„â–…â–…
wandb:                        std_reward_4 â–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–…â–…â–…
wandb:                        std_reward_5 â–‚â–â–‚â–‚â–ˆâ–ˆâ–…â–†â–…â–†
wandb:                        std_reward_6 â–‚â–â–‚â–ƒâ–ˆâ–ˆâ–†â–†â–…â–†
wandb:                        std_reward_7 â–‚â–â–‚â–ƒâ–ˆâ–†â–†â–…â–…â–…
wandb:                        std_reward_8 â–‚â–â–‚â–ƒâ–‡â–ˆâ–‡â–„â–…â–„
wandb:                        std_reward_9 â–‚â–â–‚â–ƒâ–ˆâ–†â–†â–…â–†â–…
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1113/global_step 212992
wandb:        PPO_1113/rollout/ep_len_mean 200.0
wandb:        PPO_1113/rollout/ep_rew_mean -783.6427
wandb:                   PPO_1113/time/fps 1203.0
wandb:            PPO_1113/train/approx_kl 0.01163
wandb:        PPO_1113/train/clip_fraction 0.14694
wandb:           PPO_1113/train/clip_range 0.2
wandb:         PPO_1113/train/entropy_loss -7.62233
wandb:   PPO_1113/train/explained_variance 0.96497
wandb:        PPO_1113/train/learning_rate 0.0003
wandb:                 PPO_1113/train/loss 31.05031
wandb: PPO_1113/train/policy_gradient_loss -0.0065
wandb:                  PPO_1113/train/std 0.71703
wandb:           PPO_1113/train/value_loss 83.6244
wandb:                PPO_1123/global_step 212992
wandb:        PPO_1123/rollout/ep_len_mean 200.0
wandb:        PPO_1123/rollout/ep_rew_mean -638.77991
wandb:                   PPO_1123/time/fps 1197.0
wandb:            PPO_1123/train/approx_kl 0.01413
wandb:        PPO_1123/train/clip_fraction 0.18827
wandb:           PPO_1123/train/clip_range 0.2
wandb:         PPO_1123/train/entropy_loss -6.77483
wandb:   PPO_1123/train/explained_variance 0.96641
wandb:        PPO_1123/train/learning_rate 0.0003
wandb:                 PPO_1123/train/loss 19.96198
wandb: PPO_1123/train/policy_gradient_loss -0.00594
wandb:                  PPO_1123/train/std 0.63692
wandb:           PPO_1123/train/value_loss 53.8143
wandb:                PPO_1134/global_step 212992
wandb:        PPO_1134/rollout/ep_len_mean 200.0
wandb:        PPO_1134/rollout/ep_rew_mean -587.69714
wandb:                   PPO_1134/time/fps 1195.0
wandb:            PPO_1134/train/approx_kl 0.01521
wandb:        PPO_1134/train/clip_fraction 0.21024
wandb:           PPO_1134/train/clip_range 0.2
wandb:         PPO_1134/train/entropy_loss -5.92234
wandb:   PPO_1134/train/explained_variance 0.95604
wandb:        PPO_1134/train/learning_rate 0.0003
wandb:                 PPO_1134/train/loss 7.2029
wandb: PPO_1134/train/policy_gradient_loss -0.0041
wandb:                  PPO_1134/train/std 0.56183
wandb:           PPO_1134/train/value_loss 70.62495
wandb:                PPO_1144/global_step 212992
wandb:        PPO_1144/rollout/ep_len_mean 200.0
wandb:        PPO_1144/rollout/ep_rew_mean -542.8963
wandb:                   PPO_1144/time/fps 1201.0
wandb:            PPO_1144/train/approx_kl 0.01699
wandb:        PPO_1144/train/clip_fraction 0.21124
wandb:           PPO_1144/train/clip_range 0.2
wandb:         PPO_1144/train/entropy_loss -5.29417
wandb:   PPO_1144/train/explained_variance 0.99009
wandb:        PPO_1144/train/learning_rate 0.0003
wandb:                 PPO_1144/train/loss 26.51619
wandb: PPO_1144/train/policy_gradient_loss -0.0017
wandb:                  PPO_1144/train/std 0.51509
wandb:           PPO_1144/train/value_loss 52.94361
wandb:                PPO_1153/global_step 212992
wandb:        PPO_1153/rollout/ep_len_mean 200.0
wandb:        PPO_1153/rollout/ep_rew_mean -526.00867
wandb:                   PPO_1153/time/fps 1189.0
wandb:            PPO_1153/train/approx_kl 0.01848
wandb:        PPO_1153/train/clip_fraction 0.23991
wandb:           PPO_1153/train/clip_range 0.2
wandb:         PPO_1153/train/entropy_loss -4.75893
wandb:   PPO_1153/train/explained_variance 0.997
wandb:        PPO_1153/train/learning_rate 0.0003
wandb:                 PPO_1153/train/loss 24.30634
wandb: PPO_1153/train/policy_gradient_loss -0.0033
wandb:                  PPO_1153/train/std 0.47853
wandb:           PPO_1153/train/value_loss 29.46359
wandb:                PPO_1163/global_step 212992
wandb:        PPO_1163/rollout/ep_len_mean 200.0
wandb:        PPO_1163/rollout/ep_rew_mean -484.41364
wandb:                   PPO_1163/time/fps 1196.0
wandb:            PPO_1163/train/approx_kl 0.02016
wandb:        PPO_1163/train/clip_fraction 0.25532
wandb:           PPO_1163/train/clip_range 0.2
wandb:         PPO_1163/train/entropy_loss -4.24085
wandb:   PPO_1163/train/explained_variance 0.9968
wandb:        PPO_1163/train/learning_rate 0.0003
wandb:                 PPO_1163/train/loss 2.52387
wandb: PPO_1163/train/policy_gradient_loss -0.00223
wandb:                  PPO_1163/train/std 0.44332
wandb:           PPO_1163/train/value_loss 18.39738
wandb:                PPO_1173/global_step 212992
wandb:        PPO_1173/rollout/ep_len_mean 200.0
wandb:        PPO_1173/rollout/ep_rew_mean -437.41681
wandb:                   PPO_1173/time/fps 1196.0
wandb:            PPO_1173/train/approx_kl 0.0235
wandb:        PPO_1173/train/clip_fraction 0.27603
wandb:           PPO_1173/train/clip_range 0.2
wandb:         PPO_1173/train/entropy_loss -3.5009
wandb:   PPO_1173/train/explained_variance 0.99564
wandb:        PPO_1173/train/learning_rate 0.0003
wandb:                 PPO_1173/train/loss 6.18074
wandb: PPO_1173/train/policy_gradient_loss 0.0006
wandb:                  PPO_1173/train/std 0.39907
wandb:           PPO_1173/train/value_loss 27.60092
wandb:                PPO_1183/global_step 212992
wandb:        PPO_1183/rollout/ep_len_mean 200.0
wandb:        PPO_1183/rollout/ep_rew_mean -403.60742
wandb:                   PPO_1183/time/fps 1195.0
wandb:            PPO_1183/train/approx_kl 0.0224
wandb:        PPO_1183/train/clip_fraction 0.26947
wandb:           PPO_1183/train/clip_range 0.2
wandb:         PPO_1183/train/entropy_loss -2.71409
wandb:   PPO_1183/train/explained_variance 0.99787
wandb:        PPO_1183/train/learning_rate 0.0003
wandb:                 PPO_1183/train/loss 12.69099
wandb: PPO_1183/train/policy_gradient_loss 0.00053
wandb:                  PPO_1183/train/std 0.356
wandb:           PPO_1183/train/value_loss 11.01046
wandb:                PPO_1193/global_step 212992
wandb:        PPO_1193/rollout/ep_len_mean 200.0
wandb:        PPO_1193/rollout/ep_rew_mean -377.57779
wandb:                   PPO_1193/time/fps 1192.0
wandb:            PPO_1193/train/approx_kl 0.02257
wandb:        PPO_1193/train/clip_fraction 0.29405
wandb:           PPO_1193/train/clip_range 0.2
wandb:         PPO_1193/train/entropy_loss -2.21128
wandb:   PPO_1193/train/explained_variance 0.99677
wandb:        PPO_1193/train/learning_rate 0.0003
wandb:                 PPO_1193/train/loss 2.90452
wandb: PPO_1193/train/policy_gradient_loss 0.00367
wandb:                  PPO_1193/train/std 0.33238
wandb:           PPO_1193/train/value_loss 19.90571
wandb:                    global_mean_eval -365.40014
wandb:                         global_step 212992
wandb:                       mean_reward_0 -358.31554
wandb:                       mean_reward_1 -349.01791
wandb:                      mean_reward_10 -357.01577
wandb:                      mean_reward_11 -354.50118
wandb:                      mean_reward_12 -369.14581
wandb:                      mean_reward_13 -374.14667
wandb:                      mean_reward_14 -382.07859
wandb:                      mean_reward_15 -377.81415
wandb:                      mean_reward_16 -369.98633
wandb:                      mean_reward_17 -344.12091
wandb:                      mean_reward_18 -367.95172
wandb:                      mean_reward_19 -350.21302
wandb:                       mean_reward_2 -380.4176
wandb:                      mean_reward_20 -345.48409
wandb:                      mean_reward_21 -386.29616
wandb:                      mean_reward_22 -387.74561
wandb:                      mean_reward_23 -364.5172
wandb:                      mean_reward_24 -371.74645
wandb:                      mean_reward_25 -379.2821
wandb:                      mean_reward_26 -343.28399
wandb:                      mean_reward_27 -354.29929
wandb:                      mean_reward_28 -361.85227
wandb:                      mean_reward_29 -373.5488
wandb:                       mean_reward_3 -358.64123
wandb:                      mean_reward_30 -376.45287
wandb:                      mean_reward_31 -358.16096
wandb:                      mean_reward_32 -348.96158
wandb:                      mean_reward_33 -384.782
wandb:                      mean_reward_34 -385.27372
wandb:                      mean_reward_35 -371.36278
wandb:                       mean_reward_4 -355.29938
wandb:                       mean_reward_5 -394.05653
wandb:                       mean_reward_6 -375.5873
wandb:                       mean_reward_7 -359.23986
wandb:                       mean_reward_8 -330.01087
wandb:                       mean_reward_9 -353.79471
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 142.18587
wandb:                        std_reward_1 137.84523
wandb:                       std_reward_10 141.59454
wandb:                       std_reward_11 134.98508
wandb:                       std_reward_12 144.2833
wandb:                       std_reward_13 149.54605
wandb:                       std_reward_14 153.30574
wandb:                       std_reward_15 146.99208
wandb:                       std_reward_16 147.90859
wandb:                       std_reward_17 128.68278
wandb:                       std_reward_18 149.12936
wandb:                       std_reward_19 131.5914
wandb:                        std_reward_2 157.72515
wandb:                       std_reward_20 129.40073
wandb:                       std_reward_21 156.67146
wandb:                       std_reward_22 157.99776
wandb:                       std_reward_23 151.256
wandb:                       std_reward_24 142.20364
wandb:                       std_reward_25 149.27333
wandb:                       std_reward_26 120.88418
wandb:                       std_reward_27 139.31155
wandb:                       std_reward_28 144.46103
wandb:                       std_reward_29 150.37799
wandb:                        std_reward_3 144.92466
wandb:                       std_reward_30 151.04197
wandb:                       std_reward_31 141.19281
wandb:                       std_reward_32 137.44614
wandb:                       std_reward_33 155.09414
wandb:                       std_reward_34 162.90428
wandb:                       std_reward_35 151.28573
wandb:                        std_reward_4 142.87582
wandb:                        std_reward_5 161.2606
wandb:                        std_reward_6 157.36493
wandb:                        std_reward_7 140.58214
wandb:                        std_reward_8 116.59556
wandb:                        std_reward_9 134.36515
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced different-firefly-23: https://wandb.ai/tidiane/meta_rl_context/runs/c23holdz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-c23holdz/logs
wandb: 
wandb: Run history:
wandb:                PPO_1115/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1115/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1115/rollout/ep_rew_mean â–â–‚â–â–ƒâ–„â–„â–„â–„â–†â–‡â–‡â–ˆ
wandb:                   PPO_1115/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1115/train/approx_kl â–â–…â–ƒâ–†â–…â–…â–…â–ˆâ–†â–„â–‡
wandb:        PPO_1115/train/clip_fraction â–â–„â–‚â–„â–„â–…â–…â–…â–†â–„â–ˆ
wandb:           PPO_1115/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1115/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1115/train/explained_variance â–â–…â–†â–†â–ˆâ–‡â–„â–…â–…â–ƒâ–ˆ
wandb:        PPO_1115/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1115/train/loss â–ƒâ–â–…â–â–ƒâ–„â–„â–ˆâ–ƒâ–‚â–
wandb: PPO_1115/train/policy_gradient_loss â–…â–â–‡â–„â–…â–‚â–…â–ˆâ–…â–†â–‡
wandb:                  PPO_1115/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1115/train/value_loss â–â–ƒâ–„â–„â–„â–ƒâ–†â–‡â–…â–ˆâ–ƒ
wandb:                PPO_1124/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1124/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1124/rollout/ep_rew_mean â–â–â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:                   PPO_1124/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1124/train/approx_kl â–„â–ƒâ–‚â–…â–ƒâ–â–…â–†â–ˆâ–„â–‡
wandb:        PPO_1124/train/clip_fraction â–ƒâ–…â–ƒâ–ƒâ–‚â–â–…â–…â–‡â–†â–ˆ
wandb:           PPO_1124/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1124/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1124/train/explained_variance â–†â–„â–â–„â–†â–ˆâ–ƒâ–†â–†â–â–…
wandb:        PPO_1124/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1124/train/loss â–„â–‚â–„â–ƒâ–‚â–ˆâ–‚â–ƒâ–‚â–â–‚
wandb: PPO_1124/train/policy_gradient_loss â–â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–…â–ˆ
wandb:                  PPO_1124/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1124/train/value_loss â–†â–ƒâ–…â–†â–…â–ˆâ–…â–„â–‚â–â–
wandb:                PPO_1133/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1133/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1133/rollout/ep_rew_mean â–â–‚â–‚â–ƒâ–ƒâ–…â–…â–‡â–…â–ˆâ–‡â–†
wandb:                   PPO_1133/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1133/train/approx_kl â–â–ƒâ–…â–ƒâ–†â–„â–‚â–„â–„â–ˆâ–ˆ
wandb:        PPO_1133/train/clip_fraction â–„â–…â–†â–…â–†â–…â–â–†â–„â–ˆâ–ˆ
wandb:           PPO_1133/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1133/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1133/train/explained_variance â–…â–…â–†â–‡â–‡â–ˆâ–†â–‚â–â–ƒâ–
wandb:        PPO_1133/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1133/train/loss â–‡â–„â–ˆâ–ƒâ–ˆâ–…â–…â–„â–†â–‡â–
wandb: PPO_1133/train/policy_gradient_loss â–ƒâ–‚â–â–â–„â–ƒâ–ˆâ–…â–…â–†â–ˆ
wandb:                  PPO_1133/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–‚â–
wandb:           PPO_1133/train/value_loss â–…â–ƒâ–‚â–â–„â–ƒâ–ˆâ–ƒâ–†â–„â–
wandb:                PPO_1143/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1143/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1143/rollout/ep_rew_mean â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ˆâ–†â–†â–†â–†â–„
wandb:                   PPO_1143/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1143/train/approx_kl â–…â–‚â–‚â–ƒâ–„â–‡â–ˆâ–â–ˆâ–†â–‚
wandb:        PPO_1143/train/clip_fraction â–‡â–ƒâ–„â–‚â–ƒâ–‡â–ˆâ–â–ƒâ–†â–ƒ
wandb:           PPO_1143/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1143/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1143/train/explained_variance â–†â–â–…â–ˆâ–ˆâ–„â–‡â–…â–†â–ˆâ–†
wandb:        PPO_1143/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1143/train/loss â–‚â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–â–ƒ
wandb: PPO_1143/train/policy_gradient_loss â–„â–„â–…â–†â–…â–ƒâ–‡â–â–†â–‡â–ˆ
wandb:                  PPO_1143/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1143/train/value_loss â–†â–‡â–ƒâ–†â–†â–„â–â–…â–„â–ƒâ–ˆ
wandb:                PPO_1154/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1154/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1154/rollout/ep_rew_mean â–„â–‡â–ƒâ–‡â–ƒâ–â–‡â–ˆâ–†â–„â–‡â–‡
wandb:                   PPO_1154/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1154/train/approx_kl â–†â–…â–â–†â–„â–ˆâ–‡â–‡â–…â–…â–„
wandb:        PPO_1154/train/clip_fraction â–‡â–„â–â–†â–…â–…â–ˆâ–†â–…â–„â–†
wandb:           PPO_1154/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1154/train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:   PPO_1154/train/explained_variance â–â–„â–…â–‡â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        PPO_1154/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1154/train/loss â–ˆâ–‚â–‡â–ƒâ–ƒâ–„â–â–â–ƒâ–ƒâ–‚
wandb: PPO_1154/train/policy_gradient_loss â–‡â–ƒâ–„â–â–†â–ˆâ–‚â–…â–‚â–…â–„
wandb:                  PPO_1154/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1154/train/value_loss â–‡â–‚â–ˆâ–‚â–„â–ˆâ–‚â–‚â–‚â–„â–
wandb:                PPO_1164/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1164/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1164/rollout/ep_rew_mean â–†â–†â–„â–â–†â–…â–â–„â–…â–â–ƒâ–ˆ
wandb:                   PPO_1164/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1164/train/approx_kl â–â–†â–„â–â–ƒâ–‚â–„â–‚â–‚â–ƒâ–ˆ
wandb:        PPO_1164/train/clip_fraction â–…â–‡â–…â–â–†â–ƒâ–ƒâ–†â–‡â–‡â–ˆ
wandb:           PPO_1164/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1164/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1164/train/explained_variance â–„â–„â–…â–â–…â–ƒâ–…â–…â–†â–ˆâ–
wandb:        PPO_1164/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1164/train/loss â–…â–â–…â–„â–‚â–ˆâ–„â–â–†â–…â–ƒ
wandb: PPO_1164/train/policy_gradient_loss â–„â–†â–„â–‚â–†â–â–‚â–ˆâ–…â–…â–„
wandb:                  PPO_1164/train/std â–ˆâ–‡â–†â–†â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1164/train/value_loss â–‚â–â–ƒâ–‡â–‚â–‡â–ˆâ–„â–„â–„â–…
wandb:                PPO_1174/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1174/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1174/rollout/ep_rew_mean â–â–„â–ƒâ–„â–…â–†â–†â–‚â–„â–ˆâ–ƒâ–†
wandb:                   PPO_1174/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1174/train/approx_kl â–ˆâ–†â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–„â–…
wandb:        PPO_1174/train/clip_fraction â–ƒâ–…â–â–†â–„â–…â–…â–â–ˆâ–ƒâ–‡
wandb:           PPO_1174/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1174/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1174/train/explained_variance â–ˆâ–â–‡â–ˆâ–…â–‡â–‡â–†â–‡â–…â–‡
wandb:        PPO_1174/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1174/train/loss â–…â–…â–ˆâ–ƒâ–‚â–„â–â–‡â–â–ƒâ–
wandb: PPO_1174/train/policy_gradient_loss â–â–„â–…â–‡â–„â–‡â–ˆâ–â–ƒâ–„â–‡
wandb:                  PPO_1174/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1174/train/value_loss â–…â–ƒâ–†â–„â–ƒâ–„â–â–ˆâ–‚â–†â–„
wandb:                PPO_1184/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1184/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1184/rollout/ep_rew_mean â–„â–‡â–ˆâ–…â–ˆâ–†â–â–ƒâ–†â–†â–â–ˆ
wandb:                   PPO_1184/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1184/train/approx_kl â–â–†â–†â–ƒâ–‚â–ƒâ–ƒâ–†â–ƒâ–‚â–ˆ
wandb:        PPO_1184/train/clip_fraction â–â–…â–…â–â–„â–ƒâ–„â–…â–‚â–ƒâ–ˆ
wandb:           PPO_1184/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1184/train/entropy_loss â–â–‚â–„â–„â–…â–…â–†â–†â–‡â–†â–ˆ
wandb:   PPO_1184/train/explained_variance â–…â–„â–ƒâ–„â–†â–â–â–†â–ˆâ–„â–ˆ
wandb:        PPO_1184/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1184/train/loss â–†â–ƒâ–â–ƒâ–ˆâ–†â–…â–ƒâ–…â–„â–‚
wandb: PPO_1184/train/policy_gradient_loss â–ƒâ–ˆâ–â–ƒâ–ˆâ–…â–…â–†â–„â–ƒâ–ˆ
wandb:                  PPO_1184/train/std â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–
wandb:           PPO_1184/train/value_loss â–…â–ƒâ–‚â–…â–„â–‡â–ˆâ–ƒâ–„â–…â–
wandb:                PPO_1194/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1194/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1194/rollout/ep_rew_mean â–‚â–†â–â–‚â–…â–…â–ƒâ–„â–†â–ƒâ–ˆâ–„
wandb:                   PPO_1194/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1194/train/approx_kl â–ƒâ–†â–â–ƒâ–„â–ƒâ–ˆâ–†â–†â–‡â–ˆ
wandb:        PPO_1194/train/clip_fraction â–ƒâ–‡â–â–…â–‡â–…â–†â–…â–…â–†â–ˆ
wandb:           PPO_1194/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1194/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1194/train/explained_variance â–ƒâ–„â–â–„â–„â–…â–ˆâ–„â–‚â–„â–‡
wandb:        PPO_1194/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1194/train/loss â–‚â–‚â–…â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–ƒâ–
wandb: PPO_1194/train/policy_gradient_loss â–â–†â–…â–†â–‡â–‡â–‡â–„â–…â–…â–ˆ
wandb:                  PPO_1194/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1194/train/value_loss â–„â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–â–„â–‡â–…â–‚
wandb:                    global_mean_eval â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_1 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_10 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_11 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_14 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_15 â–â–„â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_17 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–„â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_21 â–â–„â–‡â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_23 â–â–„â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_25 â–â–„â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–„â–†â–†â–†â–‡â–‡â–†â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_29 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_3 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–„â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_32 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_34 â–â–„â–†â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–„â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_6 â–â–„â–‡â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_8 â–â–„â–†â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–„â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–‡
wandb:                        std_reward_1 â–„â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡
wandb:                       std_reward_10 â–ƒâ–â–‚â–â–„â–„â–ƒâ–„â–ˆâ–ˆ
wandb:                       std_reward_11 â–„â–â–‚â–‚â–„â–„â–„â–†â–ˆâ–ˆ
wandb:                       std_reward_12 â–ƒâ–â–â–â–ƒâ–ƒâ–ƒâ–…â–ˆâ–‡
wandb:                       std_reward_13 â–„â–â–‚â–‚â–„â–„â–„â–†â–ˆâ–‡
wandb:                       std_reward_14 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡
wandb:                       std_reward_15 â–„â–â–‚â–‚â–ƒâ–„â–„â–‡â–ˆâ–ˆ
wandb:                       std_reward_16 â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–ˆ
wandb:                       std_reward_17 â–„â–â–‚â–‚â–ƒâ–ƒâ–„â–†â–ˆâ–ˆ
wandb:                       std_reward_18 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–ˆ
wandb:                       std_reward_19 â–„â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–‡
wandb:                        std_reward_2 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ˆâ–ˆ
wandb:                       std_reward_20 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–†
wandb:                       std_reward_21 â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–ˆ
wandb:                       std_reward_22 â–„â–â–‚â–‚â–ƒâ–„â–ƒâ–…â–ˆâ–‡
wandb:                       std_reward_23 â–„â–â–‚â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–ˆ
wandb:                       std_reward_24 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–†
wandb:                       std_reward_25 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–ˆâ–ˆ
wandb:                       std_reward_26 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡
wandb:                       std_reward_27 â–ƒâ–â–‚â–‚â–„â–„â–„â–‡â–ˆâ–‡
wandb:                       std_reward_28 â–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–†â–‡â–ˆ
wandb:                       std_reward_29 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡
wandb:                        std_reward_3 â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–…â–ˆâ–‡
wandb:                       std_reward_30 â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–…â–‡â–ˆ
wandb:                       std_reward_31 â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–…â–ˆâ–ˆ
wandb:                       std_reward_32 â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–…â–ˆâ–‡
wandb:                       std_reward_33 â–ƒâ–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–ˆâ–‡
wandb:                       std_reward_34 â–„â–â–‚â–‚â–ƒâ–ƒâ–‚â–…â–ˆâ–ˆ
wandb:                       std_reward_35 â–ƒâ–â–‚â–â–ƒâ–ƒâ–„â–…â–ˆâ–ˆ
wandb:                        std_reward_4 â–„â–â–‚â–‚â–‚â–ƒâ–ƒâ–…â–‡â–ˆ
wandb:                        std_reward_5 â–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–†
wandb:                        std_reward_6 â–ƒâ–â–â–‚â–„â–ƒâ–„â–†â–ˆâ–ˆ
wandb:                        std_reward_7 â–ƒâ–â–‚â–â–„â–ƒâ–ƒâ–†â–ˆâ–‡
wandb:                        std_reward_8 â–„â–â–‚â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–ˆ
wandb:                        std_reward_9 â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–†â–ˆâ–ˆ
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1115/global_step 212992
wandb:        PPO_1115/rollout/ep_len_mean 200.0
wandb:        PPO_1115/rollout/ep_rew_mean -791.05609
wandb:                   PPO_1115/time/fps 1198.0
wandb:            PPO_1115/train/approx_kl 0.01242
wandb:        PPO_1115/train/clip_fraction 0.17504
wandb:           PPO_1115/train/clip_range 0.2
wandb:         PPO_1115/train/entropy_loss -7.46013
wandb:   PPO_1115/train/explained_variance 0.97219
wandb:        PPO_1115/train/learning_rate 0.0003
wandb:                 PPO_1115/train/loss 11.58517
wandb: PPO_1115/train/policy_gradient_loss -0.00729
wandb:                  PPO_1115/train/std 0.70153
wandb:           PPO_1115/train/value_loss 45.99662
wandb:                PPO_1124/global_step 212992
wandb:        PPO_1124/rollout/ep_len_mean 200.0
wandb:        PPO_1124/rollout/ep_rew_mean -629.05542
wandb:                   PPO_1124/time/fps 1200.0
wandb:            PPO_1124/train/approx_kl 0.01527
wandb:        PPO_1124/train/clip_fraction 0.20699
wandb:           PPO_1124/train/clip_range 0.2
wandb:         PPO_1124/train/entropy_loss -6.43431
wandb:   PPO_1124/train/explained_variance 0.96586
wandb:        PPO_1124/train/learning_rate 0.0003
wandb:                 PPO_1124/train/loss 13.51613
wandb: PPO_1124/train/policy_gradient_loss -0.00479
wandb:                  PPO_1124/train/std 0.60615
wandb:           PPO_1124/train/value_loss 36.94084
wandb:                PPO_1133/global_step 212992
wandb:        PPO_1133/rollout/ep_len_mean 200.0
wandb:        PPO_1133/rollout/ep_rew_mean -566.29694
wandb:                   PPO_1133/time/fps 1197.0
wandb:            PPO_1133/train/approx_kl 0.01897
wandb:        PPO_1133/train/clip_fraction 0.23298
wandb:           PPO_1133/train/clip_range 0.2
wandb:         PPO_1133/train/entropy_loss -5.5815
wandb:   PPO_1133/train/explained_variance 0.95551
wandb:        PPO_1133/train/learning_rate 0.0003
wandb:                 PPO_1133/train/loss 7.58
wandb: PPO_1133/train/policy_gradient_loss -0.0038
wandb:                  PPO_1133/train/std 0.53761
wandb:           PPO_1133/train/value_loss 26.18486
wandb:                PPO_1143/global_step 212992
wandb:        PPO_1143/rollout/ep_len_mean 200.0
wandb:        PPO_1143/rollout/ep_rew_mean -536.89221
wandb:                   PPO_1143/time/fps 1196.0
wandb:            PPO_1143/train/approx_kl 0.01563
wandb:        PPO_1143/train/clip_fraction 0.20589
wandb:           PPO_1143/train/clip_range 0.2
wandb:         PPO_1143/train/entropy_loss -4.96122
wandb:   PPO_1143/train/explained_variance 0.96952
wandb:        PPO_1143/train/learning_rate 0.0003
wandb:                 PPO_1143/train/loss 24.87436
wandb: PPO_1143/train/policy_gradient_loss -0.00228
wandb:                  PPO_1143/train/std 0.49117
wandb:           PPO_1143/train/value_loss 64.78896
wandb:                PPO_1154/global_step 212992
wandb:        PPO_1154/rollout/ep_len_mean 200.0
wandb:        PPO_1154/rollout/ep_rew_mean -513.63818
wandb:                   PPO_1154/time/fps 1191.0
wandb:            PPO_1154/train/approx_kl 0.01761
wandb:        PPO_1154/train/clip_fraction 0.23483
wandb:           PPO_1154/train/clip_range 0.2
wandb:         PPO_1154/train/entropy_loss -4.46319
wandb:   PPO_1154/train/explained_variance 0.99098
wandb:        PPO_1154/train/learning_rate 0.0003
wandb:                 PPO_1154/train/loss 9.27769
wandb: PPO_1154/train/policy_gradient_loss -0.00378
wandb:                  PPO_1154/train/std 0.45777
wandb:           PPO_1154/train/value_loss 24.3758
wandb:                PPO_1164/global_step 212992
wandb:        PPO_1164/rollout/ep_len_mean 200.0
wandb:        PPO_1164/rollout/ep_rew_mean -490.2066
wandb:                   PPO_1164/time/fps 1191.0
wandb:            PPO_1164/train/approx_kl 0.02121
wandb:        PPO_1164/train/clip_fraction 0.25793
wandb:           PPO_1164/train/clip_range 0.2
wandb:         PPO_1164/train/entropy_loss -4.1051
wandb:   PPO_1164/train/explained_variance 0.99226
wandb:        PPO_1164/train/learning_rate 0.0003
wandb:                 PPO_1164/train/loss 8.74738
wandb: PPO_1164/train/policy_gradient_loss -0.00328
wandb:                  PPO_1164/train/std 0.43518
wandb:           PPO_1164/train/value_loss 37.40363
wandb:                PPO_1174/global_step 212992
wandb:        PPO_1174/rollout/ep_len_mean 200.0
wandb:        PPO_1174/rollout/ep_rew_mean -472.54425
wandb:                   PPO_1174/time/fps 1185.0
wandb:            PPO_1174/train/approx_kl 0.01867
wandb:        PPO_1174/train/clip_fraction 0.26879
wandb:           PPO_1174/train/clip_range 0.2
wandb:         PPO_1174/train/entropy_loss -3.50676
wandb:   PPO_1174/train/explained_variance 0.99603
wandb:        PPO_1174/train/learning_rate 0.0003
wandb:                 PPO_1174/train/loss 4.17491
wandb: PPO_1174/train/policy_gradient_loss -0.00158
wandb:                  PPO_1174/train/std 0.39871
wandb:           PPO_1174/train/value_loss 22.88469
wandb:                PPO_1184/global_step 212992
wandb:        PPO_1184/rollout/ep_len_mean 200.0
wandb:        PPO_1184/rollout/ep_rew_mean -469.15097
wandb:                   PPO_1184/time/fps 1193.0
wandb:            PPO_1184/train/approx_kl 0.02417
wandb:        PPO_1184/train/clip_fraction 0.30742
wandb:           PPO_1184/train/clip_range 0.2
wandb:         PPO_1184/train/entropy_loss -3.1403
wandb:   PPO_1184/train/explained_variance 0.99783
wandb:        PPO_1184/train/learning_rate 0.0003
wandb:                 PPO_1184/train/loss 3.57021
wandb: PPO_1184/train/policy_gradient_loss -7e-05
wandb:                  PPO_1184/train/std 0.37882
wandb:           PPO_1184/train/value_loss 11.84482
wandb:                PPO_1194/global_step 212992
wandb:        PPO_1194/rollout/ep_len_mean 200.0
wandb:        PPO_1194/rollout/ep_rew_mean -475.1344
wandb:                   PPO_1194/time/fps 1194.0
wandb:            PPO_1194/train/approx_kl 0.0239
wandb:        PPO_1194/train/clip_fraction 0.29608
wandb:           PPO_1194/train/clip_range 0.2
wandb:         PPO_1194/train/entropy_loss -2.6919
wandb:   PPO_1194/train/explained_variance 0.99828
wandb:        PPO_1194/train/learning_rate 0.0003
wandb:                 PPO_1194/train/loss 1.89926
wandb: PPO_1194/train/policy_gradient_loss 0.00146
wandb:                  PPO_1194/train/std 0.35573
wandb:           PPO_1194/train/value_loss 20.15264
wandb:                    global_mean_eval -421.16574
wandb:                         global_step 212992
wandb:                       mean_reward_0 -413.50735
wandb:                       mean_reward_1 -408.6802
wandb:                      mean_reward_10 -419.54716
wandb:                      mean_reward_11 -419.64304
wandb:                      mean_reward_12 -410.09498
wandb:                      mean_reward_13 -411.9477
wandb:                      mean_reward_14 -400.9234
wandb:                      mean_reward_15 -420.68937
wandb:                      mean_reward_16 -406.01649
wandb:                      mean_reward_17 -423.20573
wandb:                      mean_reward_18 -446.43819
wandb:                      mean_reward_19 -409.8471
wandb:                       mean_reward_2 -447.08511
wandb:                      mean_reward_20 -418.49714
wandb:                      mean_reward_21 -444.76987
wandb:                      mean_reward_22 -401.44485
wandb:                      mean_reward_23 -404.70742
wandb:                      mean_reward_24 -430.42301
wandb:                      mean_reward_25 -427.59725
wandb:                      mean_reward_26 -429.51911
wandb:                      mean_reward_27 -395.24263
wandb:                      mean_reward_28 -456.41027
wandb:                      mean_reward_29 -415.26356
wandb:                       mean_reward_3 -423.8865
wandb:                      mean_reward_30 -449.54161
wandb:                      mean_reward_31 -441.88342
wandb:                      mean_reward_32 -404.71777
wandb:                      mean_reward_33 -434.21022
wandb:                      mean_reward_34 -424.75789
wandb:                      mean_reward_35 -434.66699
wandb:                       mean_reward_4 -430.09955
wandb:                       mean_reward_5 -396.16489
wandb:                       mean_reward_6 -430.93869
wandb:                       mean_reward_7 -411.84753
wandb:                       mean_reward_8 -418.26057
wandb:                       mean_reward_9 -399.49023
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 170.15052
wandb:                        std_reward_1 160.58042
wandb:                       std_reward_10 161.48898
wandb:                       std_reward_11 163.34158
wandb:                       std_reward_12 164.42875
wandb:                       std_reward_13 150.46454
wandb:                       std_reward_14 147.40681
wandb:                       std_reward_15 160.92058
wandb:                       std_reward_16 157.07707
wandb:                       std_reward_17 165.77242
wandb:                       std_reward_18 190.35574
wandb:                       std_reward_19 159.39397
wandb:                        std_reward_2 171.2457
wandb:                       std_reward_20 152.54104
wandb:                       std_reward_21 173.35814
wandb:                       std_reward_22 167.47578
wandb:                       std_reward_23 153.16845
wandb:                       std_reward_24 161.87158
wandb:                       std_reward_25 188.38359
wandb:                       std_reward_26 151.85914
wandb:                       std_reward_27 140.27866
wandb:                       std_reward_28 179.09212
wandb:                       std_reward_29 167.2679
wandb:                        std_reward_3 169.60738
wandb:                       std_reward_30 190.64172
wandb:                       std_reward_31 188.90063
wandb:                       std_reward_32 151.72396
wandb:                       std_reward_33 169.17162
wandb:                       std_reward_34 182.33632
wandb:                       std_reward_35 175.10343
wandb:                        std_reward_4 187.59591
wandb:                        std_reward_5 137.94553
wandb:                        std_reward_6 177.91098
wandb:                        std_reward_7 159.14002
wandb:                        std_reward_8 162.00112
wandb:                        std_reward_9 160.87443
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced volcanic-bird-27: https://wandb.ai/tidiane/meta_rl_context/runs/pr1s5nmz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-pr1s5nmz/logs
wandb: 
wandb: Run history:
wandb:                PPO_1114/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1114/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1114/rollout/ep_rew_mean â–â–‚â–‚â–ƒâ–‚â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:                   PPO_1114/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1114/train/approx_kl â–†â–â–‡â–…â–„â–…â–„â–„â–…â–„â–ˆ
wandb:        PPO_1114/train/clip_fraction â–…â–â–ˆâ–„â–„â–â–ƒâ–ƒâ–„â–„â–‡
wandb:           PPO_1114/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1114/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1114/train/explained_variance â–ˆâ–‡â–ˆâ–„â–„â–ˆâ–…â–…â–‚â–‡â–
wandb:        PPO_1114/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1114/train/loss â–â–„â–‚â–†â–…â–‡â–ƒâ–ˆâ–‡â–ƒâ–†
wandb: PPO_1114/train/policy_gradient_loss â–‚â–ˆâ–â–‡â–†â–ˆâ–‡â–ˆâ–…â–…â–†
wandb:                  PPO_1114/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1114/train/value_loss â–â–ƒâ–‚â–„â–„â–†â–†â–ˆâ–ˆâ–ˆâ–†
wandb:                PPO_1126/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1126/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1126/rollout/ep_rew_mean â–â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–„â–…â–…â–†â–ˆ
wandb:                   PPO_1126/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1126/train/approx_kl â–â–„â–„â–†â–‡â–‡â–†â–†â–†â–ˆâ–‡
wandb:        PPO_1126/train/clip_fraction â–â–…â–…â–ƒâ–„â–‡â–ˆâ–„â–„â–‡â–‡
wandb:           PPO_1126/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1126/train/entropy_loss â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–‡â–ˆ
wandb:   PPO_1126/train/explained_variance â–‡â–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–â–†â–†â–ˆ
wandb:        PPO_1126/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1126/train/loss â–‡â–„â–†â–ˆâ–„â–„â–â–‚â–†â–‚â–
wandb: PPO_1126/train/policy_gradient_loss â–†â–â–ƒâ–„â–‡â–„â–ƒâ–…â–‡â–†â–ˆ
wandb:                  PPO_1126/train/std â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–‚â–‚â–
wandb:           PPO_1126/train/value_loss â–ˆâ–„â–„â–…â–‡â–ƒâ–‚â–„â–„â–…â–
wandb:                PPO_1138/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1138/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1138/rollout/ep_rew_mean â–‚â–„â–„â–â–ƒâ–„â–‡â–„â–‚â–…â–‡â–ˆ
wandb:                   PPO_1138/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1138/train/approx_kl â–…â–â–…â–„â–ˆâ–…â–‡â–…â–…â–„â–‡
wandb:        PPO_1138/train/clip_fraction â–…â–â–…â–ƒâ–ˆâ–†â–ˆâ–ƒâ–„â–‡â–„
wandb:           PPO_1138/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1138/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1138/train/explained_variance â–‚â–â–…â–‚â–ƒâ–†â–ˆâ–‡â–ˆâ–‡â–ˆ
wandb:        PPO_1138/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1138/train/loss â–‚â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–„â–ƒ
wandb: PPO_1138/train/policy_gradient_loss â–„â–†â–†â–…â–†â–†â–„â–„â–‚â–ˆâ–
wandb:                  PPO_1138/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1138/train/value_loss â–‚â–…â–ƒâ–ˆâ–‡â–„â–â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                PPO_1147/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1147/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1147/rollout/ep_rew_mean â–‚â–â–‚â–‚â–†â–„â–‚â–†â–…â–ˆâ–‡â–ˆ
wandb:                   PPO_1147/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1147/train/approx_kl â–‚â–â–â–‚â–…â–â–…â–…â–â–ˆâ–„
wandb:        PPO_1147/train/clip_fraction â–ƒâ–â–ƒâ–„â–…â–â–†â–…â–‚â–ˆâ–…
wandb:           PPO_1147/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1147/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1147/train/explained_variance â–ƒâ–ƒâ–†â–ˆâ–…â–†â–…â–ƒâ–ˆâ–…â–
wandb:        PPO_1147/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1147/train/loss â–ƒâ–ˆâ–‚â–…â–„â–„â–ƒâ–‚â–„â–â–‚
wandb: PPO_1147/train/policy_gradient_loss â–‚â–ˆâ–…â–ƒâ–‡â–â–ƒâ–‚â–„â–ƒâ–ƒ
wandb:                  PPO_1147/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1147/train/value_loss â–…â–ˆâ–…â–ƒâ–ƒâ–‡â–„â–‚â–ƒâ–â–ƒ
wandb:                PPO_1156/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1156/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1156/rollout/ep_rew_mean â–‚â–ƒâ–†â–„â–†â–ˆâ–‚â–â–ƒâ–„â–„â–†
wandb:                   PPO_1156/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1156/train/approx_kl â–„â–‚â–ƒâ–â–†â–â–ƒâ–„â–…â–‡â–ˆ
wandb:        PPO_1156/train/clip_fraction â–‚â–†â–ƒâ–„â–†â–„â–â–…â–ˆâ–„â–ˆ
wandb:           PPO_1156/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1156/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1156/train/explained_variance â–†â–…â–â–…â–‡â–„â–„â–‡â–‡â–ˆâ–‡
wandb:        PPO_1156/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1156/train/loss â–ˆâ–‚â–„â–â–‚â–…â–…â–ƒâ–â–…â–‚
wandb: PPO_1156/train/policy_gradient_loss â–‚â–â–ƒâ–‚â–ƒâ–…â–†â–ˆâ–‡â–‡â–…
wandb:                  PPO_1156/train/std â–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1156/train/value_loss â–‡â–‚â–ƒâ–ƒâ–â–‚â–ˆâ–„â–‚â–ƒâ–
wandb:                PPO_1165/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1165/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1165/rollout/ep_rew_mean â–„â–â–â–‚â–„â–‡â–‡â–†â–ˆâ–†â–„â–„
wandb:                   PPO_1165/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1165/train/approx_kl â–â–…â–ƒâ–…â–ƒâ–ˆâ–ƒâ–„â–…â–…â–ƒ
wandb:        PPO_1165/train/clip_fraction â–‚â–‚â–â–†â–„â–ˆâ–„â–ƒâ–…â–„â–
wandb:           PPO_1165/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1165/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1165/train/explained_variance â–„â–â–â–ƒâ–„â–†â–‡â–…â–†â–ˆâ–†
wandb:        PPO_1165/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1165/train/loss â–ƒâ–‚â–â–†â–ˆâ–‚â–ƒâ–ƒâ–‚â–…â–‚
wandb: PPO_1165/train/policy_gradient_loss â–‚â–â–‚â–…â–‚â–‡â–‡â–†â–…â–ˆâ–„
wandb:                  PPO_1165/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1165/train/value_loss â–„â–ˆâ–ˆâ–…â–„â–‚â–â–ƒâ–â–‚â–‚
wandb:                PPO_1175/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1175/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1175/rollout/ep_rew_mean â–‚â–‚â–ƒâ–…â–†â–„â–â–â–ƒâ–‡â–‚â–ˆ
wandb:                   PPO_1175/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1175/train/approx_kl â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–â–‚â–„â–‚â–ˆ
wandb:        PPO_1175/train/clip_fraction â–ƒâ–ƒâ–â–ƒâ–ƒâ–‡â–‚â–ƒâ–ˆâ–„â–ƒ
wandb:           PPO_1175/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1175/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1175/train/explained_variance â–„â–‡â–„â–â–‚â–†â–‡â–ˆâ–†â–ˆâ–
wandb:        PPO_1175/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1175/train/loss â–‚â–„â–…â–…â–‚â–ˆâ–ƒâ–…â–â–ƒâ–ƒ
wandb: PPO_1175/train/policy_gradient_loss â–‡â–ƒâ–â–‚â–‚â–ƒâ–…â–â–ˆâ–‚â–‡
wandb:                  PPO_1175/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1175/train/value_loss â–ˆâ–‚â–ƒâ–†â–†â–ƒâ–‚â–ƒâ–‚â–â–ˆ
wandb:                PPO_1185/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1185/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1185/rollout/ep_rew_mean â–â–„â–…â–†â–ƒâ–‡â–†â–†â–†â–ˆâ–†â–…
wandb:                   PPO_1185/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1185/train/approx_kl â–â–ƒâ–â–‚â–ƒâ–â–‚â–ˆâ–„â–‚â–„
wandb:        PPO_1185/train/clip_fraction â–„â–ˆâ–â–†â–„â–ƒâ–„â–ƒâ–„â–„â–ƒ
wandb:           PPO_1185/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1185/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1185/train/explained_variance â–â–ƒâ–‚â–„â–‡â–…â–ˆâ–„â–†â–ƒâ–ƒ
wandb:        PPO_1185/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1185/train/loss â–ˆâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚
wandb: PPO_1185/train/policy_gradient_loss â–„â–‡â–‚â–†â–ƒâ–…â–ˆâ–â–‚â–„â–‡
wandb:                  PPO_1185/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1185/train/value_loss â–ˆâ–„â–…â–â–‚â–â–â–„â–ƒâ–ƒâ–„
wandb:                PPO_1195/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1195/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1195/rollout/ep_rew_mean â–â–†â–ƒâ–ƒâ–ˆâ–…â–„â–ƒâ–ƒâ–†â–…â–ˆ
wandb:                   PPO_1195/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1195/train/approx_kl â–â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–„â–‚
wandb:        PPO_1195/train/clip_fraction â–…â–â–…â–ƒâ–…â–†â–…â–…â–‡â–ˆâ–‡
wandb:           PPO_1195/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1195/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1195/train/explained_variance â–ˆâ–„â–‡â–…â–ƒâ–ˆâ–†â–ˆâ–â–‡â–ˆ
wandb:        PPO_1195/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1195/train/loss â–‚â–„â–â–‚â–ˆâ–â–â–‚â–…â–„â–‚
wandb: PPO_1195/train/policy_gradient_loss â–â–ƒâ–„â–ƒâ–…â–†â–‚â–†â–‡â–‡â–ˆ
wandb:                  PPO_1195/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1195/train/value_loss â–‚â–„â–â–†â–†â–‚â–ƒâ–‚â–ˆâ–‚â–
wandb:                    global_mean_eval â–â–…â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–…â–†â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–…â–…â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–…â–…â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_14 â–â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_15 â–â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–…â–…â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–…â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_24 â–â–…â–…â–…â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_25 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–…â–†â–†â–†â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_30 â–â–…â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–ƒâ–â–†â–ˆâ–…â–„â–„â–„â–„â–„
wandb:                        std_reward_1 â–„â–â–†â–ˆâ–„â–„â–„â–„â–„â–„
wandb:                       std_reward_10 â–„â–â–†â–ˆâ–…â–„â–…â–…â–…â–…
wandb:                       std_reward_11 â–„â–â–‡â–ˆâ–†â–…â–„â–†â–†â–…
wandb:                       std_reward_12 â–„â–â–†â–ˆâ–„â–„â–…â–„â–„â–„
wandb:                       std_reward_13 â–„â–â–…â–ˆâ–…â–„â–…â–…â–…â–…
wandb:                       std_reward_14 â–„â–â–†â–ˆâ–„â–…â–…â–…â–„â–…
wandb:                       std_reward_15 â–ƒâ–â–‡â–ˆâ–…â–…â–…â–…â–„â–…
wandb:                       std_reward_16 â–„â–â–†â–ˆâ–…â–„â–„â–…â–…â–„
wandb:                       std_reward_17 â–„â–â–†â–ˆâ–„â–„â–„â–…â–…â–…
wandb:                       std_reward_18 â–„â–â–‡â–ˆâ–…â–…â–„â–…â–…â–…
wandb:                       std_reward_19 â–„â–â–†â–ˆâ–…â–„â–…â–…â–…â–†
wandb:                        std_reward_2 â–„â–â–‡â–ˆâ–…â–„â–„â–…â–…â–…
wandb:                       std_reward_20 â–„â–â–ˆâ–ˆâ–†â–…â–…â–…â–…â–…
wandb:                       std_reward_21 â–ƒâ–â–†â–ˆâ–…â–„â–…â–…â–„â–„
wandb:                       std_reward_22 â–„â–â–†â–ˆâ–†â–„â–…â–†â–…â–…
wandb:                       std_reward_23 â–„â–â–‡â–ˆâ–†â–…â–…â–…â–…â–†
wandb:                       std_reward_24 â–ƒâ–â–…â–ˆâ–…â–„â–„â–„â–ƒâ–…
wandb:                       std_reward_25 â–„â–â–ˆâ–ˆâ–„â–…â–„â–…â–„â–…
wandb:                       std_reward_26 â–„â–â–†â–ˆâ–…â–ƒâ–…â–…â–…â–…
wandb:                       std_reward_27 â–„â–â–‡â–ˆâ–…â–…â–„â–…â–†â–†
wandb:                       std_reward_28 â–„â–â–‡â–ˆâ–‡â–…â–…â–†â–†â–…
wandb:                       std_reward_29 â–„â–â–ˆâ–ˆâ–…â–…â–…â–…â–…â–†
wandb:                        std_reward_3 â–„â–â–…â–ˆâ–…â–…â–…â–„â–„â–†
wandb:                       std_reward_30 â–ƒâ–â–…â–ˆâ–…â–„â–„â–…â–…â–…
wandb:                       std_reward_31 â–ƒâ–â–‡â–ˆâ–…â–…â–…â–„â–†â–…
wandb:                       std_reward_32 â–…â–â–ˆâ–ˆâ–…â–„â–…â–…â–…â–…
wandb:                       std_reward_33 â–„â–â–…â–ˆâ–„â–„â–„â–„â–…â–†
wandb:                       std_reward_34 â–ƒâ–â–‡â–ˆâ–„â–„â–„â–…â–„â–…
wandb:                       std_reward_35 â–ƒâ–â–ˆâ–ˆâ–…â–…â–…â–„â–†â–†
wandb:                        std_reward_4 â–…â–â–ˆâ–ˆâ–…â–…â–…â–†â–†â–…
wandb:                        std_reward_5 â–„â–â–†â–ˆâ–…â–„â–…â–„â–…â–…
wandb:                        std_reward_6 â–„â–â–ˆâ–ˆâ–„â–…â–…â–…â–…â–†
wandb:                        std_reward_7 â–„â–â–†â–ˆâ–„â–„â–ƒâ–„â–…â–…
wandb:                        std_reward_8 â–„â–â–‡â–ˆâ–…â–„â–…â–…â–†â–†
wandb:                        std_reward_9 â–ƒâ–â–‡â–ˆâ–„â–„â–„â–…â–…â–„
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1114/global_step 212992
wandb:        PPO_1114/rollout/ep_len_mean 200.0
wandb:        PPO_1114/rollout/ep_rew_mean -703.21051
wandb:                   PPO_1114/time/fps 1207.0
wandb:            PPO_1114/train/approx_kl 0.01318
wandb:        PPO_1114/train/clip_fraction 0.15922
wandb:           PPO_1114/train/clip_range 0.2
wandb:         PPO_1114/train/entropy_loss -7.66603
wandb:   PPO_1114/train/explained_variance 0.96404
wandb:        PPO_1114/train/learning_rate 0.0003
wandb:                 PPO_1114/train/loss 71.12028
wandb: PPO_1114/train/policy_gradient_loss -0.00814
wandb:                  PPO_1114/train/std 0.72107
wandb:           PPO_1114/train/value_loss 128.5985
wandb:                PPO_1126/global_step 212992
wandb:        PPO_1126/rollout/ep_len_mean 200.0
wandb:        PPO_1126/rollout/ep_rew_mean -536.15851
wandb:                   PPO_1126/time/fps 1196.0
wandb:            PPO_1126/train/approx_kl 0.01392
wandb:        PPO_1126/train/clip_fraction 0.18828
wandb:           PPO_1126/train/clip_range 0.2
wandb:         PPO_1126/train/entropy_loss -6.95315
wandb:   PPO_1126/train/explained_variance 0.96846
wandb:        PPO_1126/train/learning_rate 0.0003
wandb:                 PPO_1126/train/loss 12.71604
wandb: PPO_1126/train/policy_gradient_loss -0.00368
wandb:                  PPO_1126/train/std 0.653
wandb:           PPO_1126/train/value_loss 45.62604
wandb:                PPO_1138/global_step 212992
wandb:        PPO_1138/rollout/ep_len_mean 200.0
wandb:        PPO_1138/rollout/ep_rew_mean -520.81738
wandb:                   PPO_1138/time/fps 1196.0
wandb:            PPO_1138/train/approx_kl 0.01388
wandb:        PPO_1138/train/clip_fraction 0.1644
wandb:           PPO_1138/train/clip_range 0.2
wandb:         PPO_1138/train/entropy_loss -6.30299
wandb:   PPO_1138/train/explained_variance 0.99426
wandb:        PPO_1138/train/learning_rate 0.0003
wandb:                 PPO_1138/train/loss 17.64169
wandb: PPO_1138/train/policy_gradient_loss -0.00546
wandb:                  PPO_1138/train/std 0.59397
wandb:           PPO_1138/train/value_loss 50.84108
wandb:                PPO_1147/global_step 212992
wandb:        PPO_1147/rollout/ep_len_mean 200.0
wandb:        PPO_1147/rollout/ep_rew_mean -464.25616
wandb:                   PPO_1147/time/fps 1196.0
wandb:            PPO_1147/train/approx_kl 0.01597
wandb:        PPO_1147/train/clip_fraction 0.2075
wandb:           PPO_1147/train/clip_range 0.2
wandb:         PPO_1147/train/entropy_loss -5.56567
wandb:   PPO_1147/train/explained_variance 0.99431
wandb:        PPO_1147/train/learning_rate 0.0003
wandb:                 PPO_1147/train/loss 8.39946
wandb: PPO_1147/train/policy_gradient_loss -0.00436
wandb:                  PPO_1147/train/std 0.53497
wandb:           PPO_1147/train/value_loss 33.34117
wandb:                PPO_1156/global_step 212992
wandb:        PPO_1156/rollout/ep_len_mean 200.0
wandb:        PPO_1156/rollout/ep_rew_mean -439.71552
wandb:                   PPO_1156/time/fps 1198.0
wandb:            PPO_1156/train/approx_kl 0.02053
wandb:        PPO_1156/train/clip_fraction 0.25289
wandb:           PPO_1156/train/clip_range 0.2
wandb:         PPO_1156/train/entropy_loss -4.75811
wandb:   PPO_1156/train/explained_variance 0.99647
wandb:        PPO_1156/train/learning_rate 0.0003
wandb:                 PPO_1156/train/loss 4.66335
wandb: PPO_1156/train/policy_gradient_loss -0.00172
wandb:                  PPO_1156/train/std 0.47748
wandb:           PPO_1156/train/value_loss 16.57761
wandb:                PPO_1165/global_step 212992
wandb:        PPO_1165/rollout/ep_len_mean 200.0
wandb:        PPO_1165/rollout/ep_rew_mean -428.6185
wandb:                   PPO_1165/time/fps 1194.0
wandb:            PPO_1165/train/approx_kl 0.01949
wandb:        PPO_1165/train/clip_fraction 0.24171
wandb:           PPO_1165/train/clip_range 0.2
wandb:         PPO_1165/train/entropy_loss -3.84728
wandb:   PPO_1165/train/explained_variance 0.99748
wandb:        PPO_1165/train/learning_rate 0.0003
wandb:                 PPO_1165/train/loss 4.71458
wandb: PPO_1165/train/policy_gradient_loss -0.00061
wandb:                  PPO_1165/train/std 0.41899
wandb:           PPO_1165/train/value_loss 12.23629
wandb:                PPO_1175/global_step 212992
wandb:        PPO_1175/rollout/ep_len_mean 200.0
wandb:        PPO_1175/rollout/ep_rew_mean -377.16266
wandb:                   PPO_1175/time/fps 1195.0
wandb:            PPO_1175/train/approx_kl 0.03107
wandb:        PPO_1175/train/clip_fraction 0.27437
wandb:           PPO_1175/train/clip_range 0.2
wandb:         PPO_1175/train/entropy_loss -3.13258
wandb:   PPO_1175/train/explained_variance 0.99524
wandb:        PPO_1175/train/learning_rate 0.0003
wandb:                 PPO_1175/train/loss 4.41541
wandb: PPO_1175/train/policy_gradient_loss 0.00361
wandb:                  PPO_1175/train/std 0.37862
wandb:           PPO_1175/train/value_loss 19.09766
wandb:                PPO_1185/global_step 212992
wandb:        PPO_1185/rollout/ep_len_mean 200.0
wandb:        PPO_1185/rollout/ep_rew_mean -389.19592
wandb:                   PPO_1185/time/fps 1195.0
wandb:            PPO_1185/train/approx_kl 0.02661
wandb:        PPO_1185/train/clip_fraction 0.2843
wandb:           PPO_1185/train/clip_range 0.2
wandb:         PPO_1185/train/entropy_loss -2.54536
wandb:   PPO_1185/train/explained_variance 0.99772
wandb:        PPO_1185/train/learning_rate 0.0003
wandb:                 PPO_1185/train/loss 4.15061
wandb: PPO_1185/train/policy_gradient_loss 0.00303
wandb:                  PPO_1185/train/std 0.34765
wandb:           PPO_1185/train/value_loss 12.66768
wandb:                PPO_1195/global_step 212992
wandb:        PPO_1195/rollout/ep_len_mean 200.0
wandb:        PPO_1195/rollout/ep_rew_mean -353.10489
wandb:                   PPO_1195/time/fps 1194.0
wandb:            PPO_1195/train/approx_kl 0.02439
wandb:        PPO_1195/train/clip_fraction 0.31754
wandb:           PPO_1195/train/clip_range 0.2
wandb:         PPO_1195/train/entropy_loss -1.91607
wandb:   PPO_1195/train/explained_variance 0.99887
wandb:        PPO_1195/train/learning_rate 0.0003
wandb:                 PPO_1195/train/loss 2.63006
wandb: PPO_1195/train/policy_gradient_loss 0.0058
wandb:                  PPO_1195/train/std 0.31829
wandb:           PPO_1195/train/value_loss 6.62768
wandb:                    global_mean_eval -341.18154
wandb:                         global_step 212992
wandb:                       mean_reward_0 -326.136
wandb:                       mean_reward_1 -332.09492
wandb:                      mean_reward_10 -331.08255
wandb:                      mean_reward_11 -332.17283
wandb:                      mean_reward_12 -330.20268
wandb:                      mean_reward_13 -370.3351
wandb:                      mean_reward_14 -351.14262
wandb:                      mean_reward_15 -342.73866
wandb:                      mean_reward_16 -325.1418
wandb:                      mean_reward_17 -356.24562
wandb:                      mean_reward_18 -342.89978
wandb:                      mean_reward_19 -353.55012
wandb:                       mean_reward_2 -336.19576
wandb:                      mean_reward_20 -323.53559
wandb:                      mean_reward_21 -322.03314
wandb:                      mean_reward_22 -332.21529
wandb:                      mean_reward_23 -349.06733
wandb:                      mean_reward_24 -357.63981
wandb:                      mean_reward_25 -343.78098
wandb:                      mean_reward_26 -351.96419
wandb:                      mean_reward_27 -360.3013
wandb:                      mean_reward_28 -323.0223
wandb:                      mean_reward_29 -341.2533
wandb:                       mean_reward_3 -351.31822
wandb:                      mean_reward_30 -345.45712
wandb:                      mean_reward_31 -350.37594
wandb:                      mean_reward_32 -336.50445
wandb:                      mean_reward_33 -358.30991
wandb:                      mean_reward_34 -341.36133
wandb:                      mean_reward_35 -354.37479
wandb:                       mean_reward_4 -326.15725
wandb:                       mean_reward_5 -326.95886
wandb:                       mean_reward_6 -347.09049
wandb:                       mean_reward_7 -346.32905
wandb:                       mean_reward_8 -348.42416
wandb:                       mean_reward_9 -315.12238
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 143.42389
wandb:                        std_reward_1 151.28965
wandb:                       std_reward_10 145.22301
wandb:                       std_reward_11 150.16194
wandb:                       std_reward_12 150.61779
wandb:                       std_reward_13 169.74624
wandb:                       std_reward_14 166.63421
wandb:                       std_reward_15 160.08396
wandb:                       std_reward_16 140.8612
wandb:                       std_reward_17 166.79809
wandb:                       std_reward_18 158.28814
wandb:                       std_reward_19 157.36151
wandb:                        std_reward_2 155.42378
wandb:                       std_reward_20 141.14471
wandb:                       std_reward_21 143.60515
wandb:                       std_reward_22 146.37147
wandb:                       std_reward_23 160.04671
wandb:                       std_reward_24 165.34072
wandb:                       std_reward_25 154.9056
wandb:                       std_reward_26 161.96065
wandb:                       std_reward_27 170.52009
wandb:                       std_reward_28 139.63152
wandb:                       std_reward_29 155.18486
wandb:                        std_reward_3 158.36099
wandb:                       std_reward_30 162.02093
wandb:                       std_reward_31 163.02311
wandb:                       std_reward_32 153.91329
wandb:                       std_reward_33 169.37521
wandb:                       std_reward_34 154.49601
wandb:                       std_reward_35 163.46833
wandb:                        std_reward_4 141.57333
wandb:                        std_reward_5 146.76976
wandb:                        std_reward_6 156.25331
wandb:                        std_reward_7 157.64086
wandb:                        std_reward_8 158.59148
wandb:                        std_reward_9 138.78751
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced glowing-blaze-23: https://wandb.ai/tidiane/meta_rl_context/runs/2din8w6f
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-2din8w6f/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1117/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1117/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1117/rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–„â–†â–ˆâ–ˆ
wandb:                   PPO_1117/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1117/train/approx_kl â–â–‚â–„â–„â–ƒâ–†â–ˆâ–„â–†â–ƒâ–‡
wandb:        PPO_1117/train/clip_fraction â–â–‚â–‡â–ƒâ–„â–ˆâ–‡â–…â–‡â–„â–ˆ
wandb:           PPO_1117/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1117/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1117/train/explained_variance â–„â–…â–ˆâ–…â–‡â–‡â–‡â–‡â–…â–â–„
wandb:        PPO_1117/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1117/train/loss â–â–â–‚â–…â–‚â–…â–„â–ƒâ–ƒâ–‡â–ˆ
wandb: PPO_1117/train/policy_gradient_loss â–„â–…â–ƒâ–ˆâ–„â–…â–â–…â–…â–„â–‚
wandb:                  PPO_1117/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1117/train/value_loss â–â–‚â–â–†â–â–ƒâ–ƒâ–„â–ƒâ–ˆâ–†
wandb:                PPO_1127/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1127/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1127/rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:                   PPO_1127/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1127/train/approx_kl â–‚â–‚â–…â–†â–â–‚â–…â–ˆâ–ƒâ–†â–‡
wandb:        PPO_1127/train/clip_fraction â–â–ƒâ–„â–†â–â–…â–„â–ˆâ–†â–„â–ˆ
wandb:           PPO_1127/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1127/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1127/train/explained_variance â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–‚â–†â–ˆâ–‡
wandb:        PPO_1127/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1127/train/loss â–†â–…â–‡â–„â–ƒâ–â–„â–‚â–ˆâ–ƒâ–
wandb: PPO_1127/train/policy_gradient_loss â–‚â–ƒâ–†â–„â–ˆâ–„â–â–ƒâ–â–„â–…
wandb:                  PPO_1127/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1127/train/value_loss â–†â–ˆâ–ˆâ–…â–‡â–„â–ˆâ–…â–†â–…â–
wandb:                PPO_1135/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1135/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1135/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–ƒâ–…â–„â–…â–…â–…â–‡â–ˆ
wandb:                   PPO_1135/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1135/train/approx_kl â–â–‚â–…â–…â–„â–ˆâ–‡â–…â–„â–…â–‡
wandb:        PPO_1135/train/clip_fraction â–â–‚â–…â–„â–ƒâ–ˆâ–„â–‚â–ƒâ–…â–ˆ
wandb:           PPO_1135/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1135/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1135/train/explained_variance â–„â–…â–„â–†â–…â–‡â–ˆâ–…â–â–…â–ˆ
wandb:        PPO_1135/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1135/train/loss â–ƒâ–ˆâ–‚â–ƒâ–‚â–â–â–â–‚â–„â–„
wandb: PPO_1135/train/policy_gradient_loss â–â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–†â–ˆâ–ƒâ–‡
wandb:                  PPO_1135/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1135/train/value_loss â–ˆâ–†â–ƒâ–ƒâ–„â–‚â–â–ƒâ–…â–„â–ƒ
wandb:                PPO_1145/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1145/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1145/rollout/ep_rew_mean â–‚â–„â–â–‚â–…â–…â–ˆâ–„â–ƒâ–ƒâ–„â–…
wandb:                   PPO_1145/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1145/train/approx_kl â–â–„â–ƒâ–…â–†â–…â–ˆâ–…â–†â–ƒâ–ˆ
wandb:        PPO_1145/train/clip_fraction â–â–ƒâ–„â–‡â–‡â–„â–‡â–†â–ƒâ–ˆâ–…
wandb:           PPO_1145/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1145/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1145/train/explained_variance â–…â–â–‚â–ˆâ–‡â–†â–ˆâ–…â–ƒâ–†â–…
wandb:        PPO_1145/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1145/train/loss â–„â–…â–ˆâ–ƒâ–…â–…â–â–â–‡â–â–ƒ
wandb: PPO_1145/train/policy_gradient_loss â–‡â–‡â–†â–ˆâ–â–†â–ƒâ–ƒâ–‚â–ˆâ–„
wandb:                  PPO_1145/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1145/train/value_loss â–…â–…â–ˆâ–„â–‚â–‚â–â–‚â–…â–‚â–ƒ
wandb:                PPO_1155/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1155/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1155/rollout/ep_rew_mean â–†â–†â–‡â–†â–‡â–†â–†â–ˆâ–…â–ˆâ–â–…
wandb:                   PPO_1155/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1155/train/approx_kl â–ˆâ–‚â–â–„â–„â–ƒâ–‚â–‡â–â–„â–„
wandb:        PPO_1155/train/clip_fraction â–‡â–„â–‡â–„â–†â–…â–…â–ˆâ–â–†â–†
wandb:           PPO_1155/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1155/train/entropy_loss â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1155/train/explained_variance â–â–†â–†â–†â–„â–†â–†â–ˆâ–†â–ˆâ–ˆ
wandb:        PPO_1155/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1155/train/loss â–â–‚â–â–ƒâ–„â–â–‚â–â–„â–ˆâ–‡
wandb: PPO_1155/train/policy_gradient_loss â–„â–‚â–…â–â–„â–„â–„â–„â–‚â–…â–ˆ
wandb:                  PPO_1155/train/std â–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–
wandb:           PPO_1155/train/value_loss â–…â–„â–â–…â–ƒâ–„â–ƒâ–‚â–‡â–…â–ˆ
wandb:                PPO_1166/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1166/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1166/rollout/ep_rew_mean â–†â–…â–„â–â–„â–ƒâ–‚â–„â–„â–ƒâ–†â–ˆ
wandb:                   PPO_1166/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1166/train/approx_kl â–„â–†â–ƒâ–„â–ƒâ–â–ˆâ–â–‡â–†â–†
wandb:        PPO_1166/train/clip_fraction â–„â–ˆâ–…â–ƒâ–ˆâ–â–‡â–‚â–‡â–†â–‡
wandb:           PPO_1166/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1166/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1166/train/explained_variance â–…â–â–‚â–‚â–ˆâ–„â–…â–„â–‚â–…â–†
wandb:        PPO_1166/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1166/train/loss â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–‚â–â–ˆâ–„
wandb: PPO_1166/train/policy_gradient_loss â–ƒâ–‚â–â–…â–…â–ˆâ–…â–…â–‚â–ƒâ–‡
wandb:                  PPO_1166/train/std â–ˆâ–ˆâ–†â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1166/train/value_loss â–„â–„â–„â–‡â–â–ˆâ–†â–ˆâ–„â–†â–„
wandb:                PPO_1176/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1176/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1176/rollout/ep_rew_mean â–†â–ƒâ–ˆâ–ˆâ–â–†â–„â–„â–…â–‡â–ˆâ–ˆ
wandb:                   PPO_1176/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1176/train/approx_kl â–â–„â–ƒâ–‚â–‚â–†â–†â–ƒâ–ˆâ–‚â–†
wandb:        PPO_1176/train/clip_fraction â–…â–ƒâ–‡â–â–„â–†â–ˆâ–ƒâ–…â–†â–‡
wandb:           PPO_1176/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1176/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1176/train/explained_variance â–†â–â–…â–ƒâ–‡â–ƒâ–â–ˆâ–…â–ˆâ–„
wandb:        PPO_1176/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1176/train/loss â–‡â–ˆâ–‚â–‚â–„â–‡â–…â–ƒâ–†â–ƒâ–
wandb: PPO_1176/train/policy_gradient_loss â–ƒâ–„â–ˆâ–â–„â–â–„â–ˆâ–‚â–†â–…
wandb:                  PPO_1176/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1176/train/value_loss â–ƒâ–ˆâ–‚â–†â–‡â–‡â–‡â–ƒâ–„â–ƒâ–
wandb:                PPO_1186/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1186/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1186/rollout/ep_rew_mean â–„â–ƒâ–„â–ƒâ–â–„â–ƒâ–…â–‚â–…â–ˆâ–…
wandb:                   PPO_1186/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1186/train/approx_kl â–‚â–â–â–‚â–â–â–„â–ƒâ–…â–ˆâ–ƒ
wandb:        PPO_1186/train/clip_fraction â–ƒâ–†â–‚â–ƒâ–…â–„â–†â–ƒâ–ƒâ–ˆâ–
wandb:           PPO_1186/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1186/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1186/train/explained_variance â–‡â–ˆâ–‡â–‡â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–
wandb:        PPO_1186/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1186/train/loss â–ˆâ–â–‚â–†â–ƒâ–…â–…â–„â–†â–‡â–ƒ
wandb: PPO_1186/train/policy_gradient_loss â–ƒâ–ƒâ–â–„â–…â–‡â–†â–†â–ƒâ–‡â–ˆ
wandb:                  PPO_1186/train/std â–ˆâ–‡â–†â–†â–…â–…â–ƒâ–ƒâ–‚â–â–
wandb:           PPO_1186/train/value_loss â–„â–â–„â–‡â–…â–‚â–â–…â–ƒâ–‚â–ˆ
wandb:                PPO_1196/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1196/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1196/rollout/ep_rew_mean â–â–ƒâ–ƒâ–„â–…â–„â–ƒâ–„â–„â–„â–…â–ˆ
wandb:                   PPO_1196/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1196/train/approx_kl â–†â–†â–â–ˆâ–†â–ƒâ–†â–†â–ˆâ–…â–†
wandb:        PPO_1196/train/clip_fraction â–„â–…â–ƒâ–‚â–â–‚â–„â–‚â–ˆâ–ˆâ–
wandb:           PPO_1196/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1196/train/entropy_loss â–â–â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1196/train/explained_variance â–„â–‡â–â–„â–†â–…â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:        PPO_1196/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1196/train/loss â–‚â–â–‚â–â–â–ˆâ–‚â–‚â–â–â–
wandb: PPO_1196/train/policy_gradient_loss â–„â–ˆâ–„â–‡â–ƒâ–â–„â–ƒâ–†â–‡â–‡
wandb:                  PPO_1196/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1196/train/value_loss â–ˆâ–ƒâ–‡â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–‚â–
wandb:                    global_mean_eval â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_1 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_10 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_11 â–â–ƒâ–…â–†â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_12 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_13 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_15 â–â–ƒâ–…â–†â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–ƒâ–…â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_20 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–…â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_27 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–…â–†â–†â–…â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_33 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–…â–†â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–â–â–â–ƒâ–‚â–†â–ˆâ–†â–…â–ƒ
wandb:                        std_reward_1 â–‚â–â–‚â–ƒâ–ƒâ–†â–ˆâ–†â–…â–„
wandb:                       std_reward_10 â–‚â–â–‚â–ƒâ–ƒâ–‡â–ˆâ–‡â–†â–„
wandb:                       std_reward_11 â–‚â–â–‚â–ƒâ–‚â–ˆâ–‡â–†â–…â–ƒ
wandb:                       std_reward_12 â–‚â–â–‚â–‚â–ƒâ–ˆâ–ˆâ–†â–†â–„
wandb:                       std_reward_13 â–‚â–â–‚â–ƒâ–ƒâ–‡â–ˆâ–†â–…â–„
wandb:                       std_reward_14 â–â–â–â–‚â–‚â–†â–ˆâ–†â–„â–„
wandb:                       std_reward_15 â–â–â–‚â–ƒâ–‚â–ˆâ–ˆâ–†â–…â–ƒ
wandb:                       std_reward_16 â–‚â–â–‚â–ƒâ–‚â–…â–ˆâ–…â–„â–ƒ
wandb:                       std_reward_17 â–‚â–â–‚â–ƒâ–ƒâ–†â–ˆâ–…â–…â–„
wandb:                       std_reward_18 â–‚â–â–‚â–ƒâ–ƒâ–‡â–ˆâ–†â–…â–„
wandb:                       std_reward_19 â–â–â–â–ƒâ–‚â–†â–ˆâ–…â–…â–„
wandb:                        std_reward_2 â–‚â–â–‚â–ƒâ–‚â–‡â–ˆâ–†â–…â–ƒ
wandb:                       std_reward_20 â–‚â–â–‚â–ƒâ–ƒâ–ˆâ–ˆâ–†â–†â–„
wandb:                       std_reward_21 â–‚â–â–‚â–ƒâ–‚â–ˆâ–ˆâ–†â–…â–„
wandb:                       std_reward_22 â–â–â–â–‚â–‚â–†â–ˆâ–…â–…â–ƒ
wandb:                       std_reward_23 â–‚â–â–‚â–ƒâ–‚â–†â–ˆâ–‡â–…â–ƒ
wandb:                       std_reward_24 â–â–â–‚â–‚â–‚â–‡â–ˆâ–…â–„â–„
wandb:                       std_reward_25 â–‚â–â–‚â–ƒâ–‚â–†â–ˆâ–‡â–†â–…
wandb:                       std_reward_26 â–‚â–â–‚â–ƒâ–ƒâ–…â–ˆâ–…â–„â–ƒ
wandb:                       std_reward_27 â–‚â–â–â–ƒâ–ƒâ–†â–ˆâ–†â–„â–„
wandb:                       std_reward_28 â–‚â–â–‚â–ƒâ–‚â–‡â–ˆâ–†â–…â–ƒ
wandb:                       std_reward_29 â–‚â–â–‚â–ƒâ–‚â–‡â–ˆâ–…â–…â–„
wandb:                        std_reward_3 â–‚â–â–‚â–ƒâ–‚â–‡â–ˆâ–…â–…â–„
wandb:                       std_reward_30 â–â–â–â–ƒâ–‚â–…â–ˆâ–…â–„â–ƒ
wandb:                       std_reward_31 â–â–â–‚â–‚â–ƒâ–‡â–ˆâ–ˆâ–†â–„
wandb:                       std_reward_32 â–‚â–â–â–ƒâ–‚â–†â–ˆâ–…â–…â–„
wandb:                       std_reward_33 â–â–â–‚â–ƒâ–ƒâ–‡â–ˆâ–‡â–†â–…
wandb:                       std_reward_34 â–‚â–â–‚â–ƒâ–‚â–ˆâ–ˆâ–†â–…â–„
wandb:                       std_reward_35 â–â–â–‚â–ƒâ–‚â–†â–ˆâ–…â–…â–ƒ
wandb:                        std_reward_4 â–‚â–â–‚â–ƒâ–ƒâ–ˆâ–ˆâ–†â–…â–„
wandb:                        std_reward_5 â–‚â–â–‚â–ƒâ–‚â–ˆâ–‡â–‡â–…â–„
wandb:                        std_reward_6 â–‚â–â–‚â–‚â–ƒâ–†â–ˆâ–†â–„â–ƒ
wandb:                        std_reward_7 â–â–â–‚â–ƒâ–‚â–†â–ˆâ–†â–„â–ƒ
wandb:                        std_reward_8 â–â–â–â–ƒâ–‚â–‡â–ˆâ–†â–…â–„
wandb:                        std_reward_9 â–‚â–â–â–ƒâ–‚â–‡â–ˆâ–†â–†â–ƒ
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1117/global_step 212992
wandb:        PPO_1117/rollout/ep_len_mean 200.0
wandb:        PPO_1117/rollout/ep_rew_mean -806.53497
wandb:                   PPO_1117/time/fps 1183.0
wandb:            PPO_1117/train/approx_kl 0.01337
wandb:        PPO_1117/train/clip_fraction 0.17341
wandb:           PPO_1117/train/clip_range 0.2
wandb:         PPO_1117/train/entropy_loss -7.74243
wandb:   PPO_1117/train/explained_variance 0.97046
wandb:        PPO_1117/train/learning_rate 0.0003
wandb:                 PPO_1117/train/loss 59.46993
wandb: PPO_1117/train/policy_gradient_loss -0.00937
wandb:                  PPO_1117/train/std 0.72989
wandb:           PPO_1117/train/value_loss 91.51332
wandb:                PPO_1127/global_step 212992
wandb:        PPO_1127/rollout/ep_len_mean 200.0
wandb:        PPO_1127/rollout/ep_rew_mean -655.13483
wandb:                   PPO_1127/time/fps 1179.0
wandb:            PPO_1127/train/approx_kl 0.01411
wandb:        PPO_1127/train/clip_fraction 0.18803
wandb:           PPO_1127/train/clip_range 0.2
wandb:         PPO_1127/train/entropy_loss -6.86193
wandb:   PPO_1127/train/explained_variance 0.97384
wandb:        PPO_1127/train/learning_rate 0.0003
wandb:                 PPO_1127/train/loss 16.71447
wandb: PPO_1127/train/policy_gradient_loss -0.00642
wandb:                  PPO_1127/train/std 0.6443
wandb:           PPO_1127/train/value_loss 55.08305
wandb:                PPO_1135/global_step 212992
wandb:        PPO_1135/rollout/ep_len_mean 200.0
wandb:        PPO_1135/rollout/ep_rew_mean -580.97168
wandb:                   PPO_1135/time/fps 1181.0
wandb:            PPO_1135/train/approx_kl 0.01635
wandb:        PPO_1135/train/clip_fraction 0.22738
wandb:           PPO_1135/train/clip_range 0.2
wandb:         PPO_1135/train/entropy_loss -6.01133
wandb:   PPO_1135/train/explained_variance 0.98148
wandb:        PPO_1135/train/learning_rate 0.0003
wandb:                 PPO_1135/train/loss 25.00337
wandb: PPO_1135/train/policy_gradient_loss -0.00306
wandb:                  PPO_1135/train/std 0.57024
wandb:           PPO_1135/train/value_loss 37.68932
wandb:                PPO_1145/global_step 212992
wandb:        PPO_1145/rollout/ep_len_mean 200.0
wandb:        PPO_1145/rollout/ep_rew_mean -548.58728
wandb:                   PPO_1145/time/fps 1182.0
wandb:            PPO_1145/train/approx_kl 0.01828
wandb:        PPO_1145/train/clip_fraction 0.21689
wandb:           PPO_1145/train/clip_range 0.2
wandb:         PPO_1145/train/entropy_loss -5.30568
wandb:   PPO_1145/train/explained_variance 0.97491
wandb:        PPO_1145/train/learning_rate 0.0003
wandb:                 PPO_1145/train/loss 13.62266
wandb: PPO_1145/train/policy_gradient_loss -0.0032
wandb:                  PPO_1145/train/std 0.51584
wandb:           PPO_1145/train/value_loss 38.10627
wandb:                PPO_1155/global_step 212992
wandb:        PPO_1155/rollout/ep_len_mean 200.0
wandb:        PPO_1155/rollout/ep_rew_mean -547.87585
wandb:                   PPO_1155/time/fps 1177.0
wandb:            PPO_1155/train/approx_kl 0.01734
wandb:        PPO_1155/train/clip_fraction 0.23331
wandb:           PPO_1155/train/clip_range 0.2
wandb:         PPO_1155/train/entropy_loss -4.79177
wandb:   PPO_1155/train/explained_variance 0.99197
wandb:        PPO_1155/train/learning_rate 0.0003
wandb:                 PPO_1155/train/loss 57.05268
wandb: PPO_1155/train/policy_gradient_loss -0.00026
wandb:                  PPO_1155/train/std 0.48004
wandb:           PPO_1155/train/value_loss 51.98913
wandb:                PPO_1166/global_step 212992
wandb:        PPO_1166/rollout/ep_len_mean 200.0
wandb:        PPO_1166/rollout/ep_rew_mean -493.93027
wandb:                   PPO_1166/time/fps 1179.0
wandb:            PPO_1166/train/approx_kl 0.01863
wandb:        PPO_1166/train/clip_fraction 0.24725
wandb:           PPO_1166/train/clip_range 0.2
wandb:         PPO_1166/train/entropy_loss -4.34192
wandb:   PPO_1166/train/explained_variance 0.99613
wandb:        PPO_1166/train/learning_rate 0.0003
wandb:                 PPO_1166/train/loss 17.94283
wandb: PPO_1166/train/policy_gradient_loss -0.00153
wandb:                  PPO_1166/train/std 0.4497
wandb:           PPO_1166/train/value_loss 30.32799
wandb:                PPO_1176/global_step 212992
wandb:        PPO_1176/rollout/ep_len_mean 200.0
wandb:        PPO_1176/rollout/ep_rew_mean -472.10199
wandb:                   PPO_1176/time/fps 1170.0
wandb:            PPO_1176/train/approx_kl 0.02057
wandb:        PPO_1176/train/clip_fraction 0.26909
wandb:           PPO_1176/train/clip_range 0.2
wandb:         PPO_1176/train/entropy_loss -3.76953
wandb:   PPO_1176/train/explained_variance 0.99618
wandb:        PPO_1176/train/learning_rate 0.0003
wandb:                 PPO_1176/train/loss 4.34526
wandb: PPO_1176/train/policy_gradient_loss -0.00075
wandb:                  PPO_1176/train/std 0.41389
wandb:           PPO_1176/train/value_loss 14.17826
wandb:                PPO_1186/global_step 212992
wandb:        PPO_1186/rollout/ep_len_mean 200.0
wandb:        PPO_1186/rollout/ep_rew_mean -442.65521
wandb:                   PPO_1186/time/fps 1172.0
wandb:            PPO_1186/train/approx_kl 0.02213
wandb:        PPO_1186/train/clip_fraction 0.24152
wandb:           PPO_1186/train/clip_range 0.2
wandb:         PPO_1186/train/entropy_loss -3.16215
wandb:   PPO_1186/train/explained_variance 0.99333
wandb:        PPO_1186/train/learning_rate 0.0003
wandb:                 PPO_1186/train/loss 5.24602
wandb: PPO_1186/train/policy_gradient_loss -0.00042
wandb:                  PPO_1186/train/std 0.38062
wandb:           PPO_1186/train/value_loss 37.33779
wandb:                PPO_1196/global_step 212992
wandb:        PPO_1196/rollout/ep_len_mean 200.0
wandb:        PPO_1196/rollout/ep_rew_mean -387.63049
wandb:                   PPO_1196/time/fps 1174.0
wandb:            PPO_1196/train/approx_kl 0.02401
wandb:        PPO_1196/train/clip_fraction 0.27295
wandb:           PPO_1196/train/clip_range 0.2
wandb:         PPO_1196/train/entropy_loss -2.62132
wandb:   PPO_1196/train/explained_variance 0.99764
wandb:        PPO_1196/train/learning_rate 0.0003
wandb:                 PPO_1196/train/loss 3.05157
wandb: PPO_1196/train/policy_gradient_loss 0.00147
wandb:                  PPO_1196/train/std 0.35239
wandb:           PPO_1196/train/value_loss 12.52542
wandb:                    global_mean_eval -344.2355
wandb:                         global_step 212992
wandb:                       mean_reward_0 -328.32249
wandb:                       mean_reward_1 -335.10796
wandb:                      mean_reward_10 -335.345
wandb:                      mean_reward_11 -319.06802
wandb:                      mean_reward_12 -324.5103
wandb:                      mean_reward_13 -352.34166
wandb:                      mean_reward_14 -340.81282
wandb:                      mean_reward_15 -320.40336
wandb:                      mean_reward_16 -345.60057
wandb:                      mean_reward_17 -352.06167
wandb:                      mean_reward_18 -337.49166
wandb:                      mean_reward_19 -357.73939
wandb:                       mean_reward_2 -332.22568
wandb:                      mean_reward_20 -347.62554
wandb:                      mean_reward_21 -333.36358
wandb:                      mean_reward_22 -355.97691
wandb:                      mean_reward_23 -336.53302
wandb:                      mean_reward_24 -358.34481
wandb:                      mean_reward_25 -355.69773
wandb:                      mean_reward_26 -333.16312
wandb:                      mean_reward_27 -345.24116
wandb:                      mean_reward_28 -344.57724
wandb:                      mean_reward_29 -345.36716
wandb:                       mean_reward_3 -363.21964
wandb:                      mean_reward_30 -338.16022
wandb:                      mean_reward_31 -350.60821
wandb:                      mean_reward_32 -336.9381
wandb:                      mean_reward_33 -369.08202
wandb:                      mean_reward_34 -338.34881
wandb:                      mean_reward_35 -344.71727
wandb:                       mean_reward_4 -356.63212
wandb:                       mean_reward_5 -367.53833
wandb:                       mean_reward_6 -336.69842
wandb:                       mean_reward_7 -355.17359
wandb:                       mean_reward_8 -357.55288
wandb:                       mean_reward_9 -340.88762
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 97.24383
wandb:                        std_reward_1 98.1722
wandb:                       std_reward_10 89.8402
wandb:                       std_reward_11 78.48317
wandb:                       std_reward_12 91.36386
wandb:                       std_reward_13 100.5348
wandb:                       std_reward_14 98.92139
wandb:                       std_reward_15 78.99336
wandb:                       std_reward_16 94.37805
wandb:                       std_reward_17 92.8945
wandb:                       std_reward_18 89.95932
wandb:                       std_reward_19 107.12979
wandb:                        std_reward_2 74.69759
wandb:                       std_reward_20 89.67911
wandb:                       std_reward_21 94.94468
wandb:                       std_reward_22 86.27447
wandb:                       std_reward_23 89.35972
wandb:                       std_reward_24 111.18888
wandb:                       std_reward_25 102.67087
wandb:                       std_reward_26 86.5129
wandb:                       std_reward_27 101.15824
wandb:                       std_reward_28 88.07574
wandb:                       std_reward_29 101.30665
wandb:                        std_reward_3 103.99157
wandb:                       std_reward_30 86.53874
wandb:                       std_reward_31 92.9074
wandb:                       std_reward_32 98.19385
wandb:                       std_reward_33 112.80678
wandb:                       std_reward_34 94.70476
wandb:                       std_reward_35 94.30607
wandb:                        std_reward_4 92.28082
wandb:                        std_reward_5 103.94557
wandb:                        std_reward_6 88.46338
wandb:                        std_reward_7 92.87797
wandb:                        std_reward_8 105.63941
wandb:                        std_reward_9 88.7726
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced dazzling-jazz-32: https://wandb.ai/tidiane/meta_rl_context/runs/2fbip4iu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-2fbip4iu/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1118/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1118/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1118/rollout/ep_rew_mean â–â–‚â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–†â–†â–ˆ
wandb:                   PPO_1118/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1118/train/approx_kl â–‚â–â–‚â–â–ƒâ–‚â–„â–„â–‡â–„â–ˆ
wandb:        PPO_1118/train/clip_fraction â–ƒâ–â–‚â–â–„â–…â–„â–†â–‡â–…â–ˆ
wandb:           PPO_1118/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1118/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1118/train/explained_variance â–‚â–‚â–„â–â–‡â–…â–…â–‡â–ˆâ–ƒâ–ƒ
wandb:        PPO_1118/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1118/train/loss â–‚â–‚â–ƒâ–ˆâ–â–â–‚â–â–â–â–‚
wandb: PPO_1118/train/policy_gradient_loss â–â–„â–„â–‡â–‚â–ƒâ–ˆâ–†â–â–†â–…
wandb:                  PPO_1118/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1118/train/value_loss â–â–†â–‚â–†â–„â–„â–†â–„â–ƒâ–ˆâ–†
wandb:                PPO_1128/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1128/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1128/rollout/ep_rew_mean â–â–‚â–‚â–„â–ƒâ–„â–†â–…â–‡â–‡â–‡â–ˆ
wandb:                   PPO_1128/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1128/train/approx_kl â–ƒâ–â–…â–‡â–…â–ˆâ–ƒâ–ƒâ–†â–…â–‡
wandb:        PPO_1128/train/clip_fraction â–‚â–‚â–†â–ˆâ–ƒâ–…â–â–‚â–…â–‚â–‚
wandb:           PPO_1128/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1128/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1128/train/explained_variance â–‡â–„â–„â–…â–ˆâ–â–‚â–…â–ƒâ–ˆâ–…
wandb:        PPO_1128/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1128/train/loss â–‚â–ˆâ–ˆâ–‚â–ƒâ–â–‚â–‚â–â–â–‚
wandb: PPO_1128/train/policy_gradient_loss â–„â–…â–â–„â–„â–…â–†â–†â–†â–†â–ˆ
wandb:                  PPO_1128/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1128/train/value_loss â–ˆâ–‡â–„â–â–ƒâ–„â–ƒâ–…â–…â–…â–…
wandb:                PPO_1137/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1137/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1137/rollout/ep_rew_mean â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:                   PPO_1137/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1137/train/approx_kl â–‚â–â–„â–„â–â–„â–…â–„â–‡â–ˆâ–‡
wandb:        PPO_1137/train/clip_fraction â–‚â–â–‚â–„â–‚â–†â–†â–„â–†â–ˆâ–†
wandb:           PPO_1137/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1137/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1137/train/explained_variance â–…â–ƒâ–â–„â–â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:        PPO_1137/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1137/train/loss â–„â–‡â–ˆâ–…â–ƒâ–‚â–„â–â–â–†â–
wandb: PPO_1137/train/policy_gradient_loss â–‚â–ƒâ–‚â–†â–ƒâ–â–‚â–…â–…â–…â–ˆ
wandb:                  PPO_1137/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1137/train/value_loss â–‡â–‡â–ˆâ–†â–‡â–…â–ƒâ–ƒâ–ƒâ–‚â–
wandb:                PPO_1146/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1146/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1146/rollout/ep_rew_mean â–â–ƒâ–ƒâ–„â–…â–†â–…â–‡â–…â–…â–†â–ˆ
wandb:                   PPO_1146/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1146/train/approx_kl â–â–ˆâ–â–…â–„â–ƒâ–â–…â–†â–…â–ƒ
wandb:        PPO_1146/train/clip_fraction â–â–ˆâ–…â–†â–…â–‡â–ƒâ–‡â–…â–ˆâ–
wandb:           PPO_1146/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1146/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1146/train/explained_variance â–†â–‡â–ˆâ–‡â–‡â–ˆâ–†â–ƒâ–„â–â–ƒ
wandb:        PPO_1146/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1146/train/loss â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–„â–ˆâ–…â–ƒ
wandb: PPO_1146/train/policy_gradient_loss â–â–…â–…â–…â–…â–„â–„â–…â–„â–ˆâ–†
wandb:                  PPO_1146/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1146/train/value_loss â–„â–‚â–â–‚â–‚â–â–ƒâ–„â–ˆâ–…â–…
wandb:                PPO_1158/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1158/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1158/rollout/ep_rew_mean â–ƒâ–…â–„â–†â–‡â–ˆâ–†â–â–ƒâ–‡â–‡â–†
wandb:                   PPO_1158/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1158/train/approx_kl â–ƒâ–ƒâ–ƒâ–‡â–…â–ˆâ–â–‚â–‚â–†â–‡
wandb:        PPO_1158/train/clip_fraction â–â–ƒâ–‚â–ˆâ–ƒâ–‡â–‚â–‚â–â–†â–ˆ
wandb:           PPO_1158/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1158/train/entropy_loss â–â–‚â–â–‚â–ƒâ–„â–…â–…â–…â–‡â–ˆ
wandb:   PPO_1158/train/explained_variance â–â–ƒâ–‚â–…â–…â–†â–…â–…â–‡â–†â–ˆ
wandb:        PPO_1158/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1158/train/loss â–„â–‚â–‡â–ˆâ–…â–‚â–…â–‡â–‡â–â–†
wandb: PPO_1158/train/policy_gradient_loss â–…â–‡â–…â–â–…â–†â–…â–ˆâ–‡â–†â–
wandb:                  PPO_1158/train/std â–ˆâ–‡â–ˆâ–‡â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1158/train/value_loss â–ˆâ–…â–ˆâ–…â–…â–ƒâ–†â–ˆâ–…â–ƒâ–
wandb:                PPO_1168/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1168/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1168/rollout/ep_rew_mean â–â–‚â–‚â–‚â–…â–…â–„â–†â–„â–ƒâ–…â–ˆ
wandb:                   PPO_1168/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1168/train/approx_kl â–‚â–â–ƒâ–ƒâ–†â–†â–…â–„â–ˆâ–…â–‚
wandb:        PPO_1168/train/clip_fraction â–â–‚â–…â–‚â–‡â–…â–ˆâ–†â–‡â–‡â–ƒ
wandb:           PPO_1168/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1168/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1168/train/explained_variance â–â–…â–†â–ƒâ–†â–‡â–‡â–†â–†â–ˆâ–†
wandb:        PPO_1168/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1168/train/loss â–ˆâ–‚â–â–…â–‚â–ˆâ–â–ƒâ–ƒâ–ƒâ–
wandb: PPO_1168/train/policy_gradient_loss â–‚â–‡â–ƒâ–â–‡â–â–„â–ƒâ–ƒâ–ˆâ–„
wandb:                  PPO_1168/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1168/train/value_loss â–ˆâ–ƒâ–‚â–†â–‚â–‚â–â–‚â–…â–ƒâ–…
wandb:                PPO_1178/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1178/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1178/rollout/ep_rew_mean â–â–‚â–„â–„â–…â–‚â–‚â–ˆâ–†â–†â–ˆâ–ˆ
wandb:                   PPO_1178/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1178/train/approx_kl â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–â–‡â–ƒâ–ˆâ–ƒ
wandb:        PPO_1178/train/clip_fraction â–‚â–‚â–…â–ƒâ–ƒâ–â–‚â–ˆâ–…â–‡â–„
wandb:           PPO_1178/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1178/train/entropy_loss â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–‡â–ˆ
wandb:   PPO_1178/train/explained_variance â–†â–ˆâ–ˆâ–‡â–†â–…â–â–…â–†â–ƒâ–
wandb:        PPO_1178/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1178/train/loss â–‚â–â–‚â–â–…â–‚â–…â–…â–ˆâ–â–‚
wandb: PPO_1178/train/policy_gradient_loss â–„â–…â–ƒâ–ƒâ–…â–‚â–â–ˆâ–…â–„â–‚
wandb:                  PPO_1178/train/std â–ˆâ–ˆâ–‡â–‡â–‡â–†â–…â–…â–ƒâ–‚â–
wandb:           PPO_1178/train/value_loss â–…â–ƒâ–ƒâ–…â–…â–ˆâ–‡â–…â–ƒâ–â–…
wandb:                PPO_1188/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1188/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1188/rollout/ep_rew_mean â–â–‚â–‚â–„â–…â–†â–„â–ƒâ–ˆâ–‡â–ƒâ–„
wandb:                   PPO_1188/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1188/train/approx_kl â–‡â–â–„â–‚â–ƒâ–‚â–ˆâ–„â–‚â–ƒâ–„
wandb:        PPO_1188/train/clip_fraction â–†â–ƒâ–…â–‚â–ˆâ–ƒâ–ˆâ–â–„â–ˆâ–†
wandb:           PPO_1188/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1188/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1188/train/explained_variance â–†â–‡â–†â–„â–â–…â–‡â–„â–‡â–†â–ˆ
wandb:        PPO_1188/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1188/train/loss â–â–â–â–‚â–â–â–‚â–â–â–ˆâ–
wandb: PPO_1188/train/policy_gradient_loss â–†â–‚â–…â–„â–„â–ƒâ–‡â–â–„â–†â–ˆ
wandb:                  PPO_1188/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1188/train/value_loss â–†â–‡â–†â–ˆâ–‡â–„â–ƒâ–…â–â–†â–‚
wandb:                PPO_1197/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1197/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1197/rollout/ep_rew_mean â–â–‚â–…â–‚â–„â–…â–ƒâ–…â–†â–†â–‡â–ˆ
wandb:                   PPO_1197/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1197/train/approx_kl â–„â–‚â–…â–â–ƒâ–„â–…â–‡â–…â–„â–ˆ
wandb:        PPO_1197/train/clip_fraction â–„â–†â–†â–ƒâ–…â–…â–‡â–ˆâ–‡â–â–‡
wandb:           PPO_1197/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1197/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1197/train/explained_variance â–‡â–ˆâ–â–…â–…â–…â–†â–‡â–‡â–†â–†
wandb:        PPO_1197/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1197/train/loss â–ˆâ–â–â–â–‚â–‚â–†â–â–â–â–
wandb: PPO_1197/train/policy_gradient_loss â–ˆâ–‡â–„â–„â–„â–ƒâ–…â–…â–ƒâ–â–‡
wandb:                  PPO_1197/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1197/train/value_loss â–ˆâ–†â–ƒâ–„â–ƒâ–„â–…â–â–â–„â–ƒ
wandb:                    global_mean_eval â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_1 â–â–‚â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–‚â–ƒâ–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–‚â–ƒâ–…â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–‚â–ƒâ–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–‡
wandb:                      mean_reward_14 â–â–‚â–ƒâ–†â–‡â–…â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–‚â–ƒâ–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–â–‚â–ƒâ–†â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–‚â–ƒâ–…â–†â–†â–…â–‡â–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_21 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_22 â–â–‚â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_23 â–â–‚â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_24 â–â–‚â–ƒâ–†â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–‚â–ƒâ–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–‚â–ƒâ–†â–†â–†â–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_27 â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_28 â–â–‚â–ƒâ–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–‚â–ƒâ–…â–†â–…â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–‚â–ƒâ–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_32 â–â–‚â–ƒâ–…â–‡â–…â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–‚â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_34 â–â–‚â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_35 â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_4 â–â–‚â–ƒâ–…â–‡â–†â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_5 â–â–‚â–ƒâ–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_6 â–â–‚â–ƒâ–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–‚â–ƒâ–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_8 â–â–‚â–ƒâ–…â–†â–…â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_9 â–â–‚â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–†â–…â–…â–„
wandb:                        std_reward_1 â–ƒâ–‚â–â–ƒâ–„â–‡â–ˆâ–…â–‡â–…
wandb:                       std_reward_10 â–ƒâ–‚â–â–ƒâ–ƒâ–ˆâ–†â–„â–…â–…
wandb:                       std_reward_11 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–ˆâ–…â–…â–…
wandb:                       std_reward_12 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–ˆâ–„â–„â–„
wandb:                       std_reward_13 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–ˆâ–…â–„â–…
wandb:                       std_reward_14 â–ƒâ–â–â–‚â–ƒâ–ˆâ–†â–„â–„â–„
wandb:                       std_reward_15 â–ƒâ–‚â–â–‚â–„â–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_16 â–ƒâ–â–â–ƒâ–„â–ˆâ–ˆâ–†â–…â–…
wandb:                       std_reward_17 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–†â–†â–…
wandb:                       std_reward_18 â–ƒâ–â–â–‚â–ƒâ–ˆâ–†â–…â–„â–„
wandb:                       std_reward_19 â–ƒâ–‚â–â–ƒâ–ƒâ–ˆâ–ˆâ–…â–…â–„
wandb:                        std_reward_2 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–ˆâ–„â–…â–„
wandb:                       std_reward_20 â–ƒâ–â–â–ƒâ–„â–ˆâ–†â–…â–‡â–„
wandb:                       std_reward_21 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–‡â–…â–…â–…
wandb:                       std_reward_22 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_23 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–ˆâ–…â–…â–ƒ
wandb:                       std_reward_24 â–ƒâ–â–â–‚â–„â–ˆâ–‡â–†â–…â–…
wandb:                       std_reward_25 â–ƒâ–â–â–‚â–ƒâ–ˆâ–ˆâ–„â–…â–…
wandb:                       std_reward_26 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–„â–†â–…
wandb:                       std_reward_27 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_28 â–ƒâ–â–â–‚â–„â–ˆâ–‡â–…â–„â–…
wandb:                       std_reward_29 â–ƒâ–‚â–â–‚â–„â–ˆâ–‡â–…â–„â–„
wandb:                        std_reward_3 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–…â–„â–„
wandb:                       std_reward_30 â–ƒâ–â–â–‚â–ƒâ–ˆâ–‡â–„â–…â–…
wandb:                       std_reward_31 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–†â–…â–…â–…
wandb:                       std_reward_32 â–ƒâ–â–â–‚â–ƒâ–ˆâ–‡â–…â–„â–„
wandb:                       std_reward_33 â–ƒâ–‚â–â–‚â–„â–ˆâ–ˆâ–„â–†â–„
wandb:                       std_reward_34 â–ƒâ–‚â–â–‚â–ƒâ–‡â–ˆâ–„â–…â–„
wandb:                       std_reward_35 â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–‡â–…â–…â–„
wandb:                        std_reward_4 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–‡â–…â–…â–…
wandb:                        std_reward_5 â–ƒâ–‚â–â–‚â–„â–ˆâ–ˆâ–…â–…â–…
wandb:                        std_reward_6 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–‡â–„â–…â–…
wandb:                        std_reward_7 â–ƒâ–‚â–â–‚â–„â–ˆâ–‡â–…â–„â–„
wandb:                        std_reward_8 â–ƒâ–â–â–‚â–„â–ˆâ–†â–…â–…â–„
wandb:                        std_reward_9 â–ƒâ–‚â–â–ƒâ–„â–ˆâ–ˆâ–†â–†â–†
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1118/global_step 212992
wandb:        PPO_1118/rollout/ep_len_mean 200.0
wandb:        PPO_1118/rollout/ep_rew_mean -806.60681
wandb:                   PPO_1118/time/fps 1188.0
wandb:            PPO_1118/train/approx_kl 0.01425
wandb:        PPO_1118/train/clip_fraction 0.17943
wandb:           PPO_1118/train/clip_range 0.2
wandb:         PPO_1118/train/entropy_loss -7.66831
wandb:   PPO_1118/train/explained_variance 0.96717
wandb:        PPO_1118/train/learning_rate 0.0003
wandb:                 PPO_1118/train/loss 24.69952
wandb: PPO_1118/train/policy_gradient_loss -0.00747
wandb:                  PPO_1118/train/std 0.72216
wandb:           PPO_1118/train/value_loss 64.70163
wandb:                PPO_1128/global_step 212992
wandb:        PPO_1128/rollout/ep_len_mean 200.0
wandb:        PPO_1128/rollout/ep_rew_mean -737.68671
wandb:                   PPO_1128/time/fps 1187.0
wandb:            PPO_1128/train/approx_kl 0.01426
wandb:        PPO_1128/train/clip_fraction 0.17299
wandb:           PPO_1128/train/clip_range 0.2
wandb:         PPO_1128/train/entropy_loss -6.85158
wandb:   PPO_1128/train/explained_variance 0.96573
wandb:        PPO_1128/train/learning_rate 0.0003
wandb:                 PPO_1128/train/loss 24.70881
wandb: PPO_1128/train/policy_gradient_loss -0.00618
wandb:                  PPO_1128/train/std 0.64266
wandb:           PPO_1128/train/value_loss 63.74884
wandb:                PPO_1137/global_step 212992
wandb:        PPO_1137/rollout/ep_len_mean 200.0
wandb:        PPO_1137/rollout/ep_rew_mean -611.55518
wandb:                   PPO_1137/time/fps 1181.0
wandb:            PPO_1137/train/approx_kl 0.01725
wandb:        PPO_1137/train/clip_fraction 0.21804
wandb:           PPO_1137/train/clip_range 0.2
wandb:         PPO_1137/train/entropy_loss -5.98934
wandb:   PPO_1137/train/explained_variance 0.9784
wandb:        PPO_1137/train/learning_rate 0.0003
wandb:                 PPO_1137/train/loss 5.86868
wandb: PPO_1137/train/policy_gradient_loss -0.00478
wandb:                  PPO_1137/train/std 0.56878
wandb:           PPO_1137/train/value_loss 19.70825
wandb:                PPO_1146/global_step 212992
wandb:        PPO_1146/rollout/ep_len_mean 200.0
wandb:        PPO_1146/rollout/ep_rew_mean -537.79535
wandb:                   PPO_1146/time/fps 1182.0
wandb:            PPO_1146/train/approx_kl 0.01695
wandb:        PPO_1146/train/clip_fraction 0.19887
wandb:           PPO_1146/train/clip_range 0.2
wandb:         PPO_1146/train/entropy_loss -5.29923
wandb:   PPO_1146/train/explained_variance 0.95942
wandb:        PPO_1146/train/learning_rate 0.0003
wandb:                 PPO_1146/train/loss 16.36348
wandb: PPO_1146/train/policy_gradient_loss -0.00342
wandb:                  PPO_1146/train/std 0.51557
wandb:           PPO_1146/train/value_loss 51.32154
wandb:                PPO_1158/global_step 212992
wandb:        PPO_1158/rollout/ep_len_mean 200.0
wandb:        PPO_1158/rollout/ep_rew_mean -538.49762
wandb:                   PPO_1158/time/fps 1184.0
wandb:            PPO_1158/train/approx_kl 0.01911
wandb:        PPO_1158/train/clip_fraction 0.23535
wandb:           PPO_1158/train/clip_range 0.2
wandb:         PPO_1158/train/entropy_loss -5.09153
wandb:   PPO_1158/train/explained_variance 0.99446
wandb:        PPO_1158/train/learning_rate 0.0003
wandb:                 PPO_1158/train/loss 29.89468
wandb: PPO_1158/train/policy_gradient_loss -0.00628
wandb:                  PPO_1158/train/std 0.50045
wandb:           PPO_1158/train/value_loss 27.54531
wandb:                PPO_1168/global_step 212992
wandb:        PPO_1168/rollout/ep_len_mean 200.0
wandb:        PPO_1168/rollout/ep_rew_mean -471.39389
wandb:                   PPO_1168/time/fps 1179.0
wandb:            PPO_1168/train/approx_kl 0.01606
wandb:        PPO_1168/train/clip_fraction 0.20063
wandb:           PPO_1168/train/clip_range 0.2
wandb:         PPO_1168/train/entropy_loss -4.57132
wandb:   PPO_1168/train/explained_variance 0.99565
wandb:        PPO_1168/train/learning_rate 0.0003
wandb:                 PPO_1168/train/loss 5.73586
wandb: PPO_1168/train/policy_gradient_loss -0.00375
wandb:                  PPO_1168/train/std 0.46466
wandb:           PPO_1168/train/value_loss 63.19474
wandb:                PPO_1178/global_step 212992
wandb:        PPO_1178/rollout/ep_len_mean 200.0
wandb:        PPO_1178/rollout/ep_rew_mean -474.38269
wandb:                   PPO_1178/time/fps 1180.0
wandb:            PPO_1178/train/approx_kl 0.02038
wandb:        PPO_1178/train/clip_fraction 0.26533
wandb:           PPO_1178/train/clip_range 0.2
wandb:         PPO_1178/train/entropy_loss -4.06835
wandb:   PPO_1178/train/explained_variance 0.99416
wandb:        PPO_1178/train/learning_rate 0.0003
wandb:                 PPO_1178/train/loss 12.98298
wandb: PPO_1178/train/policy_gradient_loss -0.00236
wandb:                  PPO_1178/train/std 0.43282
wandb:           PPO_1178/train/value_loss 54.4174
wandb:                PPO_1188/global_step 212992
wandb:        PPO_1188/rollout/ep_len_mean 200.0
wandb:        PPO_1188/rollout/ep_rew_mean -472.3027
wandb:                   PPO_1188/time/fps 1183.0
wandb:            PPO_1188/train/approx_kl 0.02418
wandb:        PPO_1188/train/clip_fraction 0.28844
wandb:           PPO_1188/train/clip_range 0.2
wandb:         PPO_1188/train/entropy_loss -3.55841
wandb:   PPO_1188/train/explained_variance 0.99724
wandb:        PPO_1188/train/learning_rate 0.0003
wandb:                 PPO_1188/train/loss 8.71315
wandb: PPO_1188/train/policy_gradient_loss 0.00314
wandb:                  PPO_1188/train/std 0.40193
wandb:           PPO_1188/train/value_loss 26.62407
wandb:                PPO_1197/global_step 212992
wandb:        PPO_1197/rollout/ep_len_mean 200.0
wandb:        PPO_1197/rollout/ep_rew_mean -394.75476
wandb:                   PPO_1197/time/fps 1184.0
wandb:            PPO_1197/train/approx_kl 0.02838
wandb:        PPO_1197/train/clip_fraction 0.31467
wandb:           PPO_1197/train/clip_range 0.2
wandb:         PPO_1197/train/entropy_loss -2.82475
wandb:   PPO_1197/train/explained_variance 0.99662
wandb:        PPO_1197/train/learning_rate 0.0003
wandb:                 PPO_1197/train/loss 4.69701
wandb: PPO_1197/train/policy_gradient_loss 0.00344
wandb:                  PPO_1197/train/std 0.36177
wandb:           PPO_1197/train/value_loss 23.04381
wandb:                    global_mean_eval -377.32494
wandb:                         global_step 212992
wandb:                       mean_reward_0 -381.23039
wandb:                       mean_reward_1 -404.54136
wandb:                      mean_reward_10 -383.21759
wandb:                      mean_reward_11 -401.57254
wandb:                      mean_reward_12 -362.42391
wandb:                      mean_reward_13 -397.3539
wandb:                      mean_reward_14 -386.20892
wandb:                      mean_reward_15 -356.66323
wandb:                      mean_reward_16 -403.26827
wandb:                      mean_reward_17 -387.77858
wandb:                      mean_reward_18 -375.09282
wandb:                      mean_reward_19 -378.47053
wandb:                       mean_reward_2 -361.24195
wandb:                      mean_reward_20 -357.88496
wandb:                      mean_reward_21 -355.70051
wandb:                      mean_reward_22 -356.18324
wandb:                      mean_reward_23 -329.30216
wandb:                      mean_reward_24 -395.35839
wandb:                      mean_reward_25 -397.62871
wandb:                      mean_reward_26 -394.8055
wandb:                      mean_reward_27 -355.79927
wandb:                      mean_reward_28 -391.52652
wandb:                      mean_reward_29 -373.34624
wandb:                       mean_reward_3 -372.89585
wandb:                      mean_reward_30 -388.45349
wandb:                      mean_reward_31 -372.08257
wandb:                      mean_reward_32 -380.02053
wandb:                      mean_reward_33 -376.02525
wandb:                      mean_reward_34 -381.62817
wandb:                      mean_reward_35 -366.76962
wandb:                       mean_reward_4 -380.64097
wandb:                       mean_reward_5 -377.6287
wandb:                       mean_reward_6 -380.39306
wandb:                       mean_reward_7 -359.8588
wandb:                       mean_reward_8 -363.96383
wandb:                       mean_reward_9 -396.73764
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 137.87462
wandb:                        std_reward_1 144.87044
wandb:                       std_reward_10 149.87105
wandb:                       std_reward_11 156.80139
wandb:                       std_reward_12 127.5912
wandb:                       std_reward_13 154.91294
wandb:                       std_reward_14 147.86673
wandb:                       std_reward_15 116.85423
wandb:                       std_reward_16 146.35836
wandb:                       std_reward_17 156.8356
wandb:                       std_reward_18 133.63184
wandb:                       std_reward_19 137.25115
wandb:                        std_reward_2 122.68329
wandb:                       std_reward_20 111.26418
wandb:                       std_reward_21 128.79909
wandb:                       std_reward_22 115.69526
wandb:                       std_reward_23 90.46953
wandb:                       std_reward_24 150.42602
wandb:                       std_reward_25 156.07459
wandb:                       std_reward_26 161.81002
wandb:                       std_reward_27 124.22723
wandb:                       std_reward_28 146.34034
wandb:                       std_reward_29 131.86359
wandb:                        std_reward_3 136.51357
wandb:                       std_reward_30 143.78728
wandb:                       std_reward_31 151.87329
wandb:                       std_reward_32 149.4344
wandb:                       std_reward_33 131.10291
wandb:                       std_reward_34 149.10726
wandb:                       std_reward_35 136.64276
wandb:                        std_reward_4 149.7594
wandb:                        std_reward_5 134.10172
wandb:                        std_reward_6 145.14849
wandb:                        std_reward_7 121.58371
wandb:                        std_reward_8 125.84304
wandb:                        std_reward_9 166.6153
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced pretty-dust-31: https://wandb.ai/tidiane/meta_rl_context/runs/37wdxx29
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-37wdxx29/logs
wandb: 
wandb: Run history:
wandb:                PPO_1119/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1119/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1119/rollout/ep_rew_mean â–â–â–‚â–ƒâ–„â–ƒâ–…â–…â–†â–†â–‡â–ˆ
wandb:                   PPO_1119/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1119/train/approx_kl â–„â–â–ƒâ–†â–„â–„â–…â–ˆâ–„â–‡â–‚
wandb:        PPO_1119/train/clip_fraction â–„â–â–â–…â–†â–„â–ˆâ–‡â–„â–ˆâ–†
wandb:           PPO_1119/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1119/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1119/train/explained_variance â–‡â–†â–‡â–ƒâ–ˆâ–â–…â–…â–‡â–…â–…
wandb:        PPO_1119/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1119/train/loss â–‚â–‚â–â–‚â–…â–‚â–ƒâ–…â–†â–ˆâ–…
wandb: PPO_1119/train/policy_gradient_loss â–â–‡â–…â–†â–ƒâ–„â–…â–â–…â–„â–ˆ
wandb:                  PPO_1119/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1119/train/value_loss â–â–‚â–ƒâ–ˆâ–ƒâ–‡â–„â–…â–…â–…â–…
wandb:                PPO_1129/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1129/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1129/rollout/ep_rew_mean â–â–â–‚â–ƒâ–„â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                   PPO_1129/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1129/train/approx_kl â–â–ƒâ–â–ƒâ–â–â–‚â–‚â–…â–ˆâ–…
wandb:        PPO_1129/train/clip_fraction â–‚â–‚â–â–‚â–ƒâ–„â–…â–ƒâ–…â–‡â–ˆ
wandb:           PPO_1129/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1129/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1129/train/explained_variance â–â–„â–…â–„â–…â–‡â–‡â–†â–ˆâ–†â–†
wandb:        PPO_1129/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1129/train/loss â–…â–„â–…â–„â–ˆâ–ˆâ–‚â–ƒâ–â–‚â–‚
wandb: PPO_1129/train/policy_gradient_loss â–â–‚â–„â–ƒâ–„â–â–„â–†â–…â–ƒâ–ˆ
wandb:                  PPO_1129/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1129/train/value_loss â–ˆâ–‡â–ˆâ–†â–ˆâ–…â–‚â–‚â–ƒâ–„â–
wandb:                PPO_1139/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1139/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1139/rollout/ep_rew_mean â–â–‚â–„â–ƒâ–†â–„â–…â–†â–‡â–‡â–†â–ˆ
wandb:                   PPO_1139/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1139/train/approx_kl â–‚â–ƒâ–â–…â–„â–‚â–„â–ƒâ–„â–‚â–ˆ
wandb:        PPO_1139/train/clip_fraction â–ƒâ–„â–‚â–…â–ˆâ–â–…â–„â–…â–„â–ˆ
wandb:           PPO_1139/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1139/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1139/train/explained_variance â–ƒâ–…â–ƒâ–…â–â–…â–â–†â–ˆâ–„â–„
wandb:        PPO_1139/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1139/train/loss â–ƒâ–ˆâ–‚â–â–‚â–â–„â–ƒâ–â–‚â–ˆ
wandb: PPO_1139/train/policy_gradient_loss â–â–‚â–ƒâ–ƒâ–…â–†â–…â–…â–ˆâ–‡â–ˆ
wandb:                  PPO_1139/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1139/train/value_loss â–†â–„â–ˆâ–‡â–‚â–„â–‡â–ƒâ–â–‚â–…
wandb:                PPO_1149/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1149/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1149/rollout/ep_rew_mean â–â–‚â–„â–…â–†â–ˆâ–‡â–ˆâ–…â–ˆâ–ˆâ–…
wandb:                   PPO_1149/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1149/train/approx_kl â–ƒâ–ˆâ–†â–†â–‚â–â–‡â–†â–„â–„â–‚
wandb:        PPO_1149/train/clip_fraction â–â–„â–†â–ˆâ–‡â–„â–†â–„â–„â–„â–…
wandb:           PPO_1149/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1149/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1149/train/explained_variance â–‡â–‡â–‡â–ˆâ–â–†â–†â–‡â–…â–‡â–†
wandb:        PPO_1149/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1149/train/loss â–ƒâ–‚â–‚â–„â–‚â–â–‚â–â–ƒâ–ˆâ–†
wandb: PPO_1149/train/policy_gradient_loss â–„â–â–„â–‡â–ˆâ–†â–‡â–ƒâ–„â–…â–„
wandb:                  PPO_1149/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–â–‚â–
wandb:           PPO_1149/train/value_loss â–†â–…â–…â–ƒâ–‡â–‚â–â–‚â–ƒâ–ƒâ–ˆ
wandb:                PPO_1159/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1159/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1159/rollout/ep_rew_mean â–â–ƒâ–‚â–ƒâ–†â–ƒâ–…â–ˆâ–…â–‡â–†â–ˆ
wandb:                   PPO_1159/time/fps â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1159/train/approx_kl â–‚â–„â–…â–ˆâ–â–„â–…â–…â–„â–†â–…
wandb:        PPO_1159/train/clip_fraction â–‚â–†â–…â–†â–â–„â–‡â–ˆâ–‚â–ˆâ–‡
wandb:           PPO_1159/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1159/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1159/train/explained_variance â–â–„â–ƒâ–„â–…â–…â–…â–†â–…â–†â–ˆ
wandb:        PPO_1159/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1159/train/loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–…â–„â–â–„â–‡â–
wandb: PPO_1159/train/policy_gradient_loss â–…â–…â–â–†â–‚â–ƒâ–„â–„â–ƒâ–„â–ˆ
wandb:                  PPO_1159/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1159/train/value_loss â–ˆâ–„â–…â–…â–‡â–‡â–†â–ƒâ–ˆâ–„â–
wandb:                PPO_1169/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1169/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1169/rollout/ep_rew_mean â–‡â–…â–„â–…â–ˆâ–…â–‚â–„â–ˆâ–â–ˆâ–†
wandb:                   PPO_1169/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1169/train/approx_kl â–†â–„â–„â–„â–ƒâ–â–â–…â–ˆâ–…â–ƒ
wandb:        PPO_1169/train/clip_fraction â–ˆâ–‚â–ƒâ–†â–„â–‚â–â–†â–‡â–â–‚
wandb:           PPO_1169/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1169/train/entropy_loss â–â–‚â–‚â–„â–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1169/train/explained_variance â–„â–â–‚â–…â–…â–„â–ƒâ–„â–„â–ˆâ–ˆ
wandb:        PPO_1169/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1169/train/loss â–„â–ˆâ–„â–‚â–â–…â–„â–…â–…â–ƒâ–‚
wandb: PPO_1169/train/policy_gradient_loss â–†â–ƒâ–„â–ˆâ–…â–‚â–ƒâ–ˆâ–ƒâ–â–„
wandb:                  PPO_1169/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–„â–‚â–‚â–
wandb:           PPO_1169/train/value_loss â–‚â–„â–„â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒ
wandb:                PPO_1179/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1179/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1179/rollout/ep_rew_mean â–…â–â–„â–…â–†â–…â–„â–…â–†â–…â–ˆâ–„
wandb:                   PPO_1179/time/fps â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1179/train/approx_kl â–â–ƒâ–†â–ƒâ–ƒâ–ˆâ–ˆâ–‡â–†â–ƒâ–…
wandb:        PPO_1179/train/clip_fraction â–â–â–ƒâ–ƒâ–‚â–‚â–„â–ˆâ–‚â–„â–…
wandb:           PPO_1179/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1179/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1179/train/explained_variance â–„â–†â–ˆâ–ƒâ–…â–†â–ƒâ–â–‚â–‚â–
wandb:        PPO_1179/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1179/train/loss â–„â–„â–ƒâ–ˆâ–â–‡â–„â–‚â–„â–…â–
wandb: PPO_1179/train/policy_gradient_loss â–‚â–„â–â–…â–ƒâ–‡â–„â–†â–„â–ˆâ–‡
wandb:                  PPO_1179/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1179/train/value_loss â–ƒâ–ƒâ–â–â–‚â–ƒâ–„â–…â–†â–ˆâ–„
wandb:                PPO_1189/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1189/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1189/rollout/ep_rew_mean â–„â–‚â–…â–†â–‚â–ƒâ–â–…â–ˆâ–„â–…â–…
wandb:                   PPO_1189/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1189/train/approx_kl â–‡â–â–…â–†â–‚â–ˆâ–‚â–‡â–†â–â–…
wandb:        PPO_1189/train/clip_fraction â–ˆâ–â–…â–†â–â–ˆâ–‚â–‡â–…â–‚â–…
wandb:           PPO_1189/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1189/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1189/train/explained_variance â–‡â–‡â–ˆâ–„â–â–‡â–„â–†â–‚â–†â–„
wandb:        PPO_1189/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1189/train/loss â–â–„â–…â–‚â–ƒâ–â–ˆâ–ˆâ–‚â–ƒâ–†
wandb: PPO_1189/train/policy_gradient_loss â–‡â–‚â–‡â–†â–‚â–†â–â–ˆâ–‡â–„â–†
wandb:                  PPO_1189/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1189/train/value_loss â–‚â–…â–ƒâ–â–ˆâ–‚â–‡â–‚â–‚â–„â–„
wandb:                PPO_1199/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1199/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1199/rollout/ep_rew_mean â–‚â–â–‚â–ƒâ–„â–…â–…â–ˆâ–ˆâ–†â–‡â–ˆ
wandb:                   PPO_1199/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1199/train/approx_kl â–„â–‚â–†â–ƒâ–â–ƒâ–ƒâ–‚â–†â–ˆâ–ƒ
wandb:        PPO_1199/train/clip_fraction â–…â–â–„â–…â–‚â–†â–„â–ƒâ–ƒâ–ˆâ–
wandb:           PPO_1199/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1199/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1199/train/explained_variance â–â–‡â–†â–…â–†â–…â–ˆâ–‡â–…â–†â–…
wandb:        PPO_1199/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1199/train/loss â–‚â–ˆâ–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–â–ƒ
wandb: PPO_1199/train/policy_gradient_loss â–‡â–„â–â–ƒâ–…â–ˆâ–„â–ƒâ–‚â–…â–‚
wandb:                  PPO_1199/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1199/train/value_loss â–‡â–ƒâ–„â–…â–ˆâ–„â–â–‚â–ƒâ–‚â–„
wandb:                    global_mean_eval â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–‚â–…â–†â–†â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_11 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–‚â–…â–†â–‡â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_16 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_18 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–‚â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_27 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–‚â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–‚â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–‚â–…â–†â–†â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_33 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                       mean_reward_4 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–‚â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–‚â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:                       mean_reward_8 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–ƒâ–â–â–ƒâ–„â–…â–ˆâ–ˆâ–‚â–ˆ
wandb:                        std_reward_1 â–ƒâ–‚â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–†
wandb:                       std_reward_10 â–ƒâ–‚â–â–ƒâ–ƒâ–…â–‡â–ˆâ–‚â–†
wandb:                       std_reward_11 â–ƒâ–‚â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–‡
wandb:                       std_reward_12 â–‚â–â–â–ƒâ–„â–„â–‡â–ˆâ–‚â–…
wandb:                       std_reward_13 â–‚â–‚â–â–‚â–„â–…â–ˆâ–ˆâ–ƒâ–ˆ
wandb:                       std_reward_14 â–‚â–â–â–ƒâ–„â–„â–‡â–ˆâ–ƒâ–†
wandb:                       std_reward_15 â–ƒâ–‚â–â–ƒâ–„â–†â–ˆâ–‡â–ƒâ–ˆ
wandb:                       std_reward_16 â–ƒâ–‚â–â–ƒâ–†â–…â–ˆâ–‡â–ƒâ–‡
wandb:                       std_reward_17 â–ƒâ–â–â–‚â–…â–„â–‡â–ˆâ–ƒâ–ˆ
wandb:                       std_reward_18 â–ƒâ–â–â–ƒâ–…â–…â–ˆâ–ˆâ–ƒâ–†
wandb:                       std_reward_19 â–ƒâ–‚â–â–ƒâ–„â–„â–ˆâ–ˆâ–ƒâ–‡
wandb:                        std_reward_2 â–ƒâ–‚â–â–‚â–„â–…â–…â–ˆâ–ƒâ–‡
wandb:                       std_reward_20 â–ƒâ–‚â–â–ƒâ–„â–…â–ˆâ–ˆâ–ƒâ–‡
wandb:                       std_reward_21 â–ƒâ–â–â–ƒâ–„â–ƒâ–†â–ˆâ–ƒâ–‡
wandb:                       std_reward_22 â–ƒâ–â–â–ƒâ–…â–„â–‡â–ˆâ–ƒâ–‡
wandb:                       std_reward_23 â–„â–‚â–â–ƒâ–†â–†â–‡â–ˆâ–ƒâ–ˆ
wandb:                       std_reward_24 â–ƒâ–‚â–â–ƒâ–…â–†â–ˆâ–ˆâ–„â–‡
wandb:                       std_reward_25 â–‚â–â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–†
wandb:                       std_reward_26 â–ƒâ–‚â–â–„â–„â–„â–ˆâ–ˆâ–ƒâ–ˆ
wandb:                       std_reward_27 â–ƒâ–â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–†
wandb:                       std_reward_28 â–ƒâ–â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–‡
wandb:                       std_reward_29 â–ƒâ–‚â–â–ƒâ–„â–…â–‡â–ˆâ–ƒâ–ˆ
wandb:                        std_reward_3 â–‚â–â–â–„â–…â–…â–†â–ˆâ–ƒâ–‡
wandb:                       std_reward_30 â–ƒâ–‚â–â–‚â–…â–…â–‡â–ˆâ–ƒâ–‡
wandb:                       std_reward_31 â–ƒâ–â–â–ƒâ–„â–…â–ˆâ–‡â–ƒâ–‡
wandb:                       std_reward_32 â–ƒâ–‚â–â–ƒâ–„â–…â–‡â–‡â–ƒâ–ˆ
wandb:                       std_reward_33 â–ƒâ–‚â–â–‚â–„â–„â–‡â–ˆâ–ƒâ–ˆ
wandb:                       std_reward_34 â–ƒâ–‚â–â–ƒâ–…â–…â–ˆâ–ˆâ–ƒâ–ˆ
wandb:                       std_reward_35 â–ƒâ–â–â–ƒâ–„â–„â–‡â–ˆâ–ƒâ–‡
wandb:                        std_reward_4 â–‚â–‚â–â–ƒâ–…â–…â–…â–ˆâ–ƒâ–‡
wandb:                        std_reward_5 â–ƒâ–â–â–ƒâ–„â–…â–ˆâ–ˆâ–‚â–†
wandb:                        std_reward_6 â–ƒâ–‚â–â–ƒâ–„â–…â–ˆâ–ˆâ–ƒâ–‡
wandb:                        std_reward_7 â–ƒâ–‚â–â–„â–…â–…â–ˆâ–ˆâ–ƒâ–‡
wandb:                        std_reward_8 â–ƒâ–â–â–„â–…â–…â–‡â–ˆâ–ƒâ–‡
wandb:                        std_reward_9 â–ƒâ–‚â–â–ƒâ–„â–„â–ˆâ–‡â–ƒâ–†
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1119/global_step 212992
wandb:        PPO_1119/rollout/ep_len_mean 200.0
wandb:        PPO_1119/rollout/ep_rew_mean -801.11975
wandb:                   PPO_1119/time/fps 1191.0
wandb:            PPO_1119/train/approx_kl 0.01157
wandb:        PPO_1119/train/clip_fraction 0.15542
wandb:           PPO_1119/train/clip_range 0.2
wandb:         PPO_1119/train/entropy_loss -7.80952
wandb:   PPO_1119/train/explained_variance 0.96427
wandb:        PPO_1119/train/learning_rate 0.0003
wandb:                 PPO_1119/train/loss 44.9323
wandb: PPO_1119/train/policy_gradient_loss -0.00635
wandb:                  PPO_1119/train/std 0.7371
wandb:           PPO_1119/train/value_loss 92.43653
wandb:                PPO_1129/global_step 212992
wandb:        PPO_1129/rollout/ep_len_mean 200.0
wandb:        PPO_1129/rollout/ep_rew_mean -638.87787
wandb:                   PPO_1129/time/fps 1177.0
wandb:            PPO_1129/train/approx_kl 0.01403
wandb:        PPO_1129/train/clip_fraction 0.20406
wandb:           PPO_1129/train/clip_range 0.2
wandb:         PPO_1129/train/entropy_loss -6.92374
wandb:   PPO_1129/train/explained_variance 0.97222
wandb:        PPO_1129/train/learning_rate 0.0003
wandb:                 PPO_1129/train/loss 17.50189
wandb: PPO_1129/train/policy_gradient_loss -0.00616
wandb:                  PPO_1129/train/std 0.64982
wandb:           PPO_1129/train/value_loss 36.05498
wandb:                PPO_1139/global_step 212992
wandb:        PPO_1139/rollout/ep_len_mean 200.0
wandb:        PPO_1139/rollout/ep_rew_mean -564.62262
wandb:                   PPO_1139/time/fps 1196.0
wandb:            PPO_1139/train/approx_kl 0.01968
wandb:        PPO_1139/train/clip_fraction 0.23318
wandb:           PPO_1139/train/clip_range 0.2
wandb:         PPO_1139/train/entropy_loss -5.93181
wandb:   PPO_1139/train/explained_variance 0.97749
wandb:        PPO_1139/train/learning_rate 0.0003
wandb:                 PPO_1139/train/loss 27.73149
wandb: PPO_1139/train/policy_gradient_loss -0.00122
wandb:                  PPO_1139/train/std 0.56382
wandb:           PPO_1139/train/value_loss 34.4876
wandb:                PPO_1149/global_step 212992
wandb:        PPO_1149/rollout/ep_len_mean 200.0
wandb:        PPO_1149/rollout/ep_rew_mean -553.34308
wandb:                   PPO_1149/time/fps 1181.0
wandb:            PPO_1149/train/approx_kl 0.01598
wandb:        PPO_1149/train/clip_fraction 0.22374
wandb:           PPO_1149/train/clip_range 0.2
wandb:         PPO_1149/train/entropy_loss -5.29782
wandb:   PPO_1149/train/explained_variance 0.96823
wandb:        PPO_1149/train/learning_rate 0.0003
wandb:                 PPO_1149/train/loss 34.67154
wandb: PPO_1149/train/policy_gradient_loss -0.00249
wandb:                  PPO_1149/train/std 0.51646
wandb:           PPO_1149/train/value_loss 61.98979
wandb:                PPO_1159/global_step 212992
wandb:        PPO_1159/rollout/ep_len_mean 200.0
wandb:        PPO_1159/rollout/ep_rew_mean -506.172
wandb:                   PPO_1159/time/fps 1189.0
wandb:            PPO_1159/train/approx_kl 0.01763
wandb:        PPO_1159/train/clip_fraction 0.23568
wandb:           PPO_1159/train/clip_range 0.2
wandb:         PPO_1159/train/entropy_loss -4.67527
wandb:   PPO_1159/train/explained_variance 0.99496
wandb:        PPO_1159/train/learning_rate 0.0003
wandb:                 PPO_1159/train/loss 5.23414
wandb: PPO_1159/train/policy_gradient_loss -0.00027
wandb:                  PPO_1159/train/std 0.47207
wandb:           PPO_1159/train/value_loss 15.23505
wandb:                PPO_1169/global_step 212992
wandb:        PPO_1169/rollout/ep_len_mean 200.0
wandb:        PPO_1169/rollout/ep_rew_mean -484.87326
wandb:                   PPO_1169/time/fps 1186.0
wandb:            PPO_1169/train/approx_kl 0.01685
wandb:        PPO_1169/train/clip_fraction 0.20613
wandb:           PPO_1169/train/clip_range 0.2
wandb:         PPO_1169/train/entropy_loss -4.03637
wandb:   PPO_1169/train/explained_variance 0.99687
wandb:        PPO_1169/train/learning_rate 0.0003
wandb:                 PPO_1169/train/loss 12.61903
wandb: PPO_1169/train/policy_gradient_loss -0.0016
wandb:                  PPO_1169/train/std 0.43102
wandb:           PPO_1169/train/value_loss 29.39071
wandb:                PPO_1179/global_step 212992
wandb:        PPO_1179/rollout/ep_len_mean 200.0
wandb:        PPO_1179/rollout/ep_rew_mean -476.27716
wandb:                   PPO_1179/time/fps 1188.0
wandb:            PPO_1179/train/approx_kl 0.01908
wandb:        PPO_1179/train/clip_fraction 0.25165
wandb:           PPO_1179/train/clip_range 0.2
wandb:         PPO_1179/train/entropy_loss -3.44226
wandb:   PPO_1179/train/explained_variance 0.997
wandb:        PPO_1179/train/learning_rate 0.0003
wandb:                 PPO_1179/train/loss 2.96779
wandb: PPO_1179/train/policy_gradient_loss -7e-05
wandb:                  PPO_1179/train/std 0.39621
wandb:           PPO_1179/train/value_loss 20.61847
wandb:                PPO_1189/global_step 212992
wandb:        PPO_1189/rollout/ep_len_mean 200.0
wandb:        PPO_1189/rollout/ep_rew_mean -437.25967
wandb:                   PPO_1189/time/fps 1193.0
wandb:            PPO_1189/train/approx_kl 0.01988
wandb:        PPO_1189/train/clip_fraction 0.25717
wandb:           PPO_1189/train/clip_range 0.2
wandb:         PPO_1189/train/entropy_loss -2.95845
wandb:   PPO_1189/train/explained_variance 0.99763
wandb:        PPO_1189/train/learning_rate 0.0003
wandb:                 PPO_1189/train/loss 6.90984
wandb: PPO_1189/train/policy_gradient_loss -0.00033
wandb:                  PPO_1189/train/std 0.36918
wandb:           PPO_1189/train/value_loss 14.41674
wandb:                PPO_1199/global_step 212992
wandb:        PPO_1199/rollout/ep_len_mean 200.0
wandb:        PPO_1199/rollout/ep_rew_mean -398.87546
wandb:                   PPO_1199/time/fps 1185.0
wandb:            PPO_1199/train/approx_kl 0.02093
wandb:        PPO_1199/train/clip_fraction 0.24432
wandb:           PPO_1199/train/clip_range 0.2
wandb:         PPO_1199/train/entropy_loss -2.4954
wandb:   PPO_1199/train/explained_variance 0.99616
wandb:        PPO_1199/train/learning_rate 0.0003
wandb:                 PPO_1199/train/loss 6.66541
wandb: PPO_1199/train/policy_gradient_loss -0.0
wandb:                  PPO_1199/train/std 0.3458
wandb:           PPO_1199/train/value_loss 16.71874
wandb:                    global_mean_eval -398.05711
wandb:                         global_step 212992
wandb:                       mean_reward_0 -405.76919
wandb:                       mean_reward_1 -400.77561
wandb:                      mean_reward_10 -406.95946
wandb:                      mean_reward_11 -399.57153
wandb:                      mean_reward_12 -382.92806
wandb:                      mean_reward_13 -408.32372
wandb:                      mean_reward_14 -394.2734
wandb:                      mean_reward_15 -413.31578
wandb:                      mean_reward_16 -382.74654
wandb:                      mean_reward_17 -411.63527
wandb:                      mean_reward_18 -375.66534
wandb:                      mean_reward_19 -402.39336
wandb:                       mean_reward_2 -391.06243
wandb:                      mean_reward_20 -391.10966
wandb:                      mean_reward_21 -406.92027
wandb:                      mean_reward_22 -403.65237
wandb:                      mean_reward_23 -404.13454
wandb:                      mean_reward_24 -386.23908
wandb:                      mean_reward_25 -387.91886
wandb:                      mean_reward_26 -416.46405
wandb:                      mean_reward_27 -389.86566
wandb:                      mean_reward_28 -405.96707
wandb:                      mean_reward_29 -414.73958
wandb:                       mean_reward_3 -391.74631
wandb:                      mean_reward_30 -392.75933
wandb:                      mean_reward_31 -407.76679
wandb:                      mean_reward_32 -420.9289
wandb:                      mean_reward_33 -399.52156
wandb:                      mean_reward_34 -401.84771
wandb:                      mean_reward_35 -406.56309
wandb:                       mean_reward_4 -388.05435
wandb:                       mean_reward_5 -386.1726
wandb:                       mean_reward_6 -397.57126
wandb:                       mean_reward_7 -401.02142
wandb:                       mean_reward_8 -373.21898
wandb:                       mean_reward_9 -380.45272
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 139.88075
wandb:                        std_reward_1 131.12652
wandb:                       std_reward_10 121.60036
wandb:                       std_reward_11 132.17608
wandb:                       std_reward_12 111.28876
wandb:                       std_reward_13 153.91053
wandb:                       std_reward_14 121.81042
wandb:                       std_reward_15 137.15254
wandb:                       std_reward_16 125.81353
wandb:                       std_reward_17 135.01644
wandb:                       std_reward_18 113.56639
wandb:                       std_reward_19 133.0681
wandb:                        std_reward_2 135.94427
wandb:                       std_reward_20 130.32475
wandb:                       std_reward_21 137.52076
wandb:                       std_reward_22 129.25501
wandb:                       std_reward_23 133.91434
wandb:                       std_reward_24 128.06774
wandb:                       std_reward_25 112.18869
wandb:                       std_reward_26 136.7663
wandb:                       std_reward_27 123.28655
wandb:                       std_reward_28 134.15388
wandb:                       std_reward_29 141.3729
wandb:                        std_reward_3 129.91976
wandb:                       std_reward_30 124.15218
wandb:                       std_reward_31 132.46566
wandb:                       std_reward_32 159.98526
wandb:                       std_reward_33 143.87559
wandb:                       std_reward_34 134.8628
wandb:                       std_reward_35 134.99779
wandb:                        std_reward_4 132.35698
wandb:                        std_reward_5 124.38424
wandb:                        std_reward_6 126.06382
wandb:                        std_reward_7 128.57303
wandb:                        std_reward_8 121.48147
wandb:                        std_reward_9 120.7675
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced colorful-cherry-27: https://wandb.ai/tidiane/meta_rl_context/runs/15t9fds4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-15t9fds4/logs
wandb: 
wandb: Run history:
wandb:                PPO_1116/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1116/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1116/rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–„â–…â–…â–…â–†â–‡â–ˆ
wandb:                   PPO_1116/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1116/train/approx_kl â–ˆâ–„â–â–†â–„â–ˆâ–…â–„â–‡â–‡â–‡
wandb:        PPO_1116/train/clip_fraction â–†â–„â–â–‡â–„â–‡â–‡â–„â–†â–ˆâ–ˆ
wandb:           PPO_1116/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1116/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1116/train/explained_variance â–â–ƒâ–…â–ˆâ–†â–„â–†â–†â–†â–ƒâ–ƒ
wandb:        PPO_1116/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1116/train/loss â–‚â–‡â–ƒâ–â–‡â–„â–…â–‚â–„â–…â–ˆ
wandb: PPO_1116/train/policy_gradient_loss â–‚â–ƒâ–‡â–‚â–„â–â–ƒâ–ˆâ–…â–ƒâ–ƒ
wandb:                  PPO_1116/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1116/train/value_loss â–†â–‚â–‡â–â–…â–„â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:                PPO_1125/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1125/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1125/rollout/ep_rew_mean â–‚â–â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                   PPO_1125/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1125/train/approx_kl â–…â–â–ƒâ–ƒâ–ƒâ–…â–†â–†â–‡â–†â–ˆ
wandb:        PPO_1125/train/clip_fraction â–‚â–â–ƒâ–‚â–ƒâ–„â–†â–†â–ˆâ–…â–‡
wandb:           PPO_1125/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1125/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1125/train/explained_variance â–â–‚â–„â–„â–„â–ƒâ–…â–†â–…â–†â–ˆ
wandb:        PPO_1125/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1125/train/loss â–ˆâ–‡â–‚â–…â–‡â–…â–„â–â–â–â–‚
wandb: PPO_1125/train/policy_gradient_loss â–…â–…â–…â–ƒâ–„â–…â–ˆâ–‚â–â–…â–†
wandb:                  PPO_1125/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1125/train/value_loss â–ˆâ–ˆâ–„â–…â–†â–…â–ƒâ–„â–â–‚â–„
wandb:                PPO_1136/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1136/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1136/rollout/ep_rew_mean â–â–â–‚â–ƒâ–„â–„â–†â–…â–…â–„â–…â–ˆ
wandb:                   PPO_1136/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1136/train/approx_kl â–†â–ƒâ–â–ˆâ–â–„â–…â–ˆâ–‚â–†â–‡
wandb:        PPO_1136/train/clip_fraction â–…â–ƒâ–â–…â–‚â–„â–‡â–ƒâ–„â–ˆâ–…
wandb:           PPO_1136/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1136/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1136/train/explained_variance â–â–…â–â–…â–„â–†â–†â–‚â–‡â–ˆâ–‚
wandb:        PPO_1136/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1136/train/loss â–‚â–‚â–ˆâ–â–„â–ƒâ–ƒâ–†â–…â–ƒâ–†
wandb: PPO_1136/train/policy_gradient_loss â–â–â–‚â–‚â–„â–ƒâ–„â–…â–ˆâ–†â–„
wandb:                  PPO_1136/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1136/train/value_loss â–…â–ƒâ–ˆâ–ƒâ–…â–…â–â–…â–†â–‚â–…
wandb:                PPO_1148/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1148/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1148/rollout/ep_rew_mean â–â–‚â–„â–„â–â–ƒâ–‚â–†â–†â–ƒâ–‡â–ˆ
wandb:                   PPO_1148/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1148/train/approx_kl â–†â–ˆâ–„â–â–ƒâ–ƒâ–‚â–„â–„â–„â–ƒ
wandb:        PPO_1148/train/clip_fraction â–…â–ˆâ–‡â–â–„â–„â–†â–†â–…â–„â–ƒ
wandb:           PPO_1148/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1148/train/entropy_loss â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1148/train/explained_variance â–‡â–†â–…â–ˆâ–†â–ˆâ–ˆâ–‡â–‡â–ƒâ–
wandb:        PPO_1148/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1148/train/loss â–„â–‚â–ˆâ–…â–â–‚â–‚â–â–â–‚â–ƒ
wandb: PPO_1148/train/policy_gradient_loss â–â–†â–‡â–…â–‡â–ˆâ–‡â–…â–†â–†â–‡
wandb:                  PPO_1148/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1148/train/value_loss â–…â–…â–‚â–†â–ˆâ–…â–†â–â–â–ˆâ–‚
wandb:                PPO_1157/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1157/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1157/rollout/ep_rew_mean â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–„â–†â–‡â–…â–
wandb:                   PPO_1157/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1157/train/approx_kl â–„â–â–…â–ˆâ–‚â–„â–…â–ƒâ–„â–â–ƒ
wandb:        PPO_1157/train/clip_fraction â–…â–â–†â–ˆâ–‚â–ƒâ–…â–â–†â–„â–
wandb:           PPO_1157/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1157/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–‡â–‡â–ˆ
wandb:   PPO_1157/train/explained_variance â–â–‚â–â–ƒâ–‚â–†â–…â–…â–„â–ˆâ–ˆ
wandb:        PPO_1157/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1157/train/loss â–ˆâ–„â–„â–‚â–ƒâ–„â–ƒâ–ˆâ–‡â–â–‚
wandb: PPO_1157/train/policy_gradient_loss â–…â–â–„â–ƒâ–†â–„â–…â–ˆâ–†â–ˆâ–…
wandb:                  PPO_1157/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–‚â–‚â–
wandb:           PPO_1157/train/value_loss â–…â–‡â–â–‚â–ƒâ–‡â–…â–ˆâ–†â–‚â–…
wandb:                PPO_1167/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1167/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1167/rollout/ep_rew_mean â–‚â–ƒâ–…â–…â–ƒâ–‚â–†â–â–â–„â–ˆâ–†
wandb:                   PPO_1167/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1167/train/approx_kl â–â–â–…â–†â–â–„â–„â–ˆâ–†â–…â–ƒ
wandb:        PPO_1167/train/clip_fraction â–â–â–…â–†â–„â–…â–ƒâ–ˆâ–…â–ƒâ–†
wandb:           PPO_1167/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1167/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1167/train/explained_variance â–â–‚â–†â–†â–ƒâ–‡â–†â–†â–†â–„â–ˆ
wandb:        PPO_1167/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1167/train/loss â–…â–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–â–ƒâ–â–‚
wandb: PPO_1167/train/policy_gradient_loss â–ƒâ–…â–ƒâ–‡â–†â–‡â–‡â–ˆâ–…â–â–‡
wandb:                  PPO_1167/train/std â–ˆâ–‡â–†â–†â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1167/train/value_loss â–†â–ˆâ–ƒâ–‚â–„â–ƒâ–„â–…â–„â–„â–
wandb:                PPO_1177/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1177/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1177/rollout/ep_rew_mean â–â–‡â–‡â–†â–…â–ˆâ–†â–‡â–†â–‡â–‡â–‡
wandb:                   PPO_1177/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1177/train/approx_kl â–ƒâ–ƒâ–‚â–‡â–†â–‚â–â–ˆâ–‡â–‚â–‚
wandb:        PPO_1177/train/clip_fraction â–ƒâ–‡â–ƒâ–†â–„â–‡â–â–ˆâ–„â–‡â–‚
wandb:           PPO_1177/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1177/train/entropy_loss â–â–â–‚â–ƒâ–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1177/train/explained_variance â–ƒâ–„â–ƒâ–…â–‚â–‚â–‚â–â–ƒâ–„â–ˆ
wandb:        PPO_1177/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1177/train/loss â–‚â–â–â–â–„â–ˆâ–ƒâ–‚â–ƒâ–â–‚
wandb: PPO_1177/train/policy_gradient_loss â–â–„â–„â–†â–â–ˆâ–„â–†â–†â–‡â–†
wandb:                  PPO_1177/train/std â–ˆâ–‡â–‡â–†â–„â–„â–„â–„â–‚â–â–
wandb:           PPO_1177/train/value_loss â–‚â–â–„â–‚â–†â–†â–ˆâ–†â–†â–‚â–ƒ
wandb:                PPO_1187/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1187/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1187/rollout/ep_rew_mean â–‚â–…â–ƒâ–…â–„â–„â–†â–ƒâ–…â–â–…â–ˆ
wandb:                   PPO_1187/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1187/train/approx_kl â–„â–ƒâ–â–…â–…â–ˆâ–…â–ˆâ–â–„â–‚
wandb:        PPO_1187/train/clip_fraction â–„â–ˆâ–â–ƒâ–‚â–†â–…â–†â–„â–â–„
wandb:           PPO_1187/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1187/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1187/train/explained_variance â–‡â–†â–…â–‡â–…â–â–‡â–†â–ˆâ–ˆâ–…
wandb:        PPO_1187/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1187/train/loss â–‡â–…â–ˆâ–‡â–†â–†â–…â–â–ƒâ–ƒâ–ƒ
wandb: PPO_1187/train/policy_gradient_loss â–ƒâ–„â–„â–â–…â–ˆâ–„â–ƒâ–†â–‡â–‡
wandb:                  PPO_1187/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1187/train/value_loss â–‡â–â–ˆâ–†â–ˆâ–ˆâ–‚â–…â–„â–ƒâ–„
wandb:                PPO_1198/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1198/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1198/rollout/ep_rew_mean â–†â–†â–†â–„â–†â–†â–†â–†â–â–…â–ˆâ–†
wandb:                   PPO_1198/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1198/train/approx_kl â–â–ƒâ–…â–ƒâ–ˆâ–„â–†â–†â–ƒâ–…â–†
wandb:        PPO_1198/train/clip_fraction â–„â–„â–…â–â–ˆâ–„â–ƒâ–†â–‚â–…â–…
wandb:           PPO_1198/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1198/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–†â–ˆ
wandb:   PPO_1198/train/explained_variance â–â–ƒâ–‚â–…â–…â–‚â–†â–ˆâ–â–†â–„
wandb:        PPO_1198/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1198/train/loss â–†â–â–‚â–ƒâ–â–ƒâ–â–â–ˆâ–‚â–ƒ
wandb: PPO_1198/train/policy_gradient_loss â–…â–†â–…â–â–ˆâ–„â–„â–‡â–ƒâ–†â–‚
wandb:                  PPO_1198/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1198/train/value_loss â–ƒâ–‚â–‚â–…â–â–‚â–ƒâ–‚â–ˆâ–„â–ƒ
wandb:                    global_mean_eval â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–ƒâ–„â–‡â–‡â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–ƒâ–„â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–ƒâ–„â–‡â–‡â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–ƒâ–ƒâ–‡â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–ƒâ–„â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–ƒâ–„â–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–ƒâ–„â–‡â–‡â–‡â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–ƒâ–„â–‡â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–ƒâ–„â–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–ƒâ–‡â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–„â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–ƒâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–ƒâ–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–ƒâ–ƒâ–‡â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–ƒâ–ƒâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–ƒâ–ƒâ–‡â–‡â–‡â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–ƒâ–ƒâ–‡â–‡â–…â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–ƒâ–‡â–‡â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–ƒâ–ƒâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–ƒâ–„â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                        std_reward_1 â–†â–‚â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                       std_reward_10 â–†â–ƒâ–ƒâ–†â–â–ˆâ–„â–ƒâ–ƒâ–„
wandb:                       std_reward_11 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_12 â–‡â–ƒâ–„â–‡â–â–ˆâ–†â–„â–„â–„
wandb:                       std_reward_13 â–†â–‚â–ƒâ–†â–â–ˆâ–…â–„â–ƒâ–ƒ
wandb:                       std_reward_14 â–‡â–‚â–ƒâ–…â–â–ˆâ–„â–„â–ƒâ–ƒ
wandb:                       std_reward_15 â–†â–‚â–ƒâ–…â–â–ˆâ–„â–„â–ƒâ–„
wandb:                       std_reward_16 â–†â–‚â–ƒâ–†â–â–ˆâ–…â–„â–„â–ƒ
wandb:                       std_reward_17 â–‡â–‚â–„â–†â–â–ˆâ–…â–„â–ƒâ–ƒ
wandb:                       std_reward_18 â–ˆâ–‚â–„â–†â–â–ˆâ–„â–„â–ƒâ–„
wandb:                       std_reward_19 â–†â–‚â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                        std_reward_2 â–†â–‚â–ƒâ–…â–â–ˆâ–„â–„â–ƒâ–ƒ
wandb:                       std_reward_20 â–†â–‚â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–…
wandb:                       std_reward_21 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                       std_reward_22 â–†â–ƒâ–ƒâ–…â–â–ˆâ–…â–ƒâ–‚â–„
wandb:                       std_reward_23 â–†â–‚â–„â–‡â–â–ˆâ–†â–„â–„â–…
wandb:                       std_reward_24 â–…â–‚â–„â–†â–â–ˆâ–†â–„â–ƒâ–„
wandb:                       std_reward_25 â–†â–‚â–ƒâ–„â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                       std_reward_26 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_27 â–…â–‚â–‚â–…â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_28 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                       std_reward_29 â–‡â–‚â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–…
wandb:                        std_reward_3 â–‡â–‚â–ƒâ–…â–â–ˆâ–…â–„â–ƒâ–„
wandb:                       std_reward_30 â–‡â–‚â–ƒâ–…â–â–ˆâ–„â–ƒâ–„â–„
wandb:                       std_reward_31 â–…â–ƒâ–‚â–†â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_32 â–†â–‚â–„â–†â–â–ˆâ–„â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_33 â–†â–‚â–ƒâ–…â–â–ˆâ–„â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_34 â–‡â–‚â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                       std_reward_35 â–†â–ƒâ–ƒâ–…â–â–ˆâ–…â–„â–‚â–„
wandb:                        std_reward_4 â–…â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–„
wandb:                        std_reward_5 â–†â–‚â–ƒâ–…â–â–ˆâ–„â–ƒâ–ƒâ–ƒ
wandb:                        std_reward_6 â–†â–‚â–ƒâ–…â–â–ˆâ–„â–ƒâ–ƒâ–„
wandb:                        std_reward_7 â–‡â–‚â–„â–†â–â–ˆâ–…â–„â–„â–…
wandb:                        std_reward_8 â–†â–‚â–ƒâ–…â–â–ˆâ–…â–ƒâ–ƒâ–ƒ
wandb:                        std_reward_9 â–†â–‚â–ƒâ–†â–â–ˆâ–†â–„â–‚â–„
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1116/global_step 212992
wandb:        PPO_1116/rollout/ep_len_mean 200.0
wandb:        PPO_1116/rollout/ep_rew_mean -764.61316
wandb:                   PPO_1116/time/fps 1180.0
wandb:            PPO_1116/train/approx_kl 0.01155
wandb:        PPO_1116/train/clip_fraction 0.15005
wandb:           PPO_1116/train/clip_range 0.2
wandb:         PPO_1116/train/entropy_loss -7.76708
wandb:   PPO_1116/train/explained_variance 0.95912
wandb:        PPO_1116/train/learning_rate 0.0003
wandb:                 PPO_1116/train/loss 52.23923
wandb: PPO_1116/train/policy_gradient_loss -0.0082
wandb:                  PPO_1116/train/std 0.73328
wandb:           PPO_1116/train/value_loss 92.09692
wandb:                PPO_1125/global_step 212992
wandb:        PPO_1125/rollout/ep_len_mean 200.0
wandb:        PPO_1125/rollout/ep_rew_mean -634.38531
wandb:                   PPO_1125/time/fps 1176.0
wandb:            PPO_1125/train/approx_kl 0.01532
wandb:        PPO_1125/train/clip_fraction 0.1925
wandb:           PPO_1125/train/clip_range 0.2
wandb:         PPO_1125/train/entropy_loss -6.77512
wandb:   PPO_1125/train/explained_variance 0.98027
wandb:        PPO_1125/train/learning_rate 0.0003
wandb:                 PPO_1125/train/loss 23.81393
wandb: PPO_1125/train/policy_gradient_loss -0.00674
wandb:                  PPO_1125/train/std 0.63537
wandb:           PPO_1125/train/value_loss 54.41357
wandb:                PPO_1136/global_step 212992
wandb:        PPO_1136/rollout/ep_len_mean 200.0
wandb:        PPO_1136/rollout/ep_rew_mean -544.76105
wandb:                   PPO_1136/time/fps 1171.0
wandb:            PPO_1136/train/approx_kl 0.01766
wandb:        PPO_1136/train/clip_fraction 0.21356
wandb:           PPO_1136/train/clip_range 0.2
wandb:         PPO_1136/train/entropy_loss -5.78952
wandb:   PPO_1136/train/explained_variance 0.97544
wandb:        PPO_1136/train/learning_rate 0.0003
wandb:                 PPO_1136/train/loss 16.48898
wandb: PPO_1136/train/policy_gradient_loss -0.00341
wandb:                  PPO_1136/train/std 0.55308
wandb:           PPO_1136/train/value_loss 29.82028
wandb:                PPO_1148/global_step 212992
wandb:        PPO_1148/rollout/ep_len_mean 200.0
wandb:        PPO_1148/rollout/ep_rew_mean -500.98575
wandb:                   PPO_1148/time/fps 1170.0
wandb:            PPO_1148/train/approx_kl 0.01569
wandb:        PPO_1148/train/clip_fraction 0.19767
wandb:           PPO_1148/train/clip_range 0.2
wandb:         PPO_1148/train/entropy_loss -5.00553
wandb:   PPO_1148/train/explained_variance 0.94942
wandb:        PPO_1148/train/learning_rate 0.0003
wandb:                 PPO_1148/train/loss 13.44773
wandb: PPO_1148/train/policy_gradient_loss -0.00053
wandb:                  PPO_1148/train/std 0.49403
wandb:           PPO_1148/train/value_loss 24.53321
wandb:                PPO_1157/global_step 212992
wandb:        PPO_1157/rollout/ep_len_mean 200.0
wandb:        PPO_1157/rollout/ep_rew_mean -539.59314
wandb:                   PPO_1157/time/fps 1168.0
wandb:            PPO_1157/train/approx_kl 0.01602
wandb:        PPO_1157/train/clip_fraction 0.19053
wandb:           PPO_1157/train/clip_range 0.2
wandb:         PPO_1157/train/entropy_loss -4.45727
wandb:   PPO_1157/train/explained_variance 0.98847
wandb:        PPO_1157/train/learning_rate 0.0003
wandb:                 PPO_1157/train/loss 3.81125
wandb: PPO_1157/train/policy_gradient_loss -0.00143
wandb:                  PPO_1157/train/std 0.45741
wandb:           PPO_1157/train/value_loss 21.81461
wandb:                PPO_1167/global_step 212992
wandb:        PPO_1167/rollout/ep_len_mean 200.0
wandb:        PPO_1167/rollout/ep_rew_mean -502.89282
wandb:                   PPO_1167/time/fps 1164.0
wandb:            PPO_1167/train/approx_kl 0.01644
wandb:        PPO_1167/train/clip_fraction 0.23008
wandb:           PPO_1167/train/clip_range 0.2
wandb:         PPO_1167/train/entropy_loss -3.94667
wandb:   PPO_1167/train/explained_variance 0.99489
wandb:        PPO_1167/train/learning_rate 0.0003
wandb:                 PPO_1167/train/loss 7.59322
wandb: PPO_1167/train/policy_gradient_loss -0.00033
wandb:                  PPO_1167/train/std 0.42441
wandb:           PPO_1167/train/value_loss 15.52127
wandb:                PPO_1177/global_step 212992
wandb:        PPO_1177/rollout/ep_len_mean 200.0
wandb:        PPO_1177/rollout/ep_rew_mean -483.66675
wandb:                   PPO_1177/time/fps 1166.0
wandb:            PPO_1177/train/approx_kl 0.01694
wandb:        PPO_1177/train/clip_fraction 0.21706
wandb:           PPO_1177/train/clip_range 0.2
wandb:         PPO_1177/train/entropy_loss -3.51779
wandb:   PPO_1177/train/explained_variance 0.99631
wandb:        PPO_1177/train/learning_rate 0.0003
wandb:                 PPO_1177/train/loss 6.71561
wandb: PPO_1177/train/policy_gradient_loss 5e-05
wandb:                  PPO_1177/train/std 0.40126
wandb:           PPO_1177/train/value_loss 18.40078
wandb:                PPO_1187/global_step 212992
wandb:        PPO_1187/rollout/ep_len_mean 200.0
wandb:        PPO_1187/rollout/ep_rew_mean -456.53333
wandb:                   PPO_1187/time/fps 1163.0
wandb:            PPO_1187/train/approx_kl 0.01822
wandb:        PPO_1187/train/clip_fraction 0.24057
wandb:           PPO_1187/train/clip_range 0.2
wandb:         PPO_1187/train/entropy_loss -2.99241
wandb:   PPO_1187/train/explained_variance 0.99206
wandb:        PPO_1187/train/learning_rate 0.0003
wandb:                 PPO_1187/train/loss 3.57618
wandb: PPO_1187/train/policy_gradient_loss 0.00091
wandb:                  PPO_1187/train/std 0.37118
wandb:           PPO_1187/train/value_loss 16.14437
wandb:                PPO_1198/global_step 212992
wandb:        PPO_1198/rollout/ep_len_mean 200.0
wandb:        PPO_1198/rollout/ep_rew_mean -454.65833
wandb:                   PPO_1198/time/fps 1162.0
wandb:            PPO_1198/train/approx_kl 0.02077
wandb:        PPO_1198/train/clip_fraction 0.25457
wandb:           PPO_1198/train/clip_range 0.2
wandb:         PPO_1198/train/entropy_loss -2.49996
wandb:   PPO_1198/train/explained_variance 0.99545
wandb:        PPO_1198/train/learning_rate 0.0003
wandb:                 PPO_1198/train/loss 6.32369
wandb: PPO_1198/train/policy_gradient_loss -0.00086
wandb:                  PPO_1198/train/std 0.34569
wandb:           PPO_1198/train/value_loss 14.57812
wandb:                    global_mean_eval -427.16949
wandb:                         global_step 212992
wandb:                       mean_reward_0 -426.12243
wandb:                       mean_reward_1 -426.36965
wandb:                      mean_reward_10 -426.67317
wandb:                      mean_reward_11 -421.48387
wandb:                      mean_reward_12 -425.75681
wandb:                      mean_reward_13 -420.84064
wandb:                      mean_reward_14 -430.80794
wandb:                      mean_reward_15 -424.79321
wandb:                      mean_reward_16 -423.89092
wandb:                      mean_reward_17 -420.49006
wandb:                      mean_reward_18 -422.34557
wandb:                      mean_reward_19 -427.62107
wandb:                       mean_reward_2 -429.93496
wandb:                      mean_reward_20 -436.12833
wandb:                      mean_reward_21 -431.00998
wandb:                      mean_reward_22 -426.60929
wandb:                      mean_reward_23 -424.94012
wandb:                      mean_reward_24 -433.38387
wandb:                      mean_reward_25 -425.09866
wandb:                      mean_reward_26 -433.30771
wandb:                      mean_reward_27 -419.32656
wandb:                      mean_reward_28 -426.37329
wandb:                      mean_reward_29 -430.62373
wandb:                       mean_reward_3 -429.58605
wandb:                      mean_reward_30 -434.37606
wandb:                      mean_reward_31 -422.69081
wandb:                      mean_reward_32 -419.74876
wandb:                      mean_reward_33 -431.56773
wandb:                      mean_reward_34 -426.06605
wandb:                      mean_reward_35 -433.28122
wandb:                       mean_reward_4 -435.79192
wandb:                       mean_reward_5 -429.3578
wandb:                       mean_reward_6 -429.05185
wandb:                       mean_reward_7 -426.52131
wandb:                       mean_reward_8 -423.55908
wandb:                       mean_reward_9 -422.57114
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 42.32701
wandb:                        std_reward_1 51.77243
wandb:                       std_reward_10 50.26745
wandb:                       std_reward_11 47.85057
wandb:                       std_reward_12 45.83664
wandb:                       std_reward_13 40.29571
wandb:                       std_reward_14 45.46179
wandb:                       std_reward_15 48.00129
wandb:                       std_reward_16 46.45779
wandb:                       std_reward_17 43.37865
wandb:                       std_reward_18 49.95932
wandb:                       std_reward_19 50.61582
wandb:                        std_reward_2 47.68979
wandb:                       std_reward_20 59.0702
wandb:                       std_reward_21 55.2789
wandb:                       std_reward_22 54.90933
wandb:                       std_reward_23 54.684
wandb:                       std_reward_24 51.9567
wandb:                       std_reward_25 54.20555
wandb:                       std_reward_26 46.74819
wandb:                       std_reward_27 43.84924
wandb:                       std_reward_28 51.20647
wandb:                       std_reward_29 56.97984
wandb:                        std_reward_3 50.62087
wandb:                       std_reward_30 51.50303
wandb:                       std_reward_31 45.44872
wandb:                       std_reward_32 42.3609
wandb:                       std_reward_33 47.81331
wandb:                       std_reward_34 52.32255
wandb:                       std_reward_35 49.34264
wandb:                        std_reward_4 52.33741
wandb:                        std_reward_5 42.3453
wandb:                        std_reward_6 52.36154
wandb:                        std_reward_7 53.1219
wandb:                        std_reward_8 46.58897
wandb:                        std_reward_9 52.69047
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced spring-surf-24: https://wandb.ai/tidiane/meta_rl_context/runs/1jxiownk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-1jxiownk/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1121/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1121/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1121/rollout/ep_rew_mean â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–‡
wandb:                   PPO_1121/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1121/train/approx_kl â–â–…â–ˆâ–†â–†â–†â–ƒâ–‡â–…â–ƒâ–†
wandb:        PPO_1121/train/clip_fraction â–â–‚â–‡â–†â–„â–†â–„â–‡â–†â–„â–ˆ
wandb:           PPO_1121/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1121/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1121/train/explained_variance â–ˆâ–â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–„â–…
wandb:        PPO_1121/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1121/train/loss â–â–‚â–â–ƒâ–‚â–â–‚â–ƒâ–â–ˆâ–
wandb: PPO_1121/train/policy_gradient_loss â–ˆâ–ˆâ–â–„â–„â–…â–†â–‡â–†â–ˆâ–…
wandb:                  PPO_1121/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1121/train/value_loss â–â–„â–‚â–ƒâ–…â–ƒâ–…â–„â–„â–ˆâ–„
wandb:                PPO_1131/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1131/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1131/rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–„â–…â–†â–‡â–ˆ
wandb:                   PPO_1131/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1131/train/approx_kl â–â–ƒâ–â–â–…â–â–†â–†â–ˆâ–„â–†
wandb:        PPO_1131/train/clip_fraction â–â–„â–â–„â–†â–„â–…â–ˆâ–ˆâ–†â–‡
wandb:           PPO_1131/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1131/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1131/train/explained_variance â–â–„â–„â–ƒâ–ƒâ–ƒâ–‡â–ˆâ–ƒâ–‡â–†
wandb:        PPO_1131/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1131/train/loss â–‚â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–‚â–ˆ
wandb: PPO_1131/train/policy_gradient_loss â–†â–„â–ˆâ–†â–†â–…â–â–„â–…â–…â–†
wandb:                  PPO_1131/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1131/train/value_loss â–ˆâ–‡â–‡â–ƒâ–â–‚â–„â–â–„â–ƒâ–ƒ
wandb:                PPO_1140/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1140/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1140/rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–„â–ƒâ–„â–…â–†â–‡â–ˆ
wandb:                   PPO_1140/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1140/train/approx_kl â–â–…â–ƒâ–„â–ˆâ–…â–ˆâ–ƒâ–ˆâ–†â–‚
wandb:        PPO_1140/train/clip_fraction â–â–„â–ƒâ–„â–‚â–ƒâ–ˆâ–ƒâ–…â–„â–‡
wandb:           PPO_1140/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1140/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1140/train/explained_variance â–…â–…â–‡â–‡â–…â–…â–ˆâ–‡â–â–„â–‡
wandb:        PPO_1140/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1140/train/loss â–‚â–â–†â–â–‡â–„â–ƒâ–â–„â–…â–ˆ
wandb: PPO_1140/train/policy_gradient_loss â–ƒâ–‚â–„â–ƒâ–â–ƒâ–„â–„â–…â–‡â–ˆ
wandb:                  PPO_1140/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1140/train/value_loss â–„â–‚â–ƒâ–„â–…â–†â–â–ƒâ–†â–ˆâ–‚
wandb:                PPO_1150/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1150/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1150/rollout/ep_rew_mean â–„â–„â–â–‚â–„â–‚â–„â–…â–ˆâ–ƒâ–‡â–„
wandb:                   PPO_1150/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1150/train/approx_kl â–‡â–ˆâ–â–‡â–„â–‡â–‡â–‡â–‡â–â–…
wandb:        PPO_1150/train/clip_fraction â–†â–‡â–â–‡â–†â–ƒâ–†â–ˆâ–‡â–â–†
wandb:           PPO_1150/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1150/train/entropy_loss â–â–‚â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:   PPO_1150/train/explained_variance â–ƒâ–…â–â–ƒâ–„â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:        PPO_1150/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1150/train/loss â–ƒâ–‚â–ˆâ–…â–â–ˆâ–‡â–…â–‚â–ƒâ–‡
wandb: PPO_1150/train/policy_gradient_loss â–â–‡â–‡â–ƒâ–ˆâ–‡â–…â–ƒâ–„â–„â–‡
wandb:                  PPO_1150/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1150/train/value_loss â–‚â–ƒâ–ˆâ–ƒâ–†â–ˆâ–‡â–ƒâ–â–‡â–„
wandb:                PPO_1160/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1160/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1160/rollout/ep_rew_mean â–‡â–†â–…â–â–â–ˆâ–†â–‡â–ƒâ–†â–ˆâ–ˆ
wandb:                   PPO_1160/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1160/train/approx_kl â–‚â–‚â–‚â–â–‚â–…â–‡â–„â–â–…â–ˆ
wandb:        PPO_1160/train/clip_fraction â–ƒâ–ƒâ–ƒâ–â–‚â–…â–†â–„â–‚â–ƒâ–ˆ
wandb:           PPO_1160/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1160/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1160/train/explained_variance â–â–‚â–â–…â–‡â–…â–ˆâ–ˆâ–‡â–‚â–†
wandb:        PPO_1160/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1160/train/loss â–…â–„â–‚â–…â–…â–„â–‚â–â–„â–…â–ˆ
wandb: PPO_1160/train/policy_gradient_loss â–â–…â–‚â–â–‚â–„â–…â–â–ƒâ–„â–ˆ
wandb:                  PPO_1160/train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1160/train/value_loss â–ƒâ–…â–…â–ˆâ–…â–ƒâ–â–ƒâ–†â–…â–‚
wandb:                PPO_1170/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1170/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1170/rollout/ep_rew_mean â–…â–ƒâ–â–…â–„â–ƒâ–â–„â–…â–…â–„â–ˆ
wandb:                   PPO_1170/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1170/train/approx_kl â–„â–â–â–ˆâ–â–…â–‚â–†â–ƒâ–ˆâ–…
wandb:        PPO_1170/train/clip_fraction â–†â–â–ƒâ–ˆâ–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:           PPO_1170/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1170/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1170/train/explained_variance â–ˆâ–‡â–ˆâ–â–‡â–ˆâ–‡â–‡â–†â–ƒâ–‡
wandb:        PPO_1170/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1170/train/loss â–‚â–‡â–ƒâ–â–ƒâ–ˆâ–†â–„â–‚â–ƒâ–‚
wandb: PPO_1170/train/policy_gradient_loss â–ˆâ–‚â–„â–†â–â–…â–‡â–ƒâ–â–…â–„
wandb:                  PPO_1170/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1170/train/value_loss â–‚â–‡â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆâ–‡â–
wandb:                PPO_1180/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1180/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1180/rollout/ep_rew_mean â–„â–â–ƒâ–„â–ƒâ–†â–‡â–ˆâ–…â–‚â–†â–ƒ
wandb:                   PPO_1180/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1180/train/approx_kl â–ƒâ–ƒâ–†â–„â–„â–„â–„â–â–ˆâ–„â–‡
wandb:        PPO_1180/train/clip_fraction â–â–â–…â–‡â–‚â–ˆâ–‚â–ƒâ–†â–„â–†
wandb:           PPO_1180/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1180/train/entropy_loss â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1180/train/explained_variance â–…â–†â–„â–‚â–â–ˆâ–â–â–ƒâ–…â–ƒ
wandb:        PPO_1180/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1180/train/loss â–‚â–ƒâ–‚â–â–ˆâ–â–ƒâ–â–†â–‚â–…
wandb: PPO_1180/train/policy_gradient_loss â–‚â–‚â–‡â–ˆâ–„â–ˆâ–„â–†â–†â–â–†
wandb:                  PPO_1180/train/std â–ˆâ–‡â–†â–†â–†â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1180/train/value_loss â–„â–†â–†â–‡â–ˆâ–â–ƒâ–ƒâ–…â–ˆâ–‡
wandb:                PPO_1190/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1190/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1190/rollout/ep_rew_mean â–†â–†â–â–ƒâ–…â–„â–ˆâ–ƒâ–…â–„â–‡â–‡
wandb:                   PPO_1190/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1190/train/approx_kl â–‚â–â–‚â–ˆâ–ƒâ–ˆâ–â–…â–…â–…â–ˆ
wandb:        PPO_1190/train/clip_fraction â–†â–â–„â–ˆâ–„â–„â–‡â–„â–…â–„â–ˆ
wandb:           PPO_1190/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1190/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1190/train/explained_variance â–…â–â–„â–‡â–‚â–†â–ˆâ–„â–„â–†â–„
wandb:        PPO_1190/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1190/train/loss â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–â–â–‚â–‚
wandb: PPO_1190/train/policy_gradient_loss â–…â–‚â–†â–ˆâ–…â–ƒâ–…â–†â–ƒâ–â–ˆ
wandb:                  PPO_1190/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1190/train/value_loss â–ƒâ–‡â–‡â–ˆâ–…â–†â–â–‚â–„â–†â–„
wandb:                PPO_1200/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1200/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1200/rollout/ep_rew_mean â–…â–…â–†â–…â–†â–ƒâ–‚â–â–ˆâ–‡â–ˆâ–…
wandb:                   PPO_1200/time/fps â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1200/train/approx_kl â–†â–…â–â–ƒâ–„â–…â–†â–„â–ˆâ–‡â–„
wandb:        PPO_1200/train/clip_fraction â–…â–…â–‚â–‚â–ƒâ–…â–ˆâ–â–…â–„â–ƒ
wandb:           PPO_1200/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1200/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1200/train/explained_variance â–â–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–„â–†â–‡
wandb:        PPO_1200/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1200/train/loss â–„â–…â–„â–â–…â–ˆâ–‚â–ƒâ–‚â–â–
wandb: PPO_1200/train/policy_gradient_loss â–‚â–ˆâ–…â–†â–…â–†â–†â–â–…â–ƒâ–†
wandb:                  PPO_1200/train/std â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–â–
wandb:           PPO_1200/train/value_loss â–‡â–ƒâ–â–ƒâ–‚â–‚â–…â–ˆâ–„â–…â–„
wandb:                    global_mean_eval â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–‚â–„â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_10 â–â–‚â–„â–†â–„â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_11 â–â–‚â–„â–†â–„â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_12 â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_13 â–â–‚â–„â–†â–„â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_14 â–â–‚â–…â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–‚â–„â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–‚â–„â–†â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–‚â–„â–…â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–‚â–„â–†â–…â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–‚â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–‚â–„â–†â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–‚â–„â–†â–„â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_21 â–â–‚â–„â–†â–…â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–‚â–„â–‡â–…â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_23 â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_24 â–â–‚â–„â–†â–…â–‡â–‡â–†â–‡â–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_26 â–â–‚â–„â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_27 â–â–ƒâ–…â–†â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–‚â–„â–‡â–…â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_29 â–â–‚â–„â–†â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–‚â–„â–†â–…â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–‚â–…â–†â–…â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–‚â–„â–†â–…â–…â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_32 â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_33 â–â–‚â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_34 â–â–‚â–…â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–…â–†â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–‚â–„â–†â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–‚â–„â–†â–„â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_6 â–â–‚â–…â–†â–…â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_8 â–â–‚â–„â–†â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–‚â–„â–†â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–„
wandb:                        std_reward_1 â–‚â–â–â–„â–ˆâ–…â–„â–ƒâ–„â–„
wandb:                       std_reward_10 â–‚â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–ƒ
wandb:                       std_reward_11 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_12 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_13 â–‚â–â–â–ƒâ–ˆâ–…â–‚â–ƒâ–ƒâ–ƒ
wandb:                       std_reward_14 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–„
wandb:                       std_reward_15 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_16 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_17 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_18 â–‚â–â–â–„â–ˆâ–…â–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_19 â–‚â–â–â–ƒâ–ˆâ–†â–„â–ƒâ–„â–„
wandb:                        std_reward_2 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–„
wandb:                       std_reward_20 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_21 â–‚â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–ƒ
wandb:                       std_reward_22 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–„â–ƒ
wandb:                       std_reward_23 â–‚â–â–â–„â–ˆâ–†â–ƒâ–„â–„â–„
wandb:                       std_reward_24 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–„â–ƒ
wandb:                       std_reward_25 â–â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_26 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–ƒ
wandb:                       std_reward_27 â–‚â–â–â–„â–ˆâ–…â–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_28 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–„
wandb:                       std_reward_29 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–ƒ
wandb:                        std_reward_3 â–‚â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                       std_reward_30 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–„
wandb:                       std_reward_31 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–„â–„â–ƒ
wandb:                       std_reward_32 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–ƒ
wandb:                       std_reward_33 â–‚â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–„
wandb:                       std_reward_34 â–‚â–â–‚â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–„
wandb:                       std_reward_35 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–„
wandb:                        std_reward_4 â–‚â–â–â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–„
wandb:                        std_reward_5 â–â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                        std_reward_6 â–‚â–â–â–ƒâ–ˆâ–…â–‚â–ƒâ–ƒâ–„
wandb:                        std_reward_7 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–ƒ
wandb:                        std_reward_8 â–‚â–â–â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–„
wandb:                        std_reward_9 â–â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–„â–ƒ
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1121/global_step 212992
wandb:        PPO_1121/rollout/ep_len_mean 200.0
wandb:        PPO_1121/rollout/ep_rew_mean -814.53625
wandb:                   PPO_1121/time/fps 1177.0
wandb:            PPO_1121/train/approx_kl 0.01277
wandb:        PPO_1121/train/clip_fraction 0.17025
wandb:           PPO_1121/train/clip_range 0.2
wandb:         PPO_1121/train/entropy_loss -7.71907
wandb:   PPO_1121/train/explained_variance 0.95801
wandb:        PPO_1121/train/learning_rate 0.0003
wandb:                 PPO_1121/train/loss 17.68281
wandb: PPO_1121/train/policy_gradient_loss -0.00888
wandb:                  PPO_1121/train/std 0.72821
wandb:           PPO_1121/train/value_loss 85.28061
wandb:                PPO_1131/global_step 212992
wandb:        PPO_1131/rollout/ep_len_mean 200.0
wandb:        PPO_1131/rollout/ep_rew_mean -729.67847
wandb:                   PPO_1131/time/fps 1167.0
wandb:            PPO_1131/train/approx_kl 0.01495
wandb:        PPO_1131/train/clip_fraction 0.19674
wandb:           PPO_1131/train/clip_range 0.2
wandb:         PPO_1131/train/entropy_loss -6.82301
wandb:   PPO_1131/train/explained_variance 0.96536
wandb:        PPO_1131/train/learning_rate 0.0003
wandb:                 PPO_1131/train/loss 54.72609
wandb: PPO_1131/train/policy_gradient_loss -0.00735
wandb:                  PPO_1131/train/std 0.64101
wandb:           PPO_1131/train/value_loss 43.35217
wandb:                PPO_1140/global_step 212992
wandb:        PPO_1140/rollout/ep_len_mean 200.0
wandb:        PPO_1140/rollout/ep_rew_mean -555.20276
wandb:                   PPO_1140/time/fps 1164.0
wandb:            PPO_1140/train/approx_kl 0.01501
wandb:        PPO_1140/train/clip_fraction 0.21677
wandb:           PPO_1140/train/clip_range 0.2
wandb:         PPO_1140/train/entropy_loss -6.08575
wandb:   PPO_1140/train/explained_variance 0.97165
wandb:        PPO_1140/train/learning_rate 0.0003
wandb:                 PPO_1140/train/loss 38.80249
wandb: PPO_1140/train/policy_gradient_loss -0.00353
wandb:                  PPO_1140/train/std 0.57674
wandb:           PPO_1140/train/value_loss 43.11947
wandb:                PPO_1150/global_step 212992
wandb:        PPO_1150/rollout/ep_len_mean 200.0
wandb:        PPO_1150/rollout/ep_rew_mean -580.68933
wandb:                   PPO_1150/time/fps 1152.0
wandb:            PPO_1150/train/approx_kl 0.01529
wandb:        PPO_1150/train/clip_fraction 0.19775
wandb:           PPO_1150/train/clip_range 0.2
wandb:         PPO_1150/train/entropy_loss -5.61789
wandb:   PPO_1150/train/explained_variance 0.98922
wandb:        PPO_1150/train/learning_rate 0.0003
wandb:                 PPO_1150/train/loss 74.46011
wandb: PPO_1150/train/policy_gradient_loss -0.0033
wandb:                  PPO_1150/train/std 0.53993
wandb:           PPO_1150/train/value_loss 92.94354
wandb:                PPO_1160/global_step 212992
wandb:        PPO_1160/rollout/ep_len_mean 200.0
wandb:        PPO_1160/rollout/ep_rew_mean -532.73938
wandb:                   PPO_1160/time/fps 1175.0
wandb:            PPO_1160/train/approx_kl 0.01974
wandb:        PPO_1160/train/clip_fraction 0.26909
wandb:           PPO_1160/train/clip_range 0.2
wandb:         PPO_1160/train/entropy_loss -5.1251
wandb:   PPO_1160/train/explained_variance 0.99511
wandb:        PPO_1160/train/learning_rate 0.0003
wandb:                 PPO_1160/train/loss 60.86214
wandb: PPO_1160/train/policy_gradient_loss -0.0005
wandb:                  PPO_1160/train/std 0.50183
wandb:           PPO_1160/train/value_loss 52.68937
wandb:                PPO_1170/global_step 212992
wandb:        PPO_1170/rollout/ep_len_mean 200.0
wandb:        PPO_1170/rollout/ep_rew_mean -461.85205
wandb:                   PPO_1170/time/fps 1173.0
wandb:            PPO_1170/train/approx_kl 0.021
wandb:        PPO_1170/train/clip_fraction 0.2578
wandb:           PPO_1170/train/clip_range 0.2
wandb:         PPO_1170/train/entropy_loss -4.56233
wandb:   PPO_1170/train/explained_variance 0.99367
wandb:        PPO_1170/train/learning_rate 0.0003
wandb:                 PPO_1170/train/loss 13.65897
wandb: PPO_1170/train/policy_gradient_loss -0.00182
wandb:                  PPO_1170/train/std 0.46386
wandb:           PPO_1170/train/value_loss 32.60191
wandb:                PPO_1180/global_step 212992
wandb:        PPO_1180/rollout/ep_len_mean 200.0
wandb:        PPO_1180/rollout/ep_rew_mean -483.05478
wandb:                   PPO_1180/time/fps 1168.0
wandb:            PPO_1180/train/approx_kl 0.02446
wandb:        PPO_1180/train/clip_fraction 0.27141
wandb:           PPO_1180/train/clip_range 0.2
wandb:         PPO_1180/train/entropy_loss -3.91078
wandb:   PPO_1180/train/explained_variance 0.99474
wandb:        PPO_1180/train/learning_rate 0.0003
wandb:                 PPO_1180/train/loss 33.14694
wandb: PPO_1180/train/policy_gradient_loss 0.00145
wandb:                  PPO_1180/train/std 0.42259
wandb:           PPO_1180/train/value_loss 51.00081
wandb:                PPO_1190/global_step 212992
wandb:        PPO_1190/rollout/ep_len_mean 200.0
wandb:        PPO_1190/rollout/ep_rew_mean -436.42831
wandb:                   PPO_1190/time/fps 1165.0
wandb:            PPO_1190/train/approx_kl 0.02657
wandb:        PPO_1190/train/clip_fraction 0.30443
wandb:           PPO_1190/train/clip_range 0.2
wandb:         PPO_1190/train/entropy_loss -3.31628
wandb:   PPO_1190/train/explained_variance 0.99533
wandb:        PPO_1190/train/learning_rate 0.0003
wandb:                 PPO_1190/train/loss 5.53272
wandb: PPO_1190/train/policy_gradient_loss 0.0043
wandb:                  PPO_1190/train/std 0.38817
wandb:           PPO_1190/train/value_loss 36.84404
wandb:                PPO_1200/global_step 212992
wandb:        PPO_1200/rollout/ep_len_mean 200.0
wandb:        PPO_1200/rollout/ep_rew_mean -418.2193
wandb:                   PPO_1200/time/fps 1166.0
wandb:            PPO_1200/train/approx_kl 0.0228
wandb:        PPO_1200/train/clip_fraction 0.28937
wandb:           PPO_1200/train/clip_range 0.2
wandb:         PPO_1200/train/entropy_loss -2.88643
wandb:   PPO_1200/train/explained_variance 0.99632
wandb:        PPO_1200/train/learning_rate 0.0003
wandb:                 PPO_1200/train/loss 3.66067
wandb: PPO_1200/train/policy_gradient_loss 0.00329
wandb:                  PPO_1200/train/std 0.36603
wandb:           PPO_1200/train/value_loss 25.13123
wandb:                    global_mean_eval -362.8814
wandb:                         global_step 212992
wandb:                       mean_reward_0 -359.25258
wandb:                       mean_reward_1 -356.65708
wandb:                      mean_reward_10 -360.90328
wandb:                      mean_reward_11 -339.45626
wandb:                      mean_reward_12 -342.44594
wandb:                      mean_reward_13 -345.62393
wandb:                      mean_reward_14 -383.2747
wandb:                      mean_reward_15 -366.04616
wandb:                      mean_reward_16 -357.22906
wandb:                      mean_reward_17 -360.49058
wandb:                      mean_reward_18 -367.24069
wandb:                      mean_reward_19 -375.62765
wandb:                       mean_reward_2 -383.78389
wandb:                      mean_reward_20 -348.36969
wandb:                      mean_reward_21 -362.65826
wandb:                      mean_reward_22 -373.19144
wandb:                      mean_reward_23 -367.87347
wandb:                      mean_reward_24 -348.16302
wandb:                      mean_reward_25 -364.95497
wandb:                      mean_reward_26 -354.41146
wandb:                      mean_reward_27 -377.63155
wandb:                      mean_reward_28 -377.39074
wandb:                      mean_reward_29 -372.4352
wandb:                       mean_reward_3 -363.20695
wandb:                      mean_reward_30 -379.07418
wandb:                      mean_reward_31 -328.64959
wandb:                      mean_reward_32 -347.09675
wandb:                      mean_reward_33 -368.37569
wandb:                      mean_reward_34 -379.33015
wandb:                      mean_reward_35 -380.5612
wandb:                       mean_reward_4 -389.13455
wandb:                       mean_reward_5 -348.00405
wandb:                       mean_reward_6 -380.44897
wandb:                       mean_reward_7 -341.6057
wandb:                       mean_reward_8 -386.19998
wandb:                       mean_reward_9 -326.93102
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 143.54135
wandb:                        std_reward_1 138.61459
wandb:                       std_reward_10 145.80737
wandb:                       std_reward_11 137.59549
wandb:                       std_reward_12 134.18119
wandb:                       std_reward_13 122.65295
wandb:                       std_reward_14 149.02075
wandb:                       std_reward_15 146.65232
wandb:                       std_reward_16 135.05189
wandb:                       std_reward_17 145.72375
wandb:                       std_reward_18 143.23654
wandb:                       std_reward_19 154.14007
wandb:                        std_reward_2 160.50854
wandb:                       std_reward_20 133.13621
wandb:                       std_reward_21 145.88288
wandb:                       std_reward_22 147.83639
wandb:                       std_reward_23 149.24221
wandb:                       std_reward_24 134.44741
wandb:                       std_reward_25 140.69146
wandb:                       std_reward_26 140.97521
wandb:                       std_reward_27 153.65389
wandb:                       std_reward_28 157.14261
wandb:                       std_reward_29 153.7738
wandb:                        std_reward_3 147.90564
wandb:                       std_reward_30 155.70609
wandb:                       std_reward_31 118.7647
wandb:                       std_reward_32 139.07409
wandb:                       std_reward_33 149.96956
wandb:                       std_reward_34 150.705
wandb:                       std_reward_35 153.10904
wandb:                        std_reward_4 162.8246
wandb:                        std_reward_5 138.69479
wandb:                        std_reward_6 159.07173
wandb:                        std_reward_7 133.14694
wandb:                        std_reward_8 157.28754
wandb:                        std_reward_9 108.72189
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced wise-totem-24: https://wandb.ai/tidiane/meta_rl_context/runs/15smaiuw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-15smaiuw/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1120/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1120/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1120/rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                   PPO_1120/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1120/train/approx_kl â–â–‚â–†â–†â–ˆâ–…â–‡â–ˆâ–†â–„â–ƒ
wandb:        PPO_1120/train/clip_fraction â–‚â–â–†â–†â–†â–„â–…â–ˆâ–‡â–„â–…
wandb:           PPO_1120/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1120/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1120/train/explained_variance â–ƒâ–â–…â–ˆâ–‡â–‡â–…â–‡â–„â–†â–…
wandb:        PPO_1120/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1120/train/loss â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–‚
wandb: PPO_1120/train/policy_gradient_loss â–‚â–‡â–„â–â–…â–…â–‡â–‚â–„â–†â–ˆ
wandb:                  PPO_1120/train/std â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1120/train/value_loss â–â–‚â–ƒâ–â–ƒâ–„â–‡â–„â–†â–ˆâ–‡
wandb:                PPO_1130/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1130/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1130/rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–†â–†â–‡â–ˆ
wandb:                   PPO_1130/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1130/train/approx_kl â–â–‚â–ƒâ–„â–…â–„â–…â–â–…â–ƒâ–ˆ
wandb:        PPO_1130/train/clip_fraction â–â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–„â–†â–…â–ˆ
wandb:           PPO_1130/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1130/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1130/train/explained_variance â–ˆâ–„â–„â–‡â–†â–†â–„â–…â–â–†â–†
wandb:        PPO_1130/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1130/train/loss â–†â–â–ˆâ–ƒâ–„â–‡â–…â–‚â–â–ƒâ–ƒ
wandb: PPO_1130/train/policy_gradient_loss â–ƒâ–„â–ƒâ–ƒâ–â–„â–„â–†â–ˆâ–…â–ƒ
wandb:                  PPO_1130/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1130/train/value_loss â–‡â–…â–„â–…â–ˆâ–…â–„â–†â–‚â–â–
wandb:                PPO_1141/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1141/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1141/rollout/ep_rew_mean â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–‡â–†â–ˆ
wandb:                   PPO_1141/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1141/train/approx_kl â–â–ƒâ–‚â–‚â–‚â–ƒâ–„â–‚â–ˆâ–…â–‡
wandb:        PPO_1141/train/clip_fraction â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‡â–ˆâ–†
wandb:           PPO_1141/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1141/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1141/train/explained_variance â–„â–…â–â–…â–†â–ˆâ–ˆâ–‡â–ˆâ–…â–‡
wandb:        PPO_1141/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1141/train/loss â–…â–…â–ˆâ–‚â–…â–â–‚â–‚â–†â–ƒâ–
wandb: PPO_1141/train/policy_gradient_loss â–„â–â–…â–‡â–ˆâ–†â–…â–†â–ˆâ–†â–ˆ
wandb:                  PPO_1141/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1141/train/value_loss â–ˆâ–…â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–
wandb:                PPO_1151/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1151/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1151/rollout/ep_rew_mean â–â–ƒâ–ƒâ–„â–ƒâ–…â–ˆâ–…â–†â–ˆâ–‡â–†
wandb:                   PPO_1151/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1151/train/approx_kl â–â–„â–†â–†â–„â–†â–ˆâ–„â–†â–‡â–‡
wandb:        PPO_1151/train/clip_fraction â–‚â–ƒâ–…â–†â–…â–†â–ˆâ–â–ˆâ–†â–„
wandb:           PPO_1151/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1151/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1151/train/explained_variance â–ˆâ–†â–†â–‡â–ˆâ–†â–‡â–â–â–ƒâ–‚
wandb:        PPO_1151/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1151/train/loss â–‚â–ƒâ–„â–‚â–â–„â–„â–‚â–ˆâ–ƒâ–‚
wandb: PPO_1151/train/policy_gradient_loss â–ƒâ–â–„â–„â–â–†â–†â–…â–†â–ˆâ–†
wandb:                  PPO_1151/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1151/train/value_loss â–‚â–‡â–ˆâ–†â–…â–‚â–â–ˆâ–‡â–„â–†
wandb:                PPO_1161/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1161/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1161/rollout/ep_rew_mean â–…â–„â–…â–…â–‡â–†â–†â–â–â–‚â–ƒâ–ˆ
wandb:                   PPO_1161/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1161/train/approx_kl â–„â–†â–…â–‡â–ˆâ–„â–ƒâ–â–‚â–ƒâ–„
wandb:        PPO_1161/train/clip_fraction â–ˆâ–„â–ˆâ–‡â–‡â–ˆâ–â–ƒâ–„â–ƒâ–†
wandb:           PPO_1161/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1161/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–†â–‡â–ˆ
wandb:   PPO_1161/train/explained_variance â–ƒâ–‚â–â–†â–…â–‡â–†â–…â–‡â–‡â–ˆ
wandb:        PPO_1161/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1161/train/loss â–â–ƒâ–ˆâ–„â–‚â–â–„â–„â–…â–‚â–„
wandb: PPO_1161/train/policy_gradient_loss â–ˆâ–ƒâ–…â–„â–‚â–„â–â–…â–ƒâ–„â–„
wandb:                  PPO_1161/train/std â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–…â–ƒâ–‚â–
wandb:           PPO_1161/train/value_loss â–†â–ˆâ–†â–…â–„â–â–…â–‡â–†â–…â–„
wandb:                PPO_1171/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1171/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1171/rollout/ep_rew_mean â–â–†â–‡â–…â–‡â–…â–†â–‡â–‡â–†â–ˆâ–‡
wandb:                   PPO_1171/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1171/train/approx_kl â–„â–â–ƒâ–…â–‡â–†â–‡â–†â–ˆâ–â–‡
wandb:        PPO_1171/train/clip_fraction â–â–…â–ƒâ–„â–ˆâ–„â–‡â–‡â–ƒâ–ƒâ–ˆ
wandb:           PPO_1171/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1171/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1171/train/explained_variance â–â–†â–ˆâ–†â–†â–…â–…â–ˆâ–†â–…â–†
wandb:        PPO_1171/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1171/train/loss â–‚â–‚â–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–â–ˆâ–
wandb: PPO_1171/train/policy_gradient_loss â–‚â–ˆâ–‡â–‚â–„â–…â–„â–‚â–â–†â–†
wandb:                  PPO_1171/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1171/train/value_loss â–ˆâ–ƒâ–‚â–„â–â–„â–„â–â–…â–†â–‚
wandb:                PPO_1181/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1181/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1181/rollout/ep_rew_mean â–â–‚â–‡â–„â–†â–ˆâ–…â–‚â–…â–…â–„â–ˆ
wandb:                   PPO_1181/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1181/train/approx_kl â–„â–‚â–ˆâ–â–†â–†â–ƒâ–…â–…â–‚â–…
wandb:        PPO_1181/train/clip_fraction â–…â–‚â–‡â–â–†â–…â–‚â–ƒâ–ˆâ–„â–„
wandb:           PPO_1181/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1181/train/entropy_loss â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–ˆâ–†
wandb:   PPO_1181/train/explained_variance â–‚â–â–…â–ƒâ–ˆâ–ˆâ–‡â–†â–‚â–‡â–…
wandb:        PPO_1181/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1181/train/loss â–†â–ˆâ–‚â–…â–â–‚â–‚â–‡â–„â–ƒâ–ƒ
wandb: PPO_1181/train/policy_gradient_loss â–ƒâ–…â–„â–â–†â–ˆâ–„â–â–‡â–„â–…
wandb:                  PPO_1181/train/std â–ˆâ–†â–„â–†â–†â–…â–„â–ƒâ–â–â–‚
wandb:           PPO_1181/train/value_loss â–†â–‡â–ƒâ–ˆâ–â–‚â–„â–ˆâ–â–ƒâ–ƒ
wandb:                PPO_1191/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1191/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1191/rollout/ep_rew_mean â–ƒâ–â–â–â–‚â–„â–†â–„â–ˆâ–‡â–†â–†
wandb:                   PPO_1191/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1191/train/approx_kl â–„â–ˆâ–â–ƒâ–‡â–ˆâ–…â–…â–‡â–†â–…
wandb:        PPO_1191/train/clip_fraction â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–‚
wandb:           PPO_1191/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1191/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1191/train/explained_variance â–â–ƒâ–…â–…â–‚â–…â–†â–ƒâ–ƒâ–â–ˆ
wandb:        PPO_1191/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1191/train/loss â–‚â–…â–ƒâ–„â–â–„â–‚â–†â–â–â–ˆ
wandb: PPO_1191/train/policy_gradient_loss â–‡â–„â–‚â–…â–â–„â–…â–„â–ˆâ–„â–„
wandb:                  PPO_1191/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1191/train/value_loss â–†â–‡â–ˆâ–ƒâ–„â–ƒâ–„â–ˆâ–â–‚â–…
wandb:                PPO_1201/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1201/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1201/rollout/ep_rew_mean â–‚â–â–â–ƒâ–ƒâ–‚â–ˆâ–…â–†â–†â–‡â–†
wandb:                   PPO_1201/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1201/train/approx_kl â–…â–…â–‡â–…â–„â–â–…â–‡â–…â–ˆâ–†
wandb:        PPO_1201/train/clip_fraction â–„â–â–‡â–†â–„â–„â–ˆâ–†â–„â–†â–ƒ
wandb:           PPO_1201/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1201/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1201/train/explained_variance â–â–‡â–…â–ˆâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        PPO_1201/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1201/train/loss â–‚â–ˆâ–‡â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–„â–
wandb: PPO_1201/train/policy_gradient_loss â–†â–â–†â–ˆâ–†â–„â–ˆâ–ƒâ–„â–…â–‡
wandb:                  PPO_1201/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1201/train/value_loss â–ˆâ–ˆâ–†â–‚â–ƒâ–ƒâ–â–â–â–â–‚
wandb:                    global_mean_eval â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_11 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–ƒâ–…â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–…â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–„â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–ƒâ–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–â–â–â–‚â–ƒâ–‡â–ˆâ–„â–…â–„
wandb:                        std_reward_1 â–‚â–â–â–ƒâ–„â–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_10 â–‚â–â–â–‚â–„â–ˆâ–‡â–„â–…â–ƒ
wandb:                       std_reward_11 â–‚â–â–â–‚â–ƒâ–‡â–ˆâ–„â–…â–„
wandb:                       std_reward_12 â–‚â–â–â–ƒâ–ƒâ–ˆâ–ˆâ–„â–…â–„
wandb:                       std_reward_13 â–â–â–â–‚â–„â–ˆâ–ˆâ–…â–„â–ƒ
wandb:                       std_reward_14 â–‚â–â–â–ƒâ–„â–ˆâ–ˆâ–„â–…â–„
wandb:                       std_reward_15 â–‚â–â–â–‚â–„â–ˆâ–ˆâ–„â–…â–„
wandb:                       std_reward_16 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–„â–„
wandb:                       std_reward_17 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_18 â–‚â–â–â–‚â–„â–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_19 â–‚â–â–â–‚â–ƒâ–‡â–ˆâ–„â–…â–ƒ
wandb:                        std_reward_2 â–‚â–â–â–ƒâ–ƒâ–†â–ˆâ–…â–…â–„
wandb:                       std_reward_20 â–‚â–â–â–‚â–„â–‡â–ˆâ–„â–…â–„
wandb:                       std_reward_21 â–‚â–â–â–‚â–ƒâ–ˆâ–‡â–„â–„â–„
wandb:                       std_reward_22 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–„â–…â–„
wandb:                       std_reward_23 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_24 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–„â–„
wandb:                       std_reward_25 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_26 â–‚â–â–â–ƒâ–„â–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_27 â–‚â–â–â–ƒâ–„â–‡â–ˆâ–„â–…â–ƒ
wandb:                       std_reward_28 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–†â–„
wandb:                       std_reward_29 â–‚â–â–â–‚â–„â–ˆâ–ˆâ–…â–…â–„
wandb:                        std_reward_3 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_30 â–‚â–â–â–‚â–„â–ˆâ–ˆâ–…â–…â–„
wandb:                       std_reward_31 â–‚â–â–â–‚â–ƒâ–‡â–ˆâ–…â–…â–„
wandb:                       std_reward_32 â–‚â–â–â–ƒâ–ƒâ–ˆâ–ˆâ–„â–„â–„
wandb:                       std_reward_33 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–„â–„â–„
wandb:                       std_reward_34 â–‚â–â–â–‚â–ƒâ–‡â–ˆâ–„â–„â–„
wandb:                       std_reward_35 â–‚â–â–â–ƒâ–ƒâ–ˆâ–‡â–…â–…â–„
wandb:                        std_reward_4 â–‚â–â–â–‚â–ƒâ–†â–ˆâ–„â–„â–ƒ
wandb:                        std_reward_5 â–â–â–â–‚â–ƒâ–ˆâ–ˆâ–…â–…â–ƒ
wandb:                        std_reward_6 â–‚â–â–â–‚â–ƒâ–ˆâ–ˆâ–„â–„â–„
wandb:                        std_reward_7 â–‚â–â–â–‚â–ƒâ–‡â–ˆâ–„â–…â–„
wandb:                        std_reward_8 â–‚â–â–â–ƒâ–„â–ˆâ–‡â–„â–…â–„
wandb:                        std_reward_9 â–‚â–â–â–‚â–„â–‡â–ˆâ–…â–…â–„
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1120/global_step 212992
wandb:        PPO_1120/rollout/ep_len_mean 200.0
wandb:        PPO_1120/rollout/ep_rew_mean -831.30267
wandb:                   PPO_1120/time/fps 1175.0
wandb:            PPO_1120/train/approx_kl 0.01202
wandb:        PPO_1120/train/clip_fraction 0.15948
wandb:           PPO_1120/train/clip_range 0.2
wandb:         PPO_1120/train/entropy_loss -7.63312
wandb:   PPO_1120/train/explained_variance 0.96781
wandb:        PPO_1120/train/learning_rate 0.0003
wandb:                 PPO_1120/train/loss 16.05584
wandb: PPO_1120/train/policy_gradient_loss -0.00777
wandb:                  PPO_1120/train/std 0.71941
wandb:           PPO_1120/train/value_loss 71.51579
wandb:                PPO_1130/global_step 212992
wandb:        PPO_1130/rollout/ep_len_mean 200.0
wandb:        PPO_1130/rollout/ep_rew_mean -695.57788
wandb:                   PPO_1130/time/fps 1163.0
wandb:            PPO_1130/train/approx_kl 0.01606
wandb:        PPO_1130/train/clip_fraction 0.21004
wandb:           PPO_1130/train/clip_range 0.2
wandb:         PPO_1130/train/entropy_loss -6.61702
wandb:   PPO_1130/train/explained_variance 0.96771
wandb:        PPO_1130/train/learning_rate 0.0003
wandb:                 PPO_1130/train/loss 24.09903
wandb: PPO_1130/train/policy_gradient_loss -0.00769
wandb:                  PPO_1130/train/std 0.62277
wandb:           PPO_1130/train/value_loss 47.69817
wandb:                PPO_1141/global_step 212992
wandb:        PPO_1141/rollout/ep_len_mean 200.0
wandb:        PPO_1141/rollout/ep_rew_mean -565.15503
wandb:                   PPO_1141/time/fps 1161.0
wandb:            PPO_1141/train/approx_kl 0.01834
wandb:        PPO_1141/train/clip_fraction 0.22277
wandb:           PPO_1141/train/clip_range 0.2
wandb:         PPO_1141/train/entropy_loss -5.67604
wandb:   PPO_1141/train/explained_variance 0.97753
wandb:        PPO_1141/train/learning_rate 0.0003
wandb:                 PPO_1141/train/loss 4.35276
wandb: PPO_1141/train/policy_gradient_loss -0.00412
wandb:                  PPO_1141/train/std 0.5431
wandb:           PPO_1141/train/value_loss 24.3551
wandb:                PPO_1151/global_step 212992
wandb:        PPO_1151/rollout/ep_len_mean 200.0
wandb:        PPO_1151/rollout/ep_rew_mean -547.46997
wandb:                   PPO_1151/time/fps 1169.0
wandb:            PPO_1151/train/approx_kl 0.01985
wandb:        PPO_1151/train/clip_fraction 0.23166
wandb:           PPO_1151/train/clip_range 0.2
wandb:         PPO_1151/train/entropy_loss -4.92103
wandb:   PPO_1151/train/explained_variance 0.95775
wandb:        PPO_1151/train/learning_rate 0.0003
wandb:                 PPO_1151/train/loss 10.41072
wandb: PPO_1151/train/policy_gradient_loss -0.00048
wandb:                  PPO_1151/train/std 0.48848
wandb:           PPO_1151/train/value_loss 39.32831
wandb:                PPO_1161/global_step 212992
wandb:        PPO_1161/rollout/ep_len_mean 200.0
wandb:        PPO_1161/rollout/ep_rew_mean -516.47333
wandb:                   PPO_1161/time/fps 1162.0
wandb:            PPO_1161/train/approx_kl 0.01695
wandb:        PPO_1161/train/clip_fraction 0.22978
wandb:           PPO_1161/train/clip_range 0.2
wandb:         PPO_1161/train/entropy_loss -4.48877
wandb:   PPO_1161/train/explained_variance 0.98744
wandb:        PPO_1161/train/learning_rate 0.0003
wandb:                 PPO_1161/train/loss 22.85974
wandb: PPO_1161/train/policy_gradient_loss -0.00159
wandb:                  PPO_1161/train/std 0.45895
wandb:           PPO_1161/train/value_loss 34.10161
wandb:                PPO_1171/global_step 212992
wandb:        PPO_1171/rollout/ep_len_mean 200.0
wandb:        PPO_1171/rollout/ep_rew_mean -509.65793
wandb:                   PPO_1171/time/fps 1159.0
wandb:            PPO_1171/train/approx_kl 0.01782
wandb:        PPO_1171/train/clip_fraction 0.23892
wandb:           PPO_1171/train/clip_range 0.2
wandb:         PPO_1171/train/entropy_loss -4.14891
wandb:   PPO_1171/train/explained_variance 0.98823
wandb:        PPO_1171/train/learning_rate 0.0003
wandb:                 PPO_1171/train/loss 11.52244
wandb: PPO_1171/train/policy_gradient_loss -0.00163
wandb:                  PPO_1171/train/std 0.4375
wandb:           PPO_1171/train/value_loss 47.35141
wandb:                PPO_1181/global_step 212992
wandb:        PPO_1181/rollout/ep_len_mean 200.0
wandb:        PPO_1181/rollout/ep_rew_mean -471.17471
wandb:                   PPO_1181/time/fps 1167.0
wandb:            PPO_1181/train/approx_kl 0.01951
wandb:        PPO_1181/train/clip_fraction 0.23051
wandb:           PPO_1181/train/clip_range 0.2
wandb:         PPO_1181/train/entropy_loss -4.01216
wandb:   PPO_1181/train/explained_variance 0.99176
wandb:        PPO_1181/train/learning_rate 0.0003
wandb:                 PPO_1181/train/loss 17.14367
wandb: PPO_1181/train/policy_gradient_loss -0.00146
wandb:                  PPO_1181/train/std 0.42953
wandb:           PPO_1181/train/value_loss 48.32584
wandb:                PPO_1191/global_step 212992
wandb:        PPO_1191/rollout/ep_len_mean 200.0
wandb:        PPO_1191/rollout/ep_rew_mean -430.90793
wandb:                   PPO_1191/time/fps 1167.0
wandb:            PPO_1191/train/approx_kl 0.01849
wandb:        PPO_1191/train/clip_fraction 0.23685
wandb:           PPO_1191/train/clip_range 0.2
wandb:         PPO_1191/train/entropy_loss -3.50595
wandb:   PPO_1191/train/explained_variance 0.99604
wandb:        PPO_1191/train/learning_rate 0.0003
wandb:                 PPO_1191/train/loss 19.87695
wandb: PPO_1191/train/policy_gradient_loss -0.00122
wandb:                  PPO_1191/train/std 0.39919
wandb:           PPO_1191/train/value_loss 32.35122
wandb:                PPO_1201/global_step 212992
wandb:        PPO_1201/rollout/ep_len_mean 200.0
wandb:        PPO_1201/rollout/ep_rew_mean -403.49664
wandb:                   PPO_1201/time/fps 1170.0
wandb:            PPO_1201/train/approx_kl 0.02197
wandb:        PPO_1201/train/clip_fraction 0.25259
wandb:           PPO_1201/train/clip_range 0.2
wandb:         PPO_1201/train/entropy_loss -3.11101
wandb:   PPO_1201/train/explained_variance 0.99616
wandb:        PPO_1201/train/learning_rate 0.0003
wandb:                 PPO_1201/train/loss 4.38856
wandb: PPO_1201/train/policy_gradient_loss 0.00012
wandb:                  PPO_1201/train/std 0.37704
wandb:           PPO_1201/train/value_loss 23.01128
wandb:                    global_mean_eval -383.69622
wandb:                         global_step 212992
wandb:                       mean_reward_0 -384.7851
wandb:                       mean_reward_1 -393.15757
wandb:                      mean_reward_10 -383.8183
wandb:                      mean_reward_11 -374.8733
wandb:                      mean_reward_12 -395.80335
wandb:                      mean_reward_13 -383.72752
wandb:                      mean_reward_14 -396.72029
wandb:                      mean_reward_15 -388.31478
wandb:                      mean_reward_16 -384.57075
wandb:                      mean_reward_17 -386.0883
wandb:                      mean_reward_18 -383.14235
wandb:                      mean_reward_19 -367.81066
wandb:                       mean_reward_2 -383.39261
wandb:                      mean_reward_20 -380.09824
wandb:                      mean_reward_21 -391.29962
wandb:                      mean_reward_22 -397.5307
wandb:                      mean_reward_23 -391.28321
wandb:                      mean_reward_24 -379.96522
wandb:                      mean_reward_25 -378.94007
wandb:                      mean_reward_26 -381.40968
wandb:                      mean_reward_27 -382.79076
wandb:                      mean_reward_28 -381.49204
wandb:                      mean_reward_29 -382.25025
wandb:                       mean_reward_3 -379.40084
wandb:                      mean_reward_30 -389.1704
wandb:                      mean_reward_31 -395.19848
wandb:                      mean_reward_32 -372.87368
wandb:                      mean_reward_33 -368.40089
wandb:                      mean_reward_34 -380.69193
wandb:                      mean_reward_35 -391.02783
wandb:                       mean_reward_4 -373.89832
wandb:                       mean_reward_5 -359.09469
wandb:                       mean_reward_6 -390.53849
wandb:                       mean_reward_7 -393.12019
wandb:                       mean_reward_8 -394.42131
wandb:                       mean_reward_9 -371.96206
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 97.19771
wandb:                        std_reward_1 98.74095
wandb:                       std_reward_10 86.31339
wandb:                       std_reward_11 89.48045
wandb:                       std_reward_12 91.0774
wandb:                       std_reward_13 87.36547
wandb:                       std_reward_14 94.53606
wandb:                       std_reward_15 92.41501
wandb:                       std_reward_16 94.58237
wandb:                       std_reward_17 97.07774
wandb:                       std_reward_18 92.50418
wandb:                       std_reward_19 86.85524
wandb:                        std_reward_2 90.80126
wandb:                       std_reward_20 87.02601
wandb:                       std_reward_21 93.48887
wandb:                       std_reward_22 92.55775
wandb:                       std_reward_23 86.84994
wandb:                       std_reward_24 101.66554
wandb:                       std_reward_25 96.28752
wandb:                       std_reward_26 89.36404
wandb:                       std_reward_27 85.42189
wandb:                       std_reward_28 85.27738
wandb:                       std_reward_29 88.20388
wandb:                        std_reward_3 90.41064
wandb:                       std_reward_30 94.73672
wandb:                       std_reward_31 92.26221
wandb:                       std_reward_32 89.18544
wandb:                       std_reward_33 90.32146
wandb:                       std_reward_34 94.94128
wandb:                       std_reward_35 102.905
wandb:                        std_reward_4 84.4848
wandb:                        std_reward_5 79.30228
wandb:                        std_reward_6 89.60618
wandb:                        std_reward_7 92.05307
wandb:                        std_reward_8 92.11589
wandb:                        std_reward_9 88.37466
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced misunderstood-monkey-27: https://wandb.ai/tidiane/meta_rl_context/runs/q658kpqh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-q658kpqh/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1122/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1122/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1122/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:                   PPO_1122/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1122/train/approx_kl â–‚â–…â–ˆâ–ˆâ–†â–ƒâ–„â–‚â–‚â–†â–
wandb:        PPO_1122/train/clip_fraction â–ƒâ–ƒâ–ˆâ–†â–…â–ƒâ–…â–ƒâ–ƒâ–„â–
wandb:           PPO_1122/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1122/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1122/train/explained_variance â–†â–ˆâ–‡â–…â–…â–ƒâ–†â–ƒâ–â–ƒâ–‚
wandb:        PPO_1122/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1122/train/loss â–‚â–â–‚â–„â–â–‚â–‚â–†â–…â–ƒâ–ˆ
wandb: PPO_1122/train/policy_gradient_loss â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–ˆ
wandb:                  PPO_1122/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1122/train/value_loss â–â–‚â–â–ƒâ–‚â–†â–ƒâ–„â–ˆâ–ˆâ–ˆ
wandb:                PPO_1132/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1132/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1132/rollout/ep_rew_mean â–â–â–‚â–„â–…â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:                   PPO_1132/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1132/train/approx_kl â–„â–ƒâ–†â–‚â–†â–â–‚â–â–ƒâ–ƒâ–ˆ
wandb:        PPO_1132/train/clip_fraction â–â–„â–ˆâ–…â–…â–„â–†â–ƒâ–†â–„â–„
wandb:           PPO_1132/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1132/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1132/train/explained_variance â–â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:        PPO_1132/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1132/train/loss â–†â–ˆâ–â–‚â–ˆâ–„â–„â–‡â–‚â–â–‚
wandb: PPO_1132/train/policy_gradient_loss â–„â–„â–â–‚â–â–…â–„â–‡â–‡â–ˆâ–†
wandb:                  PPO_1132/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1132/train/value_loss â–‡â–ˆâ–„â–†â–‡â–ƒâ–ƒâ–ƒâ–â–â–‚
wandb:                PPO_1142/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1142/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1142/rollout/ep_rew_mean â–â–â–ƒâ–†â–‚â–„â–†â–‡â–†â–†â–ˆâ–†
wandb:                   PPO_1142/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1142/train/approx_kl â–…â–ƒâ–…â–ˆâ–â–…â–ƒâ–ƒâ–„â–…â–‡
wandb:        PPO_1142/train/clip_fraction â–„â–†â–†â–‡â–â–ˆâ–†â–…â–†â–ˆâ–†
wandb:           PPO_1142/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1142/train/entropy_loss â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1142/train/explained_variance â–ˆâ–‡â–†â–‡â–„â–â–„â–ƒâ–‡â–‡â–„
wandb:        PPO_1142/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1142/train/loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–
wandb: PPO_1142/train/policy_gradient_loss â–†â–ƒâ–â–ƒâ–„â–…â–„â–ƒâ–ˆâ–†â–…
wandb:                  PPO_1142/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1142/train/value_loss â–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–‚â–â–‚
wandb:                PPO_1152/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1152/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1152/rollout/ep_rew_mean â–†â–‚â–„â–‚â–…â–„â–ˆâ–ˆâ–â–†â–ˆâ–
wandb:                   PPO_1152/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1152/train/approx_kl â–ˆâ–†â–â–‚â–„â–ƒâ–†â–ˆâ–ƒâ–ˆâ–‚
wandb:        PPO_1152/train/clip_fraction â–†â–‡â–†â–ƒâ–„â–ƒâ–‡â–‡â–â–ˆâ–‚
wandb:           PPO_1152/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1152/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1152/train/explained_variance â–â–â–‚â–„â–‚â–„â–†â–†â–„â–‡â–ˆ
wandb:        PPO_1152/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1152/train/loss â–ƒâ–‚â–â–ƒâ–„â–†â–‚â–â–ˆâ–ƒâ–ƒ
wandb: PPO_1152/train/policy_gradient_loss â–‡â–„â–…â–ƒâ–†â–‚â–‚â–„â–ƒâ–ˆâ–
wandb:                  PPO_1152/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1152/train/value_loss â–ƒâ–„â–„â–ƒâ–„â–†â–â–â–ˆâ–„â–‚
wandb:                PPO_1162/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1162/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1162/rollout/ep_rew_mean â–â–„â–†â–ˆâ–ˆâ–…â–„â–†â–†â–†â–„â–‡
wandb:                   PPO_1162/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1162/train/approx_kl â–â–‚â–ƒâ–†â–„â–ˆâ–†â–†â–†â–‚â–†
wandb:        PPO_1162/train/clip_fraction â–â–…â–†â–ˆâ–…â–…â–†â–…â–†â–…â–…
wandb:           PPO_1162/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1162/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1162/train/explained_variance â–â–„â–‚â–†â–‡â–…â–†â–‡â–ˆâ–‡â–ˆ
wandb:        PPO_1162/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1162/train/loss â–ˆâ–‚â–ƒâ–„â–‚â–„â–‚â–â–ƒâ–†â–…
wandb: PPO_1162/train/policy_gradient_loss â–„â–ˆâ–‡â–‡â–…â–ƒâ–ˆâ–â–„â–„â–‡
wandb:                  PPO_1162/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1162/train/value_loss â–ˆâ–„â–„â–‚â–â–„â–‚â–ƒâ–ƒâ–†â–ƒ
wandb:                PPO_1172/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1172/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1172/rollout/ep_rew_mean â–‡â–â–ƒâ–ˆâ–‚â–â–ƒâ–ƒâ–ƒâ–‡â–„â–‚
wandb:                   PPO_1172/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1172/train/approx_kl â–„â–ƒâ–ƒâ–‡â–â–â–â–ƒâ–‡â–ˆâ–†
wandb:        PPO_1172/train/clip_fraction â–†â–â–ƒâ–‡â–‚â–‚â–„â–†â–ˆâ–ˆâ–‡
wandb:           PPO_1172/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1172/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–†â–‡â–ˆ
wandb:   PPO_1172/train/explained_variance â–â–ƒâ–…â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        PPO_1172/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1172/train/loss â–â–‚â–ˆâ–â–„â–…â–ˆâ–…â–‚â–â–‚
wandb: PPO_1172/train/policy_gradient_loss â–â–†â–…â–‡â–ˆâ–…â–…â–‡â–‡â–ˆâ–…
wandb:                  PPO_1172/train/std â–ˆâ–ˆâ–ˆâ–†â–†â–†â–…â–…â–ƒâ–‚â–
wandb:           PPO_1172/train/value_loss â–‚â–ˆâ–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–â–
wandb:                PPO_1182/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1182/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1182/rollout/ep_rew_mean â–…â–â–„â–„â–„â–…â–†â–†â–„â–‡â–‡â–ˆ
wandb:                   PPO_1182/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1182/train/approx_kl â–â–â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–„â–„â–†â–†
wandb:        PPO_1182/train/clip_fraction â–â–â–ƒâ–…â–„â–ˆâ–â–„â–ƒâ–†â–…
wandb:           PPO_1182/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1182/train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–ˆ
wandb:   PPO_1182/train/explained_variance â–†â–ˆâ–…â–…â–…â–†â–â–‡â–ˆâ–‡â–
wandb:        PPO_1182/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1182/train/loss â–ƒâ–ƒâ–†â–…â–ƒâ–â–‚â–ƒâ–ˆâ–„â–…
wandb: PPO_1182/train/policy_gradient_loss â–ƒâ–‚â–„â–ƒâ–ƒâ–ˆâ–‚â–â–‚â–‚â–
wandb:                  PPO_1182/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–„â–
wandb:           PPO_1182/train/value_loss â–„â–‡â–†â–…â–†â–â–ˆâ–…â–…â–ƒâ–‡
wandb:                PPO_1192/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1192/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1192/rollout/ep_rew_mean â–ƒâ–ƒâ–†â–„â–‚â–â–â–„â–ƒâ–„â–ˆâ–ˆ
wandb:                   PPO_1192/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1192/train/approx_kl â–ƒâ–„â–ˆâ–ƒâ–â–…â–ˆâ–ˆâ–‚â–†â–
wandb:        PPO_1192/train/clip_fraction â–„â–†â–†â–â–ƒâ–…â–†â–†â–‚â–ˆâ–‚
wandb:           PPO_1192/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1192/train/entropy_loss â–â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–ˆ
wandb:   PPO_1192/train/explained_variance â–†â–ˆâ–„â–†â–‡â–‚â–…â–ƒâ–ƒâ–…â–
wandb:        PPO_1192/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1192/train/loss â–‚â–‚â–…â–â–‚â–ˆâ–†â–‚â–ƒâ–ƒâ–†
wandb: PPO_1192/train/policy_gradient_loss â–†â–‡â–ˆâ–…â–ƒâ–…â–â–…â–…â–‡â–†
wandb:                  PPO_1192/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1192/train/value_loss â–„â–â–‚â–…â–†â–‡â–…â–†â–ˆâ–„â–‡
wandb:                PPO_1202/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1202/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1202/rollout/ep_rew_mean â–â–ƒâ–â–â–ˆâ–…â–†â–ƒâ–†â–„â–„â–
wandb:                   PPO_1202/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1202/train/approx_kl â–ƒâ–ƒâ–â–†â–…â–ˆâ–ƒâ–†â–‡â–‚â–†
wandb:        PPO_1202/train/clip_fraction â–ƒâ–ƒâ–â–ˆâ–†â–ƒâ–â–†â–‡â–„â–…
wandb:           PPO_1202/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1202/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1202/train/explained_variance â–„â–†â–„â–â–†â–†â–‚â–…â–ƒâ–„â–ˆ
wandb:        PPO_1202/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1202/train/loss â–„â–ƒâ–†â–„â–â–„â–ˆâ–„â–„â–‚â–ƒ
wandb: PPO_1202/train/policy_gradient_loss â–‚â–„â–…â–ˆâ–ˆâ–ƒâ–„â–ƒâ–†â–â–‚
wandb:                  PPO_1202/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1202/train/value_loss â–†â–„â–ˆâ–‚â–â–‚â–‡â–ƒâ–‚â–‚â–
wandb:                    global_mean_eval â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–„â–†â–†â–†â–†â–…â–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–„â–…â–†â–†â–…â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–…â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–„â–†â–†â–†â–…â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–„â–†â–†â–†â–†â–‡â–†â–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–†â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–„â–†â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–„â–†â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–„â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–„â–†â–†â–†â–†â–…â–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–„â–…â–†â–†â–†â–†â–…â–‡â–ˆ
wandb:                      mean_reward_30 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–„â–…â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–„â–…â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–„â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–„â–…â–†â–†â–†â–…â–†â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–â–‚â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–ˆ
wandb:                        std_reward_0 â–‚â–â–â–â–‚â–…â–ˆâ–†â–ƒâ–ƒ
wandb:                        std_reward_1 â–‚â–â–‚â–â–‚â–…â–ˆâ–…â–ƒâ–ƒ
wandb:                       std_reward_10 â–‚â–â–‚â–â–‚â–†â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_11 â–‚â–â–â–‚â–‚â–‡â–ˆâ–ˆâ–ƒâ–ƒ
wandb:                       std_reward_12 â–‚â–â–‚â–â–‚â–…â–‡â–ˆâ–ƒâ–ƒ
wandb:                       std_reward_13 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_14 â–‚â–â–‚â–â–‚â–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_15 â–‚â–â–‚â–â–‚â–…â–ˆâ–†â–‚â–‚
wandb:                       std_reward_16 â–â–â–‚â–â–‚â–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_17 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–†â–ƒâ–ƒ
wandb:                       std_reward_18 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–ˆâ–ƒâ–„
wandb:                       std_reward_19 â–‚â–â–‚â–‚â–ƒâ–…â–‡â–ˆâ–ƒâ–„
wandb:                        std_reward_2 â–‚â–â–‚â–â–ƒâ–†â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_20 â–‚â–â–‚â–â–‚â–„â–ˆâ–†â–ƒâ–ƒ
wandb:                       std_reward_21 â–‚â–â–‚â–‚â–ƒâ–†â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_22 â–‚â–â–â–â–ƒâ–…â–ˆâ–†â–‚â–ƒ
wandb:                       std_reward_23 â–â–â–‚â–‚â–‚â–…â–ˆâ–‡â–‚â–ƒ
wandb:                       std_reward_24 â–‚â–â–‚â–â–‚â–…â–ˆâ–‡â–‚â–ƒ
wandb:                       std_reward_25 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–†â–ƒâ–ƒ
wandb:                       std_reward_26 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_27 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–†â–ƒâ–ƒ
wandb:                       std_reward_28 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_29 â–‚â–â–â–‚â–‚â–…â–ˆâ–†â–ƒâ–ƒ
wandb:                        std_reward_3 â–‚â–â–â–â–ƒâ–†â–ˆâ–ˆâ–ƒâ–ƒ
wandb:                       std_reward_30 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_31 â–‚â–â–‚â–â–‚â–…â–‡â–ˆâ–ƒâ–ƒ
wandb:                       std_reward_32 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_33 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–†â–ƒâ–ƒ
wandb:                       std_reward_34 â–‚â–â–‚â–â–ƒâ–†â–ˆâ–‡â–ƒâ–ƒ
wandb:                       std_reward_35 â–‚â–â–‚â–‚â–ƒâ–†â–ˆâ–ˆâ–ƒâ–„
wandb:                        std_reward_4 â–‚â–â–‚â–â–‚â–„â–ˆâ–†â–ƒâ–ƒ
wandb:                        std_reward_5 â–‚â–â–â–â–ƒâ–†â–‡â–ˆâ–ƒâ–„
wandb:                        std_reward_6 â–‚â–â–‚â–â–ƒâ–…â–ˆâ–‡â–ƒâ–ƒ
wandb:                        std_reward_7 â–‚â–â–â–‚â–‚â–…â–ˆâ–ˆâ–ƒâ–ƒ
wandb:                        std_reward_8 â–‚â–â–‚â–â–ƒâ–†â–‡â–ˆâ–ƒâ–ƒ
wandb:                        std_reward_9 â–‚â–â–‚â–â–‚â–…â–ˆâ–†â–‚â–‚
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–‚â–ƒâ–ˆâ–â–‚â–‚â–„â–ƒâ–„â–†â–†
wandb:                 train/clip_fraction â–ƒâ–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1122/global_step 212992
wandb:        PPO_1122/rollout/ep_len_mean 200.0
wandb:        PPO_1122/rollout/ep_rew_mean -765.4762
wandb:                   PPO_1122/time/fps 1164.0
wandb:            PPO_1122/train/approx_kl 0.0109
wandb:        PPO_1122/train/clip_fraction 0.13574
wandb:           PPO_1122/train/clip_range 0.2
wandb:         PPO_1122/train/entropy_loss -7.48617
wandb:   PPO_1122/train/explained_variance 0.9617
wandb:        PPO_1122/train/learning_rate 0.0003
wandb:                 PPO_1122/train/loss 54.31795
wandb: PPO_1122/train/policy_gradient_loss -0.00502
wandb:                  PPO_1122/train/std 0.70378
wandb:           PPO_1122/train/value_loss 85.49967
wandb:                PPO_1132/global_step 212992
wandb:        PPO_1132/rollout/ep_len_mean 200.0
wandb:        PPO_1132/rollout/ep_rew_mean -609.03107
wandb:                   PPO_1132/time/fps 1165.0
wandb:            PPO_1132/train/approx_kl 0.01428
wandb:        PPO_1132/train/clip_fraction 0.17495
wandb:           PPO_1132/train/clip_range 0.2
wandb:         PPO_1132/train/entropy_loss -6.60693
wandb:   PPO_1132/train/explained_variance 0.98015
wandb:        PPO_1132/train/learning_rate 0.0003
wandb:                 PPO_1132/train/loss 19.59736
wandb: PPO_1132/train/policy_gradient_loss -0.00558
wandb:                  PPO_1132/train/std 0.622
wandb:           PPO_1132/train/value_loss 59.69187
wandb:                PPO_1142/global_step 212992
wandb:        PPO_1142/rollout/ep_len_mean 200.0
wandb:        PPO_1142/rollout/ep_rew_mean -557.48566
wandb:                   PPO_1142/time/fps 1159.0
wandb:            PPO_1142/train/approx_kl 0.01786
wandb:        PPO_1142/train/clip_fraction 0.19352
wandb:           PPO_1142/train/clip_range 0.2
wandb:         PPO_1142/train/entropy_loss -5.76783
wandb:   PPO_1142/train/explained_variance 0.96782
wandb:        PPO_1142/train/learning_rate 0.0003
wandb:                 PPO_1142/train/loss 10.53841
wandb: PPO_1142/train/policy_gradient_loss -0.00336
wandb:                  PPO_1142/train/std 0.55095
wandb:           PPO_1142/train/value_loss 42.45692
wandb:                PPO_1152/global_step 212992
wandb:        PPO_1152/rollout/ep_len_mean 200.0
wandb:        PPO_1152/rollout/ep_rew_mean -568.17651
wandb:                   PPO_1152/time/fps 1157.0
wandb:            PPO_1152/train/approx_kl 0.01418
wandb:        PPO_1152/train/clip_fraction 0.17045
wandb:           PPO_1152/train/clip_range 0.2
wandb:         PPO_1152/train/entropy_loss -5.26857
wandb:   PPO_1152/train/explained_variance 0.98839
wandb:        PPO_1152/train/learning_rate 0.0003
wandb:                 PPO_1152/train/loss 12.1888
wandb: PPO_1152/train/policy_gradient_loss -0.00495
wandb:                  PPO_1152/train/std 0.5135
wandb:           PPO_1152/train/value_loss 33.66475
wandb:                PPO_1162/global_step 212992
wandb:        PPO_1162/rollout/ep_len_mean 200.0
wandb:        PPO_1162/rollout/ep_rew_mean -521.18518
wandb:                   PPO_1162/time/fps 1163.0
wandb:            PPO_1162/train/approx_kl 0.01731
wandb:        PPO_1162/train/clip_fraction 0.20936
wandb:           PPO_1162/train/clip_range 0.2
wandb:         PPO_1162/train/entropy_loss -4.73434
wandb:   PPO_1162/train/explained_variance 0.99581
wandb:        PPO_1162/train/learning_rate 0.0003
wandb:                 PPO_1162/train/loss 24.35085
wandb: PPO_1162/train/policy_gradient_loss -0.00296
wandb:                  PPO_1162/train/std 0.47589
wandb:           PPO_1162/train/value_loss 30.86611
wandb:                PPO_1172/global_step 212992
wandb:        PPO_1172/rollout/ep_len_mean 200.0
wandb:        PPO_1172/rollout/ep_rew_mean -553.91174
wandb:                   PPO_1172/time/fps 1147.0
wandb:            PPO_1172/train/approx_kl 0.01804
wandb:        PPO_1172/train/clip_fraction 0.23018
wandb:           PPO_1172/train/clip_range 0.2
wandb:         PPO_1172/train/entropy_loss -4.33654
wandb:   PPO_1172/train/explained_variance 0.9984
wandb:        PPO_1172/train/learning_rate 0.0003
wandb:                 PPO_1172/train/loss 11.16779
wandb: PPO_1172/train/policy_gradient_loss -0.0032
wandb:                  PPO_1172/train/std 0.44925
wandb:           PPO_1172/train/value_loss 26.65805
wandb:                PPO_1182/global_step 212992
wandb:        PPO_1182/rollout/ep_len_mean 200.0
wandb:        PPO_1182/rollout/ep_rew_mean -482.63354
wandb:                   PPO_1182/time/fps 1156.0
wandb:            PPO_1182/train/approx_kl 0.01961
wandb:        PPO_1182/train/clip_fraction 0.23301
wandb:           PPO_1182/train/clip_range 0.2
wandb:         PPO_1182/train/entropy_loss -3.96466
wandb:   PPO_1182/train/explained_variance 0.99724
wandb:        PPO_1182/train/learning_rate 0.0003
wandb:                 PPO_1182/train/loss 24.03317
wandb: PPO_1182/train/policy_gradient_loss -0.00324
wandb:                  PPO_1182/train/std 0.42647
wandb:           PPO_1182/train/value_loss 54.08805
wandb:                PPO_1192/global_step 212992
wandb:        PPO_1192/rollout/ep_len_mean 200.0
wandb:        PPO_1192/rollout/ep_rew_mean -439.90277
wandb:                   PPO_1192/time/fps 1155.0
wandb:            PPO_1192/train/approx_kl 0.01683
wandb:        PPO_1192/train/clip_fraction 0.21965
wandb:           PPO_1192/train/clip_range 0.2
wandb:         PPO_1192/train/entropy_loss -3.49153
wandb:   PPO_1192/train/explained_variance 0.99646
wandb:        PPO_1192/train/learning_rate 0.0003
wandb:                 PPO_1192/train/loss 30.70124
wandb: PPO_1192/train/policy_gradient_loss -0.00139
wandb:                  PPO_1192/train/std 0.39883
wandb:           PPO_1192/train/value_loss 69.04636
wandb:                PPO_1202/global_step 212992
wandb:        PPO_1202/rollout/ep_len_mean 200.0
wandb:        PPO_1202/rollout/ep_rew_mean -423.01669
wandb:                   PPO_1202/time/fps 1141.0
wandb:            PPO_1202/train/approx_kl 0.02192
wandb:        PPO_1202/train/clip_fraction 0.26978
wandb:           PPO_1202/train/clip_range 0.2
wandb:         PPO_1202/train/entropy_loss -3.10655
wandb:   PPO_1202/train/explained_variance 0.9967
wandb:        PPO_1202/train/learning_rate 0.0003
wandb:                 PPO_1202/train/loss 8.33119
wandb: PPO_1202/train/policy_gradient_loss -0.00166
wandb:                  PPO_1202/train/std 0.37717
wandb:           PPO_1202/train/value_loss 16.68729
wandb:                    global_mean_eval -359.50565
wandb:                         global_step 212992
wandb:                       mean_reward_0 -366.65689
wandb:                       mean_reward_1 -363.67762
wandb:                      mean_reward_10 -365.90022
wandb:                      mean_reward_11 -352.87199
wandb:                      mean_reward_12 -350.27905
wandb:                      mean_reward_13 -340.10972
wandb:                      mean_reward_14 -361.10595
wandb:                      mean_reward_15 -341.36968
wandb:                      mean_reward_16 -346.69381
wandb:                      mean_reward_17 -369.23699
wandb:                      mean_reward_18 -382.84609
wandb:                      mean_reward_19 -372.20828
wandb:                       mean_reward_2 -356.49624
wandb:                      mean_reward_20 -366.55385
wandb:                      mean_reward_21 -341.61389
wandb:                      mean_reward_22 -366.68838
wandb:                      mean_reward_23 -362.12759
wandb:                      mean_reward_24 -366.37933
wandb:                      mean_reward_25 -358.15034
wandb:                      mean_reward_26 -371.47504
wandb:                      mean_reward_27 -355.19137
wandb:                      mean_reward_28 -373.67665
wandb:                      mean_reward_29 -372.56528
wandb:                       mean_reward_3 -334.86244
wandb:                      mean_reward_30 -356.51653
wandb:                      mean_reward_31 -350.80372
wandb:                      mean_reward_32 -353.17293
wandb:                      mean_reward_33 -363.25271
wandb:                      mean_reward_34 -352.19961
wandb:                      mean_reward_35 -377.6418
wandb:                       mean_reward_4 -342.52911
wandb:                       mean_reward_5 -372.40568
wandb:                       mean_reward_6 -357.46801
wandb:                       mean_reward_7 -375.87417
wandb:                       mean_reward_8 -350.46951
wandb:                       mean_reward_9 -351.13286
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -931.94031
wandb:                        std_reward_0 115.89513
wandb:                        std_reward_1 109.63733
wandb:                       std_reward_10 117.09353
wandb:                       std_reward_11 116.24516
wandb:                       std_reward_12 113.0151
wandb:                       std_reward_13 112.4244
wandb:                       std_reward_14 123.49972
wandb:                       std_reward_15 100.8525
wandb:                       std_reward_16 106.69157
wandb:                       std_reward_17 126.57376
wandb:                       std_reward_18 127.29333
wandb:                       std_reward_19 119.15283
wandb:                        std_reward_2 116.13506
wandb:                       std_reward_20 113.11483
wandb:                       std_reward_21 101.19329
wandb:                       std_reward_22 122.05421
wandb:                       std_reward_23 114.46882
wandb:                       std_reward_24 110.02731
wandb:                       std_reward_25 115.82819
wandb:                       std_reward_26 123.80979
wandb:                       std_reward_27 110.37146
wandb:                       std_reward_28 108.06505
wandb:                       std_reward_29 110.12748
wandb:                        std_reward_3 94.02416
wandb:                       std_reward_30 112.56716
wandb:                       std_reward_31 106.45361
wandb:                       std_reward_32 112.39167
wandb:                       std_reward_33 115.97323
wandb:                       std_reward_34 116.98897
wandb:                       std_reward_35 118.70519
wandb:                        std_reward_4 111.52134
wandb:                        std_reward_5 119.7748
wandb:                        std_reward_6 118.10891
wandb:                        std_reward_7 123.06819
wandb:                        std_reward_8 110.85624
wandb:                        std_reward_9 105.51659
wandb:                            time/fps 1178.0
wandb:                     train/approx_kl 0.01244
wandb:                 train/clip_fraction 0.15652
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7411
wandb:            train/explained_variance 0.96718
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 11.08948
wandb:          train/policy_gradient_loss -0.01304
wandb:                           train/std 0.84138
wandb:                    train/value_loss 21.77692
wandb: 
wandb: Synced azure-valley-27: https://wandb.ai/tidiane/meta_rl_context/runs/1mez24fw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_012622-1mez24fw/logs

real	121m11.352s
user	1175m47.719s
sys	3m30.264s
+ mpirun python dev/automl/meta_rl/scripts/orig_impl/striker_baselines.py --context none
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-260njzkv
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-25ymiicf
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-27vz0el0
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-3d0g5b5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-capybara-36
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/260njzkv
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-3s3rvojv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-night-38
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/25ymiicf
wandb: Syncing run splendid-gorge-35
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/27vz0el0
wandb: Syncing run pious-star-36
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/3d0g5b5s
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-n0hoact8
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-1uc7k9re
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-2znu6ayn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-shadow-33
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: Tracking run with wandb version 0.13.5
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/3s3rvojv
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-jt2eiuao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-totem-39
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/n0hoact8
wandb: Syncing run legendary-snowflake-39
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1uc7k9re
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Syncing run curious-universe-39
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2znu6ayn
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_032708-1ol3e8yx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-planet-38
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/jt2eiuao
wandb: Syncing run deft-snow-34
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1ol3e8yx
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1205/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1205/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1205/rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–…â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:                   PPO_1205/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1205/train/approx_kl â–…â–„â–â–†â–†â–„â–†â–„â–ˆâ–‡â–‡
wandb:        PPO_1205/train/clip_fraction â–„â–„â–â–‡â–‡â–†â–‡â–„â–‡â–‡â–ˆ
wandb:           PPO_1205/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1205/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1205/train/explained_variance â–†â–‡â–â–ˆâ–†â–ˆâ–…â–†â–‡â–‚â–…
wandb:        PPO_1205/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1205/train/loss â–â–â–ƒâ–…â–‚â–ƒâ–†â–â–‚â–‚â–ˆ
wandb: PPO_1205/train/policy_gradient_loss â–â–†â–ˆâ–â–â–…â–†â–…â–‚â–ƒâ–‚
wandb:                  PPO_1205/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1205/train/value_loss â–â–„â–‡â–ƒâ–†â–„â–†â–‡â–‡â–†â–ˆ
wandb:                PPO_1214/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1214/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1214/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–†â–†â–ˆ
wandb:                   PPO_1214/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1214/train/approx_kl â–â–â–â–‚â–‚â–‚â–„â–…â–ˆâ–†â–†
wandb:        PPO_1214/train/clip_fraction â–â–ƒâ–ƒâ–â–‚â–ƒâ–…â–‡â–ˆâ–‡â–†
wandb:           PPO_1214/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1214/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1214/train/explained_variance â–ƒâ–…â–â–„â–ƒâ–â–â–‚â–ƒâ–…â–ˆ
wandb:        PPO_1214/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1214/train/loss â–„â–„â–„â–„â–â–ˆâ–…â–â–…â–‚â–„
wandb: PPO_1214/train/policy_gradient_loss â–ƒâ–â–‚â–‡â–„â–ˆâ–ƒâ–…â–„â–‚â–‡
wandb:                  PPO_1214/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1214/train/value_loss â–ˆâ–‡â–…â–…â–†â–…â–„â–ƒâ–â–â–ƒ
wandb:                PPO_1224/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1224/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1224/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–ƒâ–„â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                   PPO_1224/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1224/train/approx_kl â–â–â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–ˆ
wandb:        PPO_1224/train/clip_fraction â–‚â–â–†â–„â–„â–‡â–…â–…â–„â–…â–ˆ
wandb:           PPO_1224/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1224/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1224/train/explained_variance â–…â–‡â–†â–â–†â–…â–‡â–ˆâ–„â–†â–…
wandb:        PPO_1224/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1224/train/loss â–‚â–ƒâ–ˆâ–†â–‚â–â–„â–â–‚â–‚â–
wandb: PPO_1224/train/policy_gradient_loss â–‚â–â–„â–ƒâ–„â–„â–†â–…â–…â–†â–ˆ
wandb:                  PPO_1224/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1224/train/value_loss â–†â–ˆâ–‚â–†â–…â–„â–ƒâ–‚â–ƒâ–„â–
wandb:                PPO_1234/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1234/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1234/rollout/ep_rew_mean â–â–„â–‚â–‚â–ƒâ–…â–†â–…â–ˆâ–…â–†â–‡
wandb:                   PPO_1234/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1234/train/approx_kl â–‚â–‡â–ƒâ–„â–ƒâ–‡â–ˆâ–â–ƒâ–†â–ˆ
wandb:        PPO_1234/train/clip_fraction â–ƒâ–‡â–‚â–‚â–‚â–ˆâ–ˆâ–â–„â–„â–…
wandb:           PPO_1234/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1234/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1234/train/explained_variance â–â–„â–ƒâ–…â–‚â–†â–…â–‡â–‡â–ˆâ–ˆ
wandb:        PPO_1234/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1234/train/loss â–†â–‚â–‚â–ˆâ–‚â–â–„â–‚â–ƒâ–‚â–ƒ
wandb: PPO_1234/train/policy_gradient_loss â–‚â–†â–â–‚â–â–„â–„â–…â–‚â–ƒâ–ˆ
wandb:                  PPO_1234/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1234/train/value_loss â–ˆâ–â–„â–†â–ˆâ–„â–‚â–ƒâ–…â–‡â–ƒ
wandb:                PPO_1244/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1244/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1244/rollout/ep_rew_mean â–â–…â–†â–„â–ˆâ–ˆâ–ˆâ–†â–…â–‚â–„â–‚
wandb:                   PPO_1244/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1244/train/approx_kl â–ƒâ–‚â–â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–‚â–†
wandb:        PPO_1244/train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–„â–…â–‚â–ˆâ–â–‡
wandb:           PPO_1244/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1244/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–‡â–‡â–ˆ
wandb:   PPO_1244/train/explained_variance â–„â–â–…â–†â–†â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:        PPO_1244/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1244/train/loss â–â–â–‚â–„â–…â–„â–‡â–…â–„â–„â–ˆ
wandb: PPO_1244/train/policy_gradient_loss â–„â–‚â–†â–ƒâ–â–…â–ƒâ–…â–ˆâ–‡â–‡
wandb:                  PPO_1244/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–„â–‚â–‚â–
wandb:           PPO_1244/train/value_loss â–‚â–‡â–â–ƒâ–…â–â–â–‡â–‚â–ˆâ–„
wandb:                PPO_1254/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1254/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1254/rollout/ep_rew_mean â–…â–â–„â–…â–…â–…â–â–†â–‚â–ˆâ–…â–‚
wandb:                   PPO_1254/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1254/train/approx_kl â–‚â–â–„â–„â–‚â–â–ˆâ–ƒâ–ƒâ–„â–„
wandb:        PPO_1254/train/clip_fraction â–ƒâ–ƒâ–‡â–†â–…â–‚â–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:           PPO_1254/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1254/train/entropy_loss â–â–â–ƒâ–„â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1254/train/explained_variance â–â–„â–ƒâ–†â–‡â–‡â–‡â–ƒâ–ˆâ–…â–†
wandb:        PPO_1254/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1254/train/loss â–‚â–ˆâ–„â–‚â–ƒâ–‚â–â–‡â–‚â–â–‚
wandb: PPO_1254/train/policy_gradient_loss â–„â–â–‚â–…â–„â–…â–…â–â–…â–ˆâ–…
wandb:                  PPO_1254/train/std â–ˆâ–ˆâ–†â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1254/train/value_loss â–…â–‡â–†â–…â–ƒâ–†â–„â–ˆâ–ƒâ–â–†
wandb:                PPO_1264/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1264/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1264/rollout/ep_rew_mean â–â–…â–†â–„â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                   PPO_1264/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1264/train/approx_kl â–ƒâ–‡â–â–†â–‡â–„â–‡â–ˆâ–ƒâ–…â–‡
wandb:        PPO_1264/train/clip_fraction â–†â–‡â–â–†â–„â–†â–…â–ˆâ–‡â–†â–‡
wandb:           PPO_1264/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1264/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–ˆ
wandb:   PPO_1264/train/explained_variance â–‡â–„â–â–…â–†â–…â–…â–‡â–…â–†â–ˆ
wandb:        PPO_1264/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1264/train/loss â–ˆâ–ƒâ–‡â–‡â–ˆâ–„â–…â–…â–„â–ƒâ–
wandb: PPO_1264/train/policy_gradient_loss â–ƒâ–ˆâ–â–…â–ƒâ–†â–â–…â–†â–ˆâ–‡
wandb:                  PPO_1264/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–„â–‚â–
wandb:           PPO_1264/train/value_loss â–â–‚â–ˆâ–‚â–…â–‚â–ƒâ–â–‚â–ƒâ–
wandb:                PPO_1274/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1274/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1274/rollout/ep_rew_mean â–…â–‡â–ˆâ–„â–„â–†â–…â–†â–‚â–‚â–â–ƒ
wandb:                   PPO_1274/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1274/train/approx_kl â–ƒâ–‚â–ˆâ–â–â–†â–‡â–†â–â–â–…
wandb:        PPO_1274/train/clip_fraction â–†â–‡â–ˆâ–â–„â–‡â–…â–‡â–„â–…â–…
wandb:           PPO_1274/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1274/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆ
wandb:   PPO_1274/train/explained_variance â–‚â–„â–…â–‡â–â–…â–ˆâ–„â–„â–†â–…
wandb:        PPO_1274/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1274/train/loss â–…â–„â–â–…â–‚â–‚â–‚â–ƒâ–‚â–ˆâ–†
wandb: PPO_1274/train/policy_gradient_loss â–ƒâ–†â–ˆâ–â–â–„â–„â–‡â–„â–„â–„
wandb:                  PPO_1274/train/std â–ˆâ–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1274/train/value_loss â–„â–ƒâ–â–…â–†â–ƒâ–„â–…â–ˆâ–‡â–ˆ
wandb:                PPO_1284/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1284/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1284/rollout/ep_rew_mean â–…â–…â–†â–‡â–ˆâ–â–†â–ƒâ–„â–…â–†â–„
wandb:                   PPO_1284/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1284/train/approx_kl â–…â–ˆâ–„â–…â–ƒâ–â–ƒâ–â–ˆâ–ƒâ–ƒ
wandb:        PPO_1284/train/clip_fraction â–ƒâ–‡â–„â–„â–„â–â–‡â–„â–†â–ˆâ–„
wandb:           PPO_1284/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1284/train/entropy_loss â–â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:   PPO_1284/train/explained_variance â–„â–â–ˆâ–„â–ƒâ–†â–ƒâ–‡â–„â–„â–…
wandb:        PPO_1284/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1284/train/loss â–â–‚â–‚â–â–‚â–„â–‚â–â–†â–ƒâ–ˆ
wandb: PPO_1284/train/policy_gradient_loss â–â–‡â–†â–ƒâ–„â–„â–ˆâ–â–ˆâ–†â–‡
wandb:                  PPO_1284/train/std â–ˆâ–‡â–†â–„â–‚â–ƒâ–ƒâ–‚â–â–‚â–
wandb:           PPO_1284/train/value_loss â–†â–„â–â–…â–„â–„â–†â–…â–ˆâ–„â–ˆ
wandb:                    global_mean_eval â–â–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–‚â–ˆâ–‡â–‡â–‡â–‡â–‡â–†
wandb:                       mean_reward_1 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–â–‚â–ˆâ–‡â–†â–†â–‡â–‡â–…
wandb:                      mean_reward_13 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–‚â–‚â–ˆâ–‡â–‡â–‡â–‡â–‡â–†
wandb:                      mean_reward_19 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–â–‚â–ˆâ–‡â–‡â–†â–‡â–‡â–†
wandb:                      mean_reward_25 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–„â–†â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–â–‚â–ˆâ–‡â–†â–†â–†â–‡â–…
wandb:                      mean_reward_31 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–„â–†â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–â–‚â–ˆâ–‡â–‡â–†â–‡â–‡â–…
wandb:                       mean_reward_7 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–â–ƒâ–â–‚â–â–‚â–‚â–â–ƒ
wandb:                        std_reward_1 â–„â–â–â–â–â–â–â–‚â–ƒâ–ˆ
wandb:                       std_reward_10 â–‚â–ˆâ–â–‚â–‚â–â–‚â–â–â–
wandb:                       std_reward_11 â–‚â–ˆâ–‚â–ƒâ–â–â–‚â–â–â–‚
wandb:                       std_reward_12 â–ˆâ–â–ƒâ–â–‚â–â–â–‚â–‚â–ƒ
wandb:                       std_reward_13 â–…â–â–â–‚â–‚â–â–â–ƒâ–„â–ˆ
wandb:                       std_reward_14 â–„â–ˆâ–â–‚â–‚â–â–â–ƒâ–ƒâ–…
wandb:                       std_reward_15 â–‚â–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_16 â–‚â–ˆâ–â–ƒâ–‚â–â–â–â–â–
wandb:                       std_reward_17 â–‚â–ˆâ–‚â–‚â–â–â–‚â–â–â–‚
wandb:                       std_reward_18 â–ˆâ–â–ƒâ–â–‚â–â–‚â–‚â–‚â–ƒ
wandb:                       std_reward_19 â–„â–‚â–â–â–‚â–â–â–‚â–ƒâ–ˆ
wandb:                        std_reward_2 â–…â–ˆâ–â–‚â–‚â–â–â–ƒâ–ƒâ–…
wandb:                       std_reward_20 â–„â–ˆâ–â–‚â–‚â–â–â–ƒâ–ƒâ–…
wandb:                       std_reward_21 â–ƒâ–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_22 â–‚â–ˆâ–â–ƒâ–‚â–â–‚â–â–â–
wandb:                       std_reward_23 â–‚â–ˆâ–â–ƒâ–â–â–‚â–â–â–‚
wandb:                       std_reward_24 â–ˆâ–â–ƒâ–â–‚â–â–â–‚â–â–ƒ
wandb:                       std_reward_25 â–…â–â–â–â–‚â–â–â–ƒâ–ƒâ–ˆ
wandb:                       std_reward_26 â–…â–ˆâ–â–‚â–‚â–â–â–ƒâ–„â–†
wandb:                       std_reward_27 â–‚â–ˆâ–â–ƒâ–‚â–â–â–‚â–â–‚
wandb:                       std_reward_28 â–‚â–ˆâ–â–ƒâ–‚â–â–â–â–â–
wandb:                       std_reward_29 â–‚â–ˆâ–â–‚â–â–â–‚â–â–â–‚
wandb:                        std_reward_3 â–‚â–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_30 â–ˆâ–â–ƒâ–â–‚â–â–‚â–ƒâ–‚â–ƒ
wandb:                       std_reward_31 â–„â–â–â–â–â–â–â–ƒâ–ƒâ–ˆ
wandb:                       std_reward_32 â–„â–ˆâ–â–‚â–‚â–â–â–ƒâ–ƒâ–†
wandb:                       std_reward_33 â–ƒâ–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_34 â–‚â–ˆâ–â–‚â–‚â–â–â–â–â–
wandb:                       std_reward_35 â–‚â–ˆâ–‚â–ƒâ–â–â–‚â–â–â–‚
wandb:                        std_reward_4 â–‚â–ˆâ–â–ƒâ–‚â–â–â–â–â–
wandb:                        std_reward_5 â–‚â–ˆâ–‚â–ƒâ–â–â–â–â–â–‚
wandb:                        std_reward_6 â–ˆâ–â–ƒâ–â–‚â–â–‚â–‚â–‚â–„
wandb:                        std_reward_7 â–…â–‚â–â–â–‚â–â–â–ƒâ–ƒâ–ˆ
wandb:                        std_reward_8 â–…â–ˆâ–â–‚â–‚â–â–â–ƒâ–„â–„
wandb:                        std_reward_9 â–ƒâ–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1205/global_step 212992
wandb:        PPO_1205/rollout/ep_len_mean 200.0
wandb:        PPO_1205/rollout/ep_rew_mean -805.2749
wandb:                   PPO_1205/time/fps 1203.0
wandb:            PPO_1205/train/approx_kl 0.01247
wandb:        PPO_1205/train/clip_fraction 0.1606
wandb:           PPO_1205/train/clip_range 0.2
wandb:         PPO_1205/train/entropy_loss -7.77934
wandb:   PPO_1205/train/explained_variance 0.95789
wandb:        PPO_1205/train/learning_rate 0.0003
wandb:                 PPO_1205/train/loss 65.84785
wandb: PPO_1205/train/policy_gradient_loss -0.00929
wandb:                  PPO_1205/train/std 0.73392
wandb:           PPO_1205/train/value_loss 97.94604
wandb:                PPO_1214/global_step 212992
wandb:        PPO_1214/rollout/ep_len_mean 200.0
wandb:        PPO_1214/rollout/ep_rew_mean -664.48822
wandb:                   PPO_1214/time/fps 1203.0
wandb:            PPO_1214/train/approx_kl 0.0146
wandb:        PPO_1214/train/clip_fraction 0.18329
wandb:           PPO_1214/train/clip_range 0.2
wandb:         PPO_1214/train/entropy_loss -7.00572
wandb:   PPO_1214/train/explained_variance 0.97086
wandb:        PPO_1214/train/learning_rate 0.0003
wandb:                 PPO_1214/train/loss 38.31045
wandb: PPO_1214/train/policy_gradient_loss -0.00718
wandb:                  PPO_1214/train/std 0.65751
wandb:           PPO_1214/train/value_loss 70.15537
wandb:                PPO_1224/global_step 212992
wandb:        PPO_1224/rollout/ep_len_mean 200.0
wandb:        PPO_1224/rollout/ep_rew_mean -576.60651
wandb:                   PPO_1224/time/fps 1197.0
wandb:            PPO_1224/train/approx_kl 0.01755
wandb:        PPO_1224/train/clip_fraction 0.214
wandb:           PPO_1224/train/clip_range 0.2
wandb:         PPO_1224/train/entropy_loss -6.1475
wandb:   PPO_1224/train/explained_variance 0.96407
wandb:        PPO_1224/train/learning_rate 0.0003
wandb:                 PPO_1224/train/loss 12.80777
wandb: PPO_1224/train/policy_gradient_loss -0.0033
wandb:                  PPO_1224/train/std 0.58186
wandb:           PPO_1224/train/value_loss 41.48785
wandb:                PPO_1234/global_step 212992
wandb:        PPO_1234/rollout/ep_len_mean 200.0
wandb:        PPO_1234/rollout/ep_rew_mean -543.07617
wandb:                   PPO_1234/time/fps 1195.0
wandb:            PPO_1234/train/approx_kl 0.0176
wandb:        PPO_1234/train/clip_fraction 0.2142
wandb:           PPO_1234/train/clip_range 0.2
wandb:         PPO_1234/train/entropy_loss -5.4342
wandb:   PPO_1234/train/explained_variance 0.97669
wandb:        PPO_1234/train/learning_rate 0.0003
wandb:                 PPO_1234/train/loss 28.95366
wandb: PPO_1234/train/policy_gradient_loss -0.00253
wandb:                  PPO_1234/train/std 0.5253
wandb:           PPO_1234/train/value_loss 54.49433
wandb:                PPO_1244/global_step 212992
wandb:        PPO_1244/rollout/ep_len_mean 200.0
wandb:        PPO_1244/rollout/ep_rew_mean -572.27435
wandb:                   PPO_1244/time/fps 1196.0
wandb:            PPO_1244/train/approx_kl 0.01822
wandb:        PPO_1244/train/clip_fraction 0.24073
wandb:           PPO_1244/train/clip_range 0.2
wandb:         PPO_1244/train/entropy_loss -5.05347
wandb:   PPO_1244/train/explained_variance 0.98451
wandb:        PPO_1244/train/learning_rate 0.0003
wandb:                 PPO_1244/train/loss 75.51214
wandb: PPO_1244/train/policy_gradient_loss -0.00242
wandb:                  PPO_1244/train/std 0.49787
wandb:           PPO_1244/train/value_loss 105.54469
wandb:                PPO_1254/global_step 212992
wandb:        PPO_1254/rollout/ep_len_mean 200.0
wandb:        PPO_1254/rollout/ep_rew_mean -563.04944
wandb:                   PPO_1254/time/fps 1195.0
wandb:            PPO_1254/train/approx_kl 0.01787
wandb:        PPO_1254/train/clip_fraction 0.23976
wandb:           PPO_1254/train/clip_range 0.2
wandb:         PPO_1254/train/entropy_loss -4.66117
wandb:   PPO_1254/train/explained_variance 0.98512
wandb:        PPO_1254/train/learning_rate 0.0003
wandb:                 PPO_1254/train/loss 59.09639
wandb: PPO_1254/train/policy_gradient_loss -0.00101
wandb:                  PPO_1254/train/std 0.47101
wandb:           PPO_1254/train/value_loss 196.36703
wandb:                PPO_1264/global_step 212992
wandb:        PPO_1264/rollout/ep_len_mean 200.0
wandb:        PPO_1264/rollout/ep_rew_mean -535.07129
wandb:                   PPO_1264/time/fps 1195.0
wandb:            PPO_1264/train/approx_kl 0.02103
wandb:        PPO_1264/train/clip_fraction 0.248
wandb:           PPO_1264/train/clip_range 0.2
wandb:         PPO_1264/train/entropy_loss -4.26442
wandb:   PPO_1264/train/explained_variance 0.99033
wandb:        PPO_1264/train/learning_rate 0.0003
wandb:                 PPO_1264/train/loss 24.61095
wandb: PPO_1264/train/policy_gradient_loss 0.00166
wandb:                  PPO_1264/train/std 0.44471
wandb:           PPO_1264/train/value_loss 171.54788
wandb:                PPO_1274/global_step 212992
wandb:        PPO_1274/rollout/ep_len_mean 200.0
wandb:        PPO_1274/rollout/ep_rew_mean -545.6203
wandb:                   PPO_1274/time/fps 1193.0
wandb:            PPO_1274/train/approx_kl 0.02305
wandb:        PPO_1274/train/clip_fraction 0.2357
wandb:           PPO_1274/train/clip_range 0.2
wandb:         PPO_1274/train/entropy_loss -3.79929
wandb:   PPO_1274/train/explained_variance 0.98725
wandb:        PPO_1274/train/learning_rate 0.0003
wandb:                 PPO_1274/train/loss 141.28677
wandb: PPO_1274/train/policy_gradient_loss 0.00194
wandb:                  PPO_1274/train/std 0.41544
wandb:           PPO_1274/train/value_loss 290.38177
wandb:                PPO_1284/global_step 212992
wandb:        PPO_1284/rollout/ep_len_mean 200.0
wandb:        PPO_1284/rollout/ep_rew_mean -560.60712
wandb:                   PPO_1284/time/fps 1195.0
wandb:            PPO_1284/train/approx_kl 0.01818
wandb:        PPO_1284/train/clip_fraction 0.24084
wandb:           PPO_1284/train/clip_range 0.2
wandb:         PPO_1284/train/entropy_loss -3.54834
wandb:   PPO_1284/train/explained_variance 0.98748
wandb:        PPO_1284/train/learning_rate 0.0003
wandb:                 PPO_1284/train/loss 699.79517
wandb: PPO_1284/train/policy_gradient_loss 0.00511
wandb:                  PPO_1284/train/std 0.40326
wandb:           PPO_1284/train/value_loss 408.62311
wandb:                    global_mean_eval -437.80984
wandb:                         global_step 212992
wandb:                       mean_reward_0 -459.0984
wandb:                       mean_reward_1 -327.45453
wandb:                      mean_reward_10 -484.30669
wandb:                      mean_reward_11 -490.8868
wandb:                      mean_reward_12 -480.16064
wandb:                      mean_reward_13 -309.9498
wandb:                      mean_reward_14 -404.61578
wandb:                      mean_reward_15 -458.29863
wandb:                      mean_reward_16 -484.55229
wandb:                      mean_reward_17 -491.3382
wandb:                      mean_reward_18 -463.6253
wandb:                      mean_reward_19 -331.07386
wandb:                       mean_reward_2 -404.09115
wandb:                      mean_reward_20 -404.82557
wandb:                      mean_reward_21 -458.57979
wandb:                      mean_reward_22 -483.27696
wandb:                      mean_reward_23 -490.88107
wandb:                      mean_reward_24 -453.90458
wandb:                      mean_reward_25 -320.36624
wandb:                      mean_reward_26 -406.60537
wandb:                      mean_reward_27 -459.19153
wandb:                      mean_reward_28 -484.57351
wandb:                      mean_reward_29 -491.7365
wandb:                       mean_reward_3 -458.97567
wandb:                      mean_reward_30 -461.58253
wandb:                      mean_reward_31 -320.03082
wandb:                      mean_reward_32 -408.97098
wandb:                      mean_reward_33 -457.88257
wandb:                      mean_reward_34 -484.26527
wandb:                      mean_reward_35 -492.14056
wandb:                       mean_reward_4 -484.21562
wandb:                       mean_reward_5 -492.09585
wandb:                       mean_reward_6 -469.6561
wandb:                       mean_reward_7 -320.94063
wandb:                       mean_reward_8 -406.63007
wandb:                       mean_reward_9 -460.37455
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 62.41127
wandb:                        std_reward_1 74.26109
wandb:                       std_reward_10 4.37166
wandb:                       std_reward_11 7.26388
wandb:                       std_reward_12 57.97595
wandb:                       std_reward_13 45.15359
wandb:                       std_reward_14 27.0521
wandb:                       std_reward_15 11.58439
wandb:                       std_reward_16 4.33233
wandb:                       std_reward_17 7.34452
wandb:                       std_reward_18 63.6336
wandb:                       std_reward_19 67.10001
wandb:                        std_reward_2 21.75933
wandb:                       std_reward_20 25.31844
wandb:                       std_reward_21 11.70671
wandb:                       std_reward_22 4.80294
wandb:                       std_reward_23 7.62653
wandb:                       std_reward_24 62.38097
wandb:                       std_reward_25 57.85785
wandb:                       std_reward_26 27.84791
wandb:                       std_reward_27 11.95338
wandb:                       std_reward_28 4.21385
wandb:                       std_reward_29 6.78733
wandb:                        std_reward_3 12.86711
wandb:                       std_reward_30 58.60251
wandb:                       std_reward_31 54.18466
wandb:                       std_reward_32 31.33932
wandb:                       std_reward_33 11.6258
wandb:                       std_reward_34 4.64285
wandb:                       std_reward_35 8.04228
wandb:                        std_reward_4 4.48645
wandb:                        std_reward_5 7.19947
wandb:                        std_reward_6 64.43883
wandb:                        std_reward_7 56.64435
wandb:                        std_reward_8 15.27768
wandb:                        std_reward_9 14.60557
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced upbeat-planet-38: https://wandb.ai/tidiane/meta_rl_context/runs/jt2eiuao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-jt2eiuao/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1204/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1204/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1204/rollout/ep_rew_mean â–‚â–â–â–ƒâ–ƒâ–ƒâ–„â–…â–„â–…â–…â–ˆ
wandb:                   PPO_1204/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1204/train/approx_kl â–â–‚â–‡â–‡â–†â–ƒâ–ˆâ–†â–…â–‡â–‡
wandb:        PPO_1204/train/clip_fraction â–â–…â–†â–‡â–‡â–„â–ˆâ–…â–‡â–ˆâ–ˆ
wandb:           PPO_1204/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1204/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1204/train/explained_variance â–ˆâ–…â–†â–ˆâ–„â–â–…â–„â–…â–…â–‚
wandb:        PPO_1204/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1204/train/loss â–â–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ˆâ–„
wandb: PPO_1204/train/policy_gradient_loss â–‡â–ˆâ–ƒâ–‚â–„â–‡â–â–…â–„â–ƒâ–ƒ
wandb:                  PPO_1204/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1204/train/value_loss â–â–„â–‚â–ƒâ–â–‡â–…â–ˆâ–†â–‡â–ˆ
wandb:                PPO_1215/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1215/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1215/rollout/ep_rew_mean â–â–â–‚â–‚â–„â–„â–†â–†â–†â–‡â–‡â–ˆ
wandb:                   PPO_1215/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1215/train/approx_kl â–ƒâ–‚â–â–ƒâ–„â–‡â–†â–‡â–ˆâ–ˆâ–†
wandb:        PPO_1215/train/clip_fraction â–‚â–â–‚â–â–ƒâ–…â–…â–†â–ˆâ–†â–…
wandb:           PPO_1215/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1215/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1215/train/explained_variance â–„â–ƒâ–„â–†â–â–‚â–‡â–‡â–ˆâ–†â–†
wandb:        PPO_1215/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1215/train/loss â–…â–ˆâ–ƒâ–‡â–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–
wandb: PPO_1215/train/policy_gradient_loss â–‚â–â–„â–ƒâ–„â–‚â–„â–†â–†â–ˆâ–‡
wandb:                  PPO_1215/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1215/train/value_loss â–†â–ˆâ–†â–†â–„â–ƒâ–‚â–â–â–â–
wandb:                PPO_1225/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1225/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1225/rollout/ep_rew_mean â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–„â–„â–ˆâ–…â–ƒâ–
wandb:                   PPO_1225/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1225/train/approx_kl â–…â–‡â–‚â–ˆâ–ˆâ–„â–‡â–…â–†â–…â–
wandb:        PPO_1225/train/clip_fraction â–†â–‡â–…â–‡â–ƒâ–ƒâ–†â–‡â–ˆâ–‚â–
wandb:           PPO_1225/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1225/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1225/train/explained_variance â–â–…â–†â–†â–„â–„â–†â–‡â–‡â–…â–ˆ
wandb:        PPO_1225/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1225/train/loss â–„â–â–â–‚â–‚â–‡â–…â–„â–â–…â–ˆ
wandb: PPO_1225/train/policy_gradient_loss â–â–ˆâ–†â–ƒâ–†â–ˆâ–†â–ˆâ–…â–‡â–ƒ
wandb:                  PPO_1225/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–â–â–
wandb:           PPO_1225/train/value_loss â–‚â–‚â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–†â–ˆ
wandb:                PPO_1235/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1235/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1235/rollout/ep_rew_mean â–ˆâ–†â–„â–„â–‚â–â–…â–†â–„â–…â–ƒâ–„
wandb:                   PPO_1235/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1235/train/approx_kl â–„â–„â–„â–ƒâ–‚â–â–ˆâ–ˆâ–„â–…â–ƒ
wandb:        PPO_1235/train/clip_fraction â–‡â–†â–ƒâ–†â–â–…â–‡â–‡â–„â–ˆâ–ƒ
wandb:           PPO_1235/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1235/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1235/train/explained_variance â–…â–‡â–â–ˆâ–„â–‚â–†â–„â–‡â–…â–†
wandb:        PPO_1235/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1235/train/loss â–â–‚â–„â–„â–†â–„â–‚â–…â–ˆâ–‚â–…
wandb: PPO_1235/train/policy_gradient_loss â–…â–‡â–‚â–†â–ƒâ–„â–â–‚â–…â–ˆâ–…
wandb:                  PPO_1235/train/std â–ˆâ–‡â–‡â–‡â–†â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1235/train/value_loss â–‚â–â–†â–‚â–ˆâ–‡â–†â–ƒâ–ˆâ–‡â–†
wandb:                PPO_1245/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1245/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1245/rollout/ep_rew_mean â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–†â–â–â–ˆâ–…
wandb:                   PPO_1245/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1245/train/approx_kl â–„â–â–…â–†â–„â–…â–ˆâ–ˆâ–…â–„â–…
wandb:        PPO_1245/train/clip_fraction â–„â–â–ƒâ–ƒâ–ƒâ–„â–ˆâ–†â–ƒâ–ƒâ–ˆ
wandb:           PPO_1245/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1245/train/entropy_loss â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–ˆ
wandb:   PPO_1245/train/explained_variance â–ˆâ–ˆâ–†â–…â–â–‡â–‡â–â–†â–†â–†
wandb:        PPO_1245/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1245/train/loss â–…â–„â–‡â–ˆâ–ƒâ–â–ƒâ–‚â–‚â–‚â–
wandb: PPO_1245/train/policy_gradient_loss â–â–†â–…â–†â–…â–…â–‡â–†â–‡â–„â–ˆ
wandb:                  PPO_1245/train/std â–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–…â–„â–
wandb:           PPO_1245/train/value_loss â–â–…â–†â–†â–ˆâ–†â–â–†â–‡â–ˆâ–†
wandb:                PPO_1255/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1255/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1255/rollout/ep_rew_mean â–„â–„â–…â–†â–ƒâ–†â–‡â–‡â–â–†â–ˆâ–‡
wandb:                   PPO_1255/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1255/train/approx_kl â–â–â–„â–â–‡â–‚â–…â–†â–â–…â–ˆ
wandb:        PPO_1255/train/clip_fraction â–„â–â–„â–‚â–…â–„â–†â–…â–â–ˆâ–ˆ
wandb:           PPO_1255/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1255/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1255/train/explained_variance â–…â–ƒâ–â–ƒâ–†â–ˆâ–‚â–…â–ƒâ–…â–…
wandb:        PPO_1255/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1255/train/loss â–â–â–ˆâ–†â–ƒâ–ˆâ–‚â–‚â–ƒâ–„â–ˆ
wandb: PPO_1255/train/policy_gradient_loss â–‡â–…â–â–â–†â–…â–…â–…â–â–‡â–ˆ
wandb:                  PPO_1255/train/std â–ˆâ–ˆâ–‡â–…â–…â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1255/train/value_loss â–ƒâ–…â–…â–†â–„â–â–â–‚â–ˆâ–â–‚
wandb:                PPO_1265/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1265/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1265/rollout/ep_rew_mean â–ˆâ–‡â–ˆâ–‚â–…â–ƒâ–ƒâ–â–‚â–„â–ƒâ–†
wandb:                   PPO_1265/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1265/train/approx_kl â–ˆâ–â–â–„â–‚â–‚â–â–„â–…â–ˆâ–†
wandb:        PPO_1265/train/clip_fraction â–ˆâ–„â–„â–…â–â–„â–‚â–ƒâ–†â–…â–ˆ
wandb:           PPO_1265/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1265/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–„â–…â–…â–ˆ
wandb:   PPO_1265/train/explained_variance â–ˆâ–…â–†â–ˆâ–…â–‡â–â–†â–‡â–‚â–†
wandb:        PPO_1265/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1265/train/loss â–â–‚â–…â–â–â–ˆâ–‚â–ƒâ–ƒâ–…â–ƒ
wandb: PPO_1265/train/policy_gradient_loss â–†â–â–„â–†â–ˆâ–†â–‚â–…â–„â–„â–„
wandb:                  PPO_1265/train/std â–ˆâ–‡â–†â–†â–…â–†â–…â–…â–„â–ƒâ–
wandb:           PPO_1265/train/value_loss â–â–„â–…â–…â–‡â–…â–ˆâ–‡â–†â–‡â–ƒ
wandb:                PPO_1275/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1275/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1275/rollout/ep_rew_mean â–‡â–â–ƒâ–ˆâ–…â–„â–†â–„â–†â–„â–‡â–†
wandb:                   PPO_1275/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1275/train/approx_kl â–†â–‚â–â–…â–†â–ˆâ–ƒâ–ƒâ–„â–â–‡
wandb:        PPO_1275/train/clip_fraction â–ˆâ–â–†â–‡â–„â–‡â–ƒâ–„â–…â–ƒâ–…
wandb:           PPO_1275/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1275/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1275/train/explained_variance â–â–„â–ˆâ–‚â–ƒâ–…â–„â–…â–ƒâ–‡â–‡
wandb:        PPO_1275/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1275/train/loss â–â–†â–ƒâ–â–â–‚â–‚â–â–ˆâ–‚â–ƒ
wandb: PPO_1275/train/policy_gradient_loss â–ˆâ–â–ƒâ–ˆâ–‡â–ƒâ–„â–‡â–ƒâ–‚â–…
wandb:                  PPO_1275/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–
wandb:           PPO_1275/train/value_loss â–ƒâ–ˆâ–…â–â–„â–ƒâ–…â–ˆâ–†â–„â–‚
wandb:                PPO_1285/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1285/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1285/rollout/ep_rew_mean â–…â–‡â–ˆâ–†â–â–…â–ƒâ–…â–„â–„â–†â–…
wandb:                   PPO_1285/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1285/train/approx_kl â–‚â–â–…â–ƒâ–…â–…â–…â–ˆâ–‚â–‚â–ƒ
wandb:        PPO_1285/train/clip_fraction â–ƒâ–†â–ˆâ–„â–†â–‡â–‡â–ˆâ–ƒâ–â–
wandb:           PPO_1285/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1285/train/entropy_loss â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1285/train/explained_variance â–â–„â–„â–†â–†â–†â–„â–…â–ˆâ–…â–‡
wandb:        PPO_1285/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1285/train/loss â–ˆâ–â–‚â–‚â–ƒâ–„â–‡â–‚â–â–‚â–ƒ
wandb: PPO_1285/train/policy_gradient_loss â–ƒâ–„â–ˆâ–„â–‚â–„â–ƒâ–†â–…â–â–
wandb:                  PPO_1285/train/std â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1285/train/value_loss â–ˆâ–â–…â–†â–…â–„â–‡â–†â–â–ˆâ–…
wandb:                    global_mean_eval â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–ˆâ–…â–ƒâ–„â–…â–†â–†â–‡
wandb:                       mean_reward_1 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_10 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–„â–ˆâ–…â–„â–…â–†â–†â–†â–‡
wandb:                      mean_reward_13 â–â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_14 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_15 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–„â–ˆâ–…â–„â–„â–…â–…â–†â–‡
wandb:                      mean_reward_19 â–â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                       mean_reward_2 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_20 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_21 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–„â–ˆâ–…â–ƒâ–„â–…â–†â–‡â–‡
wandb:                      mean_reward_25 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_26 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_27 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–„â–ˆâ–…â–ƒâ–„â–…â–†â–†â–‡
wandb:                      mean_reward_31 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_32 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_33 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–„â–ˆâ–…â–ƒâ–„â–…â–…â–†â–‡
wandb:                       mean_reward_7 â–â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                       mean_reward_8 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                       mean_reward_9 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–‚â–â–‚â–â–‚â–‚â–â–‚â–‚
wandb:                        std_reward_1 â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–
wandb:                       std_reward_10 â–ˆâ–ƒâ–â–â–‚â–ƒâ–â–â–‚â–‚
wandb:                       std_reward_11 â–†â–ˆâ–â–â–â–„â–â–â–‚â–
wandb:                       std_reward_12 â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:                       std_reward_13 â–ˆâ–â–â–â–â–…â–‚â–‚â–ƒâ–
wandb:                       std_reward_14 â–ˆâ–‚â–â–â–â–„â–â–‚â–‚â–‚
wandb:                       std_reward_15 â–ˆâ–ƒâ–â–â–‚â–„â–â–‚â–‚â–‚
wandb:                       std_reward_16 â–ˆâ–ƒâ–â–â–‚â–†â–â–â–‚â–‚
wandb:                       std_reward_17 â–…â–ˆâ–â–â–â–„â–â–â–â–
wandb:                       std_reward_18 â–ˆâ–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚
wandb:                       std_reward_19 â–ˆâ–â–â–â–â–…â–‚â–‚â–ƒâ–
wandb:                        std_reward_2 â–ˆâ–‚â–â–â–‚â–ƒâ–â–‚â–‚â–‚
wandb:                       std_reward_20 â–ˆâ–‚â–â–â–â–…â–â–‚â–‚â–‚
wandb:                       std_reward_21 â–ˆâ–‚â–â–â–‚â–„â–â–â–‚â–‚
wandb:                       std_reward_22 â–ˆâ–ƒâ–â–â–‚â–‡â–â–‚â–‚â–‚
wandb:                       std_reward_23 â–„â–ˆâ–â–â–â–ƒâ–â–â–â–
wandb:                       std_reward_24 â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒ
wandb:                       std_reward_25 â–ˆâ–‚â–â–â–â–„â–‚â–‚â–ƒâ–
wandb:                       std_reward_26 â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–‚â–‚
wandb:                       std_reward_27 â–ˆâ–‚â–â–â–â–‚â–â–â–‚â–‚
wandb:                       std_reward_28 â–ˆâ–ƒâ–â–â–‚â–„â–â–‚â–‚â–‚
wandb:                       std_reward_29 â–…â–ˆâ–â–â–â–„â–‚â–â–‚â–‚
wandb:                        std_reward_3 â–ˆâ–‚â–â–â–‚â–ƒâ–â–‚â–‚â–‚
wandb:                       std_reward_30 â–ˆâ–‚â–â–‚â–â–â–â–‚â–‚â–‚
wandb:                       std_reward_31 â–ˆâ–â–â–â–â–ƒâ–‚â–‚â–‚â–
wandb:                       std_reward_32 â–ˆâ–‚â–â–â–‚â–‚â–â–‚â–‚â–‚
wandb:                       std_reward_33 â–ˆâ–‚â–â–â–‚â–„â–â–‚â–‚â–‚
wandb:                       std_reward_34 â–ˆâ–ƒâ–â–â–‚â–ƒâ–â–‚â–‚â–‚
wandb:                       std_reward_35 â–‡â–ˆâ–â–â–â–‚â–â–‚â–‚â–‚
wandb:                        std_reward_4 â–ˆâ–‚â–â–â–â–„â–â–â–‚â–‚
wandb:                        std_reward_5 â–…â–ˆâ–â–â–â–„â–â–â–‚â–‚
wandb:                        std_reward_6 â–ˆâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:                        std_reward_7 â–ˆâ–‚â–â–â–â–…â–‚â–‚â–‚â–
wandb:                        std_reward_8 â–ˆâ–‚â–â–â–â–‚â–â–‚â–‚â–‚
wandb:                        std_reward_9 â–ˆâ–‚â–â–â–â–„â–â–â–‚â–‚
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1204/global_step 212992
wandb:        PPO_1204/rollout/ep_len_mean 200.0
wandb:        PPO_1204/rollout/ep_rew_mean -766.41443
wandb:                   PPO_1204/time/fps 1201.0
wandb:            PPO_1204/train/approx_kl 0.01136
wandb:        PPO_1204/train/clip_fraction 0.14548
wandb:           PPO_1204/train/clip_range 0.2
wandb:         PPO_1204/train/entropy_loss -7.78763
wandb:   PPO_1204/train/explained_variance 0.95962
wandb:        PPO_1204/train/learning_rate 0.0003
wandb:                 PPO_1204/train/loss 65.06133
wandb: PPO_1204/train/policy_gradient_loss -0.00892
wandb:                  PPO_1204/train/std 0.73537
wandb:           PPO_1204/train/value_loss 177.50426
wandb:                PPO_1215/global_step 212992
wandb:        PPO_1215/rollout/ep_len_mean 200.0
wandb:        PPO_1215/rollout/ep_rew_mean -589.49054
wandb:                   PPO_1215/time/fps 1195.0
wandb:            PPO_1215/train/approx_kl 0.0135
wandb:        PPO_1215/train/clip_fraction 0.18517
wandb:           PPO_1215/train/clip_range 0.2
wandb:         PPO_1215/train/entropy_loss -6.88918
wandb:   PPO_1215/train/explained_variance 0.96359
wandb:        PPO_1215/train/learning_rate 0.0003
wandb:                 PPO_1215/train/loss 13.75859
wandb: PPO_1215/train/policy_gradient_loss -0.00593
wandb:                  PPO_1215/train/std 0.64799
wandb:           PPO_1215/train/value_loss 53.65878
wandb:                PPO_1225/global_step 212992
wandb:        PPO_1225/rollout/ep_len_mean 200.0
wandb:        PPO_1225/rollout/ep_rew_mean -586.01599
wandb:                   PPO_1225/time/fps 1197.0
wandb:            PPO_1225/train/approx_kl 0.01191
wandb:        PPO_1225/train/clip_fraction 0.15842
wandb:           PPO_1225/train/clip_range 0.2
wandb:         PPO_1225/train/entropy_loss -6.37916
wandb:   PPO_1225/train/explained_variance 0.97763
wandb:        PPO_1225/train/learning_rate 0.0003
wandb:                 PPO_1225/train/loss 85.02012
wandb: PPO_1225/train/policy_gradient_loss -0.00525
wandb:                  PPO_1225/train/std 0.60272
wandb:           PPO_1225/train/value_loss 224.20891
wandb:                PPO_1235/global_step 212992
wandb:        PPO_1235/rollout/ep_len_mean 200.0
wandb:        PPO_1235/rollout/ep_rew_mean -573.11615
wandb:                   PPO_1235/time/fps 1199.0
wandb:            PPO_1235/train/approx_kl 0.01354
wandb:        PPO_1235/train/clip_fraction 0.16572
wandb:           PPO_1235/train/clip_range 0.2
wandb:         PPO_1235/train/entropy_loss -5.92667
wandb:   PPO_1235/train/explained_variance 0.98066
wandb:        PPO_1235/train/learning_rate 0.0003
wandb:                 PPO_1235/train/loss 93.41003
wandb: PPO_1235/train/policy_gradient_loss -0.00257
wandb:                  PPO_1235/train/std 0.56465
wandb:           PPO_1235/train/value_loss 292.11072
wandb:                PPO_1245/global_step 212992
wandb:        PPO_1245/rollout/ep_len_mean 200.0
wandb:        PPO_1245/rollout/ep_rew_mean -587.41986
wandb:                   PPO_1245/time/fps 1195.0
wandb:            PPO_1245/train/approx_kl 0.01302
wandb:        PPO_1245/train/clip_fraction 0.19999
wandb:           PPO_1245/train/clip_range 0.2
wandb:         PPO_1245/train/entropy_loss -5.58866
wandb:   PPO_1245/train/explained_variance 0.9806
wandb:        PPO_1245/train/learning_rate 0.0003
wandb:                 PPO_1245/train/loss 102.58804
wandb: PPO_1245/train/policy_gradient_loss -0.00052
wandb:                  PPO_1245/train/std 0.53807
wandb:           PPO_1245/train/value_loss 534.59552
wandb:                PPO_1255/global_step 212992
wandb:        PPO_1255/rollout/ep_len_mean 200.0
wandb:        PPO_1255/rollout/ep_rew_mean -566.57007
wandb:                   PPO_1255/time/fps 1194.0
wandb:            PPO_1255/train/approx_kl 0.01691
wandb:        PPO_1255/train/clip_fraction 0.21627
wandb:           PPO_1255/train/clip_range 0.2
wandb:         PPO_1255/train/entropy_loss -5.07658
wandb:   PPO_1255/train/explained_variance 0.98337
wandb:        PPO_1255/train/learning_rate 0.0003
wandb:                 PPO_1255/train/loss 369.5806
wandb: PPO_1255/train/policy_gradient_loss -0.00039
wandb:                  PPO_1255/train/std 0.49945
wandb:           PPO_1255/train/value_loss 398.09641
wandb:                PPO_1265/global_step 212992
wandb:        PPO_1265/rollout/ep_len_mean 200.0
wandb:        PPO_1265/rollout/ep_rew_mean -545.69714
wandb:                   PPO_1265/time/fps 1189.0
wandb:            PPO_1265/train/approx_kl 0.01682
wandb:        PPO_1265/train/clip_fraction 0.23752
wandb:           PPO_1265/train/clip_range 0.2
wandb:         PPO_1265/train/entropy_loss -4.67195
wandb:   PPO_1265/train/explained_variance 0.98133
wandb:        PPO_1265/train/learning_rate 0.0003
wandb:                 PPO_1265/train/loss 136.51187
wandb: PPO_1265/train/policy_gradient_loss -6e-05
wandb:                  PPO_1265/train/std 0.47252
wandb:           PPO_1265/train/value_loss 318.72162
wandb:                PPO_1275/global_step 212992
wandb:        PPO_1275/rollout/ep_len_mean 200.0
wandb:        PPO_1275/rollout/ep_rew_mean -530.84143
wandb:                   PPO_1275/time/fps 1192.0
wandb:            PPO_1275/train/approx_kl 0.01941
wandb:        PPO_1275/train/clip_fraction 0.23215
wandb:           PPO_1275/train/clip_range 0.2
wandb:         PPO_1275/train/entropy_loss -4.34057
wandb:   PPO_1275/train/explained_variance 0.98406
wandb:        PPO_1275/train/learning_rate 0.0003
wandb:                 PPO_1275/train/loss 132.52335
wandb: PPO_1275/train/policy_gradient_loss 0.00135
wandb:                  PPO_1275/train/std 0.44947
wandb:           PPO_1275/train/value_loss 176.00734
wandb:                PPO_1285/global_step 212992
wandb:        PPO_1285/rollout/ep_len_mean 200.0
wandb:        PPO_1285/rollout/ep_rew_mean -521.65717
wandb:                   PPO_1285/time/fps 1189.0
wandb:            PPO_1285/train/approx_kl 0.01871
wandb:        PPO_1285/train/clip_fraction 0.2222
wandb:           PPO_1285/train/clip_range 0.2
wandb:         PPO_1285/train/entropy_loss -3.96569
wandb:   PPO_1285/train/explained_variance 0.98722
wandb:        PPO_1285/train/learning_rate 0.0003
wandb:                 PPO_1285/train/loss 75.33188
wandb: PPO_1285/train/policy_gradient_loss 0.00022
wandb:                  PPO_1285/train/std 0.42712
wandb:           PPO_1285/train/value_loss 176.69337
wandb:                    global_mean_eval -457.19261
wandb:                         global_step 212992
wandb:                       mean_reward_0 -402.26806
wandb:                       mean_reward_1 -401.2081
wandb:                      mean_reward_10 -497.64192
wandb:                      mean_reward_11 -506.5726
wandb:                      mean_reward_12 -405.42843
wandb:                      mean_reward_13 -401.44989
wandb:                      mean_reward_14 -450.83252
wandb:                      mean_reward_15 -481.57192
wandb:                      mean_reward_16 -497.90762
wandb:                      mean_reward_17 -506.58164
wandb:                      mean_reward_18 -402.54593
wandb:                      mean_reward_19 -401.19902
wandb:                       mean_reward_2 -450.5175
wandb:                      mean_reward_20 -450.76696
wandb:                      mean_reward_21 -481.86438
wandb:                      mean_reward_22 -497.48536
wandb:                      mean_reward_23 -506.42191
wandb:                      mean_reward_24 -409.92687
wandb:                      mean_reward_25 -401.20762
wandb:                      mean_reward_26 -450.81294
wandb:                      mean_reward_27 -481.63637
wandb:                      mean_reward_28 -497.93473
wandb:                      mean_reward_29 -507.04155
wandb:                       mean_reward_3 -481.7625
wandb:                      mean_reward_30 -403.89078
wandb:                      mean_reward_31 -400.87704
wandb:                      mean_reward_32 -450.42453
wandb:                      mean_reward_33 -481.31828
wandb:                      mean_reward_34 -497.3866
wandb:                      mean_reward_35 -506.74366
wandb:                       mean_reward_4 -497.4769
wandb:                       mean_reward_5 -507.10342
wandb:                       mean_reward_6 -407.50753
wandb:                       mean_reward_7 -401.21901
wandb:                       mean_reward_8 -450.73775
wandb:                       mean_reward_9 -481.66211
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 42.52398
wandb:                        std_reward_1 2.14159
wandb:                       std_reward_10 2.47662
wandb:                       std_reward_11 2.41686
wandb:                       std_reward_12 46.44858
wandb:                       std_reward_13 2.4424
wandb:                       std_reward_14 2.87985
wandb:                       std_reward_15 2.66923
wandb:                       std_reward_16 2.4102
wandb:                       std_reward_17 2.46581
wandb:                       std_reward_18 43.24126
wandb:                       std_reward_19 2.82917
wandb:                        std_reward_2 2.91597
wandb:                       std_reward_20 2.79294
wandb:                       std_reward_21 2.10695
wandb:                       std_reward_22 2.50803
wandb:                       std_reward_23 2.27387
wandb:                       std_reward_24 52.47012
wandb:                       std_reward_25 2.43814
wandb:                       std_reward_26 2.62061
wandb:                       std_reward_27 2.21787
wandb:                       std_reward_28 2.44042
wandb:                       std_reward_29 2.47788
wandb:                        std_reward_3 2.29548
wandb:                       std_reward_30 46.00493
wandb:                       std_reward_31 2.94185
wandb:                       std_reward_32 2.87932
wandb:                       std_reward_33 2.24897
wandb:                       std_reward_34 2.42452
wandb:                       std_reward_35 2.39107
wandb:                        std_reward_4 2.49362
wandb:                        std_reward_5 2.71916
wandb:                        std_reward_6 49.01591
wandb:                        std_reward_7 2.64564
wandb:                        std_reward_8 2.87704
wandb:                        std_reward_9 2.0105
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced flowing-totem-39: https://wandb.ai/tidiane/meta_rl_context/runs/n0hoact8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-n0hoact8/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1207/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1207/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1207/rollout/ep_rew_mean â–â–‚â–‚â–‚â–„â–ƒâ–„â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                   PPO_1207/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1207/train/approx_kl â–„â–‚â–‚â–â–„â–†â–ƒâ–„â–ˆâ–ˆâ–ˆ
wandb:        PPO_1207/train/clip_fraction â–â–â–‚â–‚â–…â–†â–…â–…â–‡â–‡â–ˆ
wandb:           PPO_1207/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1207/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1207/train/explained_variance â–â–ˆâ–ˆâ–†â–‡â–…â–†â–„â–†â–‚â–‚
wandb:        PPO_1207/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1207/train/loss â–â–ˆâ–â–ƒâ–ƒâ–‡â–‡â–…â–„â–â–‚
wandb: PPO_1207/train/policy_gradient_loss â–â–…â–ˆâ–…â–„â–â–‡â–‡â–…â–†â–ˆ
wandb:                  PPO_1207/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1207/train/value_loss â–ƒâ–â–‚â–…â–‚â–‡â–…â–ˆâ–…â–‚â–‚
wandb:                PPO_1216/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1216/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1216/rollout/ep_rew_mean â–‚â–â–â–â–„â–„â–…â–†â–…â–‡â–ˆâ–ˆ
wandb:                   PPO_1216/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1216/train/approx_kl â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–ˆâ–…â–ˆâ–…
wandb:        PPO_1216/train/clip_fraction â–‚â–ƒâ–‚â–â–‚â–â–ƒâ–ˆâ–…â–ˆâ–…
wandb:           PPO_1216/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1216/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1216/train/explained_variance â–„â–„â–ƒâ–…â–â–„â–†â–ƒâ–ˆâ–…â–„
wandb:        PPO_1216/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1216/train/loss â–ƒâ–ƒâ–ˆâ–…â–†â–†â–„â–â–‚â–‚â–‚
wandb: PPO_1216/train/policy_gradient_loss â–ƒâ–â–„â–„â–‡â–‡â–…â–„â–…â–†â–ˆ
wandb:                  PPO_1216/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1216/train/value_loss â–†â–„â–ˆâ–…â–ˆâ–†â–†â–â–†â–â–
wandb:                PPO_1226/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1226/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1226/rollout/ep_rew_mean â–â–â–â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–†â–ˆ
wandb:                   PPO_1226/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1226/train/approx_kl â–â–„â–„â–‡â–‚â–‡â–ƒâ–‡â–ˆâ–†â–ƒ
wandb:        PPO_1226/train/clip_fraction â–â–â–„â–…â–â–‚â–ƒâ–…â–„â–ˆâ–„
wandb:           PPO_1226/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1226/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1226/train/explained_variance â–„â–†â–†â–†â–…â–†â–ˆâ–‡â–‚â–„â–
wandb:        PPO_1226/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1226/train/loss â–â–ƒâ–„â–â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚
wandb: PPO_1226/train/policy_gradient_loss â–†â–â–‚â–†â–†â–‚â–ƒâ–â–‚â–„â–ˆ
wandb:                  PPO_1226/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1226/train/value_loss â–ƒâ–ˆâ–…â–â–‡â–…â–ƒâ–†â–‡â–‚â–…
wandb:                PPO_1236/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1236/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1236/rollout/ep_rew_mean â–â–„â–†â–„â–â–„â–…â–†â–‡â–‡â–ˆâ–…
wandb:                   PPO_1236/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1236/train/approx_kl â–â–‚â–…â–‚â–ˆâ–‡â–†â–â–…â–‚â–„
wandb:        PPO_1236/train/clip_fraction â–…â–…â–†â–„â–‡â–ˆâ–‡â–â–ˆâ–‡â–ƒ
wandb:           PPO_1236/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1236/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1236/train/explained_variance â–â–‡â–‚â–‡â–ˆâ–‡â–†â–…â–†â–â–…
wandb:        PPO_1236/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1236/train/loss â–„â–â–‚â–‡â–†â–‚â–â–„â–ƒâ–ˆâ–„
wandb: PPO_1236/train/policy_gradient_loss â–„â–â–…â–…â–ƒâ–…â–ƒâ–ƒâ–ˆâ–…â–
wandb:                  PPO_1236/train/std â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1236/train/value_loss â–‚â–ƒâ–‚â–ƒâ–‡â–ƒâ–â–ˆâ–†â–‚â–‚
wandb:                PPO_1246/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1246/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1246/rollout/ep_rew_mean â–â–â–â–‚â–ƒâ–†â–†â–†â–ƒâ–…â–…â–ˆ
wandb:                   PPO_1246/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1246/train/approx_kl â–â–…â–„â–„â–„â–…â–„â–ƒâ–‚â–‡â–ˆ
wandb:        PPO_1246/train/clip_fraction â–â–‚â–‚â–†â–ƒâ–…â–†â–â–‚â–†â–ˆ
wandb:           PPO_1246/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1246/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1246/train/explained_variance â–â–ƒâ–„â–…â–„â–…â–ˆâ–‡â–†â–†â–ˆ
wandb:        PPO_1246/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1246/train/loss â–‡â–„â–…â–â–ƒâ–ˆâ–ƒâ–…â–…â–„â–ƒ
wandb: PPO_1246/train/policy_gradient_loss â–‡â–‚â–â–„â–‚â–†â–…â–ƒâ–„â–†â–ˆ
wandb:                  PPO_1246/train/std â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1246/train/value_loss â–†â–…â–ˆâ–ƒâ–…â–…â–â–„â–ˆâ–…â–
wandb:                PPO_1256/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1256/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1256/rollout/ep_rew_mean â–â–ƒâ–…â–†â–…â–†â–ˆâ–†â–‡â–†â–‡â–„
wandb:                   PPO_1256/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1256/train/approx_kl â–â–â–…â–ƒâ–ƒâ–„â–ˆâ–„â–„â–‡â–ƒ
wandb:        PPO_1256/train/clip_fraction â–„â–„â–†â–†â–â–…â–†â–ˆâ–†â–„â–„
wandb:           PPO_1256/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1256/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1256/train/explained_variance â–†â–†â–‡â–†â–‡â–‡â–‚â–â–ˆâ–†â–‡
wandb:        PPO_1256/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1256/train/loss â–â–ˆâ–ƒâ–â–ƒâ–‚â–‚â–†â–‚â–„â–‡
wandb: PPO_1256/train/policy_gradient_loss â–„â–â–ƒâ–†â–…â–‚â–†â–ˆâ–‚â–…â–„
wandb:                  PPO_1256/train/std â–ˆâ–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1256/train/value_loss â–…â–‡â–…â–â–…â–…â–ˆâ–ƒâ–ƒâ–…â–‡
wandb:                PPO_1266/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1266/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1266/rollout/ep_rew_mean â–‚â–„â–ƒâ–„â–„â–…â–†â–ˆâ–â–„â–…â–„
wandb:                   PPO_1266/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1266/train/approx_kl â–ƒâ–‡â–„â–ˆâ–‚â–‡â–†â–â–â–„â–„
wandb:        PPO_1266/train/clip_fraction â–…â–ˆâ–…â–‡â–„â–ˆâ–†â–†â–â–…â–„
wandb:           PPO_1266/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1266/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1266/train/explained_variance â–…â–…â–ˆâ–†â–†â–‡â–„â–„â–…â–â–„
wandb:        PPO_1266/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1266/train/loss â–â–ƒâ–â–â–‚â–â–â–‚â–ƒâ–‚â–ˆ
wandb: PPO_1266/train/policy_gradient_loss â–„â–â–‚â–…â–†â–‡â–†â–‡â–ƒâ–ˆâ–
wandb:                  PPO_1266/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1266/train/value_loss â–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–†â–†â–ˆ
wandb:                PPO_1276/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1276/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1276/rollout/ep_rew_mean â–„â–‚â–â–ƒâ–ˆâ–†â–‡â–†â–ƒâ–„â–‡â–„
wandb:                   PPO_1276/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1276/train/approx_kl â–‚â–ƒâ–ƒâ–‚â–…â–…â–â–ˆâ–‚â–„â–„
wandb:        PPO_1276/train/clip_fraction â–‚â–†â–â–„â–†â–„â–ƒâ–ˆâ–„â–†â–†
wandb:           PPO_1276/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1276/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1276/train/explained_variance â–ƒâ–ˆâ–â–â–‡â–…â–…â–†â–‚â–„â–
wandb:        PPO_1276/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1276/train/loss â–ƒâ–‚â–‚â–‡â–â–‚â–ƒâ–â–ƒâ–â–ˆ
wandb: PPO_1276/train/policy_gradient_loss â–â–…â–‚â–„â–ƒâ–‚â–„â–‡â–„â–ˆâ–„
wandb:                  PPO_1276/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1276/train/value_loss â–†â–ƒâ–ˆâ–†â–â–ƒâ–…â–‚â–…â–†â–‡
wandb:                PPO_1286/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1286/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1286/rollout/ep_rew_mean â–„â–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ˆâ–„â–„â–‡
wandb:                   PPO_1286/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1286/train/approx_kl â–„â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–„â–ˆâ–‚
wandb:        PPO_1286/train/clip_fraction â–‚â–ˆâ–â–‡â–ƒâ–…â–…â–ˆâ–†â–ˆâ–‚
wandb:           PPO_1286/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1286/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1286/train/explained_variance â–„â–ˆâ–‡â–„â–‡â–†â–…â–„â–â–„â–‚
wandb:        PPO_1286/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1286/train/loss â–ƒâ–‚â–â–‚â–ƒâ–â–â–ˆâ–‚â–‚â–‚
wandb: PPO_1286/train/policy_gradient_loss â–‚â–ƒâ–†â–„â–…â–â–†â–„â–ˆâ–†â–‡
wandb:                  PPO_1286/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1286/train/value_loss â–ˆâ–‚â–‡â–†â–†â–„â–„â–…â–â–â–…
wandb:                    global_mean_eval â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                       mean_reward_1 â–‚â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_13 â–‚â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_19 â–â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_24 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                      mean_reward_25 â–â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                      mean_reward_31 â–‚â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_5 â–â–ƒâ–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–â–‚â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                       mean_reward_7 â–‚â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–‡â–ƒâ–ƒâ–‚â–â–â–ƒâ–‚â–†â–ˆ
wandb:                        std_reward_1 â–ˆâ–…â–â–‚â–â–‚â–â–â–â–‡
wandb:                       std_reward_10 â–„â–ƒâ–â–‚â–â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_11 â–„â–„â–â–â–‚â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_12 â–‡â–‚â–ƒâ–‚â–â–â–‚â–‚â–†â–ˆ
wandb:                       std_reward_13 â–ˆâ–„â–â–‚â–â–‚â–â–â–â–†
wandb:                       std_reward_14 â–ˆâ–†â–â–â–„â–‚â–‚â–â–â–…
wandb:                       std_reward_15 â–„â–‚â–â–â–ƒâ–â–‚â–â–â–ˆ
wandb:                       std_reward_16 â–„â–ƒâ–â–‚â–‚â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_17 â–„â–ƒâ–â–â–‚â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_18 â–ˆâ–ƒâ–ƒâ–‚â–â–â–ƒâ–‚â–†â–†
wandb:                       std_reward_19 â–ˆâ–„â–â–‚â–â–‚â–â–â–â–„
wandb:                        std_reward_2 â–ˆâ–…â–â–â–ƒâ–â–‚â–â–â–†
wandb:                       std_reward_20 â–ˆâ–†â–â–â–„â–‚â–‚â–â–â–†
wandb:                       std_reward_21 â–‡â–ƒâ–â–â–†â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_22 â–ƒâ–‚â–â–‚â–â–‚â–â–â–â–ˆ
wandb:                       std_reward_23 â–ƒâ–ƒâ–â–â–â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_24 â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–ˆâ–‡
wandb:                       std_reward_25 â–ˆâ–„â–â–‚â–â–‚â–â–â–â–ƒ
wandb:                       std_reward_26 â–ˆâ–†â–â–â–„â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_27 â–…â–ƒâ–â–â–…â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_28 â–„â–„â–â–‚â–‚â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_29 â–„â–„â–â–â–‚â–‚â–‚â–â–â–ˆ
wandb:                        std_reward_3 â–„â–‚â–â–â–„â–â–‚â–â–â–ˆ
wandb:                       std_reward_30 â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‡â–†
wandb:                       std_reward_31 â–ˆâ–…â–â–‚â–â–‚â–â–â–â–‚
wandb:                       std_reward_32 â–ˆâ–†â–â–â–„â–‚â–‚â–â–â–
wandb:                       std_reward_33 â–ˆâ–ƒâ–â–‚â–†â–‚â–‚â–â–â–
wandb:                       std_reward_34 â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–â–â–ˆ
wandb:                       std_reward_35 â–„â–ƒâ–â–â–â–‚â–‚â–â–â–ˆ
wandb:                        std_reward_4 â–ƒâ–‚â–â–‚â–â–‚â–â–â–â–ˆ
wandb:                        std_reward_5 â–ƒâ–ƒâ–â–â–‚â–‚â–‚â–…â–â–ˆ
wandb:                        std_reward_6 â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‡â–ˆ
wandb:                        std_reward_7 â–ˆâ–„â–â–‚â–â–‚â–â–‚â–â–ƒ
wandb:                        std_reward_8 â–ˆâ–…â–â–â–ƒâ–‚â–‚â–â–â–‚
wandb:                        std_reward_9 â–…â–ƒâ–â–â–„â–‚â–‚â–â–â–ˆ
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1207/global_step 212992
wandb:        PPO_1207/rollout/ep_len_mean 200.0
wandb:        PPO_1207/rollout/ep_rew_mean -801.86603
wandb:                   PPO_1207/time/fps 1198.0
wandb:            PPO_1207/train/approx_kl 0.0114
wandb:        PPO_1207/train/clip_fraction 0.14545
wandb:           PPO_1207/train/clip_range 0.2
wandb:         PPO_1207/train/entropy_loss -7.9137
wandb:   PPO_1207/train/explained_variance 0.9505
wandb:        PPO_1207/train/learning_rate 0.0003
wandb:                 PPO_1207/train/loss 35.40438
wandb: PPO_1207/train/policy_gradient_loss -0.00701
wandb:                  PPO_1207/train/std 0.74801
wandb:           PPO_1207/train/value_loss 93.91075
wandb:                PPO_1216/global_step 212992
wandb:        PPO_1216/rollout/ep_len_mean 200.0
wandb:        PPO_1216/rollout/ep_rew_mean -693.40479
wandb:                   PPO_1216/time/fps 1190.0
wandb:            PPO_1216/train/approx_kl 0.01378
wandb:        PPO_1216/train/clip_fraction 0.17845
wandb:           PPO_1216/train/clip_range 0.2
wandb:         PPO_1216/train/entropy_loss -7.0129
wandb:   PPO_1216/train/explained_variance 0.96496
wandb:        PPO_1216/train/learning_rate 0.0003
wandb:                 PPO_1216/train/loss 17.15711
wandb: PPO_1216/train/policy_gradient_loss -0.00465
wandb:                  PPO_1216/train/std 0.65719
wandb:           PPO_1216/train/value_loss 64.93651
wandb:                PPO_1226/global_step 212992
wandb:        PPO_1226/rollout/ep_len_mean 200.0
wandb:        PPO_1226/rollout/ep_rew_mean -580.71161
wandb:                   PPO_1226/time/fps 1186.0
wandb:            PPO_1226/train/approx_kl 0.01445
wandb:        PPO_1226/train/clip_fraction 0.20764
wandb:           PPO_1226/train/clip_range 0.2
wandb:         PPO_1226/train/entropy_loss -6.18124
wandb:   PPO_1226/train/explained_variance 0.96164
wandb:        PPO_1226/train/learning_rate 0.0003
wandb:                 PPO_1226/train/loss 18.89764
wandb: PPO_1226/train/policy_gradient_loss -0.00255
wandb:                  PPO_1226/train/std 0.58586
wandb:           PPO_1226/train/value_loss 59.14081
wandb:                PPO_1236/global_step 212992
wandb:        PPO_1236/rollout/ep_len_mean 200.0
wandb:        PPO_1236/rollout/ep_rew_mean -570.59174
wandb:                   PPO_1236/time/fps 1187.0
wandb:            PPO_1236/train/approx_kl 0.01559
wandb:        PPO_1236/train/clip_fraction 0.20027
wandb:           PPO_1236/train/clip_range 0.2
wandb:         PPO_1236/train/entropy_loss -5.47799
wandb:   PPO_1236/train/explained_variance 0.95709
wandb:        PPO_1236/train/learning_rate 0.0003
wandb:                 PPO_1236/train/loss 25.40697
wandb: PPO_1236/train/policy_gradient_loss -0.00381
wandb:                  PPO_1236/train/std 0.53076
wandb:           PPO_1236/train/value_loss 59.93459
wandb:                PPO_1246/global_step 212992
wandb:        PPO_1246/rollout/ep_len_mean 200.0
wandb:        PPO_1246/rollout/ep_rew_mean -489.90472
wandb:                   PPO_1246/time/fps 1185.0
wandb:            PPO_1246/train/approx_kl 0.01847
wandb:        PPO_1246/train/clip_fraction 0.24537
wandb:           PPO_1246/train/clip_range 0.2
wandb:         PPO_1246/train/entropy_loss -4.88699
wandb:   PPO_1246/train/explained_variance 0.98646
wandb:        PPO_1246/train/learning_rate 0.0003
wandb:                 PPO_1246/train/loss 17.36936
wandb: PPO_1246/train/policy_gradient_loss -0.00064
wandb:                  PPO_1246/train/std 0.48676
wandb:           PPO_1246/train/value_loss 39.52348
wandb:                PPO_1256/global_step 212992
wandb:        PPO_1256/rollout/ep_len_mean 200.0
wandb:        PPO_1256/rollout/ep_rew_mean -504.86896
wandb:                   PPO_1256/time/fps 1183.0
wandb:            PPO_1256/train/approx_kl 0.017
wandb:        PPO_1256/train/clip_fraction 0.22128
wandb:           PPO_1256/train/clip_range 0.2
wandb:         PPO_1256/train/entropy_loss -4.33558
wandb:   PPO_1256/train/explained_variance 0.9884
wandb:        PPO_1256/train/learning_rate 0.0003
wandb:                 PPO_1256/train/loss 34.15127
wandb: PPO_1256/train/policy_gradient_loss -0.00164
wandb:                  PPO_1256/train/std 0.44928
wandb:           PPO_1256/train/value_loss 50.13847
wandb:                PPO_1266/global_step 212992
wandb:        PPO_1266/rollout/ep_len_mean 200.0
wandb:        PPO_1266/rollout/ep_rew_mean -473.42331
wandb:                   PPO_1266/time/fps 1183.0
wandb:            PPO_1266/train/approx_kl 0.01724
wandb:        PPO_1266/train/clip_fraction 0.21964
wandb:           PPO_1266/train/clip_range 0.2
wandb:         PPO_1266/train/entropy_loss -3.8388
wandb:   PPO_1266/train/explained_variance 0.98193
wandb:        PPO_1266/train/learning_rate 0.0003
wandb:                 PPO_1266/train/loss 133.59636
wandb: PPO_1266/train/policy_gradient_loss -0.00372
wandb:                  PPO_1266/train/std 0.41892
wandb:           PPO_1266/train/value_loss 146.39839
wandb:                PPO_1276/global_step 212992
wandb:        PPO_1276/rollout/ep_len_mean 200.0
wandb:        PPO_1276/rollout/ep_rew_mean -469.83853
wandb:                   PPO_1276/time/fps 1179.0
wandb:            PPO_1276/train/approx_kl 0.01765
wandb:        PPO_1276/train/clip_fraction 0.24415
wandb:           PPO_1276/train/clip_range 0.2
wandb:         PPO_1276/train/entropy_loss -3.46681
wandb:   PPO_1276/train/explained_variance 0.98333
wandb:        PPO_1276/train/learning_rate 0.0003
wandb:                 PPO_1276/train/loss 215.29788
wandb: PPO_1276/train/policy_gradient_loss -0.00069
wandb:                  PPO_1276/train/std 0.39764
wandb:           PPO_1276/train/value_loss 144.79266
wandb:                PPO_1286/global_step 212992
wandb:        PPO_1286/rollout/ep_len_mean 200.0
wandb:        PPO_1286/rollout/ep_rew_mean -432.93704
wandb:                   PPO_1286/time/fps 1177.0
wandb:            PPO_1286/train/approx_kl 0.0175
wandb:        PPO_1286/train/clip_fraction 0.22968
wandb:           PPO_1286/train/clip_range 0.2
wandb:         PPO_1286/train/entropy_loss -3.16468
wandb:   PPO_1286/train/explained_variance 0.98013
wandb:        PPO_1286/train/learning_rate 0.0003
wandb:                 PPO_1286/train/loss 50.78264
wandb: PPO_1286/train/policy_gradient_loss 0.00103
wandb:                  PPO_1286/train/std 0.38098
wandb:           PPO_1286/train/value_loss 133.14349
wandb:                    global_mean_eval -404.48348
wandb:                         global_step 212992
wandb:                       mean_reward_0 -381.19205
wandb:                       mean_reward_1 -321.18979
wandb:                      mean_reward_10 -454.91588
wandb:                      mean_reward_11 -475.00098
wandb:                      mean_reward_12 -377.13024
wandb:                      mean_reward_13 -316.35704
wandb:                      mean_reward_14 -375.20476
wandb:                      mean_reward_15 -430.49641
wandb:                      mean_reward_16 -453.60198
wandb:                      mean_reward_17 -472.91671
wandb:                      mean_reward_18 -376.90953
wandb:                      mean_reward_19 -314.18462
wandb:                       mean_reward_2 -378.29182
wandb:                      mean_reward_20 -377.35045
wandb:                      mean_reward_21 -418.60828
wandb:                      mean_reward_22 -461.29113
wandb:                      mean_reward_23 -482.46449
wandb:                      mean_reward_24 -374.19964
wandb:                      mean_reward_25 -313.57611
wandb:                      mean_reward_26 -381.02692
wandb:                      mean_reward_27 -424.92517
wandb:                      mean_reward_28 -451.83873
wandb:                      mean_reward_29 -473.76661
wandb:                       mean_reward_3 -430.81635
wandb:                      mean_reward_30 -373.96533
wandb:                      mean_reward_31 -309.55131
wandb:                      mean_reward_32 -371.04325
wandb:                      mean_reward_33 -414.92492
wandb:                      mean_reward_34 -457.66058
wandb:                      mean_reward_35 -474.32786
wandb:                       mean_reward_4 -467.7891
wandb:                       mean_reward_5 -479.11876
wandb:                       mean_reward_6 -382.94939
wandb:                       mean_reward_7 -314.14608
wandb:                       mean_reward_8 -371.69426
wandb:                       mean_reward_9 -426.97873
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 103.2776
wandb:                        std_reward_1 74.47256
wandb:                       std_reward_10 54.46055
wandb:                       std_reward_11 53.98617
wandb:                       std_reward_12 109.1418
wandb:                       std_reward_13 69.30443
wandb:                       std_reward_14 32.80403
wandb:                       std_reward_15 70.24595
wandb:                       std_reward_16 50.31322
wandb:                       std_reward_17 49.82934
wandb:                       std_reward_18 67.17812
wandb:                       std_reward_19 49.47941
wandb:                        std_reward_2 49.29085
wandb:                       std_reward_20 46.57595
wandb:                       std_reward_21 38.81507
wandb:                       std_reward_22 72.96314
wandb:                       std_reward_23 72.4153
wandb:                       std_reward_24 71.25402
wandb:                       std_reward_25 42.81334
wandb:                       std_reward_26 63.07029
wandb:                       std_reward_27 54.60805
wandb:                       std_reward_28 41.7165
wandb:                       std_reward_29 45.62225
wandb:                        std_reward_3 72.04532
wandb:                       std_reward_30 72.7008
wandb:                       std_reward_31 12.18461
wandb:                       std_reward_32 4.78775
wandb:                       std_reward_33 1.99163
wandb:                       std_reward_34 54.55365
wandb:                       std_reward_35 52.80401
wandb:                        std_reward_4 83.73364
wandb:                        std_reward_5 63.00008
wandb:                        std_reward_6 93.62813
wandb:                        std_reward_7 35.83106
wandb:                        std_reward_8 10.74872
wandb:                        std_reward_9 58.13689
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced efficient-shadow-33: https://wandb.ai/tidiane/meta_rl_context/runs/3s3rvojv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-3s3rvojv/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1208/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1208/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1208/rollout/ep_rew_mean â–‚â–â–â–â–‚â–„â–ƒâ–„â–†â–‡â–†â–ˆ
wandb:                   PPO_1208/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1208/train/approx_kl â–â–…â–†â–…â–‚â–„â–ˆâ–‡â–‡â–…â–‡
wandb:        PPO_1208/train/clip_fraction â–â–ˆâ–…â–…â–…â–…â–‡â–‡â–„â–‡â–ˆ
wandb:           PPO_1208/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1208/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1208/train/explained_variance â–â–†â–‡â–‡â–…â–‡â–ˆâ–‡â–„â–…â–‡
wandb:        PPO_1208/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1208/train/loss â–ƒâ–„â–â–‚â–â–‚â–â–â–ƒâ–ˆâ–‚
wandb: PPO_1208/train/policy_gradient_loss â–…â–â–…â–‚â–†â–‚â–ƒâ–ƒâ–ˆâ–„â–…
wandb:                  PPO_1208/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1208/train/value_loss â–‡â–â–ƒâ–‚â–„â–†â–‚â–‚â–ˆâ–†â–…
wandb:                PPO_1218/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1218/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1218/rollout/ep_rew_mean â–â–‚â–„â–„â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                   PPO_1218/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1218/train/approx_kl â–‚â–â–…â–„â–…â–…â–†â–ƒâ–‚â–…â–ˆ
wandb:        PPO_1218/train/clip_fraction â–â–ƒâ–…â–…â–†â–ˆâ–†â–„â–„â–„â–ˆ
wandb:           PPO_1218/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1218/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1218/train/explained_variance â–â–„â–„â–†â–„â–ƒâ–ˆâ–‡â–‡â–ˆâ–‡
wandb:        PPO_1218/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1218/train/loss â–‚â–ƒâ–…â–‚â–ƒâ–â–ƒâ–ˆâ–â–‚â–
wandb: PPO_1218/train/policy_gradient_loss â–„â–ƒâ–â–ƒâ–ƒâ–†â–„â–†â–ˆâ–†â–…
wandb:                  PPO_1218/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1218/train/value_loss â–ˆâ–‡â–†â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–
wandb:                PPO_1228/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1228/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1228/rollout/ep_rew_mean â–â–ƒâ–ƒâ–…â–…â–„â–…â–‡â–†â–…â–…â–ˆ
wandb:                   PPO_1228/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1228/train/approx_kl â–‚â–…â–‚â–â–…â–‚â–â–ˆâ–„â–†â–‚
wandb:        PPO_1228/train/clip_fraction â–‚â–…â–„â–‚â–ƒâ–â–…â–ˆâ–â–„â–ƒ
wandb:           PPO_1228/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1228/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1228/train/explained_variance â–â–‡â–…â–ˆâ–†â–‡â–‡â–ˆâ–‡â–‚â–…
wandb:        PPO_1228/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1228/train/loss â–„â–„â–ˆâ–â–â–‚â–‚â–‚â–ƒâ–…â–‚
wandb: PPO_1228/train/policy_gradient_loss â–‡â–‚â–„â–„â–…â–â–ˆâ–‡â–„â–†â–‡
wandb:                  PPO_1228/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–‚â–‚â–
wandb:           PPO_1228/train/value_loss â–†â–ƒâ–‚â–â–‚â–…â–†â–â–„â–ˆâ–ƒ
wandb:                PPO_1238/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1238/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1238/rollout/ep_rew_mean â–‚â–â–â–…â–‚â–„â–…â–ƒâ–ˆâ–„â–…â–ˆ
wandb:                   PPO_1238/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1238/train/approx_kl â–…â–‚â–‚â–â–„â–ƒâ–ˆâ–„â–†â–â–ƒ
wandb:        PPO_1238/train/clip_fraction â–†â–ƒâ–†â–…â–…â–ƒâ–ˆâ–ƒâ–…â–â–‡
wandb:           PPO_1238/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1238/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1238/train/explained_variance â–†â–â–…â–ƒâ–„â–„â–ƒâ–†â–†â–…â–ˆ
wandb:        PPO_1238/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1238/train/loss â–â–ˆâ–„â–‚â–‚â–‚â–â–‚â–„â–‚â–ƒ
wandb: PPO_1238/train/policy_gradient_loss â–ˆâ–†â–†â–‡â–ˆâ–â–†â–„â–…â–„â–…
wandb:                  PPO_1238/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1238/train/value_loss â–ƒâ–†â–â–…â–‡â–ƒâ–‚â–ƒâ–‚â–ˆâ–ƒ
wandb:                PPO_1248/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1248/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1248/rollout/ep_rew_mean â–ƒâ–„â–…â–ƒâ–â–ƒâ–„â–ˆâ–†â–„â–ˆâ–†
wandb:                   PPO_1248/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1248/train/approx_kl â–ƒâ–…â–â–‚â–ƒâ–…â–…â–…â–„â–„â–ˆ
wandb:        PPO_1248/train/clip_fraction â–…â–ˆâ–…â–â–„â–†â–‡â–‡â–†â–…â–‡
wandb:           PPO_1248/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1248/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–ˆ
wandb:   PPO_1248/train/explained_variance â–ƒâ–â–ƒâ–ƒâ–…â–†â–‡â–†â–ƒâ–ˆâ–‡
wandb:        PPO_1248/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1248/train/loss â–â–†â–ˆâ–†â–ƒâ–†â–â–ƒâ–„â–‚â–„
wandb: PPO_1248/train/policy_gradient_loss â–…â–…â–†â–…â–â–…â–„â–â–ˆâ–…â–‚
wandb:                  PPO_1248/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–
wandb:           PPO_1248/train/value_loss â–ƒâ–ƒâ–ƒâ–ˆâ–„â–ƒâ–ƒâ–â–†â–ƒâ–‚
wandb:                PPO_1258/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1258/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1258/rollout/ep_rew_mean â–ƒâ–ƒâ–â–…â–†â–†â–â–‚â–ƒâ–ƒâ–…â–ˆ
wandb:                   PPO_1258/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1258/train/approx_kl â–ˆâ–â–‚â–…â–‡â–ƒâ–â–‡â–‚â–„â–„
wandb:        PPO_1258/train/clip_fraction â–†â–‚â–†â–†â–„â–â–ƒâ–ˆâ–â–‡â–ƒ
wandb:           PPO_1258/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1258/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1258/train/explained_variance â–â–‡â–ˆâ–†â–…â–‡â–ˆâ–†â–‡â–†â–ˆ
wandb:        PPO_1258/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1258/train/loss â–‡â–â–â–â–†â–ˆâ–â–ˆâ–ƒâ–‡â–
wandb: PPO_1258/train/policy_gradient_loss â–â–„â–ˆâ–‚â–ƒâ–â–„â–„â–„â–ƒâ–…
wandb:                  PPO_1258/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1258/train/value_loss â–†â–…â–‚â–â–‚â–‡â–ˆâ–ƒâ–ˆâ–ˆâ–…
wandb:                PPO_1268/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1268/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1268/rollout/ep_rew_mean â–‡â–ˆâ–‡â–†â–…â–†â–‡â–‡â–‡â–â–…â–†
wandb:                   PPO_1268/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1268/train/approx_kl â–â–ƒâ–â–ƒâ–„â–â–‚â–‚â–„â–‚â–ˆ
wandb:        PPO_1268/train/clip_fraction â–‡â–‡â–‡â–ƒâ–ˆâ–„â–†â–‚â–„â–â–ˆ
wandb:           PPO_1268/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1268/train/entropy_loss â–â–‚â–‚â–„â–„â–„â–…â–…â–…â–†â–ˆ
wandb:   PPO_1268/train/explained_variance â–†â–…â–…â–…â–‡â–â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1268/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1268/train/loss â–‚â–ˆâ–â–„â–ƒâ–ƒâ–‡â–‚â–‡â–â–‚
wandb: PPO_1268/train/policy_gradient_loss â–„â–…â–ˆâ–â–‚â–‡â–ˆâ–„â–…â–ƒâ–ˆ
wandb:                  PPO_1268/train/std â–ˆâ–‡â–‡â–…â–†â–„â–„â–„â–„â–‚â–
wandb:           PPO_1268/train/value_loss â–â–ƒâ–„â–„â–„â–‡â–„â–ƒâ–†â–ˆâ–…
wandb:                PPO_1278/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1278/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1278/rollout/ep_rew_mean â–â–‚â–„â–…â–†â–„â–ƒâ–‚â–ƒâ–…â–…â–ˆ
wandb:                   PPO_1278/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1278/train/approx_kl â–†â–â–ƒâ–†â–…â–‚â–ƒâ–ˆâ–„â–„â–ƒ
wandb:        PPO_1278/train/clip_fraction â–‚â–â–…â–ˆâ–‚â–â–†â–ƒâ–ƒâ–†â–
wandb:           PPO_1278/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1278/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1278/train/explained_variance â–†â–†â–…â–ˆâ–â–…â–†â–ƒâ–„â–‚â–†
wandb:        PPO_1278/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1278/train/loss â–ƒâ–ƒâ–ƒâ–â–ˆâ–…â–‚â–‚â–„â–‚â–‚
wandb: PPO_1278/train/policy_gradient_loss â–„â–â–ƒâ–ˆâ–†â–â–†â–ˆâ–…â–†â–…
wandb:                  PPO_1278/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1278/train/value_loss â–ˆâ–ˆâ–ƒâ–‚â–„â–‡â–‚â–â–â–â–ƒ
wandb:                PPO_1288/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1288/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1288/rollout/ep_rew_mean â–‚â–â–„â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„
wandb:                   PPO_1288/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1288/train/approx_kl â–‚â–ƒâ–…â–â–ƒâ–ˆâ–â–‡â–†â–‚â–
wandb:        PPO_1288/train/clip_fraction â–â–ƒâ–…â–ƒâ–„â–ˆâ–…â–ƒâ–†â–„â–„
wandb:           PPO_1288/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1288/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1288/train/explained_variance â–‚â–†â–ƒâ–…â–‚â–…â–†â–ˆâ–…â–â–ˆ
wandb:        PPO_1288/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1288/train/loss â–â–‚â–„â–ƒâ–ƒâ–‚â–â–â–â–ˆâ–‚
wandb: PPO_1288/train/policy_gradient_loss â–‚â–†â–…â–ƒâ–â–ƒâ–…â–†â–‡â–…â–ˆ
wandb:                  PPO_1288/train/std â–ˆâ–‡â–‡â–†â–‡â–…â–…â–„â–ƒâ–â–
wandb:           PPO_1288/train/value_loss â–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–„â–„â–ˆâ–
wandb:                    global_mean_eval â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–ƒâ–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_1 â–â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–„â–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_13 â–â–„â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–ƒâ–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_19 â–â–„â–…â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–„â–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_25 â–â–ƒâ–…â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–„â–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_31 â–â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–ƒâ–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                       mean_reward_7 â–â–ƒâ–…â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–â–ƒâ–â–‚â–â–‚â–â–â–‚
wandb:                        std_reward_1 â–ˆâ–…â–â–‚â–‚â–â–â–â–â–
wandb:                       std_reward_10 â–‡â–…â–„â–†â–ˆâ–…â–â–†â–ƒâ–
wandb:                       std_reward_11 â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–â–†â–‚â–„
wandb:                       std_reward_12 â–ˆâ–â–ƒâ–â–â–â–‚â–â–â–‚
wandb:                       std_reward_13 â–ˆâ–†â–â–‚â–‚â–â–‚â–â–‚â–
wandb:                       std_reward_14 â–‡â–ˆâ–†â–„â–…â–â–â–â–‚â–
wandb:                       std_reward_15 â–ˆâ–†â–„â–ˆâ–‚â–ƒâ–â–â–ƒâ–
wandb:                       std_reward_16 â–ˆâ–…â–„â–…â–ˆâ–…â–â–‚â–ƒâ–‚
wandb:                       std_reward_17 â–„â–ˆâ–‚â–ƒâ–„â–‚â–â–‡â–‚â–„
wandb:                       std_reward_18 â–ˆâ–â–ƒâ–â–‚â–â–‚â–â–â–‚
wandb:                       std_reward_19 â–ˆâ–…â–â–‚â–‚â–â–â–â–â–
wandb:                        std_reward_2 â–ˆâ–ˆâ–†â–„â–†â–â–â–â–‚â–
wandb:                       std_reward_20 â–‡â–ˆâ–…â–…â–†â–â–â–â–‚â–
wandb:                       std_reward_21 â–ˆâ–…â–ƒâ–‡â–â–ƒâ–â–â–‚â–
wandb:                       std_reward_22 â–ˆâ–„â–ƒâ–…â–‡â–„â–â–„â–‚â–‚
wandb:                       std_reward_23 â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–â–†â–‚â–…
wandb:                       std_reward_24 â–ˆâ–â–ƒâ–â–‚â–â–‚â–â–â–‚
wandb:                       std_reward_25 â–ˆâ–†â–â–‚â–‚â–â–‚â–â–â–
wandb:                       std_reward_26 â–‡â–ˆâ–†â–„â–…â–â–â–â–‚â–
wandb:                       std_reward_27 â–ˆâ–…â–ƒâ–‡â–â–ƒâ–â–â–‚â–
wandb:                       std_reward_28 â–ˆâ–„â–„â–†â–†â–„â–â–…â–ƒâ–‚
wandb:                       std_reward_29 â–ƒâ–ˆâ–‚â–ƒâ–„â–‚â–â–‡â–‚â–…
wandb:                        std_reward_3 â–ˆâ–…â–„â–‡â–â–ƒâ–â–â–‚â–
wandb:                       std_reward_30 â–ˆâ–â–ƒâ–â–‚â–â–‚â–â–â–‚
wandb:                       std_reward_31 â–ˆâ–†â–â–‚â–‚â–â–â–â–â–
wandb:                       std_reward_32 â–ˆâ–‡â–…â–„â–†â–â–â–â–‚â–
wandb:                       std_reward_33 â–ˆâ–…â–ƒâ–‡â–â–ƒâ–â–â–‚â–
wandb:                       std_reward_34 â–ˆâ–…â–„â–†â–ˆâ–…â–â–„â–ƒâ–‚
wandb:                       std_reward_35 â–ƒâ–ˆâ–‚â–ƒâ–„â–‚â–â–‡â–‚â–„
wandb:                        std_reward_4 â–ˆâ–…â–„â–†â–ˆâ–„â–â–‚â–ƒâ–‚
wandb:                        std_reward_5 â–„â–ˆâ–‚â–ƒâ–„â–‚â–â–†â–‚â–…
wandb:                        std_reward_6 â–ˆâ–â–ƒâ–â–â–â–‚â–â–â–‚
wandb:                        std_reward_7 â–ˆâ–„â–â–‚â–‚â–â–â–â–â–
wandb:                        std_reward_8 â–ˆâ–ˆâ–†â–„â–†â–â–â–â–‚â–
wandb:                        std_reward_9 â–ˆâ–…â–ƒâ–†â–â–ƒâ–â–â–‚â–
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1208/global_step 212992
wandb:        PPO_1208/rollout/ep_len_mean 200.0
wandb:        PPO_1208/rollout/ep_rew_mean -778.50555
wandb:                   PPO_1208/time/fps 1195.0
wandb:            PPO_1208/train/approx_kl 0.01084
wandb:        PPO_1208/train/clip_fraction 0.13502
wandb:           PPO_1208/train/clip_range 0.2
wandb:         PPO_1208/train/entropy_loss -7.77335
wandb:   PPO_1208/train/explained_variance 0.96973
wandb:        PPO_1208/train/learning_rate 0.0003
wandb:                 PPO_1208/train/loss 42.79044
wandb: PPO_1208/train/policy_gradient_loss -0.00627
wandb:                  PPO_1208/train/std 0.73327
wandb:           PPO_1208/train/value_loss 127.00729
wandb:                PPO_1218/global_step 212992
wandb:        PPO_1218/rollout/ep_len_mean 200.0
wandb:        PPO_1218/rollout/ep_rew_mean -611.0177
wandb:                   PPO_1218/time/fps 1191.0
wandb:            PPO_1218/train/approx_kl 0.01472
wandb:        PPO_1218/train/clip_fraction 0.19527
wandb:           PPO_1218/train/clip_range 0.2
wandb:         PPO_1218/train/entropy_loss -6.69648
wandb:   PPO_1218/train/explained_variance 0.97413
wandb:        PPO_1218/train/learning_rate 0.0003
wandb:                 PPO_1218/train/loss 24.24056
wandb: PPO_1218/train/policy_gradient_loss -0.00524
wandb:                  PPO_1218/train/std 0.62888
wandb:           PPO_1218/train/value_loss 67.75895
wandb:                PPO_1228/global_step 212992
wandb:        PPO_1228/rollout/ep_len_mean 200.0
wandb:        PPO_1228/rollout/ep_rew_mean -542.18219
wandb:                   PPO_1228/time/fps 1188.0
wandb:            PPO_1228/train/approx_kl 0.01345
wandb:        PPO_1228/train/clip_fraction 0.18564
wandb:           PPO_1228/train/clip_range 0.2
wandb:         PPO_1228/train/entropy_loss -5.81915
wandb:   PPO_1228/train/explained_variance 0.95968
wandb:        PPO_1228/train/learning_rate 0.0003
wandb:                 PPO_1228/train/loss 22.85525
wandb: PPO_1228/train/policy_gradient_loss -0.00143
wandb:                  PPO_1228/train/std 0.55572
wandb:           PPO_1228/train/value_loss 61.23231
wandb:                PPO_1238/global_step 212992
wandb:        PPO_1238/rollout/ep_len_mean 200.0
wandb:        PPO_1238/rollout/ep_rew_mean -533.55927
wandb:                   PPO_1238/time/fps 1196.0
wandb:            PPO_1238/train/approx_kl 0.01497
wandb:        PPO_1238/train/clip_fraction 0.20372
wandb:           PPO_1238/train/clip_range 0.2
wandb:         PPO_1238/train/entropy_loss -5.22251
wandb:   PPO_1238/train/explained_variance 0.97534
wandb:        PPO_1238/train/learning_rate 0.0003
wandb:                 PPO_1238/train/loss 25.88916
wandb: PPO_1238/train/policy_gradient_loss -0.00185
wandb:                  PPO_1238/train/std 0.50996
wandb:           PPO_1238/train/value_loss 63.76905
wandb:                PPO_1248/global_step 212992
wandb:        PPO_1248/rollout/ep_len_mean 200.0
wandb:        PPO_1248/rollout/ep_rew_mean -519.49084
wandb:                   PPO_1248/time/fps 1195.0
wandb:            PPO_1248/train/approx_kl 0.0174
wandb:        PPO_1248/train/clip_fraction 0.20724
wandb:           PPO_1248/train/clip_range 0.2
wandb:         PPO_1248/train/entropy_loss -4.76205
wandb:   PPO_1248/train/explained_variance 0.98255
wandb:        PPO_1248/train/learning_rate 0.0003
wandb:                 PPO_1248/train/loss 43.26511
wandb: PPO_1248/train/policy_gradient_loss -0.00332
wandb:                  PPO_1248/train/std 0.47742
wandb:           PPO_1248/train/value_loss 60.5948
wandb:                PPO_1258/global_step 212992
wandb:        PPO_1258/rollout/ep_len_mean 200.0
wandb:        PPO_1258/rollout/ep_rew_mean -471.76447
wandb:                   PPO_1258/time/fps 1194.0
wandb:            PPO_1258/train/approx_kl 0.01639
wandb:        PPO_1258/train/clip_fraction 0.21153
wandb:           PPO_1258/train/clip_range 0.2
wandb:         PPO_1258/train/entropy_loss -4.25482
wandb:   PPO_1258/train/explained_variance 0.98691
wandb:        PPO_1258/train/learning_rate 0.0003
wandb:                 PPO_1258/train/loss 18.6658
wandb: PPO_1258/train/policy_gradient_loss -0.00169
wandb:                  PPO_1258/train/std 0.44445
wandb:           PPO_1258/train/value_loss 75.69495
wandb:                PPO_1268/global_step 212992
wandb:        PPO_1268/rollout/ep_len_mean 200.0
wandb:        PPO_1268/rollout/ep_rew_mean -470.17627
wandb:                   PPO_1268/time/fps 1193.0
wandb:            PPO_1268/train/approx_kl 0.02141
wandb:        PPO_1268/train/clip_fraction 0.23713
wandb:           PPO_1268/train/clip_range 0.2
wandb:         PPO_1268/train/entropy_loss -3.77737
wandb:   PPO_1268/train/explained_variance 0.9901
wandb:        PPO_1268/train/learning_rate 0.0003
wandb:                 PPO_1268/train/loss 25.20687
wandb: PPO_1268/train/policy_gradient_loss 0.00082
wandb:                  PPO_1268/train/std 0.41482
wandb:           PPO_1268/train/value_loss 91.40865
wandb:                PPO_1278/global_step 212992
wandb:        PPO_1278/rollout/ep_len_mean 200.0
wandb:        PPO_1278/rollout/ep_rew_mean -432.05862
wandb:                   PPO_1278/time/fps 1191.0
wandb:            PPO_1278/train/approx_kl 0.01725
wandb:        PPO_1278/train/clip_fraction 0.22464
wandb:           PPO_1278/train/clip_range 0.2
wandb:         PPO_1278/train/entropy_loss -3.29807
wandb:   PPO_1278/train/explained_variance 0.98653
wandb:        PPO_1278/train/learning_rate 0.0003
wandb:                 PPO_1278/train/loss 28.46158
wandb: PPO_1278/train/policy_gradient_loss 0.00013
wandb:                  PPO_1278/train/std 0.38754
wandb:           PPO_1278/train/value_loss 87.82188
wandb:                PPO_1288/global_step 212992
wandb:        PPO_1288/rollout/ep_len_mean 200.0
wandb:        PPO_1288/rollout/ep_rew_mean -460.55188
wandb:                   PPO_1288/time/fps 1196.0
wandb:            PPO_1288/train/approx_kl 0.0177
wandb:        PPO_1288/train/clip_fraction 0.24814
wandb:           PPO_1288/train/clip_range 0.2
wandb:         PPO_1288/train/entropy_loss -2.99479
wandb:   PPO_1288/train/explained_variance 0.99197
wandb:        PPO_1288/train/learning_rate 0.0003
wandb:                 PPO_1288/train/loss 38.73233
wandb: PPO_1288/train/policy_gradient_loss 0.00304
wandb:                  PPO_1288/train/std 0.37195
wandb:           PPO_1288/train/value_loss 84.66266
wandb:                    global_mean_eval -384.86827
wandb:                         global_step 212992
wandb:                       mean_reward_0 -316.89638
wandb:                       mean_reward_1 -309.18996
wandb:                      mean_reward_10 -440.39025
wandb:                      mean_reward_11 -463.53438
wandb:                      mean_reward_12 -314.40597
wandb:                      mean_reward_13 -308.27968
wandb:                      mean_reward_14 -371.87801
wandb:                      mean_reward_15 -412.76201
wandb:                      mean_reward_16 -440.44301
wandb:                      mean_reward_17 -463.7444
wandb:                      mean_reward_18 -306.38877
wandb:                      mean_reward_19 -307.64841
wandb:                       mean_reward_2 -372.32525
wandb:                      mean_reward_20 -371.77433
wandb:                      mean_reward_21 -412.48594
wandb:                      mean_reward_22 -440.5689
wandb:                      mean_reward_23 -466.94097
wandb:                      mean_reward_24 -309.37572
wandb:                      mean_reward_25 -307.70074
wandb:                      mean_reward_26 -371.94281
wandb:                      mean_reward_27 -412.93732
wandb:                      mean_reward_28 -440.81694
wandb:                      mean_reward_29 -465.7084
wandb:                       mean_reward_3 -412.59062
wandb:                      mean_reward_30 -313.15508
wandb:                      mean_reward_31 -308.49357
wandb:                      mean_reward_32 -372.03364
wandb:                      mean_reward_33 -412.76441
wandb:                      mean_reward_34 -440.96672
wandb:                      mean_reward_35 -464.07619
wandb:                       mean_reward_4 -440.81437
wandb:                       mean_reward_5 -463.36908
wandb:                       mean_reward_6 -306.59129
wandb:                       mean_reward_7 -308.20443
wandb:                       mean_reward_8 -371.46795
wandb:                       mean_reward_9 -412.59188
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 43.69271
wandb:                        std_reward_1 6.99583
wandb:                       std_reward_10 1.85446
wandb:                       std_reward_11 11.09881
wandb:                       std_reward_12 42.56652
wandb:                       std_reward_13 7.04306
wandb:                       std_reward_14 2.94218
wandb:                       std_reward_15 1.38247
wandb:                       std_reward_16 2.42238
wandb:                       std_reward_17 10.81432
wandb:                       std_reward_18 35.25481
wandb:                       std_reward_19 6.52758
wandb:                        std_reward_2 3.22621
wandb:                       std_reward_20 2.89639
wandb:                       std_reward_21 1.49613
wandb:                       std_reward_22 2.38196
wandb:                       std_reward_23 18.67978
wandb:                       std_reward_24 35.28675
wandb:                       std_reward_25 7.16124
wandb:                       std_reward_26 2.92866
wandb:                       std_reward_27 1.88703
wandb:                       std_reward_28 2.39117
wandb:                       std_reward_29 16.59062
wandb:                        std_reward_3 1.61079
wandb:                       std_reward_30 43.27086
wandb:                       std_reward_31 7.23594
wandb:                       std_reward_32 2.58955
wandb:                       std_reward_33 1.65426
wandb:                       std_reward_34 2.1252
wandb:                       std_reward_35 13.45628
wandb:                        std_reward_4 2.7638
wandb:                        std_reward_5 14.60388
wandb:                        std_reward_6 36.54284
wandb:                        std_reward_7 7.37245
wandb:                        std_reward_8 2.64494
wandb:                        std_reward_9 1.37633
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced eager-capybara-36: https://wandb.ai/tidiane/meta_rl_context/runs/260njzkv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-260njzkv/logs
wandb: 
wandb: Run history:
wandb:                PPO_1206/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1206/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1206/rollout/ep_rew_mean â–â–â–†â–…â–‡â–‡â–ˆâ–‡â–„â–„â–ˆâ–†
wandb:                   PPO_1206/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1206/train/approx_kl â–†â–‚â–â–‚â–„â–ƒâ–ˆâ–…â–ˆâ–ƒâ–‡
wandb:        PPO_1206/train/clip_fraction â–„â–â–‚â–ƒâ–…â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:           PPO_1206/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1206/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1206/train/explained_variance â–â–ˆâ–†â–†â–ƒâ–‚â–‚â–â–ƒâ–„â–ˆ
wandb:        PPO_1206/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1206/train/loss â–â–…â–„â–…â–â–‚â–ˆâ–„â–„â–â–‚
wandb: PPO_1206/train/policy_gradient_loss â–ƒâ–†â–ƒâ–„â–†â–ƒâ–ƒâ–â–â–‡â–ˆ
wandb:                  PPO_1206/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1206/train/value_loss â–‚â–ƒâ–†â–‚â–ˆâ–…â–…â–‚â–ƒâ–â–
wandb:                PPO_1217/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1217/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1217/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–„â–…â–†â–…â–†â–‡â–‡â–ˆ
wandb:                   PPO_1217/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1217/train/approx_kl â–‚â–ƒâ–â–„â–…â–†â–„â–…â–„â–„â–ˆ
wandb:        PPO_1217/train/clip_fraction â–â–‚â–â–„â–†â–†â–‚â–‡â–†â–„â–ˆ
wandb:           PPO_1217/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1217/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1217/train/explained_variance â–„â–†â–ˆâ–†â–…â–†â–â–†â–‚â–†â–ƒ
wandb:        PPO_1217/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1217/train/loss â–â–„â–ˆâ–…â–ƒâ–â–†â–„â–…â–‡â–†
wandb: PPO_1217/train/policy_gradient_loss â–ƒâ–†â–†â–ƒâ–‚â–†â–ˆâ–„â–‚â–„â–
wandb:                  PPO_1217/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1217/train/value_loss â–ƒâ–‚â–ƒâ–‚â–‚â–â–†â–„â–„â–ˆâ–ˆ
wandb:                PPO_1227/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1227/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1227/rollout/ep_rew_mean â–â–‚â–‚â–‚â–„â–„â–†â–…â–†â–‡â–‡â–ˆ
wandb:                   PPO_1227/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1227/train/approx_kl â–‚â–…â–†â–†â–ƒâ–†â–„â–â–ˆâ–„â–†
wandb:        PPO_1227/train/clip_fraction â–…â–‡â–‡â–„â–†â–†â–‡â–â–‡â–‡â–ˆ
wandb:           PPO_1227/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1227/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1227/train/explained_variance â–†â–ˆâ–‡â–ˆâ–‡â–†â–…â–ˆâ–†â–â–†
wandb:        PPO_1227/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1227/train/loss â–„â–ˆâ–…â–„â–‚â–‚â–‡â–†â–ƒâ–„â–
wandb: PPO_1227/train/policy_gradient_loss â–…â–â–…â–ˆâ–…â–‡â–†â–ˆâ–„â–…â–‡
wandb:                  PPO_1227/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1227/train/value_loss â–†â–‡â–†â–„â–…â–…â–†â–ˆâ–‡â–…â–
wandb:                PPO_1237/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1237/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1237/rollout/ep_rew_mean â–„â–„â–â–ƒâ–ƒâ–…â–‡â–‡â–…â–„â–ˆâ–„
wandb:                   PPO_1237/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1237/train/approx_kl â–„â–„â–…â–â–ƒâ–†â–†â–…â–…â–ˆâ–‚
wandb:        PPO_1237/train/clip_fraction â–…â–…â–‚â–‚â–â–ˆâ–…â–†â–‡â–‡â–
wandb:           PPO_1237/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1237/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1237/train/explained_variance â–„â–„â–ƒâ–„â–â–‚â–†â–â–„â–ˆâ–‡
wandb:        PPO_1237/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1237/train/loss â–‚â–ƒâ–‡â–„â–ˆâ–„â–‡â–†â–„â–â–†
wandb: PPO_1237/train/policy_gradient_loss â–ƒâ–â–ƒâ–ˆâ–…â–ˆâ–†â–…â–…â–ƒâ–ƒ
wandb:                  PPO_1237/train/std â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1237/train/value_loss â–â–‚â–„â–„â–„â–‚â–‚â–„â–ƒâ–ƒâ–ˆ
wandb:                PPO_1247/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1247/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1247/rollout/ep_rew_mean â–„â–‚â–„â–‚â–‚â–â–ˆâ–…â–â–‡â–…â–…
wandb:                   PPO_1247/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1247/train/approx_kl â–„â–„â–…â–â–â–ˆâ–†â–ƒâ–„â–…â–…
wandb:        PPO_1247/train/clip_fraction â–…â–†â–…â–ƒâ–‚â–…â–ˆâ–„â–â–ˆâ–„
wandb:           PPO_1247/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1247/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1247/train/explained_variance â–â–†â–„â–†â–‡â–†â–…â–‡â–†â–ˆâ–‡
wandb:        PPO_1247/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1247/train/loss â–â–â–ƒâ–„â–‚â–†â–ˆâ–ƒâ–†â–â–‚
wandb: PPO_1247/train/policy_gradient_loss â–„â–ƒâ–â–„â–ˆâ–ˆâ–‡â–ˆâ–…â–ˆâ–†
wandb:                  PPO_1247/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1247/train/value_loss â–‚â–â–â–„â–ƒâ–†â–„â–„â–ˆâ–„â–†
wandb:                PPO_1257/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1257/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1257/rollout/ep_rew_mean â–†â–ˆâ–„â–‚â–„â–‚â–ˆâ–â–‚â–…â–â–„
wandb:                   PPO_1257/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1257/train/approx_kl â–†â–‡â–„â–…â–ˆâ–‚â–†â–â–…â–†â–†
wandb:        PPO_1257/train/clip_fraction â–†â–†â–…â–‚â–…â–â–ˆâ–â–„â–ƒâ–ƒ
wandb:           PPO_1257/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1257/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1257/train/explained_variance â–â–…â–‡â–‡â–…â–ƒâ–…â–…â–†â–…â–ˆ
wandb:        PPO_1257/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1257/train/loss â–â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ˆ
wandb: PPO_1257/train/policy_gradient_loss â–ƒâ–ƒâ–…â–â–„â–‡â–ˆâ–‡â–…â–ƒâ–
wandb:                  PPO_1257/train/std â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1257/train/value_loss â–‚â–â–â–ƒâ–„â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–†
wandb:                PPO_1267/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1267/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1267/rollout/ep_rew_mean â–â–…â–‚â–†â–…â–†â–†â–ˆâ–†â–â–â–‚
wandb:                   PPO_1267/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1267/train/approx_kl â–…â–â–„â–ˆâ–‚â–†â–…â–…â–ƒâ–‡â–
wandb:        PPO_1267/train/clip_fraction â–…â–ƒâ–†â–ˆâ–â–ˆâ–ˆâ–„â–ƒâ–‡â–‚
wandb:           PPO_1267/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1267/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:   PPO_1267/train/explained_variance â–„â–„â–ˆâ–â–ƒâ–ˆâ–†â–‡â–‡â–‡â–
wandb:        PPO_1267/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1267/train/loss â–‚â–â–‚â–ƒâ–…â–ˆâ–â–â–…â–†â–
wandb: PPO_1267/train/policy_gradient_loss â–ˆâ–‚â–†â–‡â–„â–…â–ˆâ–„â–ƒâ–ˆâ–
wandb:                  PPO_1267/train/std â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–â–â–â–
wandb:           PPO_1267/train/value_loss â–ƒâ–‚â–‚â–â–„â–‚â–â–â–ƒâ–„â–ˆ
wandb:                PPO_1277/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1277/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1277/rollout/ep_rew_mean â–…â–‚â–„â–ˆâ–…â–‚â–‡â–‚â–†â–„â–â–†
wandb:                   PPO_1277/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1277/train/approx_kl â–‚â–„â–…â–ƒâ–„â–ƒâ–ˆâ–â–…â–â–‡
wandb:        PPO_1277/train/clip_fraction â–„â–…â–‡â–…â–…â–…â–ˆâ–â–†â–„â–†
wandb:           PPO_1277/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1277/train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–…â–ˆ
wandb:   PPO_1277/train/explained_variance â–„â–‡â–„â–„â–„â–…â–…â–„â–ˆâ–â–‚
wandb:        PPO_1277/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1277/train/loss â–ˆâ–â–„â–ƒâ–ƒâ–„â–â–…â–ƒâ–‡â–†
wandb: PPO_1277/train/policy_gradient_loss â–‚â–„â–ˆâ–ƒâ–„â–„â–†â–â–†â–ƒâ–…
wandb:                  PPO_1277/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–„â–
wandb:           PPO_1277/train/value_loss â–…â–ƒâ–„â–ƒâ–„â–„â–â–ˆâ–„â–ˆâ–†
wandb:                PPO_1287/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1287/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1287/rollout/ep_rew_mean â–â–‚â–…â–„â–†â–ˆâ–ƒâ–†â–…â–‡â–†â–ƒ
wandb:                   PPO_1287/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1287/train/approx_kl â–„â–â–„â–ƒâ–ˆâ–‡â–ƒâ–…â–ƒâ–ƒâ–
wandb:        PPO_1287/train/clip_fraction â–‚â–…â–…â–‚â–†â–ˆâ–ƒâ–†â–ƒâ–…â–
wandb:           PPO_1287/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1287/train/entropy_loss â–â–â–â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1287/train/explained_variance â–ƒâ–ˆâ–†â–†â–â–…â–‡â–‡â–ƒâ–„â–ˆ
wandb:        PPO_1287/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1287/train/loss â–ƒâ–â–â–ˆâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–
wandb: PPO_1287/train/policy_gradient_loss â–‚â–„â–‡â–ƒâ–‡â–ˆâ–„â–…â–‚â–â–‚
wandb:                  PPO_1287/train/std â–ˆâ–ˆâ–‡â–…â–…â–„â–„â–ƒâ–‚â–â–‚
wandb:           PPO_1287/train/value_loss â–ˆâ–„â–†â–†â–„â–„â–â–â–„â–†â–†
wandb:                    global_mean_eval â–‚â–â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–â–†â–ˆâ–‡â–‡â–†â–†â–†â–‡
wandb:                       mean_reward_1 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_11 â–â–â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_12 â–â–â–…â–ˆâ–‡â–‡â–‡â–†â–†â–‡
wandb:                      mean_reward_13 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–ƒâ–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–ƒâ–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_17 â–â–â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_18 â–â–â–†â–ˆâ–‡â–‡â–‡â–…â–†â–‡
wandb:                      mean_reward_19 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–‚â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_20 â–ƒâ–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_21 â–‚â–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_22 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_23 â–â–â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_24 â–â–â–†â–ˆâ–‡â–‡â–‡â–†â–†â–‡
wandb:                      mean_reward_25 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–‚â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_27 â–ƒâ–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_28 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_29 â–â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_3 â–ƒâ–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_30 â–â–â–†â–ˆâ–‡â–‡â–‡â–†â–†â–‡
wandb:                      mean_reward_31 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–‚â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–ƒâ–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_34 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_35 â–â–â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_4 â–‚â–â–…â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_5 â–â–â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_6 â–â–â–†â–ˆâ–‡â–‡â–†â–…â–†â–‡
wandb:                       mean_reward_7 â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–‚â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_9 â–ƒâ–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–…â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb:                        std_reward_1 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_10 â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_11 â–ˆâ–‚â–‚â–‚â–â–‡â–â–‚â–‚â–ƒ
wandb:                       std_reward_12 â–„â–â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                       std_reward_13 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_14 â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:                       std_reward_15 â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                       std_reward_16 â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_17 â–ˆâ–â–‚â–‚â–‚â–…â–‚â–‚â–‚â–‚
wandb:                       std_reward_18 â–…â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–
wandb:                       std_reward_19 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                        std_reward_2 â–ˆâ–‚â–â–â–â–â–â–‚â–â–
wandb:                       std_reward_20 â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:                       std_reward_21 â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–
wandb:                       std_reward_22 â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                       std_reward_23 â–ˆâ–â–‚â–‚â–â–†â–‚â–‚â–‚â–‚
wandb:                       std_reward_24 â–…â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–‚
wandb:                       std_reward_25 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_26 â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–‚
wandb:                       std_reward_27 â–ˆâ–â–‚â–‚â–â–â–â–â–â–
wandb:                       std_reward_28 â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_29 â–ˆâ–ƒâ–‚â–‚â–â–…â–‚â–â–â–‚
wandb:                        std_reward_3 â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                       std_reward_30 â–…â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–‚
wandb:                       std_reward_31 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_32 â–ˆâ–â–‚â–â–â–â–â–‚â–â–
wandb:                       std_reward_33 â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                       std_reward_34 â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_35 â–ˆâ–‚â–â–â–â–…â–â–â–â–
wandb:                        std_reward_4 â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                        std_reward_5 â–ˆâ–â–â–â–â–‡â–â–â–â–‚
wandb:                        std_reward_6 â–…â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–‚
wandb:                        std_reward_7 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                        std_reward_8 â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:                        std_reward_9 â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1206/global_step 212992
wandb:        PPO_1206/rollout/ep_len_mean 200.0
wandb:        PPO_1206/rollout/ep_rew_mean -868.6546
wandb:                   PPO_1206/time/fps 1195.0
wandb:            PPO_1206/train/approx_kl 0.01207
wandb:        PPO_1206/train/clip_fraction 0.15638
wandb:           PPO_1206/train/clip_range 0.2
wandb:         PPO_1206/train/entropy_loss -7.96414
wandb:   PPO_1206/train/explained_variance 0.97329
wandb:        PPO_1206/train/learning_rate 0.0003
wandb:                 PPO_1206/train/loss 32.56976
wandb: PPO_1206/train/policy_gradient_loss -0.00637
wandb:                  PPO_1206/train/std 0.75544
wandb:           PPO_1206/train/value_loss 72.5939
wandb:                PPO_1217/global_step 212992
wandb:        PPO_1217/rollout/ep_len_mean 200.0
wandb:        PPO_1217/rollout/ep_rew_mean -721.81812
wandb:                   PPO_1217/time/fps 1197.0
wandb:            PPO_1217/train/approx_kl 0.01442
wandb:        PPO_1217/train/clip_fraction 0.17774
wandb:           PPO_1217/train/clip_range 0.2
wandb:         PPO_1217/train/entropy_loss -7.17421
wandb:   PPO_1217/train/explained_variance 0.9544
wandb:        PPO_1217/train/learning_rate 0.0003
wandb:                 PPO_1217/train/loss 43.79922
wandb: PPO_1217/train/policy_gradient_loss -0.00875
wandb:                  PPO_1217/train/std 0.67386
wandb:           PPO_1217/train/value_loss 116.3063
wandb:                PPO_1227/global_step 212992
wandb:        PPO_1227/rollout/ep_len_mean 200.0
wandb:        PPO_1227/rollout/ep_rew_mean -605.68347
wandb:                   PPO_1227/time/fps 1188.0
wandb:            PPO_1227/train/approx_kl 0.01408
wandb:        PPO_1227/train/clip_fraction 0.19233
wandb:           PPO_1227/train/clip_range 0.2
wandb:         PPO_1227/train/entropy_loss -6.48165
wandb:   PPO_1227/train/explained_variance 0.9535
wandb:        PPO_1227/train/learning_rate 0.0003
wandb:                 PPO_1227/train/loss 17.36514
wandb: PPO_1227/train/policy_gradient_loss -0.00535
wandb:                  PPO_1227/train/std 0.60985
wandb:           PPO_1227/train/value_loss 60.70319
wandb:                PPO_1237/global_step 212992
wandb:        PPO_1237/rollout/ep_len_mean 200.0
wandb:        PPO_1237/rollout/ep_rew_mean -593.50977
wandb:                   PPO_1237/time/fps 1184.0
wandb:            PPO_1237/train/approx_kl 0.01355
wandb:        PPO_1237/train/clip_fraction 0.17427
wandb:           PPO_1237/train/clip_range 0.2
wandb:         PPO_1237/train/entropy_loss -5.88306
wandb:   PPO_1237/train/explained_variance 0.96394
wandb:        PPO_1237/train/learning_rate 0.0003
wandb:                 PPO_1237/train/loss 59.46148
wandb: PPO_1237/train/policy_gradient_loss -0.00552
wandb:                  PPO_1237/train/std 0.56052
wandb:           PPO_1237/train/value_loss 149.77466
wandb:                PPO_1247/global_step 212992
wandb:        PPO_1247/rollout/ep_len_mean 200.0
wandb:        PPO_1247/rollout/ep_rew_mean -558.67432
wandb:                   PPO_1247/time/fps 1182.0
wandb:            PPO_1247/train/approx_kl 0.0156
wandb:        PPO_1247/train/clip_fraction 0.19015
wandb:           PPO_1247/train/clip_range 0.2
wandb:         PPO_1247/train/entropy_loss -5.35736
wandb:   PPO_1247/train/explained_variance 0.97714
wandb:        PPO_1247/train/learning_rate 0.0003
wandb:                 PPO_1247/train/loss 42.9418
wandb: PPO_1247/train/policy_gradient_loss -0.00346
wandb:                  PPO_1247/train/std 0.52103
wandb:           PPO_1247/train/value_loss 221.35358
wandb:                PPO_1257/global_step 212992
wandb:        PPO_1257/rollout/ep_len_mean 200.0
wandb:        PPO_1257/rollout/ep_rew_mean -556.59009
wandb:                   PPO_1257/time/fps 1179.0
wandb:            PPO_1257/train/approx_kl 0.01583
wandb:        PPO_1257/train/clip_fraction 0.19363
wandb:           PPO_1257/train/clip_range 0.2
wandb:         PPO_1257/train/entropy_loss -4.937
wandb:   PPO_1257/train/explained_variance 0.98671
wandb:        PPO_1257/train/learning_rate 0.0003
wandb:                 PPO_1257/train/loss 400.46542
wandb: PPO_1257/train/policy_gradient_loss -0.0033
wandb:                  PPO_1257/train/std 0.49053
wandb:           PPO_1257/train/value_loss 278.72729
wandb:                PPO_1267/global_step 212992
wandb:        PPO_1267/rollout/ep_len_mean 200.0
wandb:        PPO_1267/rollout/ep_rew_mean -575.88336
wandb:                   PPO_1267/time/fps 1176.0
wandb:            PPO_1267/train/approx_kl 0.01197
wandb:        PPO_1267/train/clip_fraction 0.16451
wandb:           PPO_1267/train/clip_range 0.2
wandb:         PPO_1267/train/entropy_loss -4.69031
wandb:   PPO_1267/train/explained_variance 0.98172
wandb:        PPO_1267/train/learning_rate 0.0003
wandb:                 PPO_1267/train/loss 48.12065
wandb: PPO_1267/train/policy_gradient_loss -0.00256
wandb:                  PPO_1267/train/std 0.47501
wandb:           PPO_1267/train/value_loss 542.57458
wandb:                PPO_1277/global_step 212992
wandb:        PPO_1277/rollout/ep_len_mean 200.0
wandb:        PPO_1277/rollout/ep_rew_mean -526.19519
wandb:                   PPO_1277/time/fps 1175.0
wandb:            PPO_1277/train/approx_kl 0.0208
wandb:        PPO_1277/train/clip_fraction 0.23954
wandb:           PPO_1277/train/clip_range 0.2
wandb:         PPO_1277/train/entropy_loss -4.34669
wandb:   PPO_1277/train/explained_variance 0.98164
wandb:        PPO_1277/train/learning_rate 0.0003
wandb:                 PPO_1277/train/loss 371.70401
wandb: PPO_1277/train/policy_gradient_loss 0.0021
wandb:                  PPO_1277/train/std 0.45235
wandb:           PPO_1277/train/value_loss 403.4292
wandb:                PPO_1287/global_step 212992
wandb:        PPO_1287/rollout/ep_len_mean 200.0
wandb:        PPO_1287/rollout/ep_rew_mean -536.22052
wandb:                   PPO_1287/time/fps 1179.0
wandb:            PPO_1287/train/approx_kl 0.01362
wandb:        PPO_1287/train/clip_fraction 0.18479
wandb:           PPO_1287/train/clip_range 0.2
wandb:         PPO_1287/train/entropy_loss -4.11643
wandb:   PPO_1287/train/explained_variance 0.98741
wandb:        PPO_1287/train/learning_rate 0.0003
wandb:                 PPO_1287/train/loss 29.31653
wandb: PPO_1287/train/policy_gradient_loss -5e-05
wandb:                  PPO_1287/train/std 0.43828
wandb:           PPO_1287/train/value_loss 390.00974
wandb:                    global_mean_eval -403.63309
wandb:                         global_step 212992
wandb:                       mean_reward_0 -394.90058
wandb:                       mean_reward_1 -321.39395
wandb:                      mean_reward_10 -443.20955
wandb:                      mean_reward_11 -456.03522
wandb:                      mean_reward_12 -391.63282
wandb:                      mean_reward_13 -322.65814
wandb:                      mean_reward_14 -387.44707
wandb:                      mean_reward_15 -420.99487
wandb:                      mean_reward_16 -442.88293
wandb:                      mean_reward_17 -455.01265
wandb:                      mean_reward_18 -389.65871
wandb:                      mean_reward_19 -321.79691
wandb:                       mean_reward_2 -388.25027
wandb:                      mean_reward_20 -387.61502
wandb:                      mean_reward_21 -420.81567
wandb:                      mean_reward_22 -442.77092
wandb:                      mean_reward_23 -454.76234
wandb:                      mean_reward_24 -389.4337
wandb:                      mean_reward_25 -323.33623
wandb:                      mean_reward_26 -388.5173
wandb:                      mean_reward_27 -420.72591
wandb:                      mean_reward_28 -442.83738
wandb:                      mean_reward_29 -453.8749
wandb:                       mean_reward_3 -421.59803
wandb:                      mean_reward_30 -392.85853
wandb:                      mean_reward_31 -323.0767
wandb:                      mean_reward_32 -388.02924
wandb:                      mean_reward_33 -421.46792
wandb:                      mean_reward_34 -442.91709
wandb:                      mean_reward_35 -454.22424
wandb:                       mean_reward_4 -442.80677
wandb:                       mean_reward_5 -455.06083
wandb:                       mean_reward_6 -394.81327
wandb:                       mean_reward_7 -323.3135
wandb:                       mean_reward_8 -388.74371
wandb:                       mean_reward_9 -421.31829
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 23.65129
wandb:                        std_reward_1 10.68682
wandb:                       std_reward_10 5.47903
wandb:                       std_reward_11 17.28773
wandb:                       std_reward_12 21.18191
wandb:                       std_reward_13 12.02708
wandb:                       std_reward_14 9.11288
wandb:                       std_reward_15 2.66467
wandb:                       std_reward_16 5.58635
wandb:                       std_reward_17 11.73097
wandb:                       std_reward_18 20.94794
wandb:                       std_reward_19 10.73318
wandb:                        std_reward_2 9.20092
wandb:                       std_reward_20 8.25657
wandb:                       std_reward_21 3.12496
wandb:                       std_reward_22 4.92311
wandb:                       std_reward_23 10.43526
wandb:                       std_reward_24 23.03025
wandb:                       std_reward_25 11.06284
wandb:                       std_reward_26 10.1857
wandb:                       std_reward_27 2.69076
wandb:                       std_reward_28 4.92467
wandb:                       std_reward_29 12.07996
wandb:                        std_reward_3 2.98572
wandb:                       std_reward_30 22.18528
wandb:                       std_reward_31 10.32778
wandb:                       std_reward_32 9.11105
wandb:                       std_reward_33 2.60549
wandb:                       std_reward_34 4.48311
wandb:                       std_reward_35 9.06036
wandb:                        std_reward_4 4.9066
wandb:                        std_reward_5 13.10728
wandb:                        std_reward_6 21.79344
wandb:                        std_reward_7 11.61655
wandb:                        std_reward_8 9.09269
wandb:                        std_reward_9 2.94453
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced deft-snow-34: https://wandb.ai/tidiane/meta_rl_context/runs/1ol3e8yx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-1ol3e8yx/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1209/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1209/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1209/rollout/ep_rew_mean â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–ˆ
wandb:                   PPO_1209/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1209/train/approx_kl â–†â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–†â–â–…â–ˆ
wandb:        PPO_1209/train/clip_fraction â–…â–„â–ƒâ–„â–ƒâ–â–ƒâ–†â–â–‡â–ˆ
wandb:           PPO_1209/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1209/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1209/train/explained_variance â–†â–ƒâ–ˆâ–â–…â–†â–†â–ˆâ–„â–…â–†
wandb:        PPO_1209/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1209/train/loss â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–‚â–ˆ
wandb: PPO_1209/train/policy_gradient_loss â–‚â–â–…â–„â–‡â–†â–ˆâ–‚â–ˆâ–…â–„
wandb:                  PPO_1209/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1209/train/value_loss â–â–â–‚â–…â–ƒâ–…â–…â–ƒâ–‡â–†â–ˆ
wandb:                PPO_1219/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1219/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1219/rollout/ep_rew_mean â–â–ƒâ–„â–„â–…â–†â–†â–†â–†â–‡â–†â–ˆ
wandb:                   PPO_1219/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1219/train/approx_kl â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–‚â–†â–ƒâ–â–…
wandb:        PPO_1219/train/clip_fraction â–„â–ˆâ–…â–…â–ƒâ–…â–…â–‡â–â–ƒâ–„
wandb:           PPO_1219/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1219/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1219/train/explained_variance â–„â–„â–†â–†â–…â–†â–‡â–ˆâ–ƒâ–â–…
wandb:        PPO_1219/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1219/train/loss â–†â–ˆâ–ƒâ–ƒâ–„â–â–‚â–‚â–„â–‚â–„
wandb: PPO_1219/train/policy_gradient_loss â–ƒâ–â–ƒâ–„â–‡â–ˆâ–†â–†â–‡â–ˆâ–…
wandb:                  PPO_1219/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1219/train/value_loss â–ˆâ–ˆâ–…â–„â–ƒâ–‚â–â–â–ƒâ–â–‚
wandb:                PPO_1229/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1229/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1229/rollout/ep_rew_mean â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–ƒâ–„â–„â–‡â–ˆâ–ƒ
wandb:                   PPO_1229/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1229/train/approx_kl â–†â–†â–„â–â–ƒâ–‡â–ƒâ–„â–†â–ˆâ–ƒ
wandb:        PPO_1229/train/clip_fraction â–†â–‡â–„â–ƒâ–…â–…â–…â–‚â–†â–ˆâ–
wandb:           PPO_1229/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1229/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1229/train/explained_variance â–‡â–ˆâ–â–ƒâ–‚â–†â–†â–‡â–‡â–…â–†
wandb:        PPO_1229/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1229/train/loss â–â–â–â–‚â–„â–â–â–ƒâ–ƒâ–ˆâ–…
wandb: PPO_1229/train/policy_gradient_loss â–‚â–â–„â–…â–„â–„â–„â–â–ˆâ–‡â–…
wandb:                  PPO_1229/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1229/train/value_loss â–‚â–â–ƒâ–ƒâ–…â–…â–„â–„â–„â–†â–ˆ
wandb:                PPO_1239/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1239/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1239/rollout/ep_rew_mean â–ˆâ–„â–‚â–ƒâ–â–…â–ƒâ–â–„â–ˆâ–ƒâ–‚
wandb:                   PPO_1239/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1239/train/approx_kl â–ƒâ–ƒâ–â–‚â–ƒâ–†â–„â–‚â–ƒâ–ˆâ–„
wandb:        PPO_1239/train/clip_fraction â–„â–ƒâ–‚â–â–ƒâ–†â–ƒâ–‚â–‚â–ˆâ–ƒ
wandb:           PPO_1239/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1239/train/entropy_loss â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–…â–†â–ˆ
wandb:   PPO_1239/train/explained_variance â–â–ƒâ–…â–‚â–ƒâ–†â–†â–‡â–†â–ˆâ–ˆ
wandb:        PPO_1239/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1239/train/loss â–ƒâ–ƒâ–‚â–…â–„â–â–‚â–ƒâ–‚â–„â–ˆ
wandb: PPO_1239/train/policy_gradient_loss â–â–…â–„â–„â–…â–ˆâ–†â–ˆâ–„â–†â–…
wandb:                  PPO_1239/train/std â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–
wandb:           PPO_1239/train/value_loss â–ƒâ–…â–…â–ˆâ–‡â–ƒâ–ƒâ–…â–…â–â–…
wandb:                PPO_1249/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1249/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1249/rollout/ep_rew_mean â–‚â–â–…â–ƒâ–ˆâ–†â–„â–…â–…â–…â–†â–„
wandb:                   PPO_1249/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1249/train/approx_kl â–â–ƒâ–…â–„â–ˆâ–†â–†â–‡â–‡â–ˆâ–†
wandb:        PPO_1249/train/clip_fraction â–â–ƒâ–…â–„â–ˆâ–‡â–†â–†â–‡â–†â–…
wandb:           PPO_1249/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1249/train/entropy_loss â–â–â–â–‚â–‚â–ƒâ–„â–…â–†â–‡â–ˆ
wandb:   PPO_1249/train/explained_variance â–…â–„â–†â–‡â–â–ƒâ–ˆâ–‡â–‡â–†â–ˆ
wandb:        PPO_1249/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1249/train/loss â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ˆâ–â–‚â–‚â–„
wandb: PPO_1249/train/policy_gradient_loss â–„â–â–‚â–„â–†â–‚â–ˆâ–‚â–„â–†â–‚
wandb:                  PPO_1249/train/std â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–ƒâ–ƒâ–‚â–
wandb:           PPO_1249/train/value_loss â–†â–ˆâ–â–ƒâ–â–‚â–‚â–‚â–‚â–„â–„
wandb:                PPO_1260/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1260/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1260/rollout/ep_rew_mean â–ˆâ–ƒâ–‚â–‚â–â–…â–ƒâ–…â–â–‚â–‚â–‚
wandb:                   PPO_1260/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1260/train/approx_kl â–„â–ƒâ–„â–†â–â–„â–„â–‡â–ƒâ–ˆâ–…
wandb:        PPO_1260/train/clip_fraction â–…â–â–†â–„â–ƒâ–†â–„â–‡â–ƒâ–ˆâ–„
wandb:           PPO_1260/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1260/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1260/train/explained_variance â–â–„â–ˆâ–†â–†â–‡â–‡â–„â–†â–ˆâ–…
wandb:        PPO_1260/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1260/train/loss â–„â–â–ƒâ–‚â–‡â–ƒâ–†â–ƒâ–ƒâ–â–ˆ
wandb: PPO_1260/train/policy_gradient_loss â–†â–„â–†â–„â–†â–†â–„â–ˆâ–„â–‚â–
wandb:                  PPO_1260/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1260/train/value_loss â–â–‡â–ƒâ–„â–‡â–â–‚â–â–†â–‚â–ˆ
wandb:                PPO_1269/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1269/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1269/rollout/ep_rew_mean â–†â–‚â–„â–…â–â–…â–ˆâ–„â–ƒâ–…â–†â–‡
wandb:                   PPO_1269/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1269/train/approx_kl â–„â–‡â–‡â–‚â–â–ˆâ–„â–…â–‚â–ƒâ–ƒ
wandb:        PPO_1269/train/clip_fraction â–„â–‡â–†â–â–‚â–ˆâ–…â–…â–ƒâ–…â–„
wandb:           PPO_1269/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1269/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1269/train/explained_variance â–â–ˆâ–ƒâ–…â–†â–„â–‡â–‡â–‡â–„â–†
wandb:        PPO_1269/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1269/train/loss â–…â–â–â–ˆâ–‚â–â–â–â–„â–ƒâ–ƒ
wandb: PPO_1269/train/policy_gradient_loss â–„â–…â–„â–„â–‚â–ˆâ–…â–†â–â–„â–…
wandb:                  PPO_1269/train/std â–ˆâ–‡â–†â–…â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1269/train/value_loss â–†â–â–â–ˆâ–‡â–„â–ƒâ–‚â–…â–‚â–‚
wandb:                PPO_1279/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1279/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1279/rollout/ep_rew_mean â–ˆâ–†â–ƒâ–†â–‡â–…â–„â–ˆâ–‡â–ˆâ–…â–
wandb:                   PPO_1279/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1279/train/approx_kl â–…â–‡â–„â–‡â–†â–â–‚â–ˆâ–‚â–„â–ƒ
wandb:        PPO_1279/train/clip_fraction â–ƒâ–‡â–…â–†â–ƒâ–â–‚â–ˆâ–â–‚â–ƒ
wandb:           PPO_1279/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1279/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1279/train/explained_variance â–â–„â–„â–ƒâ–…â–…â–‡â–ˆâ–†â–†â–†
wandb:        PPO_1279/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1279/train/loss â–‚â–†â–„â–â–‚â–‚â–ƒâ–…â–â–ˆâ–‚
wandb: PPO_1279/train/policy_gradient_loss â–â–…â–†â–‚â–†â–„â–â–‡â–†â–ƒâ–ˆ
wandb:                  PPO_1279/train/std â–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1279/train/value_loss â–„â–„â–„â–â–„â–…â–„â–‚â–‚â–…â–ˆ
wandb:                PPO_1289/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1289/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1289/rollout/ep_rew_mean â–†â–â–â–â–†â–‡â–ˆâ–…â–…â–ˆâ–‡â–‡
wandb:                   PPO_1289/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1289/train/approx_kl â–…â–‚â–â–ˆâ–ƒâ–‡â–â–†â–„â–†â–…
wandb:        PPO_1289/train/clip_fraction â–†â–ƒâ–â–ˆâ–†â–ˆâ–ƒâ–‡â–„â–…â–„
wandb:           PPO_1289/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1289/train/entropy_loss â–â–‚â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:   PPO_1289/train/explained_variance â–…â–†â–‡â–‡â–â–‡â–‡â–‡â–ˆâ–†â–†
wandb:        PPO_1289/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1289/train/loss â–‚â–ƒâ–ˆâ–‚â–„â–â–‚â–‚â–â–ƒâ–ƒ
wandb: PPO_1289/train/policy_gradient_loss â–‚â–ƒâ–ƒâ–â–‚â–†â–‚â–ƒâ–†â–ˆâ–†
wandb:                  PPO_1289/train/std â–ˆâ–‡â–†â–†â–„â–ƒâ–‚â–â–‚â–â–
wandb:           PPO_1289/train/value_loss â–‚â–‡â–ˆâ–„â–â–â–ƒâ–â–â–‚â–‚
wandb:                    global_mean_eval â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–‡â–ˆ
wandb:                       mean_reward_1 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_10 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–†â–ˆ
wandb:                      mean_reward_13 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_14 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_15 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_16 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_19 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_2 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_20 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_21 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_22 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_25 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_26 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_27 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_30 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_31 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_32 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_33 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_34 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–‚â–‡â–‡â–‚â–â–ƒâ–†â–ˆâ–‡â–ˆ
wandb:                       mean_reward_7 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_8 â–â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                       mean_reward_9 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–â–…â–ƒâ–‚â–‚â–„â–„â–…â–ƒ
wandb:                        std_reward_1 â–ˆâ–â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–…
wandb:                       std_reward_10 â–‚â–ˆâ–â–â–‚â–â–â–â–â–
wandb:                       std_reward_11 â–‚â–ˆâ–â–â–‚â–‚â–â–â–â–
wandb:                       std_reward_12 â–ˆâ–ƒâ–ƒâ–ƒâ–â–â–ƒâ–‚â–…â–„
wandb:                       std_reward_13 â–ˆâ–â–â–ƒâ–ƒâ–‚â–‚â–„â–„â–†
wandb:                       std_reward_14 â–ˆâ–â–‚â–‚â–„â–‚â–‚â–ˆâ–â–…
wandb:                       std_reward_15 â–„â–â–â–‚â–‚â–â–ƒâ–â–ˆâ–‚
wandb:                       std_reward_16 â–‚â–ˆâ–â–â–‚â–â–â–â–â–
wandb:                       std_reward_17 â–‚â–ˆâ–â–â–‚â–‚â–â–â–â–
wandb:                       std_reward_18 â–ˆâ–â–…â–ƒâ–â–â–„â–‚â–„â–‚
wandb:                       std_reward_19 â–ˆâ–â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–…
wandb:                        std_reward_2 â–ˆâ–â–‚â–ƒâ–„â–‚â–‚â–ƒâ–â–„
wandb:                       std_reward_20 â–…â–â–‚â–‚â–ƒâ–‚â–‚â–ˆâ–â–ƒ
wandb:                       std_reward_21 â–ƒâ–â–â–â–‚â–â–‚â–â–ˆâ–
wandb:                       std_reward_22 â–‚â–ˆâ–â–â–‚â–â–â–â–ƒâ–
wandb:                       std_reward_23 â–‚â–ˆâ–â–â–‚â–‚â–â–â–â–
wandb:                       std_reward_24 â–ˆâ–ƒâ–…â–ƒâ–â–‚â–ƒâ–‚â–†â–„
wandb:                       std_reward_25 â–‡â–â–â–‚â–ƒâ–‚â–‚â–ˆâ–‚â–„
wandb:                       std_reward_26 â–ˆâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–…
wandb:                       std_reward_27 â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–…â–‚â–â–„
wandb:                       std_reward_28 â–‚â–ˆâ–â–â–‚â–â–â–â–„â–
wandb:                       std_reward_29 â–‚â–ˆâ–â–â–‚â–‚â–â–â–â–
wandb:                        std_reward_3 â–„â–â–â–‚â–‚â–â–ƒâ–â–ˆâ–‚
wandb:                       std_reward_30 â–ˆâ–‚â–†â–ƒâ–â–â–‚â–‚â–…â–„
wandb:                       std_reward_31 â–ˆâ–â–â–‚â–ƒâ–â–‚â–ƒâ–ˆâ–…
wandb:                       std_reward_32 â–ˆâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–„
wandb:                       std_reward_33 â–ˆâ–ƒâ–‚â–‚â–„â–‚â–„â–â–â–„
wandb:                       std_reward_34 â–‚â–ˆâ–â–â–‚â–â–â–ƒâ–â–
wandb:                       std_reward_35 â–‚â–ˆâ–â–â–‚â–‚â–â–ƒâ–â–
wandb:                        std_reward_4 â–‚â–ˆâ–â–â–‚â–â–â–â–â–
wandb:                        std_reward_5 â–‚â–ˆâ–â–â–‚â–â–â–â–ƒâ–
wandb:                        std_reward_6 â–ˆâ–„â–†â–„â–â–â–ƒâ–ƒâ–†â–ƒ
wandb:                        std_reward_7 â–ˆâ–â–â–ƒâ–ƒâ–â–‚â–ƒâ–ˆâ–„
wandb:                        std_reward_8 â–ˆâ–â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–…
wandb:                        std_reward_9 â–ˆâ–„â–‚â–ƒâ–„â–‚â–…â–‚â–â–„
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1209/global_step 212992
wandb:        PPO_1209/rollout/ep_len_mean 200.0
wandb:        PPO_1209/rollout/ep_rew_mean -734.20221
wandb:                   PPO_1209/time/fps 1191.0
wandb:            PPO_1209/train/approx_kl 0.01249
wandb:        PPO_1209/train/clip_fraction 0.16172
wandb:           PPO_1209/train/clip_range 0.2
wandb:         PPO_1209/train/entropy_loss -7.68336
wandb:   PPO_1209/train/explained_variance 0.96117
wandb:        PPO_1209/train/learning_rate 0.0003
wandb:                 PPO_1209/train/loss 145.90727
wandb: PPO_1209/train/policy_gradient_loss -0.00765
wandb:                  PPO_1209/train/std 0.72482
wandb:           PPO_1209/train/value_loss 181.48923
wandb:                PPO_1219/global_step 212992
wandb:        PPO_1219/rollout/ep_len_mean 200.0
wandb:        PPO_1219/rollout/ep_rew_mean -588.39246
wandb:                   PPO_1219/time/fps 1172.0
wandb:            PPO_1219/train/approx_kl 0.01329
wandb:        PPO_1219/train/clip_fraction 0.16618
wandb:           PPO_1219/train/clip_range 0.2
wandb:         PPO_1219/train/entropy_loss -6.85361
wandb:   PPO_1219/train/explained_variance 0.96744
wandb:        PPO_1219/train/learning_rate 0.0003
wandb:                 PPO_1219/train/loss 40.85143
wandb: PPO_1219/train/policy_gradient_loss -0.00604
wandb:                  PPO_1219/train/std 0.64342
wandb:           PPO_1219/train/value_loss 87.11662
wandb:                PPO_1229/global_step 212992
wandb:        PPO_1229/rollout/ep_len_mean 200.0
wandb:        PPO_1229/rollout/ep_rew_mean -564.36133
wandb:                   PPO_1229/time/fps 1170.0
wandb:            PPO_1229/train/approx_kl 0.01121
wandb:        PPO_1229/train/clip_fraction 0.13472
wandb:           PPO_1229/train/clip_range 0.2
wandb:         PPO_1229/train/entropy_loss -6.22256
wandb:   PPO_1229/train/explained_variance 0.96471
wandb:        PPO_1229/train/learning_rate 0.0003
wandb:                 PPO_1229/train/loss 119.77422
wandb: PPO_1229/train/policy_gradient_loss -0.00352
wandb:                  PPO_1229/train/std 0.58877
wandb:           PPO_1229/train/value_loss 266.60684
wandb:                PPO_1239/global_step 212992
wandb:        PPO_1239/rollout/ep_len_mean 200.0
wandb:        PPO_1239/rollout/ep_rew_mean -616.22003
wandb:                   PPO_1239/time/fps 1165.0
wandb:            PPO_1239/train/approx_kl 0.01086
wandb:        PPO_1239/train/clip_fraction 0.13522
wandb:           PPO_1239/train/clip_range 0.2
wandb:         PPO_1239/train/entropy_loss -5.9459
wandb:   PPO_1239/train/explained_variance 0.98091
wandb:        PPO_1239/train/learning_rate 0.0003
wandb:                 PPO_1239/train/loss 410.18015
wandb: PPO_1239/train/policy_gradient_loss -0.00357
wandb:                  PPO_1239/train/std 0.56518
wandb:           PPO_1239/train/value_loss 482.26196
wandb:                PPO_1249/global_step 212992
wandb:        PPO_1249/rollout/ep_len_mean 200.0
wandb:        PPO_1249/rollout/ep_rew_mean -587.94397
wandb:                   PPO_1249/time/fps 1168.0
wandb:            PPO_1249/train/approx_kl 0.01101
wandb:        PPO_1249/train/clip_fraction 0.14436
wandb:           PPO_1249/train/clip_range 0.2
wandb:         PPO_1249/train/entropy_loss -5.53362
wandb:   PPO_1249/train/explained_variance 0.98414
wandb:        PPO_1249/train/learning_rate 0.0003
wandb:                 PPO_1249/train/loss 343.84839
wandb: PPO_1249/train/policy_gradient_loss -0.00383
wandb:                  PPO_1249/train/std 0.53325
wandb:           PPO_1249/train/value_loss 602.17615
wandb:                PPO_1260/global_step 212992
wandb:        PPO_1260/rollout/ep_len_mean 200.0
wandb:        PPO_1260/rollout/ep_rew_mean -602.44482
wandb:                   PPO_1260/time/fps 1169.0
wandb:            PPO_1260/train/approx_kl 0.0114
wandb:        PPO_1260/train/clip_fraction 0.13958
wandb:           PPO_1260/train/clip_range 0.2
wandb:         PPO_1260/train/entropy_loss -5.07221
wandb:   PPO_1260/train/explained_variance 0.98084
wandb:        PPO_1260/train/learning_rate 0.0003
wandb:                 PPO_1260/train/loss 668.16058
wandb: PPO_1260/train/policy_gradient_loss -0.00402
wandb:                  PPO_1260/train/std 0.49879
wandb:           PPO_1260/train/value_loss 943.9187
wandb:                PPO_1269/global_step 212992
wandb:        PPO_1269/rollout/ep_len_mean 200.0
wandb:        PPO_1269/rollout/ep_rew_mean -528.8446
wandb:                   PPO_1269/time/fps 1171.0
wandb:            PPO_1269/train/approx_kl 0.0133
wandb:        PPO_1269/train/clip_fraction 0.18474
wandb:           PPO_1269/train/clip_range 0.2
wandb:         PPO_1269/train/entropy_loss -4.73247
wandb:   PPO_1269/train/explained_variance 0.98072
wandb:        PPO_1269/train/learning_rate 0.0003
wandb:                 PPO_1269/train/loss 111.49516
wandb: PPO_1269/train/policy_gradient_loss -0.00133
wandb:                  PPO_1269/train/std 0.47514
wandb:           PPO_1269/train/value_loss 316.42419
wandb:                PPO_1279/global_step 212992
wandb:        PPO_1279/rollout/ep_len_mean 200.0
wandb:        PPO_1279/rollout/ep_rew_mean -556.07129
wandb:                   PPO_1279/time/fps 1172.0
wandb:            PPO_1279/train/approx_kl 0.01437
wandb:        PPO_1279/train/clip_fraction 0.18607
wandb:           PPO_1279/train/clip_range 0.2
wandb:         PPO_1279/train/entropy_loss -4.33181
wandb:   PPO_1279/train/explained_variance 0.98206
wandb:        PPO_1279/train/learning_rate 0.0003
wandb:                 PPO_1279/train/loss 56.75792
wandb: PPO_1279/train/policy_gradient_loss 0.00056
wandb:                  PPO_1279/train/std 0.44992
wandb:           PPO_1279/train/value_loss 392.21689
wandb:                PPO_1289/global_step 212992
wandb:        PPO_1289/rollout/ep_len_mean 200.0
wandb:        PPO_1289/rollout/ep_rew_mean -500.08087
wandb:                   PPO_1289/time/fps 1171.0
wandb:            PPO_1289/train/approx_kl 0.01659
wandb:        PPO_1289/train/clip_fraction 0.20763
wandb:           PPO_1289/train/clip_range 0.2
wandb:         PPO_1289/train/entropy_loss -3.95361
wandb:   PPO_1289/train/explained_variance 0.98212
wandb:        PPO_1289/train/learning_rate 0.0003
wandb:                 PPO_1289/train/loss 115.8401
wandb: PPO_1289/train/policy_gradient_loss 0.00017
wandb:                  PPO_1289/train/std 0.42705
wandb:           PPO_1289/train/value_loss 185.62531
wandb:                    global_mean_eval -436.52241
wandb:                         global_step 212992
wandb:                       mean_reward_0 -392.48394
wandb:                       mean_reward_1 -382.63338
wandb:                      mean_reward_10 -474.43172
wandb:                      mean_reward_11 -490.97444
wandb:                      mean_reward_12 -393.81578
wandb:                      mean_reward_13 -384.78328
wandb:                      mean_reward_14 -423.75841
wandb:                      mean_reward_15 -454.5402
wandb:                      mean_reward_16 -474.08714
wandb:                      mean_reward_17 -491.22672
wandb:                      mean_reward_18 -394.91883
wandb:                      mean_reward_19 -380.77342
wandb:                       mean_reward_2 -425.17367
wandb:                      mean_reward_20 -426.02049
wandb:                      mean_reward_21 -454.44216
wandb:                      mean_reward_22 -474.65253
wandb:                      mean_reward_23 -490.97808
wandb:                      mean_reward_24 -385.61694
wandb:                      mean_reward_25 -382.34961
wandb:                      mean_reward_26 -425.38508
wandb:                      mean_reward_27 -454.35685
wandb:                      mean_reward_28 -474.43769
wandb:                      mean_reward_29 -490.69247
wandb:                       mean_reward_3 -454.13005
wandb:                      mean_reward_30 -389.0102
wandb:                      mean_reward_31 -383.03354
wandb:                      mean_reward_32 -425.27858
wandb:                      mean_reward_33 -455.30743
wandb:                      mean_reward_34 -473.77854
wandb:                      mean_reward_35 -491.11856
wandb:                       mean_reward_4 -474.21271
wandb:                       mean_reward_5 -491.13551
wandb:                       mean_reward_6 -394.44658
wandb:                       mean_reward_7 -380.53785
wandb:                       mean_reward_8 -425.29413
wandb:                       mean_reward_9 -454.99036
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 59.64401
wandb:                        std_reward_1 16.47906
wandb:                       std_reward_10 3.6401
wandb:                       std_reward_11 3.87331
wandb:                       std_reward_12 67.95983
wandb:                       std_reward_13 18.47231
wandb:                       std_reward_14 11.0649
wandb:                       std_reward_15 6.31926
wandb:                       std_reward_16 3.77093
wandb:                       std_reward_17 3.55913
wandb:                       std_reward_18 53.94225
wandb:                       std_reward_19 17.00318
wandb:                        std_reward_2 9.58867
wandb:                       std_reward_20 9.9163
wandb:                       std_reward_21 5.56982
wandb:                       std_reward_22 3.92779
wandb:                       std_reward_23 3.36898
wandb:                       std_reward_24 70.72141
wandb:                       std_reward_25 15.96955
wandb:                       std_reward_26 10.7713
wandb:                       std_reward_27 6.47745
wandb:                       std_reward_28 3.60955
wandb:                       std_reward_29 3.56451
wandb:                        std_reward_3 6.19037
wandb:                       std_reward_30 74.8581
wandb:                       std_reward_31 20.01321
wandb:                       std_reward_32 9.23059
wandb:                       std_reward_33 6.5749
wandb:                       std_reward_34 3.52764
wandb:                       std_reward_35 3.97423
wandb:                        std_reward_4 4.33623
wandb:                        std_reward_5 3.49643
wandb:                        std_reward_6 59.72084
wandb:                        std_reward_7 17.39887
wandb:                        std_reward_8 11.23818
wandb:                        std_reward_9 6.77094
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced legendary-snowflake-39: https://wandb.ai/tidiane/meta_rl_context/runs/1uc7k9re
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-1uc7k9re/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1211/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1211/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1211/rollout/ep_rew_mean â–â–â–ƒâ–‚â–„â–…â–…â–†â–…â–‡â–ˆâ–ˆ
wandb:                   PPO_1211/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1211/train/approx_kl â–â–‡â–‚â–…â–…â–†â–…â–†â–ˆâ–ˆâ–‡
wandb:        PPO_1211/train/clip_fraction â–â–‚â–ƒâ–„â–ƒâ–‡â–†â–…â–‡â–ˆâ–ˆ
wandb:           PPO_1211/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1211/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1211/train/explained_variance â–„â–†â–ˆâ–ƒâ–„â–â–„â–„â–ƒâ–ƒâ–ƒ
wandb:        PPO_1211/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1211/train/loss â–„â–‚â–â–‚â–…â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚
wandb: PPO_1211/train/policy_gradient_loss â–†â–…â–â–„â–…â–„â–ˆâ–…â–â–„â–…
wandb:                  PPO_1211/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1211/train/value_loss â–â–â–â–‚â–ƒâ–ˆâ–ƒâ–†â–†â–„â–…
wandb:                PPO_1221/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1221/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1221/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–ˆ
wandb:                   PPO_1221/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1221/train/approx_kl â–‚â–„â–â–„â–ƒâ–‚â–…â–…â–ˆâ–…â–ˆ
wandb:        PPO_1221/train/clip_fraction â–â–„â–‚â–‚â–ƒâ–ƒâ–„â–†â–‡â–…â–ˆ
wandb:           PPO_1221/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1221/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1221/train/explained_variance â–„â–â–†â–„â–‚â–‚â–‡â–ˆâ–†â–…â–ˆ
wandb:        PPO_1221/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1221/train/loss â–‚â–ƒâ–ƒâ–ˆâ–â–ƒâ–‚â–„â–ƒâ–„â–‚
wandb: PPO_1221/train/policy_gradient_loss â–ƒâ–„â–ˆâ–â–…â–‡â–‡â–„â–…â–ˆâ–…
wandb:                  PPO_1221/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1221/train/value_loss â–ˆâ–…â–‚â–‡â–†â–…â–…â–„â–‡â–„â–
wandb:                PPO_1230/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1230/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1230/rollout/ep_rew_mean â–â–‚â–„â–ƒâ–„â–„â–…â–…â–…â–…â–ˆâ–†
wandb:                   PPO_1230/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1230/train/approx_kl â–‚â–â–†â–‚â–„â–„â–…â–ˆâ–†â–ƒâ–‚
wandb:        PPO_1230/train/clip_fraction â–ƒâ–â–ˆâ–ƒâ–†â–„â–†â–…â–‡â–…â–ƒ
wandb:           PPO_1230/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1230/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆ
wandb:   PPO_1230/train/explained_variance â–‡â–‡â–…â–ˆâ–ˆâ–‡â–†â–â–†â–‡â–‚
wandb:        PPO_1230/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1230/train/loss â–â–‡â–ƒâ–…â–â–ƒâ–„â–ƒâ–…â–ƒâ–ˆ
wandb: PPO_1230/train/policy_gradient_loss â–„â–ƒâ–â–…â–‡â–„â–…â–ƒâ–†â–…â–ˆ
wandb:                  PPO_1230/train/std â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1230/train/value_loss â–â–…â–‚â–‚â–â–â–‚â–†â–‚â–ƒâ–ˆ
wandb:                PPO_1240/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1240/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1240/rollout/ep_rew_mean â–â–†â–†â–…â–ˆâ–†â–‡â–…â–„â–ƒâ–†â–ˆ
wandb:                   PPO_1240/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1240/train/approx_kl â–‚â–â–ƒâ–ˆâ–…â–…â–ƒâ–„â–„â–ƒâ–
wandb:        PPO_1240/train/clip_fraction â–â–ƒâ–…â–ˆâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–„
wandb:           PPO_1240/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1240/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:   PPO_1240/train/explained_variance â–â–„â–‡â–ˆâ–‡â–‡â–ˆâ–ƒâ–‡â–„â–†
wandb:        PPO_1240/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1240/train/loss â–â–‚â–â–ƒâ–„â–ƒâ–‚â–ˆâ–‡â–†â–‚
wandb: PPO_1240/train/policy_gradient_loss â–â–‚â–‡â–…â–â–‚â–â–â–ˆâ–„â–„
wandb:                  PPO_1240/train/std â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–‚â–â–â–
wandb:           PPO_1240/train/value_loss â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–…â–ˆâ–†
wandb:                PPO_1250/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1250/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1250/rollout/ep_rew_mean â–„â–â–ƒâ–ƒâ–ƒâ–†â–ˆâ–†â–…â–‡â–…â–‡
wandb:                   PPO_1250/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1250/train/approx_kl â–‚â–â–ˆâ–ƒâ–„â–‡â–…â–‡â–†â–ˆâ–‡
wandb:        PPO_1250/train/clip_fraction â–‚â–â–†â–â–…â–‡â–…â–†â–„â–ˆâ–†
wandb:           PPO_1250/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1250/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1250/train/explained_variance â–â–â–ˆâ–…â–ˆâ–‡â–‡â–„â–‡â–…â–‡
wandb:        PPO_1250/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1250/train/loss â–„â–†â–ƒâ–„â–â–â–â–„â–‚â–ˆâ–
wandb: PPO_1250/train/policy_gradient_loss â–â–†â–ƒâ–„â–†â–ˆâ–ˆâ–ˆâ–„â–†â–†
wandb:                  PPO_1250/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1250/train/value_loss â–…â–ˆâ–â–ˆâ–â–â–â–‚â–„â–â–ƒ
wandb:                PPO_1259/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1259/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1259/rollout/ep_rew_mean â–‡â–‡â–ƒâ–â–„â–…â–ˆâ–„â–‚â–ƒâ–†â–…
wandb:                   PPO_1259/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1259/train/approx_kl â–…â–„â–‚â–„â–ˆâ–ƒâ–ˆâ–â–‚â–…â–ƒ
wandb:        PPO_1259/train/clip_fraction â–†â–„â–â–„â–„â–…â–ˆâ–â–ƒâ–„â–„
wandb:           PPO_1259/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1259/train/entropy_loss â–â–â–‚â–ƒâ–…â–†â–†â–†â–†â–‡â–ˆ
wandb:   PPO_1259/train/explained_variance â–â–â–„â–†â–†â–ˆâ–‡â–ˆâ–†â–†â–‡
wandb:        PPO_1259/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1259/train/loss â–‚â–â–ˆâ–„â–â–‚â–â–ˆâ–ƒâ–ˆâ–…
wandb: PPO_1259/train/policy_gradient_loss â–„â–„â–â–ƒâ–ƒâ–„â–ˆâ–ƒâ–„â–„â–„
wandb:                  PPO_1259/train/std â–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1259/train/value_loss â–„â–ƒâ–‡â–†â–„â–„â–â–‡â–ˆâ–†â–†
wandb:                PPO_1270/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1270/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1270/rollout/ep_rew_mean â–„â–ƒâ–‡â–ˆâ–„â–â–…â–â–‡â–‚â–„â–ˆ
wandb:                   PPO_1270/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1270/train/approx_kl â–„â–„â–ƒâ–ˆâ–â–‚â–‚â–†â–â–ƒâ–„
wandb:        PPO_1270/train/clip_fraction â–…â–„â–‡â–ˆâ–â–ƒâ–ƒâ–ˆâ–‚â–…â–…
wandb:           PPO_1270/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1270/train/entropy_loss â–â–‚â–â–â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1270/train/explained_variance â–„â–â–„â–‡â–†â–†â–„â–‡â–†â–ˆâ–†
wandb:        PPO_1270/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1270/train/loss â–â–„â–ƒâ–‚â–†â–‚â–‚â–â–‚â–ˆâ–
wandb: PPO_1270/train/policy_gradient_loss â–‚â–ƒâ–‚â–…â–â–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒ
wandb:                  PPO_1270/train/std â–‡â–‡â–ˆâ–‡â–†â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1270/train/value_loss â–†â–ˆâ–ƒâ–â–…â–ˆâ–†â–„â–…â–ƒâ–„
wandb:                PPO_1280/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1280/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1280/rollout/ep_rew_mean â–†â–†â–ˆâ–ˆâ–â–ƒâ–„â–â–…â–‡â–†â–…
wandb:                   PPO_1280/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1280/train/approx_kl â–…â–ˆâ–‡â–…â–ƒâ–„â–„â–â–ƒâ–ˆâ–ƒ
wandb:        PPO_1280/train/clip_fraction â–†â–„â–ˆâ–…â–ƒâ–ƒâ–‡â–â–…â–ˆâ–ƒ
wandb:           PPO_1280/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1280/train/entropy_loss â–â–â–â–‚â–ƒâ–„â–…â–…â–‡â–ˆâ–ˆ
wandb:   PPO_1280/train/explained_variance â–…â–„â–‡â–ˆâ–…â–‡â–‡â–‡â–‡â–â–…
wandb:        PPO_1280/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1280/train/loss â–…â–‚â–ˆâ–„â–‚â–„â–†â–…â–†â–â–‡
wandb: PPO_1280/train/policy_gradient_loss â–‚â–‚â–ˆâ–†â–†â–â–„â–‚â–â–„â–…
wandb:                  PPO_1280/train/std â–ˆâ–ˆâ–‡â–‡â–†â–„â–…â–ƒâ–‚â–‚â–
wandb:           PPO_1280/train/value_loss â–„â–„â–â–ƒâ–„â–„â–ƒâ–ˆâ–…â–„â–…
wandb:                PPO_1290/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1290/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1290/rollout/ep_rew_mean â–„â–â–ƒâ–„â–‡â–†â–„â–…â–„â–ˆâ–‡â–†
wandb:                   PPO_1290/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1290/train/approx_kl â–â–â–â–„â–ƒâ–†â–ˆâ–‡â–â–†â–‚
wandb:        PPO_1290/train/clip_fraction â–â–„â–…â–„â–†â–…â–„â–ƒâ–…â–ˆâ–„
wandb:           PPO_1290/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1290/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1290/train/explained_variance â–…â–…â–ˆâ–‡â–â–‡â–…â–‚â–…â–‚â–‡
wandb:        PPO_1290/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1290/train/loss â–ƒâ–†â–ƒâ–…â–„â–â–ˆâ–ƒâ–ƒâ–â–ƒ
wandb: PPO_1290/train/policy_gradient_loss â–â–„â–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–ˆâ–†
wandb:                  PPO_1290/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1290/train/value_loss â–‡â–†â–ƒâ–„â–ƒâ–ƒâ–†â–ˆâ–†â–â–„
wandb:                    global_mean_eval â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–ƒâ–…â–ˆâ–…â–…â–„â–…â–…â–…
wandb:                       mean_reward_1 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–ƒâ–…â–ˆâ–…â–„â–„â–…â–…â–†
wandb:                      mean_reward_13 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–…â–ˆâ–…â–…â–„â–…â–…â–†
wandb:                      mean_reward_19 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–ƒâ–…â–ˆâ–…â–…â–„â–…â–…â–…
wandb:                      mean_reward_25 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–ƒâ–…â–ˆâ–…â–…â–„â–…â–…â–†
wandb:                      mean_reward_31 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–…â–ˆâ–…â–„â–„â–…â–…â–†
wandb:                       mean_reward_7 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ƒâ–‚â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒ
wandb:                        std_reward_1 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_10 â–ˆâ–â–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–
wandb:                       std_reward_11 â–‡â–â–‚â–…â–…â–ˆâ–ƒâ–‚â–ˆâ–‚
wandb:                       std_reward_12 â–ƒâ–‚â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:                       std_reward_13 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_14 â–ˆâ–â–â–â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_15 â–ˆâ–â–„â–‚â–‚â–‚â–‚â–â–‚â–
wandb:                       std_reward_16 â–ƒâ–â–‚â–‚â–â–â–â–â–â–ˆ
wandb:                       std_reward_17 â–†â–â–‚â–„â–…â–‡â–‚â–‚â–ˆâ–‚
wandb:                       std_reward_18 â–„â–‚â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–‚â–ƒ
wandb:                       std_reward_19 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                        std_reward_2 â–ˆâ–â–â–â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_20 â–ˆâ–â–â–â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_21 â–ˆâ–â–ƒâ–‚â–â–â–‚â–â–â–
wandb:                       std_reward_22 â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–
wandb:                       std_reward_23 â–‡â–â–‚â–„â–†â–†â–ƒâ–‚â–ˆâ–‚
wandb:                       std_reward_24 â–ƒâ–‚â–ˆâ–â–ƒâ–â–‚â–‚â–‚â–‚
wandb:                       std_reward_25 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_26 â–ˆâ–â–â–â–â–â–â–â–‚â–‚
wandb:                       std_reward_27 â–„â–â–‚â–â–â–â–â–â–â–ˆ
wandb:                       std_reward_28 â–ƒâ–â–‚â–‚â–â–â–â–ˆâ–â–
wandb:                       std_reward_29 â–†â–â–ƒâ–„â–†â–ˆâ–‚â–‚â–ˆâ–‚
wandb:                        std_reward_3 â–ˆâ–â–ƒâ–â–â–‚â–‚â–â–‚â–
wandb:                       std_reward_30 â–„â–‚â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚
wandb:                       std_reward_31 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                       std_reward_32 â–ˆâ–â–â–â–‚â–â–â–â–‚â–‚
wandb:                       std_reward_33 â–ˆâ–â–ƒâ–â–‚â–‚â–‚â–â–‚â–
wandb:                       std_reward_34 â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:                       std_reward_35 â–†â–â–‚â–…â–†â–ˆâ–ƒâ–ƒâ–ˆâ–‚
wandb:                        std_reward_4 â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–
wandb:                        std_reward_5 â–ˆâ–â–‚â–„â–†â–‡â–ƒâ–‚â–ˆâ–‚
wandb:                        std_reward_6 â–„â–‚â–ˆâ–â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb:                        std_reward_7 â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                        std_reward_8 â–ˆâ–â–â–â–â–â–â–‚â–‚â–‚
wandb:                        std_reward_9 â–ˆâ–â–ƒâ–â–â–â–‚â–â–‚â–
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1211/global_step 212992
wandb:        PPO_1211/rollout/ep_len_mean 200.0
wandb:        PPO_1211/rollout/ep_rew_mean -787.46509
wandb:                   PPO_1211/time/fps 1145.0
wandb:            PPO_1211/train/approx_kl 0.01195
wandb:        PPO_1211/train/clip_fraction 0.16163
wandb:           PPO_1211/train/clip_range 0.2
wandb:         PPO_1211/train/entropy_loss -7.72936
wandb:   PPO_1211/train/explained_variance 0.9579
wandb:        PPO_1211/train/learning_rate 0.0003
wandb:                 PPO_1211/train/loss 18.39633
wandb: PPO_1211/train/policy_gradient_loss -0.00876
wandb:                  PPO_1211/train/std 0.72771
wandb:           PPO_1211/train/value_loss 81.86788
wandb:                PPO_1221/global_step 212992
wandb:        PPO_1221/rollout/ep_len_mean 200.0
wandb:        PPO_1221/rollout/ep_rew_mean -659.56287
wandb:                   PPO_1221/time/fps 1151.0
wandb:            PPO_1221/train/approx_kl 0.01569
wandb:        PPO_1221/train/clip_fraction 0.19553
wandb:           PPO_1221/train/clip_range 0.2
wandb:         PPO_1221/train/entropy_loss -6.86084
wandb:   PPO_1221/train/explained_variance 0.96582
wandb:        PPO_1221/train/learning_rate 0.0003
wandb:                 PPO_1221/train/loss 21.77687
wandb: PPO_1221/train/policy_gradient_loss -0.00778
wandb:                  PPO_1221/train/std 0.64442
wandb:           PPO_1221/train/value_loss 58.00319
wandb:                PPO_1230/global_step 212992
wandb:        PPO_1230/rollout/ep_len_mean 200.0
wandb:        PPO_1230/rollout/ep_rew_mean -587.70697
wandb:                   PPO_1230/time/fps 1147.0
wandb:            PPO_1230/train/approx_kl 0.01525
wandb:        PPO_1230/train/clip_fraction 0.19391
wandb:           PPO_1230/train/clip_range 0.2
wandb:         PPO_1230/train/entropy_loss -6.0641
wandb:   PPO_1230/train/explained_variance 0.94572
wandb:        PPO_1230/train/learning_rate 0.0003
wandb:                 PPO_1230/train/loss 67.96434
wandb: PPO_1230/train/policy_gradient_loss -0.00454
wandb:                  PPO_1230/train/std 0.5751
wandb:           PPO_1230/train/value_loss 104.22106
wandb:                PPO_1240/global_step 212992
wandb:        PPO_1240/rollout/ep_len_mean 200.0
wandb:        PPO_1240/rollout/ep_rew_mean -542.86255
wandb:                   PPO_1240/time/fps 1146.0
wandb:            PPO_1240/train/approx_kl 0.01453
wandb:        PPO_1240/train/clip_fraction 0.19754
wandb:           PPO_1240/train/clip_range 0.2
wandb:         PPO_1240/train/entropy_loss -5.6562
wandb:   PPO_1240/train/explained_variance 0.95979
wandb:        PPO_1240/train/learning_rate 0.0003
wandb:                 PPO_1240/train/loss 48.78587
wandb: PPO_1240/train/policy_gradient_loss -0.00533
wandb:                  PPO_1240/train/std 0.54352
wandb:           PPO_1240/train/value_loss 195.13499
wandb:                PPO_1250/global_step 212992
wandb:        PPO_1250/rollout/ep_len_mean 200.0
wandb:        PPO_1250/rollout/ep_rew_mean -546.62732
wandb:                   PPO_1250/time/fps 1143.0
wandb:            PPO_1250/train/approx_kl 0.01687
wandb:        PPO_1250/train/clip_fraction 0.20969
wandb:           PPO_1250/train/clip_range 0.2
wandb:         PPO_1250/train/entropy_loss -5.30308
wandb:   PPO_1250/train/explained_variance 0.97428
wandb:        PPO_1250/train/learning_rate 0.0003
wandb:                 PPO_1250/train/loss 55.35489
wandb: PPO_1250/train/policy_gradient_loss -0.00349
wandb:                  PPO_1250/train/std 0.51619
wandb:           PPO_1250/train/value_loss 252.42143
wandb:                PPO_1259/global_step 212992
wandb:        PPO_1259/rollout/ep_len_mean 200.0
wandb:        PPO_1259/rollout/ep_rew_mean -558.95416
wandb:                   PPO_1259/time/fps 1139.0
wandb:            PPO_1259/train/approx_kl 0.01479
wandb:        PPO_1259/train/clip_fraction 0.19655
wandb:           PPO_1259/train/clip_range 0.2
wandb:         PPO_1259/train/entropy_loss -4.92791
wandb:   PPO_1259/train/explained_variance 0.98141
wandb:        PPO_1259/train/learning_rate 0.0003
wandb:                 PPO_1259/train/loss 202.35579
wandb: PPO_1259/train/policy_gradient_loss -0.0024
wandb:                  PPO_1259/train/std 0.48895
wandb:           PPO_1259/train/value_loss 439.05566
wandb:                PPO_1270/global_step 212992
wandb:        PPO_1270/rollout/ep_len_mean 200.0
wandb:        PPO_1270/rollout/ep_rew_mean -539.10602
wandb:                   PPO_1270/time/fps 1140.0
wandb:            PPO_1270/train/approx_kl 0.01587
wandb:        PPO_1270/train/clip_fraction 0.19372
wandb:           PPO_1270/train/clip_range 0.2
wandb:         PPO_1270/train/entropy_loss -4.69978
wandb:   PPO_1270/train/explained_variance 0.98389
wandb:        PPO_1270/train/learning_rate 0.0003
wandb:                 PPO_1270/train/loss 68.00609
wandb: PPO_1270/train/policy_gradient_loss -0.00239
wandb:                  PPO_1270/train/std 0.47436
wandb:           PPO_1270/train/value_loss 434.90451
wandb:                PPO_1280/global_step 212992
wandb:        PPO_1280/rollout/ep_len_mean 200.0
wandb:        PPO_1280/rollout/ep_rew_mean -560.3999
wandb:                   PPO_1280/time/fps 1137.0
wandb:            PPO_1280/train/approx_kl 0.01374
wandb:        PPO_1280/train/clip_fraction 0.17939
wandb:           PPO_1280/train/clip_range 0.2
wandb:         PPO_1280/train/entropy_loss -4.47682
wandb:   PPO_1280/train/explained_variance 0.98327
wandb:        PPO_1280/train/learning_rate 0.0003
wandb:                 PPO_1280/train/loss 345.98773
wandb: PPO_1280/train/policy_gradient_loss -2e-05
wandb:                  PPO_1280/train/std 0.45847
wandb:           PPO_1280/train/value_loss 510.14438
wandb:                PPO_1290/global_step 212992
wandb:        PPO_1290/rollout/ep_len_mean 200.0
wandb:        PPO_1290/rollout/ep_rew_mean -531.86493
wandb:                   PPO_1290/time/fps 1136.0
wandb:            PPO_1290/train/approx_kl 0.01485
wandb:        PPO_1290/train/clip_fraction 0.2043
wandb:           PPO_1290/train/clip_range 0.2
wandb:         PPO_1290/train/entropy_loss -4.06698
wandb:   PPO_1290/train/explained_variance 0.98787
wandb:        PPO_1290/train/learning_rate 0.0003
wandb:                 PPO_1290/train/loss 218.7187
wandb: PPO_1290/train/policy_gradient_loss 0.00245
wandb:                  PPO_1290/train/std 0.43406
wandb:           PPO_1290/train/value_loss 413.67593
wandb:                    global_mean_eval -446.32667
wandb:                         global_step 212992
wandb:                       mean_reward_0 -518.94126
wandb:                       mean_reward_1 -302.19102
wandb:                      mean_reward_10 -492.35106
wandb:                      mean_reward_11 -515.90527
wandb:                      mean_reward_12 -509.76128
wandb:                      mean_reward_13 -302.17901
wandb:                      mean_reward_14 -396.06879
wandb:                      mean_reward_15 -454.73637
wandb:                      mean_reward_16 -495.7986
wandb:                      mean_reward_17 -516.03493
wandb:                      mean_reward_18 -509.78522
wandb:                      mean_reward_19 -303.62511
wandb:                       mean_reward_2 -396.7451
wandb:                      mean_reward_20 -396.76834
wandb:                      mean_reward_21 -454.5542
wandb:                      mean_reward_22 -492.457
wandb:                      mean_reward_23 -515.45706
wandb:                      mean_reward_24 -522.19984
wandb:                      mean_reward_25 -301.53438
wandb:                      mean_reward_26 -396.64993
wandb:                      mean_reward_27 -458.23435
wandb:                      mean_reward_28 -492.50375
wandb:                      mean_reward_29 -515.34321
wandb:                       mean_reward_3 -454.91491
wandb:                      mean_reward_30 -512.1561
wandb:                      mean_reward_31 -302.8448
wandb:                      mean_reward_32 -396.66378
wandb:                      mean_reward_33 -454.41592
wandb:                      mean_reward_34 -492.39617
wandb:                      mean_reward_35 -515.57934
wandb:                       mean_reward_4 -492.52596
wandb:                       mean_reward_5 -515.79525
wandb:                       mean_reward_6 -516.92858
wandb:                       mean_reward_7 -301.92787
wandb:                       mean_reward_8 -397.05764
wandb:                       mean_reward_9 -454.72885
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 46.61633
wandb:                        std_reward_1 8.85006
wandb:                       std_reward_10 1.15959
wandb:                       std_reward_11 2.03091
wandb:                       std_reward_12 46.14315
wandb:                       std_reward_13 8.63319
wandb:                       std_reward_14 4.30129
wandb:                       std_reward_15 1.94465
wandb:                       std_reward_16 32.5212
wandb:                       std_reward_17 2.554
wandb:                       std_reward_18 46.7723
wandb:                       std_reward_19 8.69108
wandb:                        std_reward_2 4.16572
wandb:                       std_reward_20 4.25072
wandb:                       std_reward_21 1.77389
wandb:                       std_reward_22 1.27333
wandb:                       std_reward_23 2.68374
wandb:                       std_reward_24 46.00697
wandb:                       std_reward_25 8.32086
wandb:                       std_reward_26 4.45913
wandb:                       std_reward_27 36.32484
wandb:                       std_reward_28 1.33386
wandb:                       std_reward_29 3.10278
wandb:                        std_reward_3 2.16091
wandb:                       std_reward_30 45.41987
wandb:                       std_reward_31 9.39927
wandb:                       std_reward_32 4.50236
wandb:                       std_reward_33 1.92786
wandb:                       std_reward_34 1.29477
wandb:                       std_reward_35 2.57301
wandb:                        std_reward_4 1.30989
wandb:                        std_reward_5 2.61089
wandb:                        std_reward_6 47.08549
wandb:                        std_reward_7 8.42247
wandb:                        std_reward_8 4.10876
wandb:                        std_reward_9 1.78956
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced pious-star-36: https://wandb.ai/tidiane/meta_rl_context/runs/3d0g5b5s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-3d0g5b5s/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1210/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1210/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1210/rollout/ep_rew_mean â–â–â–â–„â–„â–„â–…â–…â–†â–†â–ˆâ–ˆ
wandb:                   PPO_1210/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1210/train/approx_kl â–…â–â–‚â–‚â–†â–„â–‡â–‡â–…â–ˆâ–†
wandb:        PPO_1210/train/clip_fraction â–…â–â–„â–â–†â–„â–†â–‡â–…â–ˆâ–‡
wandb:           PPO_1210/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1210/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1210/train/explained_variance â–‡â–ˆâ–ˆâ–‡â–‡â–â–â–‚â–‚â–„â–ƒ
wandb:        PPO_1210/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1210/train/loss â–ˆâ–‚â–â–â–ƒâ–ˆâ–‡â–ƒâ–…â–„â–…
wandb: PPO_1210/train/policy_gradient_loss â–â–ˆâ–„â–†â–ƒâ–‡â–…â–ƒâ–…â–„â–‡
wandb:                  PPO_1210/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1210/train/value_loss â–â–‚â–ƒâ–…â–„â–‡â–ˆâ–‡â–‡â–†â–ˆ
wandb:                PPO_1220/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1220/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1220/rollout/ep_rew_mean â–‚â–â–ƒâ–…â–…â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:                   PPO_1220/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1220/train/approx_kl â–â–ƒâ–‚â–‡â–†â–†â–…â–„â–…â–ˆâ–„
wandb:        PPO_1220/train/clip_fraction â–â–ƒâ–„â–‡â–‡â–†â–…â–…â–†â–ˆâ–‡
wandb:           PPO_1220/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1220/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1220/train/explained_variance â–ƒâ–â–ƒâ–„â–„â–…â–‡â–…â–†â–„â–ˆ
wandb:        PPO_1220/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1220/train/loss â–‡â–…â–ˆâ–„â–„â–‚â–‚â–ƒâ–â–‚â–‡
wandb: PPO_1220/train/policy_gradient_loss â–„â–â–ƒâ–„â–ƒâ–„â–…â–‡â–†â–†â–ˆ
wandb:                  PPO_1220/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1220/train/value_loss â–†â–ˆâ–‡â–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–
wandb:                PPO_1231/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1231/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1231/rollout/ep_rew_mean â–‚â–‚â–â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–ˆ
wandb:                   PPO_1231/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1231/train/approx_kl â–ƒâ–â–‚â–…â–„â–ˆâ–‚â–†â–†â–†â–‡
wandb:        PPO_1231/train/clip_fraction â–„â–ƒâ–â–…â–„â–‡â–„â–†â–ˆâ–†â–†
wandb:           PPO_1231/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1231/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1231/train/explained_variance â–…â–ˆâ–‡â–…â–â–ƒâ–‡â–„â–‚â–„â–‡
wandb:        PPO_1231/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1231/train/loss â–ƒâ–„â–ƒâ–â–ˆâ–†â–‚â–ƒâ–„â–‚â–ƒ
wandb: PPO_1231/train/policy_gradient_loss â–„â–…â–†â–„â–ƒâ–‚â–ˆâ–â–…â–ƒâ–ˆ
wandb:                  PPO_1231/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1231/train/value_loss â–ƒâ–â–…â–â–ˆâ–„â–…â–†â–…â–ˆâ–†
wandb:                PPO_1241/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1241/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1241/rollout/ep_rew_mean â–ƒâ–„â–†â–…â–„â–…â–…â–‚â–â–‡â–‡â–ˆ
wandb:                   PPO_1241/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1241/train/approx_kl â–„â–†â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–ˆ
wandb:        PPO_1241/train/clip_fraction â–…â–…â–„â–â–„â–†â–ƒâ–ƒâ–…â–ˆâ–‡
wandb:           PPO_1241/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1241/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1241/train/explained_variance â–‡â–ˆâ–‡â–‡â–…â–‡â–„â–†â–†â–â–ƒ
wandb:        PPO_1241/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1241/train/loss â–ƒâ–‚â–‚â–„â–‚â–‚â–„â–ˆâ–ƒâ–‚â–
wandb: PPO_1241/train/policy_gradient_loss â–â–‡â–„â–†â–„â–ˆâ–…â–…â–ƒâ–„â–‡
wandb:                  PPO_1241/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1241/train/value_loss â–ƒâ–â–‚â–ƒâ–„â–„â–†â–ˆâ–…â–ƒâ–‚
wandb:                PPO_1251/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1251/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1251/rollout/ep_rew_mean â–â–â–†â–…â–†â–„â–„â–„â–…â–‡â–ˆâ–‡
wandb:                   PPO_1251/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1251/train/approx_kl â–ƒâ–ˆâ–ˆâ–„â–ˆâ–â–„â–ƒâ–„â–†â–„
wandb:        PPO_1251/train/clip_fraction â–ƒâ–†â–ˆâ–ƒâ–„â–â–ƒâ–â–‚â–‡â–ƒ
wandb:           PPO_1251/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1251/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1251/train/explained_variance â–†â–†â–â–„â–…â–…â–…â–†â–ˆâ–ˆâ–†
wandb:        PPO_1251/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1251/train/loss â–†â–…â–‡â–â–â–‡â–â–ˆâ–‚â–ƒâ–ƒ
wandb: PPO_1251/train/policy_gradient_loss â–â–â–„â–‚â–‚â–‡â–„â–…â–„â–„â–ˆ
wandb:                  PPO_1251/train/std â–ˆâ–‡â–†â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1251/train/value_loss â–†â–ˆâ–â–„â–„â–…â–†â–†â–‡â–‚â–ƒ
wandb:                PPO_1261/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1261/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1261/rollout/ep_rew_mean â–…â–…â–†â–‚â–…â–„â–â–…â–â–„â–„â–ˆ
wandb:                   PPO_1261/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1261/train/approx_kl â–„â–‚â–„â–â–ƒâ–ƒâ–ƒâ–ˆâ–…â–„â–…
wandb:        PPO_1261/train/clip_fraction â–‡â–‡â–…â–â–ƒâ–‚â–„â–ˆâ–…â–â–ˆ
wandb:           PPO_1261/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1261/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1261/train/explained_variance â–â–…â–ƒâ–â–‡â–…â–†â–…â–ˆâ–â–†
wandb:        PPO_1261/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1261/train/loss â–â–ˆâ–ƒâ–ƒâ–â–â–ˆâ–‚â–„â–ƒâ–…
wandb: PPO_1261/train/policy_gradient_loss â–„â–„â–†â–ˆâ–â–â–â–„â–…â–„â–…
wandb:                  PPO_1261/train/std â–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1261/train/value_loss â–‚â–â–‚â–ƒâ–ƒâ–…â–‡â–†â–…â–ˆâ–†
wandb:                PPO_1271/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1271/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1271/rollout/ep_rew_mean â–â–„â–…â–…â–…â–‡â–†â–‡â–ˆâ–†â–†â–
wandb:                   PPO_1271/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1271/train/approx_kl â–‚â–ƒâ–â–ˆâ–†â–‡â–†â–ƒâ–‡â–ƒâ–„
wandb:        PPO_1271/train/clip_fraction â–‚â–†â–â–ˆâ–ˆâ–ˆâ–„â–†â–†â–ƒâ–ƒ
wandb:           PPO_1271/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1271/train/entropy_loss â–â–‚â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1271/train/explained_variance â–â–ƒâ–‚â–†â–‚â–‡â–‡â–ˆâ–†â–‡â–ƒ
wandb:        PPO_1271/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1271/train/loss â–†â–ƒâ–†â–†â–ˆâ–â–ƒâ–ƒâ–ƒâ–„â–ˆ
wandb: PPO_1271/train/policy_gradient_loss â–‚â–ƒâ–‚â–‚â–ˆâ–ˆâ–…â–„â–„â–†â–
wandb:                  PPO_1271/train/std â–ˆâ–‡â–†â–‡â–†â–…â–„â–ƒâ–„â–ƒâ–
wandb:           PPO_1271/train/value_loss â–‡â–„â–ˆâ–ƒâ–„â–‚â–ƒâ–â–â–„â–‡
wandb:                PPO_1281/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1281/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1281/rollout/ep_rew_mean â–„â–„â–‚â–‚â–‡â–â–„â–ƒâ–â–ˆâ–†â–„
wandb:                   PPO_1281/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1281/train/approx_kl â–†â–â–„â–…â–†â–ƒâ–ˆâ–…â–…â–ˆâ–†
wandb:        PPO_1281/train/clip_fraction â–†â–â–…â–†â–ˆâ–„â–†â–„â–ƒâ–‡â–ƒ
wandb:           PPO_1281/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1281/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1281/train/explained_variance â–„â–ƒâ–â–„â–…â–„â–…â–ˆâ–‡â–ƒâ–…
wandb:        PPO_1281/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1281/train/loss â–â–„â–ƒâ–…â–‚â–â–‚â–ƒâ–ˆâ–â–…
wandb: PPO_1281/train/policy_gradient_loss â–†â–„â–…â–…â–†â–â–…â–†â–‡â–ˆâ–…
wandb:                  PPO_1281/train/std â–ˆâ–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1281/train/value_loss â–ƒâ–ˆâ–‡â–†â–‚â–‚â–ƒâ–ƒâ–‡â–â–†
wandb:                PPO_1291/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1291/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1291/rollout/ep_rew_mean â–â–‡â–…â–†â–…â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–‡
wandb:                   PPO_1291/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1291/train/approx_kl â–â–ƒâ–„â–‡â–„â–ƒâ–…â–†â–…â–ˆâ–…
wandb:        PPO_1291/train/clip_fraction â–â–„â–…â–ƒâ–†â–„â–†â–ˆâ–‚â–†â–†
wandb:           PPO_1291/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1291/train/entropy_loss â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1291/train/explained_variance â–„â–…â–…â–…â–â–â–‚â–ˆâ–…â–‚â–†
wandb:        PPO_1291/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1291/train/loss â–‡â–â–ˆâ–†â–ˆâ–‚â–…â–â–ƒâ–â–
wandb: PPO_1291/train/policy_gradient_loss â–…â–…â–ƒâ–â–†â–„â–ˆâ–‡â–ƒâ–†â–ˆ
wandb:                  PPO_1291/train/std â–ˆâ–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1291/train/value_loss â–ˆâ–ƒâ–ƒâ–†â–ƒâ–„â–‡â–â–ˆâ–†â–‡
wandb:                    global_mean_eval â–â–„â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                       mean_reward_1 â–â–ƒâ–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_10 â–â–…â–„â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                      mean_reward_13 â–â–‚â–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_14 â–â–„â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–…â–„â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–ƒâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                      mean_reward_19 â–â–ƒâ–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                       mean_reward_2 â–â–„â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–…â–ƒâ–…â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–„â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                      mean_reward_25 â–â–‚â–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_26 â–â–…â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–ƒâ–…â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–„â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–…â–ƒâ–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                      mean_reward_31 â–â–‚â–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_32 â–â–„â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–ƒâ–…â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–„â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–…â–„â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–…â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–ƒâ–â–‚â–„â–†â–ˆâ–‡â–‡â–†â–†
wandb:                       mean_reward_7 â–â–ƒâ–‚â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–ˆ
wandb:                       mean_reward_8 â–â–…â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–„â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–‚â–„â–‚â–â–â–â–â–‚â–‚
wandb:                        std_reward_1 â–ˆâ–â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_10 â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–â–â–
wandb:                       std_reward_11 â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_12 â–ˆâ–‚â–„â–‚â–â–â–â–â–‚â–‚
wandb:                       std_reward_13 â–ˆâ–â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_14 â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–â–â–
wandb:                       std_reward_15 â–ˆâ–â–‚â–‚â–â–â–‚â–‚â–â–
wandb:                       std_reward_16 â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–â–â–
wandb:                       std_reward_17 â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_18 â–ˆâ–‚â–„â–‚â–â–â–â–â–‚â–‚
wandb:                       std_reward_19 â–ˆâ–â–â–‚â–â–â–â–â–â–
wandb:                        std_reward_2 â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–â–â–
wandb:                       std_reward_20 â–ˆâ–â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_21 â–ˆâ–â–‚â–‚â–â–â–‚â–‚â–â–‚
wandb:                       std_reward_22 â–ˆâ–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_23 â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_24 â–ˆâ–ƒâ–„â–‚â–â–â–â–â–‚â–‚
wandb:                       std_reward_25 â–ˆâ–â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_26 â–ˆâ–â–â–â–‚â–‚â–â–â–â–
wandb:                       std_reward_27 â–ˆâ–â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:                       std_reward_28 â–ˆâ–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:                       std_reward_29 â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–
wandb:                        std_reward_3 â–ˆâ–â–ƒâ–‚â–â–â–‚â–‚â–â–
wandb:                       std_reward_30 â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–‚â–‚
wandb:                       std_reward_31 â–ˆâ–â–â–‚â–â–â–â–â–â–
wandb:                       std_reward_32 â–ˆâ–â–‚â–â–‚â–‚â–â–â–â–
wandb:                       std_reward_33 â–ˆâ–â–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb:                       std_reward_34 â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–â–â–
wandb:                       std_reward_35 â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                        std_reward_4 â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–â–â–
wandb:                        std_reward_5 â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–
wandb:                        std_reward_6 â–ˆâ–‚â–„â–‚â–â–â–â–â–‚â–‚
wandb:                        std_reward_7 â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                        std_reward_8 â–ˆâ–â–‚â–â–‚â–‚â–â–â–â–
wandb:                        std_reward_9 â–ˆâ–â–‚â–â–â–â–‚â–‚â–â–
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1210/global_step 212992
wandb:        PPO_1210/rollout/ep_len_mean 200.0
wandb:        PPO_1210/rollout/ep_rew_mean -788.40765
wandb:                   PPO_1210/time/fps 1191.0
wandb:            PPO_1210/train/approx_kl 0.01135
wandb:        PPO_1210/train/clip_fraction 0.14095
wandb:           PPO_1210/train/clip_range 0.2
wandb:         PPO_1210/train/entropy_loss -7.80498
wandb:   PPO_1210/train/explained_variance 0.96208
wandb:        PPO_1210/train/learning_rate 0.0003
wandb:                 PPO_1210/train/loss 57.57802
wandb: PPO_1210/train/policy_gradient_loss -0.00691
wandb:                  PPO_1210/train/std 0.73685
wandb:           PPO_1210/train/value_loss 160.16556
wandb:                PPO_1220/global_step 212992
wandb:        PPO_1220/rollout/ep_len_mean 200.0
wandb:        PPO_1220/rollout/ep_rew_mean -651.41107
wandb:                   PPO_1220/time/fps 1182.0
wandb:            PPO_1220/train/approx_kl 0.01272
wandb:        PPO_1220/train/clip_fraction 0.18301
wandb:           PPO_1220/train/clip_range 0.2
wandb:         PPO_1220/train/entropy_loss -6.96896
wandb:   PPO_1220/train/explained_variance 0.97788
wandb:        PPO_1220/train/learning_rate 0.0003
wandb:                 PPO_1220/train/loss 74.41776
wandb: PPO_1220/train/policy_gradient_loss -0.00414
wandb:                  PPO_1220/train/std 0.65368
wandb:           PPO_1220/train/value_loss 49.99812
wandb:                PPO_1231/global_step 212992
wandb:        PPO_1231/rollout/ep_len_mean 200.0
wandb:        PPO_1231/rollout/ep_rew_mean -585.10406
wandb:                   PPO_1231/time/fps 1180.0
wandb:            PPO_1231/train/approx_kl 0.01641
wandb:        PPO_1231/train/clip_fraction 0.20732
wandb:           PPO_1231/train/clip_range 0.2
wandb:         PPO_1231/train/entropy_loss -6.1254
wandb:   PPO_1231/train/explained_variance 0.97751
wandb:        PPO_1231/train/learning_rate 0.0003
wandb:                 PPO_1231/train/loss 26.17278
wandb: PPO_1231/train/policy_gradient_loss -0.00252
wandb:                  PPO_1231/train/std 0.57978
wandb:           PPO_1231/train/value_loss 56.15229
wandb:                PPO_1241/global_step 212992
wandb:        PPO_1241/rollout/ep_len_mean 200.0
wandb:        PPO_1241/rollout/ep_rew_mean -580.87579
wandb:                   PPO_1241/time/fps 1186.0
wandb:            PPO_1241/train/approx_kl 0.01955
wandb:        PPO_1241/train/clip_fraction 0.23644
wandb:           PPO_1241/train/clip_range 0.2
wandb:         PPO_1241/train/entropy_loss -5.3988
wandb:   PPO_1241/train/explained_variance 0.96249
wandb:        PPO_1241/train/learning_rate 0.0003
wandb:                 PPO_1241/train/loss 7.68504
wandb: PPO_1241/train/policy_gradient_loss -0.00277
wandb:                  PPO_1241/train/std 0.52311
wandb:           PPO_1241/train/value_loss 36.56745
wandb:                PPO_1251/global_step 212992
wandb:        PPO_1251/rollout/ep_len_mean 200.0
wandb:        PPO_1251/rollout/ep_rew_mean -535.39185
wandb:                   PPO_1251/time/fps 1182.0
wandb:            PPO_1251/train/approx_kl 0.01691
wandb:        PPO_1251/train/clip_fraction 0.22239
wandb:           PPO_1251/train/clip_range 0.2
wandb:         PPO_1251/train/entropy_loss -4.77797
wandb:   PPO_1251/train/explained_variance 0.96929
wandb:        PPO_1251/train/learning_rate 0.0003
wandb:                 PPO_1251/train/loss 18.00958
wandb: PPO_1251/train/policy_gradient_loss 0.00022
wandb:                  PPO_1251/train/std 0.4787
wandb:           PPO_1251/train/value_loss 39.68171
wandb:                PPO_1261/global_step 212992
wandb:        PPO_1261/rollout/ep_len_mean 200.0
wandb:        PPO_1261/rollout/ep_rew_mean -512.62616
wandb:                   PPO_1261/time/fps 1184.0
wandb:            PPO_1261/train/approx_kl 0.01773
wandb:        PPO_1261/train/clip_fraction 0.23289
wandb:           PPO_1261/train/clip_range 0.2
wandb:         PPO_1261/train/entropy_loss -4.34815
wandb:   PPO_1261/train/explained_variance 0.98169
wandb:        PPO_1261/train/learning_rate 0.0003
wandb:                 PPO_1261/train/loss 37.42626
wandb: PPO_1261/train/policy_gradient_loss -0.0006
wandb:                  PPO_1261/train/std 0.45022
wandb:           PPO_1261/train/value_loss 90.8445
wandb:                PPO_1271/global_step 212992
wandb:        PPO_1271/rollout/ep_len_mean 200.0
wandb:        PPO_1271/rollout/ep_rew_mean -588.474
wandb:                   PPO_1271/time/fps 1182.0
wandb:            PPO_1271/train/approx_kl 0.01752
wandb:        PPO_1271/train/clip_fraction 0.20226
wandb:           PPO_1271/train/clip_range 0.2
wandb:         PPO_1271/train/entropy_loss -3.95459
wandb:   PPO_1271/train/explained_variance 0.98182
wandb:        PPO_1271/train/learning_rate 0.0003
wandb:                 PPO_1271/train/loss 76.62786
wandb: PPO_1271/train/policy_gradient_loss -0.00256
wandb:                  PPO_1271/train/std 0.42604
wandb:           PPO_1271/train/value_loss 174.8204
wandb:                PPO_1281/global_step 212992
wandb:        PPO_1281/rollout/ep_len_mean 200.0
wandb:        PPO_1281/rollout/ep_rew_mean -536.20502
wandb:                   PPO_1281/time/fps 1181.0
wandb:            PPO_1281/train/approx_kl 0.01875
wandb:        PPO_1281/train/clip_fraction 0.2168
wandb:           PPO_1281/train/clip_range 0.2
wandb:         PPO_1281/train/entropy_loss -3.68467
wandb:   PPO_1281/train/explained_variance 0.98688
wandb:        PPO_1281/train/learning_rate 0.0003
wandb:                 PPO_1281/train/loss 157.26497
wandb: PPO_1281/train/policy_gradient_loss -0.00046
wandb:                  PPO_1281/train/std 0.41022
wandb:           PPO_1281/train/value_loss 180.69862
wandb:                PPO_1291/global_step 212992
wandb:        PPO_1291/rollout/ep_len_mean 200.0
wandb:        PPO_1291/rollout/ep_rew_mean -521.91608
wandb:                   PPO_1291/time/fps 1180.0
wandb:            PPO_1291/train/approx_kl 0.02073
wandb:        PPO_1291/train/clip_fraction 0.26346
wandb:           PPO_1291/train/clip_range 0.2
wandb:         PPO_1291/train/entropy_loss -3.1808
wandb:   PPO_1291/train/explained_variance 0.98795
wandb:        PPO_1291/train/learning_rate 0.0003
wandb:                 PPO_1291/train/loss 45.61468
wandb: PPO_1291/train/policy_gradient_loss 0.00173
wandb:                  PPO_1291/train/std 0.38121
wandb:           PPO_1291/train/value_loss 204.13251
wandb:                    global_mean_eval -438.69847
wandb:                         global_step 212992
wandb:                       mean_reward_0 -408.86521
wandb:                       mean_reward_1 -347.15632
wandb:                      mean_reward_10 -470.13663
wandb:                      mean_reward_11 -480.80342
wandb:                      mean_reward_12 -409.12977
wandb:                      mean_reward_13 -346.20766
wandb:                      mean_reward_14 -450.36335
wandb:                      mean_reward_15 -475.85361
wandb:                      mean_reward_16 -469.8084
wandb:                      mean_reward_17 -480.70023
wandb:                      mean_reward_18 -411.72089
wandb:                      mean_reward_19 -346.92016
wandb:                       mean_reward_2 -450.75739
wandb:                      mean_reward_20 -450.87169
wandb:                      mean_reward_21 -475.79486
wandb:                      mean_reward_22 -470.01318
wandb:                      mean_reward_23 -480.9897
wandb:                      mean_reward_24 -409.33447
wandb:                      mean_reward_25 -347.33164
wandb:                      mean_reward_26 -450.74775
wandb:                      mean_reward_27 -474.99392
wandb:                      mean_reward_28 -469.8041
wandb:                      mean_reward_29 -480.85007
wandb:                       mean_reward_3 -474.06227
wandb:                      mean_reward_30 -410.97995
wandb:                      mean_reward_31 -346.59149
wandb:                      mean_reward_32 -449.96002
wandb:                      mean_reward_33 -474.79858
wandb:                      mean_reward_34 -469.60242
wandb:                      mean_reward_35 -481.23596
wandb:                       mean_reward_4 -469.87121
wandb:                       mean_reward_5 -480.91332
wandb:                       mean_reward_6 -403.96404
wandb:                       mean_reward_7 -347.01794
wandb:                       mean_reward_8 -450.09075
wandb:                       mean_reward_9 -474.90244
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 20.86713
wandb:                        std_reward_1 4.7896
wandb:                       std_reward_10 2.3074
wandb:                       std_reward_11 3.39347
wandb:                       std_reward_12 22.56524
wandb:                       std_reward_13 5.61155
wandb:                       std_reward_14 4.59227
wandb:                       std_reward_15 6.82469
wandb:                       std_reward_16 2.36107
wandb:                       std_reward_17 3.55325
wandb:                       std_reward_18 21.55566
wandb:                       std_reward_19 5.04644
wandb:                        std_reward_2 4.65654
wandb:                       std_reward_20 4.01631
wandb:                       std_reward_21 8.01014
wandb:                       std_reward_22 3.07561
wandb:                       std_reward_23 3.12424
wandb:                       std_reward_24 22.3956
wandb:                       std_reward_25 5.39846
wandb:                       std_reward_26 4.21486
wandb:                       std_reward_27 7.87624
wandb:                       std_reward_28 2.72356
wandb:                       std_reward_29 3.58779
wandb:                        std_reward_3 7.10566
wandb:                       std_reward_30 20.74194
wandb:                       std_reward_31 5.36139
wandb:                       std_reward_32 4.61993
wandb:                       std_reward_33 8.11146
wandb:                       std_reward_34 1.72246
wandb:                       std_reward_35 3.75006
wandb:                        std_reward_4 2.61517
wandb:                        std_reward_5 3.27491
wandb:                        std_reward_6 23.05076
wandb:                        std_reward_7 5.32022
wandb:                        std_reward_8 3.92851
wandb:                        std_reward_9 7.91886
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced curious-universe-39: https://wandb.ai/tidiane/meta_rl_context/runs/2znu6ayn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-2znu6ayn/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1212/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1212/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1212/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–ƒâ–„â–…â–„â–…â–†â–‡â–ˆ
wandb:                   PPO_1212/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1212/train/approx_kl â–„â–‚â–â–„â–ƒâ–„â–ˆâ–„â–ƒâ–„â–…
wandb:        PPO_1212/train/clip_fraction â–ƒâ–‚â–â–ƒâ–„â–ƒâ–ˆâ–†â–ƒâ–…â–…
wandb:           PPO_1212/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1212/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1212/train/explained_variance â–ˆâ–„â–†â–…â–„â–…â–‚â–‡â–â–…â–ƒ
wandb:        PPO_1212/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1212/train/loss â–â–â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–„â–„
wandb: PPO_1212/train/policy_gradient_loss â–…â–†â–ˆâ–†â–†â–ˆâ–â–ƒâ–…â–ˆâ–‡
wandb:                  PPO_1212/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1212/train/value_loss â–â–‚â–„â–„â–„â–†â–†â–†â–ˆâ–†â–†
wandb:                PPO_1222/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1222/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1222/rollout/ep_rew_mean â–â–â–‚â–ƒâ–„â–„â–†â–†â–†â–†â–‡â–ˆ
wandb:                   PPO_1222/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1222/train/approx_kl â–â–‚â–ƒâ–ƒâ–â–†â–ˆâ–„â–„â–â–†
wandb:        PPO_1222/train/clip_fraction â–â–ƒâ–…â–„â–„â–…â–ˆâ–†â–„â–…â–†
wandb:           PPO_1222/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1222/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1222/train/explained_variance â–†â–‚â–„â–ˆâ–‡â–ˆâ–â–‚â–â–†â–ˆ
wandb:        PPO_1222/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1222/train/loss â–„â–ƒâ–ˆâ–…â–â–‚â–„â–ƒâ–ƒâ–‚â–
wandb: PPO_1222/train/policy_gradient_loss â–…â–‚â–‚â–ƒâ–‚â–â–â–‡â–‡â–†â–ˆ
wandb:                  PPO_1222/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1222/train/value_loss â–ˆâ–‡â–…â–…â–…â–„â–…â–ƒâ–‡â–â–
wandb:                PPO_1232/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1232/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1232/rollout/ep_rew_mean â–†â–ˆâ–‚â–…â–…â–‡â–‡â–ƒâ–‚â–ƒâ–â–‡
wandb:                   PPO_1232/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1232/train/approx_kl â–…â–ˆâ–‚â–‡â–…â–…â–â–‚â–ƒâ–…â–‡
wandb:        PPO_1232/train/clip_fraction â–†â–‡â–â–‡â–†â–ˆâ–‚â–ƒâ–„â–„â–„
wandb:           PPO_1232/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1232/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1232/train/explained_variance â–â–…â–â–ˆâ–…â–ˆâ–…â–†â–…â–†â–ˆ
wandb:        PPO_1232/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1232/train/loss â–â–â–„â–ƒâ–†â–†â–‡â–…â–ˆâ–„â–
wandb: PPO_1232/train/policy_gradient_loss â–†â–…â–†â–ƒâ–†â–ˆâ–ˆâ–†â–â–†â–ƒ
wandb:                  PPO_1232/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1232/train/value_loss â–‚â–â–ƒâ–‚â–ƒâ–â–ƒâ–†â–…â–ˆâ–‡
wandb:                PPO_1242/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1242/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1242/rollout/ep_rew_mean â–†â–ˆâ–†â–‡â–ƒâ–„â–…â–„â–‚â–„â–‚â–
wandb:                   PPO_1242/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1242/train/approx_kl â–…â–ˆâ–…â–‡â–…â–â–ˆâ–„â–…â–…â–„
wandb:        PPO_1242/train/clip_fraction â–ƒâ–ˆâ–ƒâ–…â–‚â–â–ˆâ–â–„â–ƒâ–„
wandb:           PPO_1242/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1242/train/entropy_loss â–â–‚â–ƒâ–ƒâ–…â–…â–†â–‡â–†â–‡â–ˆ
wandb:   PPO_1242/train/explained_variance â–‚â–†â–‡â–â–„â–„â–ˆâ–†â–ˆâ–…â–†
wandb:        PPO_1242/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1242/train/loss â–â–‚â–ƒâ–‚â–â–ƒâ–‚â–„â–ˆâ–…â–ƒ
wandb: PPO_1242/train/policy_gradient_loss â–…â–„â–„â–„â–„â–ˆâ–…â–‡â–†â–†â–
wandb:                  PPO_1242/train/std â–ˆâ–†â–†â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–
wandb:           PPO_1242/train/value_loss â–„â–â–ƒâ–…â–†â–‡â–ƒâ–†â–…â–‡â–ˆ
wandb:                PPO_1252/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1252/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1252/rollout/ep_rew_mean â–â–‚â–ƒâ–„â–†â–â–…â–ƒâ–…â–…â–ˆâ–‡
wandb:                   PPO_1252/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1252/train/approx_kl â–â–ˆâ–â–ƒâ–…â–…â–…â–‚â–„â–†â–ƒ
wandb:        PPO_1252/train/clip_fraction â–â–†â–â–‡â–„â–ƒâ–†â–â–ˆâ–†â–ƒ
wandb:           PPO_1252/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1252/train/entropy_loss â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:   PPO_1252/train/explained_variance â–‚â–ƒâ–ƒâ–ˆâ–…â–†â–â–†â–„â–ƒâ–…
wandb:        PPO_1252/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1252/train/loss â–ˆâ–‡â–‚â–ƒâ–‚â–„â–ƒâ–‚â–‡â–‡â–
wandb: PPO_1252/train/policy_gradient_loss â–â–„â–†â–†â–…â–…â–‡â–ƒâ–ˆâ–„â–…
wandb:                  PPO_1252/train/std â–ˆâ–ˆâ–†â–†â–†â–†â–…â–„â–„â–ƒâ–
wandb:           PPO_1252/train/value_loss â–ˆâ–‡â–‡â–â–†â–ˆâ–…â–„â–„â–…â–…
wandb:                PPO_1262/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1262/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1262/rollout/ep_rew_mean â–‚â–â–ƒâ–ƒâ–„â–‚â–†â–ˆâ–„â–„â–â–ƒ
wandb:                   PPO_1262/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1262/train/approx_kl â–†â–ƒâ–â–ˆâ–„â–ƒâ–‡â–‚â–„â–â–…
wandb:        PPO_1262/train/clip_fraction â–ƒâ–‚â–ƒâ–‡â–„â–‚â–ˆâ–â–â–â–†
wandb:           PPO_1262/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1262/train/entropy_loss â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1262/train/explained_variance â–â–†â–‚â–ˆâ–ƒâ–„â–…â–†â–„â–…â–ˆ
wandb:        PPO_1262/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1262/train/loss â–â–‚â–â–‡â–ˆâ–‡â–â–â–ƒâ–ƒâ–
wandb: PPO_1262/train/policy_gradient_loss â–‡â–ƒâ–‚â–‡â–…â–ƒâ–‡â–‚â–â–„â–ˆ
wandb:                  PPO_1262/train/std â–ˆâ–‡â–†â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1262/train/value_loss â–†â–„â–‡â–„â–„â–‡â–ƒâ–„â–‡â–ˆâ–
wandb:                PPO_1272/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1272/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1272/rollout/ep_rew_mean â–ƒâ–â–…â–…â–ƒâ–ƒâ–†â–ˆâ–‡â–‡â–ˆâ–†
wandb:                   PPO_1272/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1272/train/approx_kl â–‚â–â–†â–…â–†â–†â–ˆâ–ˆâ–…â–…â–ƒ
wandb:        PPO_1272/train/clip_fraction â–ƒâ–â–†â–†â–†â–†â–ˆâ–†â–ƒâ–„â–‚
wandb:           PPO_1272/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1272/train/entropy_loss â–â–‚â–â–‚â–‚â–‚â–ƒâ–…â–†â–‡â–ˆ
wandb:   PPO_1272/train/explained_variance â–ˆâ–…â–‡â–‡â–…â–ƒâ–â–‡â–ˆâ–ˆâ–
wandb:        PPO_1272/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1272/train/loss â–…â–…â–ƒâ–‚â–ˆâ–â–â–â–‚â–â–
wandb: PPO_1272/train/policy_gradient_loss â–â–…â–„â–‡â–‡â–„â–‡â–ˆâ–‡â–ˆâ–ƒ
wandb:                  PPO_1272/train/std â–ˆâ–‡â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–‚â–
wandb:           PPO_1272/train/value_loss â–‡â–ˆâ–…â–‚â–…â–„â–â–ƒâ–‚â–ƒâ–…
wandb:                PPO_1282/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1282/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1282/rollout/ep_rew_mean â–ˆâ–‚â–â–ƒâ–†â–†â–ƒâ–‚â–‚â–…â–â–ƒ
wandb:                   PPO_1282/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1282/train/approx_kl â–…â–‚â–â–‡â–„â–ˆâ–„â–‡â–â–†â–‡
wandb:        PPO_1282/train/clip_fraction â–„â–‚â–‚â–†â–‡â–ˆâ–„â–…â–â–‡â–ˆ
wandb:           PPO_1282/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1282/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1282/train/explained_variance â–…â–ˆâ–‡â–‡â–„â–ˆâ–†â–ˆâ–…â–â–ˆ
wandb:        PPO_1282/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1282/train/loss â–ƒâ–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–
wandb: PPO_1282/train/policy_gradient_loss â–…â–ƒâ–ƒâ–†â–‚â–ƒâ–â–„â–ƒâ–ˆâ–†
wandb:                  PPO_1282/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–â–
wandb:           PPO_1282/train/value_loss â–‚â–†â–†â–ƒâ–ƒâ–â–…â–„â–ˆâ–„â–ƒ
wandb:                PPO_1292/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1292/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1292/rollout/ep_rew_mean â–…â–â–†â–…â–ˆâ–‡â–ƒâ–„â–ƒâ–ƒâ–ˆâ–ƒ
wandb:                   PPO_1292/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1292/train/approx_kl â–…â–ƒâ–…â–‚â–â–ƒâ–ƒâ–„â–‡â–â–ˆ
wandb:        PPO_1292/train/clip_fraction â–„â–ƒâ–‡â–‚â–â–‡â–ƒâ–…â–…â–‚â–ˆ
wandb:           PPO_1292/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1292/train/entropy_loss â–â–‚â–ƒâ–„â–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1292/train/explained_variance â–ƒâ–â–ˆâ–‡â–â–‚â–†â–ˆâ–ˆâ–…â–…
wandb:        PPO_1292/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1292/train/loss â–‚â–â–…â–‚â–‚â–ˆâ–‚â–ƒâ–â–„â–‚
wandb: PPO_1292/train/policy_gradient_loss â–„â–â–â–â–‚â–†â–ƒâ–ƒâ–†â–â–ˆ
wandb:                  PPO_1292/train/std â–ˆâ–‡â–†â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1292/train/value_loss â–â–‡â–ƒâ–…â–‡â–‚â–ˆâ–†â–†â–‡â–ƒ
wandb:                    global_mean_eval â–â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–‡
wandb:                       mean_reward_1 â–â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_10 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_11 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_12 â–‚â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–‡
wandb:                      mean_reward_13 â–â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_14 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡
wandb:                      mean_reward_15 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_16 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_17 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–‡
wandb:                      mean_reward_19 â–â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                       mean_reward_2 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡
wandb:                      mean_reward_20 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡
wandb:                      mean_reward_21 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_22 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_23 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_24 â–â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–‡
wandb:                      mean_reward_25 â–â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_26 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_27 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_28 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_29 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_30 â–â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–‡
wandb:                      mean_reward_31 â–â–…â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_32 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_33 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                      mean_reward_34 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_35 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                       mean_reward_5 â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–ƒâ–‡â–â–â–„â–…â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                       mean_reward_8 â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡
wandb:                       mean_reward_9 â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–ƒâ–„â–‚â–â–‚â–„â–â–…â–„
wandb:                        std_reward_1 â–ˆâ–†â–â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–„
wandb:                       std_reward_10 â–„â–ˆâ–‚â–‚â–‚â–†â–â–â–â–‚
wandb:                       std_reward_11 â–„â–‡â–‚â–‚â–‚â–ˆâ–â–â–â–
wandb:                       std_reward_12 â–ˆâ–ƒâ–„â–‚â–â–‚â–„â–‚â–„â–„
wandb:                       std_reward_13 â–ˆâ–…â–â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–„
wandb:                       std_reward_14 â–ƒâ–ˆâ–â–â–â–‚â–‚â–â–â–
wandb:                       std_reward_15 â–‚â–ˆâ–â–â–â–‚â–â–â–â–
wandb:                       std_reward_16 â–„â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚
wandb:                       std_reward_17 â–„â–†â–‚â–‚â–‚â–ˆâ–ˆâ–â–â–
wandb:                       std_reward_18 â–ˆâ–‚â–„â–„â–â–â–„â–‚â–†â–†
wandb:                       std_reward_19 â–ˆâ–…â–â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–…
wandb:                        std_reward_2 â–ƒâ–ˆâ–â–â–â–â–â–â–â–‚
wandb:                       std_reward_20 â–ƒâ–ˆâ–â–â–â–‚â–â–â–â–
wandb:                       std_reward_21 â–‚â–ˆâ–â–â–â–‚â–‚â–â–â–
wandb:                       std_reward_22 â–„â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚
wandb:                       std_reward_23 â–…â–ˆâ–‚â–‚â–ƒâ–‚â–ˆâ–â–â–‚
wandb:                       std_reward_24 â–ˆâ–ƒâ–…â–ƒâ–â–ƒâ–„â–‚â–„â–…
wandb:                       std_reward_25 â–ˆâ–†â–â–ƒâ–‡â–„â–‡â–â–‚â–†
wandb:                       std_reward_26 â–ƒâ–ˆâ–â–â–â–‚â–‚â–â–â–‚
wandb:                       std_reward_27 â–ƒâ–ˆâ–â–â–â–‚â–â–â–â–
wandb:                       std_reward_28 â–„â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–‚
wandb:                       std_reward_29 â–„â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–‚
wandb:                        std_reward_3 â–‚â–ˆâ–â–â–â–â–‚â–â–â–
wandb:                       std_reward_30 â–ˆâ–‚â–„â–ƒâ–â–‚â–ƒâ–‚â–„â–„
wandb:                       std_reward_31 â–ˆâ–†â–â–ƒâ–‚â–†â–„â–â–ƒâ–…
wandb:                       std_reward_32 â–ƒâ–ˆâ–â–â–â–‚â–‚â–â–â–
wandb:                       std_reward_33 â–ƒâ–ˆâ–â–â–â–â–â–â–â–‚
wandb:                       std_reward_34 â–„â–ˆâ–‚â–‚â–‚â–†â–â–â–â–‚
wandb:                       std_reward_35 â–…â–ˆâ–‚â–ƒâ–ƒâ–â–ˆâ–â–â–‚
wandb:                        std_reward_4 â–ƒâ–ˆâ–‚â–‚â–‚â–ƒâ–‡â–â–â–‚
wandb:                        std_reward_5 â–…â–ˆâ–‚â–‚â–‚â–ˆâ–ƒâ–â–â–
wandb:                        std_reward_6 â–ˆâ–„â–…â–„â–â–‚â–„â–‚â–…â–„
wandb:                        std_reward_7 â–ˆâ–…â–â–‚â–‚â–ƒâ–„â–â–ƒâ–…
wandb:                        std_reward_8 â–ƒâ–ˆâ–â–â–â–‚â–â–â–â–
wandb:                        std_reward_9 â–‚â–ˆâ–â–â–â–‚â–â–â–â–
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1212/global_step 212992
wandb:        PPO_1212/rollout/ep_len_mean 200.0
wandb:        PPO_1212/rollout/ep_rew_mean -753.11841
wandb:                   PPO_1212/time/fps 1179.0
wandb:            PPO_1212/train/approx_kl 0.0117
wandb:        PPO_1212/train/clip_fraction 0.14111
wandb:           PPO_1212/train/clip_range 0.2
wandb:         PPO_1212/train/entropy_loss -7.89186
wandb:   PPO_1212/train/explained_variance 0.95476
wandb:        PPO_1212/train/learning_rate 0.0003
wandb:                 PPO_1212/train/loss 135.07863
wandb: PPO_1212/train/policy_gradient_loss -0.00751
wandb:                  PPO_1212/train/std 0.74673
wandb:           PPO_1212/train/value_loss 191.58308
wandb:                PPO_1222/global_step 212992
wandb:        PPO_1222/rollout/ep_len_mean 200.0
wandb:        PPO_1222/rollout/ep_rew_mean -564.15497
wandb:                   PPO_1222/time/fps 1181.0
wandb:            PPO_1222/train/approx_kl 0.01317
wandb:        PPO_1222/train/clip_fraction 0.16954
wandb:           PPO_1222/train/clip_range 0.2
wandb:         PPO_1222/train/entropy_loss -7.05137
wandb:   PPO_1222/train/explained_variance 0.96623
wandb:        PPO_1222/train/learning_rate 0.0003
wandb:                 PPO_1222/train/loss 32.48145
wandb: PPO_1222/train/policy_gradient_loss -0.00422
wandb:                  PPO_1222/train/std 0.6621
wandb:           PPO_1222/train/value_loss 96.60732
wandb:                PPO_1232/global_step 212992
wandb:        PPO_1232/rollout/ep_len_mean 200.0
wandb:        PPO_1232/rollout/ep_rew_mean -550.82733
wandb:                   PPO_1232/time/fps 1161.0
wandb:            PPO_1232/train/approx_kl 0.01366
wandb:        PPO_1232/train/clip_fraction 0.15359
wandb:           PPO_1232/train/clip_range 0.2
wandb:         PPO_1232/train/entropy_loss -6.49534
wandb:   PPO_1232/train/explained_variance 0.96984
wandb:        PPO_1232/train/learning_rate 0.0003
wandb:                 PPO_1232/train/loss 43.80255
wandb: PPO_1232/train/policy_gradient_loss -0.00377
wandb:                  PPO_1232/train/std 0.61127
wandb:           PPO_1232/train/value_loss 396.86841
wandb:                PPO_1242/global_step 212992
wandb:        PPO_1242/rollout/ep_len_mean 200.0
wandb:        PPO_1242/rollout/ep_rew_mean -690.26276
wandb:                   PPO_1242/time/fps 1166.0
wandb:            PPO_1242/train/approx_kl 0.01078
wandb:        PPO_1242/train/clip_fraction 0.1452
wandb:           PPO_1242/train/clip_range 0.2
wandb:         PPO_1242/train/entropy_loss -6.08313
wandb:   PPO_1242/train/explained_variance 0.97658
wandb:        PPO_1242/train/learning_rate 0.0003
wandb:                 PPO_1242/train/loss 363.82199
wandb: PPO_1242/train/policy_gradient_loss -0.00533
wandb:                  PPO_1242/train/std 0.57697
wandb:           PPO_1242/train/value_loss 782.2677
wandb:                PPO_1252/global_step 212992
wandb:        PPO_1252/rollout/ep_len_mean 200.0
wandb:        PPO_1252/rollout/ep_rew_mean -576.09406
wandb:                   PPO_1252/time/fps 1165.0
wandb:            PPO_1252/train/approx_kl 0.01061
wandb:        PPO_1252/train/clip_fraction 0.13873
wandb:           PPO_1252/train/clip_range 0.2
wandb:         PPO_1252/train/entropy_loss -5.67768
wandb:   PPO_1252/train/explained_variance 0.98077
wandb:        PPO_1252/train/learning_rate 0.0003
wandb:                 PPO_1252/train/loss 100.15254
wandb: PPO_1252/train/policy_gradient_loss -0.00255
wandb:                  PPO_1252/train/std 0.54456
wandb:           PPO_1252/train/value_loss 732.95209
wandb:                PPO_1262/global_step 212992
wandb:        PPO_1262/rollout/ep_len_mean 200.0
wandb:        PPO_1262/rollout/ep_rew_mean -599.93506
wandb:                   PPO_1262/time/fps 1170.0
wandb:            PPO_1262/train/approx_kl 0.01397
wandb:        PPO_1262/train/clip_fraction 0.19852
wandb:           PPO_1262/train/clip_range 0.2
wandb:         PPO_1262/train/entropy_loss -5.23186
wandb:   PPO_1262/train/explained_variance 0.98567
wandb:        PPO_1262/train/learning_rate 0.0003
wandb:                 PPO_1262/train/loss 52.41804
wandb: PPO_1262/train/policy_gradient_loss -0.00021
wandb:                  PPO_1262/train/std 0.51195
wandb:           PPO_1262/train/value_loss 367.24252
wandb:                PPO_1272/global_step 212992
wandb:        PPO_1272/rollout/ep_len_mean 200.0
wandb:        PPO_1272/rollout/ep_rew_mean -566.59949
wandb:                   PPO_1272/time/fps 1167.0
wandb:            PPO_1272/train/approx_kl 0.0139
wandb:        PPO_1272/train/clip_fraction 0.18967
wandb:           PPO_1272/train/clip_range 0.2
wandb:         PPO_1272/train/entropy_loss -4.9559
wandb:   PPO_1272/train/explained_variance 0.97794
wandb:        PPO_1272/train/learning_rate 0.0003
wandb:                 PPO_1272/train/loss 50.6247
wandb: PPO_1272/train/policy_gradient_loss -0.0011
wandb:                  PPO_1272/train/std 0.49314
wandb:           PPO_1272/train/value_loss 347.87076
wandb:                PPO_1282/global_step 212992
wandb:        PPO_1282/rollout/ep_len_mean 200.0
wandb:        PPO_1282/rollout/ep_rew_mean -550.52777
wandb:                   PPO_1282/time/fps 1167.0
wandb:            PPO_1282/train/approx_kl 0.01884
wandb:        PPO_1282/train/clip_fraction 0.24489
wandb:           PPO_1282/train/clip_range 0.2
wandb:         PPO_1282/train/entropy_loss -4.56825
wandb:   PPO_1282/train/explained_variance 0.98319
wandb:        PPO_1282/train/learning_rate 0.0003
wandb:                 PPO_1282/train/loss 21.68955
wandb: PPO_1282/train/policy_gradient_loss 0.00255
wandb:                  PPO_1282/train/std 0.46523
wandb:           PPO_1282/train/value_loss 187.49783
wandb:                PPO_1292/global_step 212992
wandb:        PPO_1292/rollout/ep_len_mean 200.0
wandb:        PPO_1292/rollout/ep_rew_mean -558.2218
wandb:                   PPO_1292/time/fps 1163.0
wandb:            PPO_1292/train/approx_kl 0.01919
wandb:        PPO_1292/train/clip_fraction 0.24666
wandb:           PPO_1292/train/clip_range 0.2
wandb:         PPO_1292/train/entropy_loss -4.12414
wandb:   PPO_1292/train/explained_variance 0.98103
wandb:        PPO_1292/train/learning_rate 0.0003
wandb:                 PPO_1292/train/loss 89.72524
wandb: PPO_1292/train/policy_gradient_loss 0.00353
wandb:                  PPO_1292/train/std 0.43655
wandb:           PPO_1292/train/value_loss 150.632
wandb:                    global_mean_eval -480.87509
wandb:                         global_step 212992
wandb:                       mean_reward_0 -449.20001
wandb:                       mean_reward_1 -426.11885
wandb:                      mean_reward_10 -514.59573
wandb:                      mean_reward_11 -529.37154
wandb:                      mean_reward_12 -455.14948
wandb:                      mean_reward_13 -427.33525
wandb:                      mean_reward_14 -464.13729
wandb:                      mean_reward_15 -492.65876
wandb:                      mean_reward_16 -514.87872
wandb:                      mean_reward_17 -529.41546
wandb:                      mean_reward_18 -457.72114
wandb:                      mean_reward_19 -426.59896
wandb:                       mean_reward_2 -465.26489
wandb:                      mean_reward_20 -464.09054
wandb:                      mean_reward_21 -493.00421
wandb:                      mean_reward_22 -515.01137
wandb:                      mean_reward_23 -529.73933
wandb:                      mean_reward_24 -470.42924
wandb:                      mean_reward_25 -430.74864
wandb:                      mean_reward_26 -465.40074
wandb:                      mean_reward_27 -493.71491
wandb:                      mean_reward_28 -514.93551
wandb:                      mean_reward_29 -529.95218
wandb:                       mean_reward_3 -493.53603
wandb:                      mean_reward_30 -450.3453
wandb:                      mean_reward_31 -424.86366
wandb:                      mean_reward_32 -464.79356
wandb:                      mean_reward_33 -494.11024
wandb:                      mean_reward_34 -515.13467
wandb:                      mean_reward_35 -529.58228
wandb:                       mean_reward_4 -514.67643
wandb:                       mean_reward_5 -529.57313
wandb:                       mean_reward_6 -449.40232
wandb:                       mean_reward_7 -428.18713
wandb:                       mean_reward_8 -463.90891
wandb:                       mean_reward_9 -493.91699
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 66.6543
wandb:                        std_reward_1 17.66048
wandb:                       std_reward_10 2.7029
wandb:                       std_reward_11 1.74139
wandb:                       std_reward_12 76.76003
wandb:                       std_reward_13 17.12052
wandb:                       std_reward_14 5.66549
wandb:                       std_reward_15 1.01453
wandb:                       std_reward_16 3.25734
wandb:                       std_reward_17 1.82705
wandb:                       std_reward_18 79.73865
wandb:                       std_reward_19 19.52794
wandb:                        std_reward_2 7.91902
wandb:                       std_reward_20 5.52565
wandb:                       std_reward_21 3.23612
wandb:                       std_reward_22 4.19104
wandb:                       std_reward_23 2.86713
wandb:                       std_reward_24 80.58834
wandb:                       std_reward_25 23.55113
wandb:                       std_reward_26 8.53552
wandb:                       std_reward_27 5.15243
wandb:                       std_reward_28 3.63305
wandb:                       std_reward_29 2.85025
wandb:                        std_reward_3 5.59195
wandb:                       std_reward_30 74.42151
wandb:                       std_reward_31 17.89093
wandb:                       std_reward_32 6.46825
wandb:                       std_reward_33 6.35833
wandb:                       std_reward_34 4.18227
wandb:                       std_reward_35 2.62742
wandb:                        std_reward_4 3.19557
wandb:                        std_reward_5 1.81247
wandb:                        std_reward_6 63.75943
wandb:                        std_reward_7 18.39735
wandb:                        std_reward_8 4.64034
wandb:                        std_reward_9 5.4775
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced splendid-gorge-35: https://wandb.ai/tidiane/meta_rl_context/runs/27vz0el0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-27vz0el0/logs
wandb: 
wandb: Run history:
wandb:                PPO_1213/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1213/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1213/rollout/ep_rew_mean â–â–â–‚â–ƒâ–„â–„â–„â–„â–…â–‡â–‡â–ˆ
wandb:                   PPO_1213/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1213/train/approx_kl â–„â–‡â–ƒâ–…â–â–‚â–‡â–†â–†â–ƒâ–ˆ
wandb:        PPO_1213/train/clip_fraction â–…â–‡â–ƒâ–†â–â–„â–†â–‡â–‡â–†â–ˆ
wandb:           PPO_1213/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1213/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1213/train/explained_variance â–ˆâ–‡â–†â–‡â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:        PPO_1213/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1213/train/loss â–â–â–ˆâ–ƒâ–„â–…â–…â–„â–ˆâ–‡â–ˆ
wandb: PPO_1213/train/policy_gradient_loss â–ƒâ–…â–†â–…â–ˆâ–ˆâ–‡â–‡â–â–‡â–†
wandb:                  PPO_1213/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1213/train/value_loss â–â–â–„â–ƒâ–†â–‡â–‡â–†â–ˆâ–†â–ˆ
wandb:                PPO_1223/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1223/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1223/rollout/ep_rew_mean â–â–‚â–‚â–‚â–„â–…â–„â–†â–‡â–‡â–‡â–ˆ
wandb:                   PPO_1223/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1223/train/approx_kl â–â–ƒâ–‚â–„â–…â–ƒâ–†â–ˆâ–†â–ˆâ–‡
wandb:        PPO_1223/train/clip_fraction â–‚â–‚â–â–ƒâ–†â–‚â–ƒâ–ˆâ–…â–†â–…
wandb:           PPO_1223/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1223/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1223/train/explained_variance â–„â–‚â–ƒâ–„â–â–†â–‚â–†â–ˆâ–…â–‡
wandb:        PPO_1223/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1223/train/loss â–„â–ˆâ–„â–ˆâ–„â–â–„â–„â–…â–†â–
wandb: PPO_1223/train/policy_gradient_loss â–â–ƒâ–„â–ˆâ–ƒâ–‡â–…â–…â–‡â–ˆâ–‡
wandb:                  PPO_1223/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1223/train/value_loss â–ˆâ–‡â–‡â–…â–ƒâ–…â–ˆâ–â–‚â–‚â–„
wandb:                PPO_1233/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1233/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1233/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–‚â–„â–„â–†â–…â–†â–…â–ˆ
wandb:                   PPO_1233/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1233/train/approx_kl â–…â–…â–ˆâ–†â–…â–â–ƒâ–…â–‚â–ƒâ–„
wandb:        PPO_1233/train/clip_fraction â–†â–ˆâ–†â–…â–â–ƒâ–‚â–…â–â–‚â–ƒ
wandb:           PPO_1233/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1233/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1233/train/explained_variance â–…â–‚â–â–‚â–‚â–‚â–„â–„â–„â–ˆâ–…
wandb:        PPO_1233/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1233/train/loss â–ƒâ–â–‚â–â–ƒâ–†â–‡â–ˆâ–„â–‡â–ƒ
wandb: PPO_1233/train/policy_gradient_loss â–â–…â–…â–„â–…â–‡â–„â–ˆâ–‡â–‡â–‡
wandb:                  PPO_1233/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1233/train/value_loss â–‚â–â–‚â–ƒâ–†â–…â–„â–„â–„â–„â–ˆ
wandb:                PPO_1243/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1243/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1243/rollout/ep_rew_mean â–„â–„â–†â–‡â–†â–‡â–â–…â–‡â–ˆâ–ˆâ–‡
wandb:                   PPO_1243/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1243/train/approx_kl â–†â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–â–ƒâ–„â–‡â–ƒ
wandb:        PPO_1243/train/clip_fraction â–ˆâ–„â–…â–‡â–â–†â–†â–â–ˆâ–†â–„
wandb:           PPO_1243/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1243/train/entropy_loss â–â–‚â–‚â–„â–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1243/train/explained_variance â–‚â–â–ƒâ–„â–…â–†â–…â–†â–ƒâ–ˆâ–…
wandb:        PPO_1243/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1243/train/loss â–ƒâ–†â–ƒâ–â–…â–ƒâ–…â–ƒâ–‚â–ƒâ–ˆ
wandb: PPO_1243/train/policy_gradient_loss â–â–„â–…â–„â–…â–ƒâ–…â–„â–ˆâ–ˆâ–†
wandb:                  PPO_1243/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1243/train/value_loss â–â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ˆ
wandb:                PPO_1253/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1253/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1253/rollout/ep_rew_mean â–â–‚â–ƒâ–„â–…â–ˆâ–‡â–‡â–‡â–†â–ˆâ–„
wandb:                   PPO_1253/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1253/train/approx_kl â–â–†â–…â–‡â–„â–…â–„â–ˆâ–‚â–†â–†
wandb:        PPO_1253/train/clip_fraction â–â–…â–‚â–†â–‚â–…â–…â–ˆâ–ƒâ–…â–ƒ
wandb:           PPO_1253/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1253/train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–ˆ
wandb:   PPO_1253/train/explained_variance â–†â–†â–†â–†â–â–‚â–‡â–…â–…â–†â–ˆ
wandb:        PPO_1253/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1253/train/loss â–…â–„â–â–ˆâ–‡â–‡â–â–ˆâ–…â–‚â–†
wandb: PPO_1253/train/policy_gradient_loss â–‡â–†â–„â–‡â–â–‡â–…â–‡â–…â–†â–ˆ
wandb:                  PPO_1253/train/std â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–
wandb:           PPO_1253/train/value_loss â–…â–â–†â–â–ˆâ–„â–‚â–ƒâ–…â–„â–„
wandb:                PPO_1263/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1263/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1263/rollout/ep_rew_mean â–‡â–‡â–†â–…â–…â–…â–†â–ˆâ–„â–â–„â–ƒ
wandb:                   PPO_1263/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1263/train/approx_kl â–‡â–…â–…â–…â–‡â–†â–…â–„â–ˆâ–â–ƒ
wandb:        PPO_1263/train/clip_fraction â–‡â–…â–…â–…â–…â–‡â–‚â–ˆâ–‚â–â–
wandb:           PPO_1263/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1263/train/entropy_loss â–â–‚â–„â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1263/train/explained_variance â–†â–‡â–…â–‡â–…â–ˆâ–â–‡â–…â–†â–‡
wandb:        PPO_1263/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1263/train/loss â–…â–ƒâ–„â–‚â–â–‚â–‚â–„â–ˆâ–ƒâ–ƒ
wandb: PPO_1263/train/policy_gradient_loss â–‚â–„â–‚â–†â–ƒâ–„â–â–ˆâ–‚â–†â–
wandb:                  PPO_1263/train/std â–ˆâ–‡â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–â–
wandb:           PPO_1263/train/value_loss â–‚â–‚â–ƒâ–ƒâ–‚â–â–„â–â–…â–†â–ˆ
wandb:                PPO_1273/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1273/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1273/rollout/ep_rew_mean â–ˆâ–„â–…â–‡â–‚â–ƒâ–„â–â–†â–‡â–‚â–†
wandb:                   PPO_1273/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1273/train/approx_kl â–…â–…â–„â–…â–ƒâ–‡â–â–„â–‚â–ˆâ–…
wandb:        PPO_1273/train/clip_fraction â–ƒâ–„â–ƒâ–…â–ƒâ–ˆâ–â–ƒâ–‚â–†â–„
wandb:           PPO_1273/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1273/train/entropy_loss â–â–‚â–â–â–ƒâ–„â–„â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1273/train/explained_variance â–ƒâ–…â–â–…â–†â–ˆâ–†â–…â–„â–†â–…
wandb:        PPO_1273/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1273/train/loss â–‚â–‡â–‚â–â–ƒâ–â–ˆâ–ƒâ–ƒâ–…â–„
wandb: PPO_1273/train/policy_gradient_loss â–â–‚â–â–…â–â–ˆâ–ƒâ–â–ƒâ–ˆâ–…
wandb:                  PPO_1273/train/std â–ˆâ–‡â–ˆâ–ˆâ–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1273/train/value_loss â–ƒâ–†â–ˆâ–ƒâ–…â–â–†â–†â–‡â–ƒâ–†
wandb:                PPO_1283/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1283/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1283/rollout/ep_rew_mean â–ˆâ–‡â–ˆâ–…â–†â–†â–â–…â–ˆâ–ˆâ–ƒâ–„
wandb:                   PPO_1283/time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:            PPO_1283/train/approx_kl â–‚â–†â–†â–„â–„â–ƒâ–ƒâ–„â–â–ˆâ–†
wandb:        PPO_1283/train/clip_fraction â–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–â–ˆâ–‚
wandb:           PPO_1283/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1283/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–ˆâ–ˆ
wandb:   PPO_1283/train/explained_variance â–â–‡â–„â–ˆâ–‡â–ˆâ–‡â–‡â–ƒâ–ˆâ–„
wandb:        PPO_1283/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1283/train/loss â–…â–â–â–„â–…â–â–ˆâ–…â–ƒâ–‚â–„
wandb: PPO_1283/train/policy_gradient_loss â–…â–…â–†â–ˆâ–…â–†â–…â–…â–â–ˆâ–…
wandb:                  PPO_1283/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–â–
wandb:           PPO_1283/train/value_loss â–„â–‚â–‡â–…â–…â–…â–‡â–…â–‡â–â–ˆ
wandb:                PPO_1293/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1293/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1293/rollout/ep_rew_mean â–ˆâ–„â–…â–â–„â–„â–„â–†â–‚â–â–„â–
wandb:                   PPO_1293/time/fps â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:            PPO_1293/train/approx_kl â–ƒâ–…â–„â–â–†â–ˆâ–ƒâ–‡â–‚â–ƒâ–†
wandb:        PPO_1293/train/clip_fraction â–ƒâ–ˆâ–ƒâ–â–„â–†â–ƒâ–‡â–‚â–…â–ˆ
wandb:           PPO_1293/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1293/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1293/train/explained_variance â–â–ˆâ–…â–†â–„â–†â–…â–…â–„â–†â–„
wandb:        PPO_1293/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1293/train/loss â–„â–â–‚â–ƒâ–…â–â–‚â–…â–„â–ˆâ–‚
wandb: PPO_1293/train/policy_gradient_loss â–â–ˆâ–â–‚â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–†
wandb:                  PPO_1293/train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–ƒâ–„â–ƒâ–
wandb:           PPO_1293/train/value_loss â–ˆâ–â–…â–‡â–†â–„â–‡â–†â–ˆâ–„â–ƒ
wandb:                    global_mean_eval â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–ƒâ–‚â–†â–ˆâ–…â–…â–‚â–â–â–ƒ
wandb:                       mean_reward_1 â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_10 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_11 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_12 â–‚â–‚â–†â–ˆâ–…â–…â–‚â–â–â–ƒ
wandb:                      mean_reward_13 â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_14 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_17 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_18 â–ƒâ–‚â–†â–ˆâ–…â–…â–‚â–â–â–ƒ
wandb:                      mean_reward_19 â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_2 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_20 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_23 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_24 â–‚â–‚â–†â–ˆâ–…â–…â–ƒâ–â–â–‚
wandb:                      mean_reward_25 â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_26 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_29 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                       mean_reward_3 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–‚â–‚â–†â–ˆâ–…â–…â–‚â–â–â–ƒ
wandb:                      mean_reward_31 â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_32 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_35 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                       mean_reward_4 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_5 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                       mean_reward_6 â–‚â–‚â–†â–ˆâ–…â–…â–‚â–â–â–‚
wandb:                       mean_reward_7 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_8 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_0 â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:                        std_reward_1 â–ˆâ–‚â–â–â–â–‚â–â–â–â–‚
wandb:                       std_reward_10 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–ƒâ–„
wandb:                       std_reward_11 â–ˆâ–ƒâ–‚â–‡â–ƒâ–‚â–â–â–„â–ƒ
wandb:                       std_reward_12 â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_13 â–ˆâ–‚â–â–â–â–‚â–â–â–â–‚
wandb:                       std_reward_14 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_15 â–ˆâ–‚â–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                       std_reward_16 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–ƒâ–ƒ
wandb:                       std_reward_17 â–‡â–ƒâ–‚â–ˆâ–ƒâ–‚â–â–â–ƒâ–ƒ
wandb:                       std_reward_18 â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_19 â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:                        std_reward_2 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_20 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_21 â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                       std_reward_22 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–„â–„
wandb:                       std_reward_23 â–†â–ƒâ–‚â–ˆâ–ƒâ–‚â–â–â–ƒâ–ƒ
wandb:                       std_reward_24 â–ˆâ–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_25 â–ˆâ–â–â–â–â–‚â–â–â–â–
wandb:                       std_reward_26 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_27 â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                       std_reward_28 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–ƒâ–„
wandb:                       std_reward_29 â–†â–ƒâ–‚â–ˆâ–ƒâ–‚â–â–â–ƒâ–ƒ
wandb:                        std_reward_3 â–ˆâ–‚â–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                       std_reward_30 â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:                       std_reward_31 â–ˆâ–‚â–â–â–â–‚â–â–â–â–‚
wandb:                       std_reward_32 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                       std_reward_33 â–ˆâ–‚â–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                       std_reward_34 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–ƒâ–ƒ
wandb:                       std_reward_35 â–‡â–ƒâ–‚â–ˆâ–ƒâ–‚â–â–â–ƒâ–„
wandb:                        std_reward_4 â–ˆâ–ƒâ–‚â–„â–â–‚â–â–â–ƒâ–„
wandb:                        std_reward_5 â–†â–ƒâ–‚â–ˆâ–ƒâ–‚â–â–â–ƒâ–ƒ
wandb:                        std_reward_6 â–ˆâ–ƒâ–â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…
wandb:                        std_reward_7 â–ˆâ–â–â–â–â–‚â–â–â–â–‚
wandb:                        std_reward_8 â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                        std_reward_9 â–ˆâ–‚â–ƒâ–‚â–â–‚â–â–â–‚â–ƒ
wandb:                            time/fps â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–…â–ˆâ–â–‚â–„â–…â–…â–†â–‡â–†
wandb:                 train/clip_fraction â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–…â–†â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1213/global_step 212992
wandb:        PPO_1213/rollout/ep_len_mean 200.0
wandb:        PPO_1213/rollout/ep_rew_mean -755.08856
wandb:                   PPO_1213/time/fps 1184.0
wandb:            PPO_1213/train/approx_kl 0.01333
wandb:        PPO_1213/train/clip_fraction 0.16381
wandb:           PPO_1213/train/clip_range 0.2
wandb:         PPO_1213/train/entropy_loss -7.66093
wandb:   PPO_1213/train/explained_variance 0.95629
wandb:        PPO_1213/train/learning_rate 0.0003
wandb:                 PPO_1213/train/loss 82.52277
wandb: PPO_1213/train/policy_gradient_loss -0.00855
wandb:                  PPO_1213/train/std 0.72296
wandb:           PPO_1213/train/value_loss 127.93329
wandb:                PPO_1223/global_step 212992
wandb:        PPO_1223/rollout/ep_len_mean 200.0
wandb:        PPO_1223/rollout/ep_rew_mean -618.29401
wandb:                   PPO_1223/time/fps 1161.0
wandb:            PPO_1223/train/approx_kl 0.01488
wandb:        PPO_1223/train/clip_fraction 0.19085
wandb:           PPO_1223/train/clip_range 0.2
wandb:         PPO_1223/train/entropy_loss -6.72739
wandb:   PPO_1223/train/explained_variance 0.96415
wandb:        PPO_1223/train/learning_rate 0.0003
wandb:                 PPO_1223/train/loss 14.71524
wandb: PPO_1223/train/policy_gradient_loss -0.0061
wandb:                  PPO_1223/train/std 0.63231
wandb:           PPO_1223/train/value_loss 58.13858
wandb:                PPO_1233/global_step 212992
wandb:        PPO_1233/rollout/ep_len_mean 200.0
wandb:        PPO_1233/rollout/ep_rew_mean -541.41119
wandb:                   PPO_1233/time/fps 1182.0
wandb:            PPO_1233/train/approx_kl 0.01454
wandb:        PPO_1233/train/clip_fraction 0.18992
wandb:           PPO_1233/train/clip_range 0.2
wandb:         PPO_1233/train/entropy_loss -5.90341
wandb:   PPO_1233/train/explained_variance 0.96298
wandb:        PPO_1233/train/learning_rate 0.0003
wandb:                 PPO_1233/train/loss 19.33183
wandb: PPO_1233/train/policy_gradient_loss -0.00339
wandb:                  PPO_1233/train/std 0.56273
wandb:           PPO_1233/train/value_loss 93.43872
wandb:                PPO_1243/global_step 212992
wandb:        PPO_1243/rollout/ep_len_mean 200.0
wandb:        PPO_1243/rollout/ep_rew_mean -543.84784
wandb:                   PPO_1243/time/fps 1178.0
wandb:            PPO_1243/train/approx_kl 0.01445
wandb:        PPO_1243/train/clip_fraction 0.19248
wandb:           PPO_1243/train/clip_range 0.2
wandb:         PPO_1243/train/entropy_loss -5.4425
wandb:   PPO_1243/train/explained_variance 0.97631
wandb:        PPO_1243/train/learning_rate 0.0003
wandb:                 PPO_1243/train/loss 108.76793
wandb: PPO_1243/train/policy_gradient_loss -0.00204
wandb:                  PPO_1243/train/std 0.52734
wandb:           PPO_1243/train/value_loss 223.34872
wandb:                PPO_1253/global_step 212992
wandb:        PPO_1253/rollout/ep_len_mean 200.0
wandb:        PPO_1253/rollout/ep_rew_mean -549.58661
wandb:                   PPO_1253/time/fps 1170.0
wandb:            PPO_1253/train/approx_kl 0.01571
wandb:        PPO_1253/train/clip_fraction 0.18912
wandb:           PPO_1253/train/clip_range 0.2
wandb:         PPO_1253/train/entropy_loss -5.0678
wandb:   PPO_1253/train/explained_variance 0.98451
wandb:        PPO_1253/train/learning_rate 0.0003
wandb:                 PPO_1253/train/loss 118.57575
wandb: PPO_1253/train/policy_gradient_loss -0.00066
wandb:                  PPO_1253/train/std 0.49881
wandb:           PPO_1253/train/value_loss 239.88011
wandb:                PPO_1263/global_step 212992
wandb:        PPO_1263/rollout/ep_len_mean 200.0
wandb:        PPO_1263/rollout/ep_rew_mean -565.42377
wandb:                   PPO_1263/time/fps 1175.0
wandb:            PPO_1263/train/approx_kl 0.01327
wandb:        PPO_1263/train/clip_fraction 0.17577
wandb:           PPO_1263/train/clip_range 0.2
wandb:         PPO_1263/train/entropy_loss -4.76892
wandb:   PPO_1263/train/explained_variance 0.98278
wandb:        PPO_1263/train/learning_rate 0.0003
wandb:                 PPO_1263/train/loss 103.50358
wandb: PPO_1263/train/policy_gradient_loss -0.00227
wandb:                  PPO_1263/train/std 0.47906
wandb:           PPO_1263/train/value_loss 595.14899
wandb:                PPO_1273/global_step 212992
wandb:        PPO_1273/rollout/ep_len_mean 200.0
wandb:        PPO_1273/rollout/ep_rew_mean -567.06134
wandb:                   PPO_1273/time/fps 1167.0
wandb:            PPO_1273/train/approx_kl 0.01549
wandb:        PPO_1273/train/clip_fraction 0.19781
wandb:           PPO_1273/train/clip_range 0.2
wandb:         PPO_1273/train/entropy_loss -4.54673
wandb:   PPO_1273/train/explained_variance 0.98243
wandb:        PPO_1273/train/learning_rate 0.0003
wandb:                 PPO_1273/train/loss 417.5011
wandb: PPO_1273/train/policy_gradient_loss 0.00054
wandb:                  PPO_1273/train/std 0.46314
wandb:           PPO_1273/train/value_loss 687.58997
wandb:                PPO_1283/global_step 212992
wandb:        PPO_1283/rollout/ep_len_mean 200.0
wandb:        PPO_1283/rollout/ep_rew_mean -637.14392
wandb:                   PPO_1283/time/fps 1164.0
wandb:            PPO_1283/train/approx_kl 0.01811
wandb:        PPO_1283/train/clip_fraction 0.18496
wandb:           PPO_1283/train/clip_range 0.2
wandb:         PPO_1283/train/entropy_loss -4.25394
wandb:   PPO_1283/train/explained_variance 0.98047
wandb:        PPO_1283/train/learning_rate 0.0003
wandb:                 PPO_1283/train/loss 471.44504
wandb: PPO_1283/train/policy_gradient_loss 0.00011
wandb:                  PPO_1283/train/std 0.44576
wandb:           PPO_1283/train/value_loss 1048.87366
wandb:                PPO_1293/global_step 212992
wandb:        PPO_1293/rollout/ep_len_mean 200.0
wandb:        PPO_1293/rollout/ep_rew_mean -651.1275
wandb:                   PPO_1293/time/fps 1145.0
wandb:            PPO_1293/train/approx_kl 0.01658
wandb:        PPO_1293/train/clip_fraction 0.24152
wandb:           PPO_1293/train/clip_range 0.2
wandb:         PPO_1293/train/entropy_loss -3.95685
wandb:   PPO_1293/train/explained_variance 0.98473
wandb:        PPO_1293/train/learning_rate 0.0003
wandb:                 PPO_1293/train/loss 206.33018
wandb: PPO_1293/train/policy_gradient_loss 0.00228
wandb:                  PPO_1293/train/std 0.42565
wandb:           PPO_1293/train/value_loss 592.1546
wandb:                    global_mean_eval -474.33106
wandb:                         global_step 212992
wandb:                       mean_reward_0 -607.80537
wandb:                       mean_reward_1 -305.12075
wandb:                      mean_reward_10 -516.64965
wandb:                      mean_reward_11 -553.45833
wandb:                      mean_reward_12 -609.0098
wandb:                      mean_reward_13 -305.55395
wandb:                      mean_reward_14 -393.93857
wandb:                      mean_reward_15 -465.34707
wandb:                      mean_reward_16 -516.31265
wandb:                      mean_reward_17 -553.49756
wandb:                      mean_reward_18 -611.55122
wandb:                      mean_reward_19 -303.25254
wandb:                       mean_reward_2 -395.2959
wandb:                      mean_reward_20 -395.29757
wandb:                      mean_reward_21 -465.17639
wandb:                      mean_reward_22 -515.66347
wandb:                      mean_reward_23 -551.97747
wandb:                      mean_reward_24 -616.48071
wandb:                      mean_reward_25 -304.27824
wandb:                      mean_reward_26 -395.70451
wandb:                      mean_reward_27 -464.40173
wandb:                      mean_reward_28 -515.97984
wandb:                      mean_reward_29 -553.17984
wandb:                       mean_reward_3 -465.40247
wandb:                      mean_reward_30 -603.50215
wandb:                      mean_reward_31 -305.75657
wandb:                      mean_reward_32 -394.9002
wandb:                      mean_reward_33 -466.17285
wandb:                      mean_reward_34 -515.39654
wandb:                      mean_reward_35 -552.8584
wandb:                       mean_reward_4 -515.54955
wandb:                       mean_reward_5 -552.84945
wandb:                       mean_reward_6 -621.59568
wandb:                       mean_reward_7 -306.02527
wandb:                       mean_reward_8 -395.94245
wandb:                       mean_reward_9 -465.03336
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -903.27844
wandb:                        std_reward_0 65.73527
wandb:                        std_reward_1 9.28275
wandb:                       std_reward_10 7.49656
wandb:                       std_reward_11 5.33268
wandb:                       std_reward_12 68.23034
wandb:                       std_reward_13 12.51639
wandb:                       std_reward_14 5.26448
wandb:                       std_reward_15 6.04736
wandb:                       std_reward_16 5.38444
wandb:                       std_reward_17 6.05493
wandb:                       std_reward_18 59.63169
wandb:                       std_reward_19 4.65522
wandb:                        std_reward_2 6.6487
wandb:                       std_reward_20 7.05126
wandb:                       std_reward_21 7.58883
wandb:                       std_reward_22 7.31539
wandb:                       std_reward_23 5.80287
wandb:                       std_reward_24 70.8095
wandb:                       std_reward_25 6.92872
wandb:                       std_reward_26 8.63082
wandb:                       std_reward_27 6.02778
wandb:                       std_reward_28 7.46214
wandb:                       std_reward_29 5.31364
wandb:                        std_reward_3 6.82454
wandb:                       std_reward_30 60.34328
wandb:                       std_reward_31 10.42484
wandb:                       std_reward_32 6.56076
wandb:                       std_reward_33 7.72587
wandb:                       std_reward_34 5.86097
wandb:                       std_reward_35 7.02137
wandb:                        std_reward_4 6.96175
wandb:                        std_reward_5 6.0329
wandb:                        std_reward_6 72.11563
wandb:                        std_reward_7 9.17702
wandb:                        std_reward_8 8.3314
wandb:                        std_reward_9 7.04281
wandb:                            time/fps 1153.0
wandb:                     train/approx_kl 0.01145
wandb:                 train/clip_fraction 0.14658
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.87514
wandb:            train/explained_variance 0.94396
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.10234
wandb:          train/policy_gradient_loss -0.01207
wandb:                           train/std 0.85747
wandb:                    train/value_loss 31.23324
wandb: 
wandb: Synced vague-night-38: https://wandb.ai/tidiane/meta_rl_context/runs/25ymiicf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 20 other file(s)
wandb: Find logs at: ./wandb/run-20230626_032708-25ymiicf/logs

real	119m42.790s
user	1174m6.756s
sys	3m22.342s
+ mpirun python dev/automl/meta_rl/scripts/orig_impl/striker_baselines.py --context latent
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: tidiane. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-2ow35t7w
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-c48c201m
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-tyuqum18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-terrain-50
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2ow35t7w
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-1mmglo7l
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-1mm4memk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-capybara-44
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/c48c201m
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-2uae6ict
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-2if2cb72
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-2gfbf78j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-yogurt-48
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/tyuqum18
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-1gp8uu9i
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/fr/fr_fr/fr_tn110/wandb/run-20230626_052650-2y87u8r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-mountain-51
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1mmglo7l
wandb: Syncing run twilight-dawn-43
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1mm4memk
wandb: Syncing run glowing-glitter-45
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2if2cb72
wandb: Syncing run zany-fire-50
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2uae6ict
wandb: Syncing run logical-forest-46
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2gfbf78j
wandb: Syncing run lyric-morning-48
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/1gp8uu9i
wandb: Syncing run deft-thunder-45
wandb: â­ï¸ View project at https://wandb.ai/tidiane/meta_rl_context
wandb: ğŸš€ View run at https://wandb.ai/tidiane/meta_rl_context/runs/2y87u8r8
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/dev/automl/meta_rl/meta_rl/envs/striker_predictor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643003845/work/torch/csrc/utils/tensor_new.cpp:230.)
  "s_context": torch.unsqueeze(torch.Tensor(s_[:-1]),0),
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
/home/fr/fr_fr/fr_tn110/miniconda3/envs/tid_env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: WARNING When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1297/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1297/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1297/rollout/ep_rew_mean â–â–â–ƒâ–‚â–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:                   PPO_1297/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1297/train/approx_kl â–„â–ƒâ–â–ƒâ–ˆâ–„â–ƒâ–…â–…â–â–†
wandb:        PPO_1297/train/clip_fraction â–„â–…â–â–…â–†â–…â–â–ˆâ–†â–„â–ˆ
wandb:           PPO_1297/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1297/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1297/train/explained_variance â–â–†â–‡â–‡â–…â–‡â–ˆâ–†â–†â–†â–‡
wandb:        PPO_1297/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1297/train/loss â–â–†â–‚â–ƒâ–‚â–…â–†â–â–†â–ˆâ–‡
wandb: PPO_1297/train/policy_gradient_loss â–ƒâ–â–…â–‚â–„â–†â–ˆâ–…â–„â–‡â–„
wandb:                  PPO_1297/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1297/train/value_loss â–â–â–ƒâ–ƒâ–†â–†â–‡â–†â–ˆâ–ˆâ–†
wandb:                PPO_1307/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1307/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1307/rollout/ep_rew_mean â–â–ƒâ–â–â–ƒâ–ƒâ–†â–‡â–‡â–†â–‡â–ˆ
wandb:                   PPO_1307/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:            PPO_1307/train/approx_kl â–‚â–‚â–‚â–†â–ƒâ–â–†â–„â–ˆâ–…â–„
wandb:        PPO_1307/train/clip_fraction â–‚â–â–â–â–‚â–â–…â–ƒâ–ˆâ–ƒâ–†
wandb:           PPO_1307/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1307/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1307/train/explained_variance â–‡â–‚â–ˆâ–â–ˆâ–ˆâ–ƒâ–â–†â–ˆâ–†
wandb:        PPO_1307/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1307/train/loss â–ˆâ–ƒâ–â–…â–„â–†â–„â–…â–†â–„â–‚
wandb: PPO_1307/train/policy_gradient_loss â–â–…â–…â–†â–ƒâ–…â–†â–ˆâ–„â–„â–ˆ
wandb:                  PPO_1307/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1307/train/value_loss â–ˆâ–‡â–…â–…â–„â–†â–â–„â–â–‡â–†
wandb:                PPO_1317/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1317/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1317/rollout/ep_rew_mean â–â–â–‚â–„â–ƒâ–„â–„â–…â–„â–†â–ˆâ–ˆ
wandb:                   PPO_1317/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1317/train/approx_kl â–„â–…â–â–‡â–„â–ˆâ–ˆâ–„â–‡â–‡â–ƒ
wandb:        PPO_1317/train/clip_fraction â–â–‚â–â–‚â–†â–„â–ˆâ–„â–†â–ˆâ–‡
wandb:           PPO_1317/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1317/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1317/train/explained_variance â–ƒâ–…â–â–ƒâ–‚â–‡â–ˆâ–ƒâ–ˆâ–…â–ƒ
wandb:        PPO_1317/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1317/train/loss â–„â–‡â–…â–ƒâ–„â–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒ
wandb: PPO_1317/train/policy_gradient_loss â–‚â–ˆâ–„â–…â–ƒâ–…â–â–†â–„â–ˆâ–…
wandb:                  PPO_1317/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1317/train/value_loss â–‡â–†â–ˆâ–‡â–‚â–…â–‚â–â–„â–â–†
wandb:                PPO_1327/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1327/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1327/rollout/ep_rew_mean â–â–ƒâ–…â–ˆâ–†â–…â–…â–†â–…â–…â–ƒâ–‚
wandb:                   PPO_1327/time/fps â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1327/train/approx_kl â–„â–ˆâ–†â–â–…â–†â–†â–ƒâ–„â–ƒâ–„
wandb:        PPO_1327/train/clip_fraction â–…â–ˆâ–…â–„â–„â–†â–„â–â–ƒâ–‚â–ƒ
wandb:           PPO_1327/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1327/train/entropy_loss â–â–‚â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1327/train/explained_variance â–ˆâ–ˆâ–†â–‡â–â–â–…â–‚â–ƒâ–…â–ˆ
wandb:        PPO_1327/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1327/train/loss â–‚â–†â–„â–„â–ƒâ–‡â–‚â–‚â–â–†â–ˆ
wandb: PPO_1327/train/policy_gradient_loss â–‡â–â–ƒâ–ƒâ–„â–„â–„â–‚â–‡â–†â–ˆ
wandb:                  PPO_1327/train/std â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–
wandb:           PPO_1327/train/value_loss â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–†â–ˆâ–‡
wandb:                PPO_1337/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1337/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1337/rollout/ep_rew_mean â–â–ƒâ–„â–…â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡
wandb:                   PPO_1337/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1337/train/approx_kl â–„â–ƒâ–…â–‚â–…â–‡â–ˆâ–‚â–ƒâ–â–ˆ
wandb:        PPO_1337/train/clip_fraction â–â–„â–ˆâ–…â–ƒâ–ƒâ–†â–‡â–„â–â–ˆ
wandb:           PPO_1337/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1337/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–‡â–‡â–ˆ
wandb:   PPO_1337/train/explained_variance â–â–ƒâ–…â–…â–ƒâ–‡â–†â–‡â–‡â–ˆâ–†
wandb:        PPO_1337/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1337/train/loss â–‡â–‚â–â–ƒâ–ƒâ–„â–„â–„â–ˆâ–‚â–‡
wandb: PPO_1337/train/policy_gradient_loss â–â–ƒâ–â–‚â–ƒâ–„â–„â–„â–…â–…â–ˆ
wandb:                  PPO_1337/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1337/train/value_loss â–…â–ƒâ–â–â–†â–…â–‚â–‚â–„â–‡â–ˆ
wandb:                PPO_1347/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1347/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1347/rollout/ep_rew_mean â–ƒâ–‚â–„â–â–ƒâ–„â–ˆâ–†â–ˆâ–‡â–ˆâ–
wandb:                   PPO_1347/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1347/train/approx_kl â–â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‡â–†â–‚â–ˆâ–
wandb:        PPO_1347/train/clip_fraction â–ƒâ–â–†â–ƒâ–†â–ƒâ–ˆâ–â–†â–‡â–„
wandb:           PPO_1347/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1347/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–‡â–‡â–ˆ
wandb:   PPO_1347/train/explained_variance â–…â–„â–„â–…â–…â–ˆâ–ƒâ–â–†â–‡â–„
wandb:        PPO_1347/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1347/train/loss â–ˆâ–‚â–â–â–…â–‚â–â–‚â–‚â–â–‚
wandb: PPO_1347/train/policy_gradient_loss â–…â–…â–‡â–„â–„â–‡â–ˆâ–â–ƒâ–…â–ˆ
wandb:                  PPO_1347/train/std â–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–‚â–‚â–
wandb:           PPO_1347/train/value_loss â–…â–ˆâ–„â–ˆâ–†â–†â–â–…â–â–‚â–‚
wandb:                PPO_1357/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1357/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1357/rollout/ep_rew_mean â–…â–‡â–…â–ˆâ–â–‚â–†â–‡â–…â–…â–†â–ƒ
wandb:                   PPO_1357/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1357/train/approx_kl â–â–ƒâ–‚â–ƒâ–â–â–…â–ƒâ–‚â–â–ˆ
wandb:        PPO_1357/train/clip_fraction â–…â–‡â–†â–ˆâ–â–‡â–ˆâ–†â–ˆâ–†â–‡
wandb:           PPO_1357/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1357/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1357/train/explained_variance â–‚â–…â–†â–ƒâ–â–…â–‡â–„â–†â–…â–ˆ
wandb:        PPO_1357/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1357/train/loss â–â–‚â–‚â–â–‚â–‚â–…â–ˆâ–‚â–„â–…
wandb: PPO_1357/train/policy_gradient_loss â–„â–…â–ƒâ–ƒâ–â–†â–ˆâ–†â–‡â–…â–…
wandb:                  PPO_1357/train/std â–ˆâ–‡â–†â–…â–„â–„â–„â–‚â–‚â–‚â–
wandb:           PPO_1357/train/value_loss â–„â–‚â–â–â–ˆâ–‡â–ƒâ–…â–…â–„â–…
wandb:                PPO_1367/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1367/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1367/rollout/ep_rew_mean â–‚â–†â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–‚â–†â–ˆâ–ƒ
wandb:                   PPO_1367/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1367/train/approx_kl â–‚â–‚â–â–ƒâ–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ˆ
wandb:        PPO_1367/train/clip_fraction â–‚â–†â–‡â–ˆâ–…â–‚â–ˆâ–â–†â–„â–…
wandb:           PPO_1367/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1367/train/entropy_loss â–â–â–‚â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–†â–ˆ
wandb:   PPO_1367/train/explained_variance â–…â–â–ˆâ–ˆâ–†â–‡â–‡â–‡â–ˆâ–†â–‡
wandb:        PPO_1367/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1367/train/loss â–ƒâ–ƒâ–â–ˆâ–„â–â–‚â–†â–ˆâ–ƒâ–†
wandb: PPO_1367/train/policy_gradient_loss â–ƒâ–†â–ƒâ–…â–†â–â–ˆâ–‚â–†â–„â–‡
wandb:                  PPO_1367/train/std â–ˆâ–ˆâ–†â–†â–„â–‚â–‚â–â–ƒâ–‚â–
wandb:           PPO_1367/train/value_loss â–‡â–ˆâ–‡â–ƒâ–ƒâ–†â–†â–†â–â–‚â–„
wandb:                PPO_1377/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1377/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1377/rollout/ep_rew_mean â–ˆâ–†â–‡â–â–‡â–†â–‡â–‡â–‚â–‡â–†â–‡
wandb:                   PPO_1377/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1377/train/approx_kl â–â–„â–ˆâ–â–…â–‚â–ƒâ–â–†â–„â–†
wandb:        PPO_1377/train/clip_fraction â–â–„â–‡â–â–ˆâ–‚â–‡â–‡â–‡â–…â–†
wandb:           PPO_1377/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1377/train/entropy_loss â–â–â–â–ƒâ–ƒâ–„â–…â–†â–…â–…â–ˆ
wandb:   PPO_1377/train/explained_variance â–‡â–ˆâ–‡â–‡â–â–‡â–‡â–‡â–ˆâ–†â–„
wandb:        PPO_1377/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1377/train/loss â–„â–ƒâ–â–ˆâ–â–‚â–â–‚â–â–ƒâ–‚
wandb: PPO_1377/train/policy_gradient_loss â–â–„â–ˆâ–ƒâ–†â–ƒâ–„â–‡â–‡â–†â–…
wandb:                  PPO_1377/train/std â–ˆâ–ˆâ–‡â–†â–…â–„â–„â–ƒâ–„â–ƒâ–
wandb:           PPO_1377/train/value_loss â–…â–‚â–‡â–‡â–†â–ˆâ–â–†â–â–†â–…
wandb:                    global_mean_eval â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–„â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–†
wandb:                       mean_reward_1 â–â–‚â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–‡
wandb:                      mean_reward_10 â–â–‚â–„â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡
wandb:                      mean_reward_11 â–â–‚â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_12 â–â–‚â–ƒâ–‡â–‡â–†â–ˆâ–‡â–†â–†
wandb:                      mean_reward_13 â–â–‚â–ƒâ–‡â–‡â–†â–ˆâ–‡â–‡â–…
wandb:                      mean_reward_14 â–â–‚â–„â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡
wandb:                      mean_reward_15 â–â–‚â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_16 â–â–‚â–„â–†â–‡â–ˆâ–‡â–‡â–†â–†
wandb:                      mean_reward_17 â–â–‚â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–†
wandb:                      mean_reward_18 â–â–‚â–ƒâ–‡â–‡â–‡â–ˆâ–‡â–†â–‡
wandb:                      mean_reward_19 â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡
wandb:                       mean_reward_2 â–â–‚â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–…â–‡
wandb:                      mean_reward_20 â–â–‚â–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                      mean_reward_21 â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                      mean_reward_22 â–â–‚â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_23 â–â–â–ƒâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†
wandb:                      mean_reward_24 â–â–‚â–ƒâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†
wandb:                      mean_reward_25 â–â–‚â–ƒâ–‡â–…â–ˆâ–ˆâ–‡â–†â–‡
wandb:                      mean_reward_26 â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–†
wandb:                      mean_reward_27 â–â–‚â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆ
wandb:                      mean_reward_28 â–â–‚â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–†
wandb:                      mean_reward_29 â–â–‚â–ƒâ–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–†
wandb:                       mean_reward_3 â–â–‚â–„â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–‚â–ƒâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_31 â–â–‚â–„â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_32 â–â–‚â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–…â–‡
wandb:                      mean_reward_33 â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡
wandb:                      mean_reward_34 â–â–‚â–ƒâ–†â–†â–‡â–ˆâ–†â–†â–…
wandb:                      mean_reward_35 â–â–‚â–„â–‡â–‡â–ˆâ–ˆâ–‡â–…â–†
wandb:                       mean_reward_4 â–â–‚â–„â–‡â–†â–‡â–ˆâ–‡â–†â–†
wandb:                       mean_reward_5 â–â–‚â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–†
wandb:                       mean_reward_6 â–â–‚â–„â–‡â–‡â–‡â–ˆâ–ˆâ–†â–†
wandb:                       mean_reward_7 â–â–‚â–ƒâ–‡â–‡â–‡â–ˆâ–‡â–†â–‡
wandb:                       mean_reward_8 â–â–‚â–ƒâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†
wandb:                       mean_reward_9 â–â–‚â–ƒâ–‡â–†â–ˆâ–ˆâ–‡â–†â–‡
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–„â–„â–†â–‡â–‡â–ˆ
wandb:                        std_reward_0 â–‚â–â–â–‚â–†â–†â–„â–‡â–‡â–ˆ
wandb:                        std_reward_1 â–‚â–â–â–‚â–†â–†â–…â–‡â–ˆâ–‡
wandb:                       std_reward_10 â–‚â–â–â–‚â–†â–†â–…â–‡â–ˆâ–‡
wandb:                       std_reward_11 â–‚â–‚â–â–ƒâ–†â–†â–†â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_12 â–‚â–‚â–â–‚â–‡â–ˆâ–…â–‡â–‡â–ˆ
wandb:                       std_reward_13 â–‚â–â–â–‚â–†â–ˆâ–…â–†â–‡â–ˆ
wandb:                       std_reward_14 â–‚â–â–â–‚â–†â–ˆâ–…â–‡â–ˆâ–‡
wandb:                       std_reward_15 â–‚â–‚â–â–ƒâ–‡â–ˆâ–†â–‡â–ˆâ–‡
wandb:                       std_reward_16 â–‚â–‚â–â–‚â–†â–…â–…â–‡â–ˆâ–‡
wandb:                       std_reward_17 â–‚â–â–â–‚â–†â–…â–„â–†â–†â–ˆ
wandb:                       std_reward_18 â–‚â–â–â–‚â–ˆâ–‡â–…â–‡â–ˆâ–‡
wandb:                       std_reward_19 â–‚â–â–â–‚â–…â–…â–…â–‡â–ˆâ–‡
wandb:                        std_reward_2 â–‚â–â–â–‚â–†â–†â–…â–†â–ˆâ–‡
wandb:                       std_reward_20 â–‚â–â–â–‚â–…â–…â–„â–†â–ˆâ–‡
wandb:                       std_reward_21 â–‚â–â–â–‚â–‡â–†â–…â–†â–ˆâ–‡
wandb:                       std_reward_22 â–‚â–â–â–‚â–†â–ˆâ–†â–ˆâ–ˆâ–‡
wandb:                       std_reward_23 â–‚â–â–â–ƒâ–†â–†â–…â–†â–ˆâ–ˆ
wandb:                       std_reward_24 â–‚â–â–â–‚â–†â–‡â–…â–†â–ˆâ–ˆ
wandb:                       std_reward_25 â–‚â–â–â–‚â–ˆâ–†â–„â–‡â–‡â–‡
wandb:                       std_reward_26 â–‚â–â–â–‚â–…â–…â–„â–…â–ˆâ–†
wandb:                       std_reward_27 â–‚â–â–â–‚â–†â–…â–„â–†â–ˆâ–†
wandb:                       std_reward_28 â–‚â–‚â–â–‚â–‡â–†â–„â–…â–ˆâ–‡
wandb:                       std_reward_29 â–‚â–‚â–â–‚â–…â–„â–ƒâ–‡â–‡â–ˆ
wandb:                        std_reward_3 â–‚â–‚â–â–ƒâ–‡â–ˆâ–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_30 â–‚â–‚â–â–ƒâ–ˆâ–ˆâ–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_31 â–‚â–â–â–‚â–‡â–‡â–†â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_32 â–‚â–â–â–‚â–†â–†â–„â–…â–ˆâ–†
wandb:                       std_reward_33 â–‚â–‚â–â–ƒâ–‡â–†â–†â–ˆâ–ˆâ–‡
wandb:                       std_reward_34 â–‚â–â–â–‚â–‡â–†â–ƒâ–‡â–ˆâ–ˆ
wandb:                       std_reward_35 â–‚â–‚â–â–‚â–†â–†â–„â–†â–ˆâ–‡
wandb:                        std_reward_4 â–‚â–â–â–ƒâ–‡â–‡â–…â–‡â–ˆâ–‡
wandb:                        std_reward_5 â–‚â–â–â–‚â–†â–…â–…â–‡â–ˆâ–‡
wandb:                        std_reward_6 â–‚â–‚â–â–‚â–†â–‡â–…â–†â–ˆâ–‡
wandb:                        std_reward_7 â–‚â–â–â–‚â–†â–†â–„â–…â–ˆâ–†
wandb:                        std_reward_8 â–‚â–‚â–â–‚â–‡â–†â–…â–†â–ˆâ–ˆ
wandb:                        std_reward_9 â–‚â–‚â–â–‚â–‡â–…â–…â–‡â–ˆâ–†
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–â–‚â–ƒâ–ˆâ–†â–‚â–â–ƒâ–ƒâ–…â–„â–„
wandb:                 train/clip_fraction â–„â–„â–„â–…â–…â–‚â–â–„â–‡â–ˆâ–ˆâ–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–‚â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–…â–…â–…â–ˆâ–ˆâ–†â–„â–‚â–â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1297/global_step 212992
wandb:        PPO_1297/rollout/ep_len_mean 200.0
wandb:        PPO_1297/rollout/ep_rew_mean -810.90198
wandb:                   PPO_1297/time/fps 602.0
wandb:            PPO_1297/train/approx_kl 0.01289
wandb:        PPO_1297/train/clip_fraction 0.17168
wandb:           PPO_1297/train/clip_range 0.2
wandb:         PPO_1297/train/entropy_loss -7.5924
wandb:   PPO_1297/train/explained_variance 0.95989
wandb:        PPO_1297/train/learning_rate 0.0003
wandb:                 PPO_1297/train/loss 42.32363
wandb: PPO_1297/train/policy_gradient_loss -0.00859
wandb:                  PPO_1297/train/std 0.71551
wandb:           PPO_1297/train/value_loss 67.43292
wandb:                PPO_1307/global_step 212992
wandb:        PPO_1307/rollout/ep_len_mean 200.0
wandb:        PPO_1307/rollout/ep_rew_mean -744.23724
wandb:                   PPO_1307/time/fps 609.0
wandb:            PPO_1307/train/approx_kl 0.01373
wandb:        PPO_1307/train/clip_fraction 0.1912
wandb:           PPO_1307/train/clip_range 0.2
wandb:         PPO_1307/train/entropy_loss -6.58458
wandb:   PPO_1307/train/explained_variance 0.95697
wandb:        PPO_1307/train/learning_rate 0.0003
wandb:                 PPO_1307/train/loss 17.00875
wandb: PPO_1307/train/policy_gradient_loss -0.00538
wandb:                  PPO_1307/train/std 0.61877
wandb:           PPO_1307/train/value_loss 58.2617
wandb:                PPO_1317/global_step 212992
wandb:        PPO_1317/rollout/ep_len_mean 200.0
wandb:        PPO_1317/rollout/ep_rew_mean -647.86694
wandb:                   PPO_1317/time/fps 601.0
wandb:            PPO_1317/train/approx_kl 0.01532
wandb:        PPO_1317/train/clip_fraction 0.2314
wandb:           PPO_1317/train/clip_range 0.2
wandb:         PPO_1317/train/entropy_loss -5.7819
wandb:   PPO_1317/train/explained_variance 0.95407
wandb:        PPO_1317/train/learning_rate 0.0003
wandb:                 PPO_1317/train/loss 14.01113
wandb: PPO_1317/train/policy_gradient_loss -0.00453
wandb:                  PPO_1317/train/std 0.55236
wandb:           PPO_1317/train/value_loss 50.03746
wandb:                PPO_1327/global_step 212992
wandb:        PPO_1327/rollout/ep_len_mean 200.0
wandb:        PPO_1327/rollout/ep_rew_mean -626.64215
wandb:                   PPO_1327/time/fps 606.0
wandb:            PPO_1327/train/approx_kl 0.01601
wandb:        PPO_1327/train/clip_fraction 0.20165
wandb:           PPO_1327/train/clip_range 0.2
wandb:         PPO_1327/train/entropy_loss -5.25219
wandb:   PPO_1327/train/explained_variance 0.96418
wandb:        PPO_1327/train/learning_rate 0.0003
wandb:                 PPO_1327/train/loss 58.92407
wandb: PPO_1327/train/policy_gradient_loss -0.00204
wandb:                  PPO_1327/train/std 0.51309
wandb:           PPO_1327/train/value_loss 128.97078
wandb:                PPO_1337/global_step 212992
wandb:        PPO_1337/rollout/ep_len_mean 200.0
wandb:        PPO_1337/rollout/ep_rew_mean -562.80688
wandb:                   PPO_1337/time/fps 605.0
wandb:            PPO_1337/train/approx_kl 0.01837
wandb:        PPO_1337/train/clip_fraction 0.22462
wandb:           PPO_1337/train/clip_range 0.2
wandb:         PPO_1337/train/entropy_loss -4.78217
wandb:   PPO_1337/train/explained_variance 0.97617
wandb:        PPO_1337/train/learning_rate 0.0003
wandb:                 PPO_1337/train/loss 117.47269
wandb: PPO_1337/train/policy_gradient_loss 0.0017
wandb:                  PPO_1337/train/std 0.47883
wandb:           PPO_1337/train/value_loss 237.15161
wandb:                PPO_1347/global_step 212992
wandb:        PPO_1347/rollout/ep_len_mean 200.0
wandb:        PPO_1347/rollout/ep_rew_mean -585.86896
wandb:                   PPO_1347/time/fps 604.0
wandb:            PPO_1347/train/approx_kl 0.01422
wandb:        PPO_1347/train/clip_fraction 0.202
wandb:           PPO_1347/train/clip_range 0.2
wandb:         PPO_1347/train/entropy_loss -4.44853
wandb:   PPO_1347/train/explained_variance 0.97552
wandb:        PPO_1347/train/learning_rate 0.0003
wandb:                 PPO_1347/train/loss 91.013
wandb: PPO_1347/train/policy_gradient_loss 0.0007
wandb:                  PPO_1347/train/std 0.45682
wandb:           PPO_1347/train/value_loss 231.11421
wandb:                PPO_1357/global_step 212992
wandb:        PPO_1357/rollout/ep_len_mean 200.0
wandb:        PPO_1357/rollout/ep_rew_mean -578.43091
wandb:                   PPO_1357/time/fps 603.0
wandb:            PPO_1357/train/approx_kl 0.0259
wandb:        PPO_1357/train/clip_fraction 0.22141
wandb:           PPO_1357/train/clip_range 0.2
wandb:         PPO_1357/train/entropy_loss -4.12698
wandb:   PPO_1357/train/explained_variance 0.98516
wandb:        PPO_1357/train/learning_rate 0.0003
wandb:                 PPO_1357/train/loss 380.4783
wandb: PPO_1357/train/policy_gradient_loss 0.00115
wandb:                  PPO_1357/train/std 0.43665
wandb:           PPO_1357/train/value_loss 376.22714
wandb:                PPO_1367/global_step 212992
wandb:        PPO_1367/rollout/ep_len_mean 200.0
wandb:        PPO_1367/rollout/ep_rew_mean -545.966
wandb:                   PPO_1367/time/fps 598.0
wandb:            PPO_1367/train/approx_kl 0.02505
wandb:        PPO_1367/train/clip_fraction 0.22617
wandb:           PPO_1367/train/clip_range 0.2
wandb:         PPO_1367/train/entropy_loss -3.92382
wandb:   PPO_1367/train/explained_variance 0.98334
wandb:        PPO_1367/train/learning_rate 0.0003
wandb:                 PPO_1367/train/loss 320.72751
wandb: PPO_1367/train/policy_gradient_loss 0.00251
wandb:                  PPO_1367/train/std 0.4247
wandb:           PPO_1367/train/value_loss 399.29773
wandb:                PPO_1377/global_step 212992
wandb:        PPO_1377/rollout/ep_len_mean 200.0
wandb:        PPO_1377/rollout/ep_rew_mean -561.92303
wandb:                   PPO_1377/time/fps 596.0
wandb:            PPO_1377/train/approx_kl 0.0203
wandb:        PPO_1377/train/clip_fraction 0.22671
wandb:           PPO_1377/train/clip_range 0.2
wandb:         PPO_1377/train/entropy_loss -3.77489
wandb:   PPO_1377/train/explained_variance 0.97868
wandb:        PPO_1377/train/learning_rate 0.0003
wandb:                 PPO_1377/train/loss 150.59523
wandb: PPO_1377/train/policy_gradient_loss 0.00207
wandb:                  PPO_1377/train/std 0.41519
wandb:           PPO_1377/train/value_loss 480.00906
wandb:                    global_mean_eval -534.09263
wandb:                         global_step 212992
wandb:                       mean_reward_0 -584.23988
wandb:                       mean_reward_1 -532.71359
wandb:                      mean_reward_10 -520.49007
wandb:                      mean_reward_11 -508.68852
wandb:                      mean_reward_12 -562.65065
wandb:                      mean_reward_13 -576.97154
wandb:                      mean_reward_14 -529.28561
wandb:                      mean_reward_15 -492.68724
wandb:                      mean_reward_16 -556.56203
wandb:                      mean_reward_17 -573.42627
wandb:                      mean_reward_18 -515.27653
wandb:                      mean_reward_19 -524.13483
wandb:                       mean_reward_2 -548.48444
wandb:                      mean_reward_20 -505.70783
wandb:                      mean_reward_21 -536.38052
wandb:                      mean_reward_22 -497.15831
wandb:                      mean_reward_23 -562.98405
wandb:                      mean_reward_24 -532.89307
wandb:                      mean_reward_25 -518.94803
wandb:                      mean_reward_26 -539.41671
wandb:                      mean_reward_27 -478.10749
wandb:                      mean_reward_28 -558.46144
wandb:                      mean_reward_29 -529.20282
wandb:                       mean_reward_3 -501.4809
wandb:                      mean_reward_30 -529.72869
wandb:                      mean_reward_31 -528.05006
wandb:                      mean_reward_32 -511.05523
wandb:                      mean_reward_33 -526.23947
wandb:                      mean_reward_34 -575.5968
wandb:                      mean_reward_35 -543.22037
wandb:                       mean_reward_4 -543.23563
wandb:                       mean_reward_5 -557.0231
wandb:                       mean_reward_6 -556.44236
wandb:                       mean_reward_7 -512.95587
wandb:                       mean_reward_8 -542.70323
wandb:                       mean_reward_9 -514.73165
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -901.89819
wandb:                        std_reward_0 312.79188
wandb:                        std_reward_1 290.77388
wandb:                       std_reward_10 268.3957
wandb:                       std_reward_11 248.58264
wandb:                       std_reward_12 305.52218
wandb:                       std_reward_13 304.96572
wandb:                       std_reward_14 274.73434
wandb:                       std_reward_15 229.40711
wandb:                       std_reward_16 290.70066
wandb:                       std_reward_17 313.30766
wandb:                       std_reward_18 247.60949
wandb:                       std_reward_19 263.70962
wandb:                        std_reward_2 288.10846
wandb:                       std_reward_20 258.79603
wandb:                       std_reward_21 283.62312
wandb:                       std_reward_22 249.52031
wandb:                       std_reward_23 305.10327
wandb:                       std_reward_24 273.44445
wandb:                       std_reward_25 268.9585
wandb:                       std_reward_26 279.38179
wandb:                       std_reward_27 237.27572
wandb:                       std_reward_28 283.95898
wandb:                       std_reward_29 287.40303
wandb:                        std_reward_3 262.94468
wandb:                       std_reward_30 263.14467
wandb:                       std_reward_31 282.45148
wandb:                       std_reward_32 251.09108
wandb:                       std_reward_33 265.105
wandb:                       std_reward_34 305.91825
wandb:                       std_reward_35 281.6857
wandb:                        std_reward_4 271.5696
wandb:                        std_reward_5 292.9678
wandb:                        std_reward_6 286.32467
wandb:                        std_reward_7 274.70951
wandb:                        std_reward_8 278.656
wandb:                        std_reward_9 254.10548
wandb:                            time/fps 597.0
wandb:                     train/approx_kl 0.0106
wandb:                 train/clip_fraction 0.13875
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.80915
wandb:            train/explained_variance 0.95603
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 9.91018
wandb:          train/policy_gradient_loss -0.00981
wandb:                           train/std 0.84977
wandb:                    train/value_loss 25.25248
wandb: 
wandb: Synced drawn-capybara-44: https://wandb.ai/tidiane/meta_rl_context/runs/c48c201m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-c48c201m/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1301/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1301/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1301/rollout/ep_rew_mean â–â–‚â–‚â–â–‚â–‚â–…â–…â–ƒâ–…â–‡â–ˆ
wandb:                   PPO_1301/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1301/train/approx_kl â–†â–â–…â–â–ƒâ–‡â–…â–ˆâ–†â–ˆâ–„
wandb:        PPO_1301/train/clip_fraction â–…â–â–…â–‚â–ƒâ–‡â–„â–‡â–…â–ˆâ–…
wandb:           PPO_1301/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1301/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1301/train/explained_variance â–â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†
wandb:        PPO_1301/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1301/train/loss â–‚â–â–â–‚â–â–ƒâ–„â–„â–ƒâ–â–ˆ
wandb: PPO_1301/train/policy_gradient_loss â–â–†â–†â–†â–‡â–ƒâ–…â–â–…â–ƒâ–ˆ
wandb:                  PPO_1301/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1301/train/value_loss â–‚â–‚â–â–‚â–‚â–â–ƒâ–…â–„â–ƒâ–ˆ
wandb:                PPO_1311/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1311/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1311/rollout/ep_rew_mean â–â–‚â–ƒâ–‚â–„â–…â–…â–…â–†â–†â–‡â–ˆ
wandb:                   PPO_1311/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1311/train/approx_kl â–â–„â–‚â–…â–‡â–‡â–ˆâ–†â–ˆâ–†â–†
wandb:        PPO_1311/train/clip_fraction â–â–„â–ƒâ–„â–†â–‡â–†â–†â–†â–ˆâ–ˆ
wandb:           PPO_1311/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1311/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1311/train/explained_variance â–‡â–ˆâ–…â–†â–‡â–â–ƒâ–†â–„â–ˆâ–†
wandb:        PPO_1311/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1311/train/loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–‚â–„â–‚â–â–‚
wandb: PPO_1311/train/policy_gradient_loss â–‡â–ƒâ–…â–ƒâ–â–‚â–ˆâ–‡â–†â–„â–ˆ
wandb:                  PPO_1311/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1311/train/value_loss â–‡â–ˆâ–ƒâ–…â–ˆâ–…â–‚â–ƒâ–„â–â–
wandb:                PPO_1321/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1321/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1321/rollout/ep_rew_mean â–â–‚â–â–‚â–ƒâ–ƒâ–…â–…â–„â–„â–†â–ˆ
wandb:                   PPO_1321/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1321/train/approx_kl â–â–‚â–„â–…â–…â–„â–†â–†â–ˆâ–ˆâ–‡
wandb:        PPO_1321/train/clip_fraction â–â–„â–„â–†â–…â–†â–†â–‡â–‡â–ˆâ–‡
wandb:           PPO_1321/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1321/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆ
wandb:   PPO_1321/train/explained_variance â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–â–„â–ˆâ–†â–‡
wandb:        PPO_1321/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1321/train/loss â–†â–ƒâ–ƒâ–†â–â–…â–‚â–ƒâ–‚â–ˆâ–‚
wandb: PPO_1321/train/policy_gradient_loss â–ƒâ–‚â–†â–ƒâ–ƒâ–â–…â–…â–…â–ˆâ–‡
wandb:                  PPO_1321/train/std â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–
wandb:           PPO_1321/train/value_loss â–ˆâ–„â–‡â–…â–…â–ˆâ–…â–ƒâ–‚â–„â–
wandb:                PPO_1331/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1331/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1331/rollout/ep_rew_mean â–â–ƒâ–‚â–ƒâ–‚â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:                   PPO_1331/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1331/train/approx_kl â–‚â–†â–„â–â–…â–‚â–…â–ˆâ–ˆâ–â–†
wandb:        PPO_1331/train/clip_fraction â–â–†â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–„â–„
wandb:           PPO_1331/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1331/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1331/train/explained_variance â–…â–‡â–„â–…â–†â–ˆâ–‡â–â–„â–…â–…
wandb:        PPO_1331/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1331/train/loss â–‚â–â–‡â–‚â–…â–ƒâ–†â–ˆâ–ƒâ–ƒâ–„
wandb: PPO_1331/train/policy_gradient_loss â–†â–ƒâ–â–ƒâ–ƒâ–…â–ˆâ–‡â–‡â–†â–ˆ
wandb:                  PPO_1331/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1331/train/value_loss â–ˆâ–‚â–ˆâ–ƒâ–†â–â–…â–„â–…â–„â–‚
wandb:                PPO_1340/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1340/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1340/rollout/ep_rew_mean â–â–ƒâ–ƒâ–„â–„â–ƒâ–†â–ˆâ–†â–†â–„â–…
wandb:                   PPO_1340/time/fps â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1340/train/approx_kl â–‡â–â–†â–…â–†â–‡â–…â–ˆâ–‚â–†â–†
wandb:        PPO_1340/train/clip_fraction â–‚â–‚â–…â–„â–â–…â–…â–ˆâ–â–ƒâ–„
wandb:           PPO_1340/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1340/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1340/train/explained_variance â–…â–…â–‚â–„â–„â–ƒâ–…â–â–†â–…â–ˆ
wandb:        PPO_1340/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1340/train/loss â–†â–ˆâ–‡â–â–…â–†â–â–â–ˆâ–‡â–‚
wandb: PPO_1340/train/policy_gradient_loss â–ˆâ–†â–…â–„â–ƒâ–‚â–‡â–…â–â–‡â–‡
wandb:                  PPO_1340/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1340/train/value_loss â–ˆâ–†â–…â–…â–ˆâ–‡â–…â–â–„â–…â–„
wandb:                PPO_1349/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1349/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1349/rollout/ep_rew_mean â–â–ƒâ–…â–…â–‡â–…â–ˆâ–‡â–ˆâ–‡â–†â–ˆ
wandb:                   PPO_1349/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1349/train/approx_kl â–…â–†â–…â–‡â–…â–…â–ƒâ–â–ˆâ–ˆâ–ƒ
wandb:        PPO_1349/train/clip_fraction â–…â–†â–‡â–†â–†â–ˆâ–†â–â–…â–†â–ƒ
wandb:           PPO_1349/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1349/train/entropy_loss â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1349/train/explained_variance â–â–â–„â–‚â–…â–„â–„â–…â–…â–…â–ˆ
wandb:        PPO_1349/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1349/train/loss â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–„â–‚â–ˆâ–‡
wandb: PPO_1349/train/policy_gradient_loss â–ƒâ–â–…â–„â–…â–ƒâ–ˆâ–…â–…â–„â–ƒ
wandb:                  PPO_1349/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1349/train/value_loss â–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–„â–ˆ
wandb:                PPO_1359/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1359/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1359/rollout/ep_rew_mean â–†â–„â–†â–…â–‡â–†â–â–ˆâ–…â–„â–â–„
wandb:                   PPO_1359/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:            PPO_1359/train/approx_kl â–…â–â–â–…â–„â–‡â–‚â–…â–‚â–ƒâ–ˆ
wandb:        PPO_1359/train/clip_fraction â–ƒâ–ƒâ–„â–ˆâ–ƒâ–ƒâ–„â–„â–â–†â–ˆ
wandb:           PPO_1359/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1359/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–ˆ
wandb:   PPO_1359/train/explained_variance â–â–…â–ƒâ–â–„â–…â–ˆâ–†â–„â–…â–†
wandb:        PPO_1359/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1359/train/loss â–„â–†â–„â–ƒâ–ˆâ–‚â–ƒâ–‚â–â–†â–†
wandb: PPO_1359/train/policy_gradient_loss â–…â–ƒâ–ƒâ–„â–…â–„â–â–ˆâ–„â–‡â–
wandb:                  PPO_1359/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1359/train/value_loss â–â–ƒâ–‚â–ƒâ–„â–…â–„â–„â–ˆâ–„â–…
wandb:                PPO_1369/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1369/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1369/rollout/ep_rew_mean â–†â–„â–„â–ƒâ–…â–…â–â–ˆâ–‡â–ƒâ–ƒâ–…
wandb:                   PPO_1369/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1369/train/approx_kl â–„â–…â–â–ƒâ–…â–ˆâ–†â–…â–†â–‚â–†
wandb:        PPO_1369/train/clip_fraction â–„â–‚â–ƒâ–â–ƒâ–ˆâ–‚â–†â–â–‚â–„
wandb:           PPO_1369/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1369/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1369/train/explained_variance â–â–„â–†â–„â–â–â–ˆâ–„â–ƒâ–„â–ˆ
wandb:        PPO_1369/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1369/train/loss â–ƒâ–‚â–ƒâ–ˆâ–†â–‚â–ƒâ–‚â–‚â–‡â–
wandb: PPO_1369/train/policy_gradient_loss â–…â–„â–…â–„â–â–†â–ƒâ–†â–‚â–…â–ˆ
wandb:                  PPO_1369/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1369/train/value_loss â–…â–†â–„â–‡â–†â–ƒâ–ƒâ–â–…â–ˆâ–‚
wandb:                PPO_1379/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1379/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1379/rollout/ep_rew_mean â–„â–†â–†â–ƒâ–†â–â–…â–„â–„â–ƒâ–…â–ˆ
wandb:                   PPO_1379/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1379/train/approx_kl â–â–…â–ˆâ–â–ƒâ–‚â–†â–ƒâ–â–…â–‚
wandb:        PPO_1379/train/clip_fraction â–ƒâ–‡â–ˆâ–…â–ƒâ–ƒâ–†â–„â–â–ˆâ–…
wandb:           PPO_1379/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1379/train/entropy_loss â–â–‚â–‚â–„â–„â–…â–…â–…â–…â–†â–ˆ
wandb:   PPO_1379/train/explained_variance â–â–‡â–‚â–…â–‚â–ƒâ–â–„â–â–ˆâ–…
wandb:        PPO_1379/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1379/train/loss â–„â–ˆâ–â–‚â–…â–ƒâ–ƒâ–‚â–‚â–†â–†
wandb: PPO_1379/train/policy_gradient_loss â–â–ˆâ–ƒâ–ƒâ–‚â–…â–†â–„â–â–‡â–†
wandb:                  PPO_1379/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1379/train/value_loss â–ƒâ–â–‚â–ƒâ–…â–…â–‚â–„â–ˆâ–â–…
wandb:                    global_mean_eval â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_1 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_10 â–â–‚â–…â–…â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_11 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_12 â–â–‚â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_13 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_14 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡
wandb:                      mean_reward_15 â–â–â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–†
wandb:                      mean_reward_16 â–â–‚â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_17 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_18 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_19 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_2 â–â–‚â–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_20 â–â–‚â–„â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_21 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_22 â–â–‚â–„â–…â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_23 â–â–‚â–…â–…â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_24 â–â–‚â–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_25 â–â–‚â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_26 â–â–â–„â–…â–ˆâ–‡â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_27 â–â–‚â–…â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_28 â–â–‚â–…â–…â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_29 â–â–‚â–„â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:                       mean_reward_3 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_30 â–â–â–„â–…â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_31 â–â–‚â–…â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_32 â–â–‚â–„â–…â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–‚â–…â–…â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_34 â–â–‚â–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_35 â–â–‚â–„â–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                       mean_reward_4 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_5 â–â–‚â–„â–…â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡
wandb:                       mean_reward_6 â–â–‚â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_7 â–â–‚â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                       mean_reward_8 â–â–‚â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                       mean_reward_9 â–â–‚â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–…â–†â–ˆ
wandb:                        std_reward_0 â–‚â–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                        std_reward_1 â–‚â–‚â–‚â–â–â–…â–…â–‡â–‡â–ˆ
wandb:                       std_reward_10 â–‚â–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                       std_reward_11 â–‚â–‚â–‚â–â–â–…â–…â–†â–†â–ˆ
wandb:                       std_reward_12 â–‚â–‚â–‚â–â–â–†â–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_13 â–‚â–‚â–‚â–â–‚â–†â–†â–‡â–‡â–ˆ
wandb:                       std_reward_14 â–‚â–‚â–‚â–â–â–…â–…â–†â–ˆâ–ˆ
wandb:                       std_reward_15 â–ƒâ–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                       std_reward_16 â–‚â–â–‚â–â–â–„â–†â–†â–‡â–ˆ
wandb:                       std_reward_17 â–‚â–‚â–‚â–â–â–…â–„â–…â–†â–ˆ
wandb:                       std_reward_18 â–‚â–â–‚â–â–â–…â–…â–‡â–‡â–ˆ
wandb:                       std_reward_19 â–‚â–â–‚â–â–â–…â–†â–†â–‡â–ˆ
wandb:                        std_reward_2 â–‚â–‚â–‚â–â–â–…â–†â–‡â–‡â–ˆ
wandb:                       std_reward_20 â–‚â–‚â–‚â–â–â–…â–…â–†â–…â–ˆ
wandb:                       std_reward_21 â–‚â–‚â–‚â–â–â–†â–…â–‡â–ˆâ–ˆ
wandb:                       std_reward_22 â–‚â–â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                       std_reward_23 â–ƒâ–‚â–‚â–â–â–…â–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_24 â–‚â–â–‚â–â–â–…â–†â–†â–†â–ˆ
wandb:                       std_reward_25 â–‚â–‚â–‚â–â–â–…â–†â–†â–ˆâ–ˆ
wandb:                       std_reward_26 â–‚â–â–‚â–â–â–…â–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_27 â–‚â–‚â–‚â–â–â–†â–…â–†â–ˆâ–ˆ
wandb:                       std_reward_28 â–‚â–â–‚â–â–â–…â–…â–…â–†â–ˆ
wandb:                       std_reward_29 â–‚â–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                        std_reward_3 â–‚â–â–‚â–â–â–…â–„â–†â–‡â–ˆ
wandb:                       std_reward_30 â–‚â–â–‚â–â–â–…â–…â–‡â–†â–ˆ
wandb:                       std_reward_31 â–‚â–â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                       std_reward_32 â–‚â–‚â–‚â–â–â–†â–†â–ˆâ–ˆâ–‡
wandb:                       std_reward_33 â–‚â–‚â–‚â–â–â–…â–…â–‡â–ˆâ–ˆ
wandb:                       std_reward_34 â–‚â–‚â–‚â–â–â–…â–…â–†â–†â–ˆ
wandb:                       std_reward_35 â–‚â–â–‚â–â–â–…â–†â–†â–†â–ˆ
wandb:                        std_reward_4 â–‚â–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                        std_reward_5 â–ƒâ–‚â–‚â–â–â–†â–‡â–‡â–‡â–ˆ
wandb:                        std_reward_6 â–‚â–‚â–‚â–â–â–…â–…â–†â–‡â–ˆ
wandb:                        std_reward_7 â–‚â–‚â–‚â–â–â–…â–„â–†â–‡â–ˆ
wandb:                        std_reward_8 â–‚â–‚â–‚â–â–â–†â–…â–‡â–…â–ˆ
wandb:                        std_reward_9 â–‚â–‚â–‚â–â–â–…â–†â–†â–‡â–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–„â–ˆâ–‡â–†â–„â–ƒâ–â–‚â–„â–„
wandb:                 train/clip_fraction â–‚â–ƒâ–ƒâ–„â–‡â–‚â–â–‚â–â–‚â–…â–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–â–â–â–†â–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–„â–…â–…â–ˆâ–†â–‡â–†â–…â–ƒâ–‚â–
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1301/global_step 212992
wandb:        PPO_1301/rollout/ep_len_mean 200.0
wandb:        PPO_1301/rollout/ep_rew_mean -844.30353
wandb:                   PPO_1301/time/fps 595.0
wandb:            PPO_1301/train/approx_kl 0.0112
wandb:        PPO_1301/train/clip_fraction 0.14424
wandb:           PPO_1301/train/clip_range 0.2
wandb:         PPO_1301/train/entropy_loss -7.55232
wandb:   PPO_1301/train/explained_variance 0.94968
wandb:        PPO_1301/train/learning_rate 0.0003
wandb:                 PPO_1301/train/loss 62.21507
wandb: PPO_1301/train/policy_gradient_loss -0.00538
wandb:                  PPO_1301/train/std 0.71094
wandb:           PPO_1301/train/value_loss 109.49551
wandb:                PPO_1311/global_step 212992
wandb:        PPO_1311/rollout/ep_len_mean 200.0
wandb:        PPO_1311/rollout/ep_rew_mean -757.08746
wandb:                   PPO_1311/time/fps 596.0
wandb:            PPO_1311/train/approx_kl 0.01273
wandb:        PPO_1311/train/clip_fraction 0.175
wandb:           PPO_1311/train/clip_range 0.2
wandb:         PPO_1311/train/entropy_loss -6.72545
wandb:   PPO_1311/train/explained_variance 0.96152
wandb:        PPO_1311/train/learning_rate 0.0003
wandb:                 PPO_1311/train/loss 25.72913
wandb: PPO_1311/train/policy_gradient_loss -0.0059
wandb:                  PPO_1311/train/std 0.63294
wandb:           PPO_1311/train/value_loss 66.42207
wandb:                PPO_1321/global_step 212992
wandb:        PPO_1321/rollout/ep_len_mean 200.0
wandb:        PPO_1321/rollout/ep_rew_mean -659.16974
wandb:                   PPO_1321/time/fps 594.0
wandb:            PPO_1321/train/approx_kl 0.01611
wandb:        PPO_1321/train/clip_fraction 0.19787
wandb:           PPO_1321/train/clip_range 0.2
wandb:         PPO_1321/train/entropy_loss -6.05237
wandb:   PPO_1321/train/explained_variance 0.97113
wandb:        PPO_1321/train/learning_rate 0.0003
wandb:                 PPO_1321/train/loss 22.1079
wandb: PPO_1321/train/policy_gradient_loss -0.00353
wandb:                  PPO_1321/train/std 0.5753
wandb:           PPO_1321/train/value_loss 49.95579
wandb:                PPO_1331/global_step 212992
wandb:        PPO_1331/rollout/ep_len_mean 200.0
wandb:        PPO_1331/rollout/ep_rew_mean -566.21906
wandb:                   PPO_1331/time/fps 602.0
wandb:            PPO_1331/train/approx_kl 0.01755
wandb:        PPO_1331/train/clip_fraction 0.22244
wandb:           PPO_1331/train/clip_range 0.2
wandb:         PPO_1331/train/entropy_loss -5.32586
wandb:   PPO_1331/train/explained_variance 0.96876
wandb:        PPO_1331/train/learning_rate 0.0003
wandb:                 PPO_1331/train/loss 31.77514
wandb: PPO_1331/train/policy_gradient_loss -0.00197
wandb:                  PPO_1331/train/std 0.51779
wandb:           PPO_1331/train/value_loss 42.64041
wandb:                PPO_1340/global_step 212992
wandb:        PPO_1340/rollout/ep_len_mean 200.0
wandb:        PPO_1340/rollout/ep_rew_mean -547.72687
wandb:                   PPO_1340/time/fps 599.0
wandb:            PPO_1340/train/approx_kl 0.01745
wandb:        PPO_1340/train/clip_fraction 0.22529
wandb:           PPO_1340/train/clip_range 0.2
wandb:         PPO_1340/train/entropy_loss -4.72037
wandb:   PPO_1340/train/explained_variance 0.97731
wandb:        PPO_1340/train/learning_rate 0.0003
wandb:                 PPO_1340/train/loss 12.71041
wandb: PPO_1340/train/policy_gradient_loss -0.00198
wandb:                  PPO_1340/train/std 0.47556
wandb:           PPO_1340/train/value_loss 49.99202
wandb:                PPO_1349/global_step 212992
wandb:        PPO_1349/rollout/ep_len_mean 200.0
wandb:        PPO_1349/rollout/ep_rew_mean -530.19379
wandb:                   PPO_1349/time/fps 600.0
wandb:            PPO_1349/train/approx_kl 0.01603
wandb:        PPO_1349/train/clip_fraction 0.21555
wandb:           PPO_1349/train/clip_range 0.2
wandb:         PPO_1349/train/entropy_loss -4.25689
wandb:   PPO_1349/train/explained_variance 0.9819
wandb:        PPO_1349/train/learning_rate 0.0003
wandb:                 PPO_1349/train/loss 61.56349
wandb: PPO_1349/train/policy_gradient_loss -0.00285
wandb:                  PPO_1349/train/std 0.44458
wandb:           PPO_1349/train/value_loss 120.18243
wandb:                PPO_1359/global_step 212992
wandb:        PPO_1359/rollout/ep_len_mean 200.0
wandb:        PPO_1359/rollout/ep_rew_mean -533.82062
wandb:                   PPO_1359/time/fps 597.0
wandb:            PPO_1359/train/approx_kl 0.01924
wandb:        PPO_1359/train/clip_fraction 0.24708
wandb:           PPO_1359/train/clip_range 0.2
wandb:         PPO_1359/train/entropy_loss -3.89775
wandb:   PPO_1359/train/explained_variance 0.98513
wandb:        PPO_1359/train/learning_rate 0.0003
wandb:                 PPO_1359/train/loss 50.78387
wandb: PPO_1359/train/policy_gradient_loss -0.002
wandb:                  PPO_1359/train/std 0.4223
wandb:           PPO_1359/train/value_loss 128.90108
wandb:                PPO_1369/global_step 212992
wandb:        PPO_1369/rollout/ep_len_mean 200.0
wandb:        PPO_1369/rollout/ep_rew_mean -515.25757
wandb:                   PPO_1369/time/fps 598.0
wandb:            PPO_1369/train/approx_kl 0.01975
wandb:        PPO_1369/train/clip_fraction 0.24427
wandb:           PPO_1369/train/clip_range 0.2
wandb:         PPO_1369/train/entropy_loss -3.55475
wandb:   PPO_1369/train/explained_variance 0.99014
wandb:        PPO_1369/train/learning_rate 0.0003
wandb:                 PPO_1369/train/loss 10.73959
wandb: PPO_1369/train/policy_gradient_loss 0.00225
wandb:                  PPO_1369/train/std 0.40251
wandb:           PPO_1369/train/value_loss 99.68839
wandb:                PPO_1379/global_step 212992
wandb:        PPO_1379/rollout/ep_len_mean 200.0
wandb:        PPO_1379/rollout/ep_rew_mean -502.23993
wandb:                   PPO_1379/time/fps 601.0
wandb:            PPO_1379/train/approx_kl 0.01654
wandb:        PPO_1379/train/clip_fraction 0.24799
wandb:           PPO_1379/train/clip_range 0.2
wandb:         PPO_1379/train/entropy_loss -3.30315
wandb:   PPO_1379/train/explained_variance 0.98788
wandb:        PPO_1379/train/learning_rate 0.0003
wandb:                 PPO_1379/train/loss 124.57511
wandb: PPO_1379/train/policy_gradient_loss 0.00248
wandb:                  PPO_1379/train/std 0.38871
wandb:           PPO_1379/train/value_loss 212.866
wandb:                    global_mean_eval -512.7558
wandb:                         global_step 212992
wandb:                       mean_reward_0 -543.7995
wandb:                       mean_reward_1 -521.35764
wandb:                      mean_reward_10 -508.36906
wandb:                      mean_reward_11 -526.55397
wandb:                      mean_reward_12 -488.85894
wandb:                      mean_reward_13 -484.99412
wandb:                      mean_reward_14 -511.77694
wandb:                      mean_reward_15 -528.4226
wandb:                      mean_reward_16 -518.97618
wandb:                      mean_reward_17 -518.65362
wandb:                      mean_reward_18 -512.42209
wandb:                      mean_reward_19 -526.56176
wandb:                       mean_reward_2 -517.77268
wandb:                      mean_reward_20 -513.05269
wandb:                      mean_reward_21 -484.79706
wandb:                      mean_reward_22 -534.83722
wandb:                      mean_reward_23 -508.20946
wandb:                      mean_reward_24 -533.07181
wandb:                      mean_reward_25 -518.97465
wandb:                      mean_reward_26 -491.13164
wandb:                      mean_reward_27 -499.21648
wandb:                      mean_reward_28 -547.43699
wandb:                      mean_reward_29 -502.5384
wandb:                       mean_reward_3 -513.08751
wandb:                      mean_reward_30 -524.28636
wandb:                      mean_reward_31 -508.22029
wandb:                      mean_reward_32 -503.10243
wandb:                      mean_reward_33 -492.78568
wandb:                      mean_reward_34 -513.56429
wandb:                      mean_reward_35 -515.51464
wandb:                       mean_reward_4 -515.57331
wandb:                       mean_reward_5 -489.22696
wandb:                       mean_reward_6 -518.00024
wandb:                       mean_reward_7 -523.70558
wandb:                       mean_reward_8 -509.7879
wandb:                       mean_reward_9 -490.56794
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -935.32892
wandb:                        std_reward_0 186.66603
wandb:                        std_reward_1 172.5908
wandb:                       std_reward_10 190.25908
wandb:                       std_reward_11 191.21732
wandb:                       std_reward_12 163.59867
wandb:                       std_reward_13 167.60356
wandb:                       std_reward_14 183.74414
wandb:                       std_reward_15 179.85489
wandb:                       std_reward_16 188.6409
wandb:                       std_reward_17 197.99994
wandb:                       std_reward_18 184.29904
wandb:                       std_reward_19 183.58906
wandb:                        std_reward_2 182.72258
wandb:                       std_reward_20 195.06284
wandb:                       std_reward_21 163.29174
wandb:                       std_reward_22 198.42877
wandb:                       std_reward_23 167.22026
wandb:                       std_reward_24 183.68175
wandb:                       std_reward_25 166.63949
wandb:                       std_reward_26 179.72795
wandb:                       std_reward_27 161.6134
wandb:                       std_reward_28 219.6442
wandb:                       std_reward_29 183.07093
wandb:                        std_reward_3 186.76011
wandb:                       std_reward_30 186.88418
wandb:                       std_reward_31 187.22383
wandb:                       std_reward_32 150.99516
wandb:                       std_reward_33 174.77395
wandb:                       std_reward_34 190.22823
wandb:                       std_reward_35 189.53982
wandb:                        std_reward_4 183.47765
wandb:                        std_reward_5 164.18563
wandb:                        std_reward_6 198.4082
wandb:                        std_reward_7 190.61666
wandb:                        std_reward_8 193.92551
wandb:                        std_reward_9 181.88884
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01017
wandb:                 train/clip_fraction 0.12781
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.67882
wandb:            train/explained_variance 0.87368
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 7.2388
wandb:          train/policy_gradient_loss -0.01025
wandb:                           train/std 0.83444
wandb:                    train/value_loss 20.95161
wandb: 
wandb: Synced twilight-dawn-43: https://wandb.ai/tidiane/meta_rl_context/runs/1mm4memk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-1mm4memk/logs
wandb: 
wandb: Run history:
wandb:                PPO_1300/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1300/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1300/rollout/ep_rew_mean â–â–â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb:                   PPO_1300/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1300/train/approx_kl â–â–‚â–ƒâ–ˆâ–â–‡â–†â–†â–ˆâ–†â–…
wandb:        PPO_1300/train/clip_fraction â–â–â–…â–‡â–…â–…â–…â–†â–ˆâ–‡â–…
wandb:           PPO_1300/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1300/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1300/train/explained_variance â–â–†â–‡â–ˆâ–†â–ˆâ–„â–‡â–…â–ˆâ–…
wandb:        PPO_1300/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1300/train/loss â–ƒâ–…â–‚â–â–‚â–„â–‚â–„â–„â–„â–ˆ
wandb: PPO_1300/train/policy_gradient_loss â–ˆâ–†â–ƒâ–â–„â–ƒâ–†â–„â–ƒâ–â–†
wandb:                  PPO_1300/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1300/train/value_loss â–…â–ƒâ–â–â–„â–„â–‡â–‡â–…â–…â–ˆ
wandb:                PPO_1308/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1308/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1308/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–ˆ
wandb:                   PPO_1308/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1308/train/approx_kl â–â–â–†â–‚â–„â–‚â–„â–†â–…â–ƒâ–ˆ
wandb:        PPO_1308/train/clip_fraction â–â–â–ƒâ–‚â–„â–…â–‡â–†â–ˆâ–…â–…
wandb:           PPO_1308/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1308/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1308/train/explained_variance â–†â–„â–…â–ˆâ–â–ƒâ–„â–…â–†â–‚â–…
wandb:        PPO_1308/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1308/train/loss â–†â–„â–…â–ˆâ–„â–…â–ˆâ–‡â–â–‚â–‡
wandb: PPO_1308/train/policy_gradient_loss â–â–„â–…â–‡â–„â–…â–â–‚â–†â–‡â–ˆ
wandb:                  PPO_1308/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1308/train/value_loss â–†â–ˆâ–ˆâ–…â–†â–ƒâ–ƒâ–„â–â–â–ƒ
wandb:                PPO_1318/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1318/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1318/rollout/ep_rew_mean â–â–â–ƒâ–„â–…â–„â–…â–…â–…â–‡â–ˆâ–ˆ
wandb:                   PPO_1318/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1318/train/approx_kl â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ˆâ–ƒâ–ˆâ–â–‚
wandb:        PPO_1318/train/clip_fraction â–ƒâ–â–ƒâ–„â–„â–†â–ˆâ–‚â–†â–â–‚
wandb:           PPO_1318/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1318/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1318/train/explained_variance â–†â–ˆâ–†â–…â–†â–â–…â–‡â–„â–†â–‚
wandb:        PPO_1318/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1318/train/loss â–‚â–ˆâ–‚â–„â–‡â–â–â–…â–‚â–†â–…
wandb: PPO_1318/train/policy_gradient_loss â–â–â–ƒâ–‚â–‚â–‚â–‚â–…â–ˆâ–ˆâ–†
wandb:                  PPO_1318/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1318/train/value_loss â–„â–…â–ƒâ–ˆâ–ƒâ–†â–â–ƒâ–„â–„â–‡
wandb:                PPO_1328/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1328/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1328/rollout/ep_rew_mean â–‚â–‚â–…â–â–„â–…â–‡â–‚â–‡â–ƒâ–ˆâ–ˆ
wandb:                   PPO_1328/time/fps â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1328/train/approx_kl â–â–ˆâ–ƒâ–„â–‡â–‚â–ˆâ–…â–‡â–‡â–‡
wandb:        PPO_1328/train/clip_fraction â–â–„â–ƒâ–‚â–…â–ƒâ–ˆâ–â–…â–ƒâ–…
wandb:           PPO_1328/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1328/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1328/train/explained_variance â–â–‚â–‚â–„â–†â–†â–‡â–†â–ˆâ–‡â–ˆ
wandb:        PPO_1328/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1328/train/loss â–â–â–„â–…â–…â–ˆâ–ƒâ–ˆâ–â–„â–„
wandb: PPO_1328/train/policy_gradient_loss â–…â–†â–ƒâ–‚â–ƒâ–â–„â–†â–…â–„â–ˆ
wandb:                  PPO_1328/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1328/train/value_loss â–‚â–‚â–ƒâ–‡â–„â–…â–â–…â–‚â–ˆâ–†
wandb:                PPO_1338/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1338/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1338/rollout/ep_rew_mean â–†â–ˆâ–‡â–ˆâ–‡â–„â–†â–„â–†â–‚â–â–‡
wandb:                   PPO_1338/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1338/train/approx_kl â–…â–‡â–†â–ˆâ–„â–ƒâ–†â–â–…â–ƒâ–…
wandb:        PPO_1338/train/clip_fraction â–„â–ˆâ–†â–‡â–ƒâ–‚â–„â–â–…â–‚â–…
wandb:           PPO_1338/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1338/train/entropy_loss â–â–‚â–ƒâ–ƒâ–…â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1338/train/explained_variance â–ƒâ–„â–â–‡â–„â–‚â–ˆâ–…â–…â–†â–ƒ
wandb:        PPO_1338/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1338/train/loss â–â–â–â–â–ˆâ–†â–ƒâ–ƒâ–‚â–…â–ƒ
wandb: PPO_1338/train/policy_gradient_loss â–â–ˆâ–†â–‡â–â–…â–ƒâ–…â–†â–…â–†
wandb:                  PPO_1338/train/std â–ˆâ–‡â–†â–…â–„â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1338/train/value_loss â–ƒâ–‚â–‚â–â–…â–‡â–ƒâ–ˆâ–…â–‡â–ˆ
wandb:                PPO_1348/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1348/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1348/rollout/ep_rew_mean â–‡â–„â–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–„
wandb:                   PPO_1348/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1348/train/approx_kl â–‡â–ˆâ–‚â–ˆâ–‚â–ƒâ–…â–â–‚â–„â–ƒ
wandb:        PPO_1348/train/clip_fraction â–…â–ƒâ–‚â–ˆâ–â–ƒâ–„â–‚â–ƒâ–‚â–ƒ
wandb:           PPO_1348/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1348/train/entropy_loss â–â–‚â–‚â–„â–„â–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1348/train/explained_variance â–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:        PPO_1348/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1348/train/loss â–â–…â–ˆâ–â–…â–ƒâ–…â–…â–‡â–‚â–„
wandb: PPO_1348/train/policy_gradient_loss â–‡â–‡â–‚â–â–â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–…
wandb:                  PPO_1348/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1348/train/value_loss â–ƒâ–…â–ˆâ–â–†â–†â–†â–‡â–…â–‡â–ˆ
wandb:                PPO_1358/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1358/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1358/rollout/ep_rew_mean â–â–„â–â–‚â–„â–†â–†â–„â–‡â–ˆâ–…â–„
wandb:                   PPO_1358/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1358/train/approx_kl â–â–‚â–‚â–‡â–â–„â–ƒâ–…â–„â–ˆâ–†
wandb:        PPO_1358/train/clip_fraction â–â–„â–‚â–†â–â–‡â–ƒâ–…â–ƒâ–ˆâ–„
wandb:           PPO_1358/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1358/train/entropy_loss â–â–‚â–„â–…â–†â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:   PPO_1358/train/explained_variance â–ƒâ–‡â–ˆâ–‡â–„â–‡â–…â–ˆâ–‡â–â–…
wandb:        PPO_1358/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1358/train/loss â–„â–„â–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆ
wandb: PPO_1358/train/policy_gradient_loss â–â–†â–ƒâ–â–ƒâ–„â–„â–†â–†â–ˆâ–„
wandb:                  PPO_1358/train/std â–ˆâ–‡â–†â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–
wandb:           PPO_1358/train/value_loss â–ˆâ–…â–†â–ƒâ–ˆâ–„â–†â–„â–†â–â–…
wandb:                PPO_1368/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1368/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1368/rollout/ep_rew_mean â–ƒâ–â–…â–…â–‡â–ˆâ–ˆâ–„â–ˆâ–…â–…â–…
wandb:                   PPO_1368/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1368/train/approx_kl â–‡â–„â–ˆâ–ƒâ–ƒâ–…â–…â–â–…â–…â–…
wandb:        PPO_1368/train/clip_fraction â–„â–…â–„â–„â–ƒâ–‡â–†â–â–„â–…â–ˆ
wandb:           PPO_1368/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1368/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–‡â–ˆ
wandb:   PPO_1368/train/explained_variance â–‚â–ˆâ–†â–‚â–â–ˆâ–†â–„â–…â–…â–„
wandb:        PPO_1368/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1368/train/loss â–…â–ˆâ–„â–„â–„â–‚â–â–‚â–ƒâ–â–
wandb: PPO_1368/train/policy_gradient_loss â–…â–…â–…â–â–ƒâ–…â–‡â–„â–‡â–†â–ˆ
wandb:                  PPO_1368/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–‚â–
wandb:           PPO_1368/train/value_loss â–‡â–ƒâ–…â–…â–…â–â–„â–ˆâ–„â–„â–‚
wandb:                PPO_1378/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1378/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1378/rollout/ep_rew_mean â–ˆâ–…â–â–†â–‡â–‚â–â–ƒâ–†â–†â–…â–…
wandb:                   PPO_1378/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1378/train/approx_kl â–„â–ˆâ–…â–†â–‚â–„â–â–‚â–ˆâ–ƒâ–‚
wandb:        PPO_1378/train/clip_fraction â–‡â–†â–â–ˆâ–‚â–„â–â–â–ˆâ–ƒâ–†
wandb:           PPO_1378/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1378/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1378/train/explained_variance â–â–‡â–ˆâ–ˆâ–‚â–„â–‡â–†â–…â–…â–ˆ
wandb:        PPO_1378/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1378/train/loss â–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–„â–ˆâ–â–„â–ƒ
wandb: PPO_1378/train/policy_gradient_loss â–†â–…â–â–†â–‚â–‚â–â–‚â–ˆâ–ƒâ–‡
wandb:                  PPO_1378/train/std â–ˆâ–‡â–‡â–†â–…â–„â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1378/train/value_loss â–ƒâ–‚â–‡â–â–†â–…â–„â–ˆâ–‚â–…â–†
wandb:                    global_mean_eval â–â–„â–†â–ˆâ–‡â–‡â–†â–†â–†â–†
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–†â–ˆâ–†â–‡â–ˆâ–†â–†â–†
wandb:                       mean_reward_1 â–â–„â–†â–ˆâ–‡â–†â–†â–…â–‡â–…
wandb:                      mean_reward_10 â–â–„â–†â–ˆâ–†â–ˆâ–†â–‡â–‡â–‡
wandb:                      mean_reward_11 â–â–„â–†â–ˆâ–†â–…â–…â–…â–‡â–†
wandb:                      mean_reward_12 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†
wandb:                      mean_reward_13 â–â–„â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…
wandb:                      mean_reward_14 â–â–„â–‡â–ˆâ–ˆâ–…â–†â–†â–†â–†
wandb:                      mean_reward_15 â–â–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–†
wandb:                      mean_reward_16 â–â–…â–‡â–ˆâ–ˆâ–†â–‡â–†â–‡â–…
wandb:                      mean_reward_17 â–â–„â–†â–ˆâ–ˆâ–†â–…â–…â–‡â–„
wandb:                      mean_reward_18 â–â–„â–†â–ˆâ–‡â–‡â–‡â–‡â–†â–†
wandb:                      mean_reward_19 â–â–„â–†â–ˆâ–‡â–†â–…â–†â–†â–‡
wandb:                       mean_reward_2 â–â–„â–†â–ˆâ–ˆâ–†â–†â–ˆâ–„â–…
wandb:                      mean_reward_20 â–â–…â–†â–ˆâ–‡â–‡â–‡â–…â–…â–†
wandb:                      mean_reward_21 â–â–„â–†â–ˆâ–ˆâ–‡â–†â–‡â–„â–‡
wandb:                      mean_reward_22 â–â–„â–†â–ˆâ–‡â–†â–‡â–‡â–‡â–†
wandb:                      mean_reward_23 â–â–…â–‡â–ˆâ–ˆâ–‡â–ˆâ–…â–…â–‡
wandb:                      mean_reward_24 â–â–„â–†â–ˆâ–‡â–ˆâ–…â–†â–‡â–…
wandb:                      mean_reward_25 â–â–…â–†â–ˆâ–‡â–†â–†â–‡â–†â–†
wandb:                      mean_reward_26 â–â–„â–†â–ˆâ–‡â–‡â–†â–†â–†â–…
wandb:                      mean_reward_27 â–â–„â–†â–ˆâ–‡â–‡â–†â–†â–†â–„
wandb:                      mean_reward_28 â–â–„â–†â–ˆâ–‡â–†â–†â–†â–ˆâ–†
wandb:                      mean_reward_29 â–â–„â–†â–ˆâ–‡â–‡â–…â–‡â–‡â–†
wandb:                       mean_reward_3 â–â–…â–†â–ˆâ–ˆâ–‡â–‡â–…â–…â–†
wandb:                      mean_reward_30 â–â–…â–‡â–ˆâ–ˆâ–†â–‡â–‡â–†â–‡
wandb:                      mean_reward_31 â–â–„â–†â–ˆâ–‡â–…â–†â–†â–…â–…
wandb:                      mean_reward_32 â–â–„â–†â–‡â–‡â–†â–ˆâ–…â–‡â–„
wandb:                      mean_reward_33 â–â–„â–†â–ˆâ–‡â–‡â–‡â–‡â–…â–†
wandb:                      mean_reward_34 â–â–„â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†
wandb:                      mean_reward_35 â–â–„â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†
wandb:                       mean_reward_4 â–â–„â–‡â–ˆâ–ˆâ–‡â–†â–…â–‡â–…
wandb:                       mean_reward_5 â–â–„â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡
wandb:                       mean_reward_6 â–â–„â–†â–‡â–‡â–†â–†â–…â–†â–ˆ
wandb:                       mean_reward_7 â–â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†
wandb:                       mean_reward_8 â–â–„â–†â–ˆâ–‡â–†â–†â–…â–†â–†
wandb:                       mean_reward_9 â–â–„â–†â–ˆâ–‡â–†â–‡â–†â–†â–†
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–‡â–‡â–‡â–ˆâ–†
wandb:                        std_reward_0 â–â–â–â–ƒâ–†â–‡â–†â–‡â–ˆâ–ˆ
wandb:                        std_reward_1 â–â–â–â–ƒâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆ
wandb:                       std_reward_10 â–‚â–â–‚â–ƒâ–‡â–†â–ˆâ–‡â–‡â–ˆ
wandb:                       std_reward_11 â–â–â–‚â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–‡
wandb:                       std_reward_12 â–â–â–â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_13 â–â–â–â–ƒâ–…â–†â–…â–‡â–‡â–ˆ
wandb:                       std_reward_14 â–â–â–â–ƒâ–…â–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                       std_reward_15 â–â–â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆ
wandb:                       std_reward_16 â–‚â–â–â–ƒâ–„â–†â–‡â–‡â–†â–ˆ
wandb:                       std_reward_17 â–â–â–â–‚â–„â–†â–‡â–‡â–…â–ˆ
wandb:                       std_reward_18 â–â–â–â–ƒâ–…â–†â–‡â–†â–ˆâ–ˆ
wandb:                       std_reward_19 â–â–â–‚â–ƒâ–†â–‡â–ˆâ–‡â–ˆâ–‡
wandb:                        std_reward_2 â–â–â–â–ƒâ–…â–‡â–‡â–†â–ˆâ–ˆ
wandb:                       std_reward_20 â–‚â–â–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_21 â–â–â–â–ƒâ–…â–†â–‡â–†â–ˆâ–†
wandb:                       std_reward_22 â–â–â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       std_reward_23 â–â–â–â–ƒâ–…â–†â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_24 â–â–â–â–ƒâ–…â–†â–ˆâ–‡â–‡â–ˆ
wandb:                       std_reward_25 â–‚â–â–‚â–ƒâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       std_reward_26 â–â–â–â–ƒâ–…â–†â–‡â–‡â–‡â–ˆ
wandb:                       std_reward_27 â–â–â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆ
wandb:                       std_reward_28 â–â–â–â–ƒâ–…â–‡â–ˆâ–ˆâ–†â–ˆ
wandb:                       std_reward_29 â–â–â–â–ƒâ–†â–†â–ˆâ–‡â–‡â–‡
wandb:                        std_reward_3 â–â–â–â–„â–„â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_30 â–â–â–‚â–ƒâ–…â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       std_reward_31 â–â–â–â–ƒâ–…â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_32 â–‚â–â–â–ƒâ–…â–†â–…â–ˆâ–‡â–ˆ
wandb:                       std_reward_33 â–‚â–â–â–ƒâ–†â–‡â–‡â–†â–ˆâ–ˆ
wandb:                       std_reward_34 â–â–â–â–ƒâ–…â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                       std_reward_35 â–â–â–â–ƒâ–„â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                        std_reward_4 â–â–â–â–‚â–…â–…â–‡â–ˆâ–‡â–‡
wandb:                        std_reward_5 â–‚â–â–â–ƒâ–…â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                        std_reward_6 â–‚â–â–‚â–ƒâ–…â–‡â–‡â–ˆâ–‡â–…
wandb:                        std_reward_7 â–â–â–â–ƒâ–…â–†â–‡â–‡â–‡â–ˆ
wandb:                        std_reward_8 â–â–â–â–ƒâ–†â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                        std_reward_9 â–‚â–â–â–ƒâ–†â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–ƒâ–‚â–ƒâ–ˆâ–‡â–‚â–â–ƒâ–ƒâ–„â–„â–…
wandb:                 train/clip_fraction â–…â–„â–„â–…â–…â–‚â–â–…â–†â–ˆâ–‡â–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:                           train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1300/global_step 212992
wandb:        PPO_1300/rollout/ep_len_mean 200.0
wandb:        PPO_1300/rollout/ep_rew_mean -787.52649
wandb:                   PPO_1300/time/fps 608.0
wandb:            PPO_1300/train/approx_kl 0.01178
wandb:        PPO_1300/train/clip_fraction 0.14671
wandb:           PPO_1300/train/clip_range 0.2
wandb:         PPO_1300/train/entropy_loss -7.64494
wandb:   PPO_1300/train/explained_variance 0.95211
wandb:        PPO_1300/train/learning_rate 0.0003
wandb:                 PPO_1300/train/loss 72.50619
wandb: PPO_1300/train/policy_gradient_loss -0.00744
wandb:                  PPO_1300/train/std 0.72025
wandb:           PPO_1300/train/value_loss 97.59276
wandb:                PPO_1308/global_step 212992
wandb:        PPO_1308/rollout/ep_len_mean 200.0
wandb:        PPO_1308/rollout/ep_rew_mean -691.02704
wandb:                   PPO_1308/time/fps 604.0
wandb:            PPO_1308/train/approx_kl 0.01554
wandb:        PPO_1308/train/clip_fraction 0.18
wandb:           PPO_1308/train/clip_range 0.2
wandb:         PPO_1308/train/entropy_loss -6.82727
wandb:   PPO_1308/train/explained_variance 0.95242
wandb:        PPO_1308/train/learning_rate 0.0003
wandb:                 PPO_1308/train/loss 38.44964
wandb: PPO_1308/train/policy_gradient_loss -0.0061
wandb:                  PPO_1308/train/std 0.64219
wandb:           PPO_1308/train/value_loss 70.37889
wandb:                PPO_1318/global_step 212992
wandb:        PPO_1318/rollout/ep_len_mean 200.0
wandb:        PPO_1318/rollout/ep_rew_mean -577.26294
wandb:                   PPO_1318/time/fps 607.0
wandb:            PPO_1318/train/approx_kl 0.01418
wandb:        PPO_1318/train/clip_fraction 0.18947
wandb:           PPO_1318/train/clip_range 0.2
wandb:         PPO_1318/train/entropy_loss -6.13125
wandb:   PPO_1318/train/explained_variance 0.92549
wandb:        PPO_1318/train/learning_rate 0.0003
wandb:                 PPO_1318/train/loss 39.50974
wandb: PPO_1318/train/policy_gradient_loss -0.00403
wandb:                  PPO_1318/train/std 0.58114
wandb:           PPO_1318/train/value_loss 88.93178
wandb:                PPO_1328/global_step 212992
wandb:        PPO_1328/rollout/ep_len_mean 200.0
wandb:        PPO_1328/rollout/ep_rew_mean -544.65839
wandb:                   PPO_1328/time/fps 600.0
wandb:            PPO_1328/train/approx_kl 0.01455
wandb:        PPO_1328/train/clip_fraction 0.19086
wandb:           PPO_1328/train/clip_range 0.2
wandb:         PPO_1328/train/entropy_loss -5.67665
wandb:   PPO_1328/train/explained_variance 0.97439
wandb:        PPO_1328/train/learning_rate 0.0003
wandb:                 PPO_1328/train/loss 67.59825
wandb: PPO_1328/train/policy_gradient_loss -0.00291
wandb:                  PPO_1328/train/std 0.54334
wandb:           PPO_1328/train/value_loss 271.56732
wandb:                PPO_1338/global_step 212992
wandb:        PPO_1338/rollout/ep_len_mean 200.0
wandb:        PPO_1338/rollout/ep_rew_mean -568.77698
wandb:                   PPO_1338/time/fps 604.0
wandb:            PPO_1338/train/approx_kl 0.01365
wandb:        PPO_1338/train/clip_fraction 0.17439
wandb:           PPO_1338/train/clip_range 0.2
wandb:         PPO_1338/train/entropy_loss -5.32477
wandb:   PPO_1338/train/explained_variance 0.9703
wandb:        PPO_1338/train/learning_rate 0.0003
wandb:                 PPO_1338/train/loss 150.11108
wandb: PPO_1338/train/policy_gradient_loss -0.00241
wandb:                  PPO_1338/train/std 0.5179
wandb:           PPO_1338/train/value_loss 601.03796
wandb:                PPO_1348/global_step 212992
wandb:        PPO_1348/rollout/ep_len_mean 200.0
wandb:        PPO_1348/rollout/ep_rew_mean -578.24298
wandb:                   PPO_1348/time/fps 604.0
wandb:            PPO_1348/train/approx_kl 0.01326
wandb:        PPO_1348/train/clip_fraction 0.16091
wandb:           PPO_1348/train/clip_range 0.2
wandb:         PPO_1348/train/entropy_loss -4.9795
wandb:   PPO_1348/train/explained_variance 0.98282
wandb:        PPO_1348/train/learning_rate 0.0003
wandb:                 PPO_1348/train/loss 218.25394
wandb: PPO_1348/train/policy_gradient_loss -0.00217
wandb:                  PPO_1348/train/std 0.49296
wandb:           PPO_1348/train/value_loss 668.21997
wandb:                PPO_1358/global_step 212992
wandb:        PPO_1358/rollout/ep_len_mean 200.0
wandb:        PPO_1358/rollout/ep_rew_mean -566.76184
wandb:                   PPO_1358/time/fps 603.0
wandb:            PPO_1358/train/approx_kl 0.01527
wandb:        PPO_1358/train/clip_fraction 0.17438
wandb:           PPO_1358/train/clip_range 0.2
wandb:         PPO_1358/train/entropy_loss -4.66892
wandb:   PPO_1358/train/explained_variance 0.98198
wandb:        PPO_1358/train/learning_rate 0.0003
wandb:                 PPO_1358/train/loss 775.52191
wandb: PPO_1358/train/policy_gradient_loss -0.00242
wandb:                  PPO_1358/train/std 0.47234
wandb:           PPO_1358/train/value_loss 544.29004
wandb:                PPO_1368/global_step 212992
wandb:        PPO_1368/rollout/ep_len_mean 200.0
wandb:        PPO_1368/rollout/ep_rew_mean -591.97894
wandb:                   PPO_1368/time/fps 603.0
wandb:            PPO_1368/train/approx_kl 0.01609
wandb:        PPO_1368/train/clip_fraction 0.25594
wandb:           PPO_1368/train/clip_range 0.2
wandb:         PPO_1368/train/entropy_loss -4.28729
wandb:   PPO_1368/train/explained_variance 0.98306
wandb:        PPO_1368/train/learning_rate 0.0003
wandb:                 PPO_1368/train/loss 38.86061
wandb: PPO_1368/train/policy_gradient_loss 0.00114
wandb:                  PPO_1368/train/std 0.44715
wandb:           PPO_1368/train/value_loss 425.39679
wandb:                PPO_1378/global_step 212992
wandb:        PPO_1378/rollout/ep_len_mean 200.0
wandb:        PPO_1378/rollout/ep_rew_mean -570.50494
wandb:                   PPO_1378/time/fps 604.0
wandb:            PPO_1378/train/approx_kl 0.01349
wandb:        PPO_1378/train/clip_fraction 0.21747
wandb:           PPO_1378/train/clip_range 0.2
wandb:         PPO_1378/train/entropy_loss -4.03545
wandb:   PPO_1378/train/explained_variance 0.98734
wandb:        PPO_1378/train/learning_rate 0.0003
wandb:                 PPO_1378/train/loss 254.70189
wandb: PPO_1378/train/policy_gradient_loss 0.00276
wandb:                  PPO_1378/train/std 0.43082
wandb:           PPO_1378/train/value_loss 774.4314
wandb:                    global_mean_eval -585.45343
wandb:                         global_step 212992
wandb:                       mean_reward_0 -550.34551
wandb:                       mean_reward_1 -607.23639
wandb:                      mean_reward_10 -541.60634
wandb:                      mean_reward_11 -556.2765
wandb:                      mean_reward_12 -598.84091
wandb:                      mean_reward_13 -604.38065
wandb:                      mean_reward_14 -590.85316
wandb:                      mean_reward_15 -614.2403
wandb:                      mean_reward_16 -623.10307
wandb:                      mean_reward_17 -693.69952
wandb:                      mean_reward_18 -599.03946
wandb:                      mean_reward_19 -527.12079
wandb:                       mean_reward_2 -636.5894
wandb:                      mean_reward_20 -593.52224
wandb:                      mean_reward_21 -512.83258
wandb:                      mean_reward_22 -580.6403
wandb:                      mean_reward_23 -539.15343
wandb:                      mean_reward_24 -616.59632
wandb:                      mean_reward_25 -578.38291
wandb:                      mean_reward_26 -637.88786
wandb:                      mean_reward_27 -650.81984
wandb:                      mean_reward_28 -559.43742
wandb:                      mean_reward_29 -568.37157
wandb:                       mean_reward_3 -596.22445
wandb:                      mean_reward_30 -543.69959
wandb:                      mean_reward_31 -597.97854
wandb:                      mean_reward_32 -641.83267
wandb:                      mean_reward_33 -586.64528
wandb:                      mean_reward_34 -578.35785
wandb:                      mean_reward_35 -586.08723
wandb:                       mean_reward_4 -619.55645
wandb:                       mean_reward_5 -538.85307
wandb:                       mean_reward_6 -456.35632
wandb:                       mean_reward_7 -575.36386
wandb:                       mean_reward_8 -589.33793
wandb:                       mean_reward_9 -585.05393
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -939.39148
wandb:                        std_reward_0 354.79289
wandb:                        std_reward_1 395.45364
wandb:                       std_reward_10 369.76622
wandb:                       std_reward_11 370.17749
wandb:                       std_reward_12 408.84645
wandb:                       std_reward_13 424.07685
wandb:                       std_reward_14 395.57651
wandb:                       std_reward_15 416.57923
wandb:                       std_reward_16 427.12893
wandb:                       std_reward_17 457.78585
wandb:                       std_reward_18 413.48022
wandb:                       std_reward_19 340.66245
wandb:                        std_reward_2 427.23622
wandb:                       std_reward_20 388.47772
wandb:                       std_reward_21 328.12504
wandb:                       std_reward_22 388.46005
wandb:                       std_reward_23 338.99712
wandb:                       std_reward_24 404.91467
wandb:                       std_reward_25 377.02306
wandb:                       std_reward_26 426.07803
wandb:                       std_reward_27 430.24919
wandb:                       std_reward_28 358.33016
wandb:                       std_reward_29 372.71553
wandb:                        std_reward_3 408.24533
wandb:                       std_reward_30 370.62899
wandb:                       std_reward_31 403.6844
wandb:                       std_reward_32 411.20217
wandb:                       std_reward_33 394.79641
wandb:                       std_reward_34 386.34175
wandb:                       std_reward_35 388.28665
wandb:                        std_reward_4 410.96251
wandb:                        std_reward_5 355.26455
wandb:                        std_reward_6 249.69963
wandb:                        std_reward_7 398.51302
wandb:                        std_reward_8 395.3954
wandb:                        std_reward_9 389.40886
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01128
wandb:                 train/clip_fraction 0.12654
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7942
wandb:            train/explained_variance 0.92484
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.3112
wandb:          train/policy_gradient_loss -0.0089
wandb:                           train/std 0.84816
wandb:                    train/value_loss 56.39774
wandb: 
wandb: Synced hearty-mountain-51: https://wandb.ai/tidiane/meta_rl_context/runs/1mmglo7l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 14 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-1mmglo7l/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1299/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1299/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1299/rollout/ep_rew_mean â–â–â–ƒâ–‚â–ƒâ–„â–„â–†â–…â–‡â–‡â–ˆ
wandb:                   PPO_1299/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1299/train/approx_kl â–‚â–„â–‚â–‚â–â–„â–ˆâ–ˆâ–…â–ˆâ–ƒ
wandb:        PPO_1299/train/clip_fraction â–„â–ƒâ–ƒâ–ƒâ–â–…â–ˆâ–…â–†â–‡â–„
wandb:           PPO_1299/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1299/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1299/train/explained_variance â–ƒâ–†â–‡â–ˆâ–ƒâ–…â–†â–„â–†â–â–ƒ
wandb:        PPO_1299/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1299/train/loss â–‚â–â–‡â–„â–†â–„â–†â–ˆâ–„â–‡â–„
wandb: PPO_1299/train/policy_gradient_loss â–â–ƒâ–ƒâ–†â–ˆâ–‡â–…â–‚â–„â–„â–…
wandb:                  PPO_1299/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1299/train/value_loss â–â–‚â–‚â–ƒâ–†â–…â–„â–…â–„â–…â–ˆ
wandb:                PPO_1310/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1310/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1310/rollout/ep_rew_mean â–â–‚â–â–‚â–‚â–„â–…â–…â–†â–†â–†â–ˆ
wandb:                   PPO_1310/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1310/train/approx_kl â–â–ƒâ–ƒâ–â–â–…â–â–†â–„â–‡â–ˆ
wandb:        PPO_1310/train/clip_fraction â–â–‚â–‚â–‚â–â–„â–ƒâ–…â–„â–†â–ˆ
wandb:           PPO_1310/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1310/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1310/train/explained_variance â–‡â–…â–…â–„â–„â–ƒâ–…â–â–‚â–ƒâ–ˆ
wandb:        PPO_1310/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1310/train/loss â–ƒâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚
wandb: PPO_1310/train/policy_gradient_loss â–„â–„â–ƒâ–â–ˆâ–†â–‡â–…â–„â–„â–‡
wandb:                  PPO_1310/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1310/train/value_loss â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–„â–„â–‚â–‚â–
wandb:                PPO_1320/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1320/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1320/rollout/ep_rew_mean â–‚â–â–‚â–ƒâ–„â–„â–„â–…â–†â–…â–†â–ˆ
wandb:                   PPO_1320/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1320/train/approx_kl â–…â–ƒâ–‡â–ƒâ–‡â–†â–ˆâ–ƒâ–‚â–â–†
wandb:        PPO_1320/train/clip_fraction â–ƒâ–†â–‡â–â–‡â–ˆâ–„â–‡â–ƒâ–†â–‡
wandb:           PPO_1320/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1320/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1320/train/explained_variance â–‚â–‚â–„â–…â–„â–ƒâ–â–„â–ƒâ–‡â–ˆ
wandb:        PPO_1320/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1320/train/loss â–ƒâ–‚â–â–‚â–â–ƒâ–…â–‚â–ˆâ–†â–
wandb: PPO_1320/train/policy_gradient_loss â–ƒâ–ƒâ–„â–„â–â–‚â–‚â–…â–…â–†â–ˆ
wandb:                  PPO_1320/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1320/train/value_loss â–†â–…â–â–…â–‡â–â–†â–ƒâ–ˆâ–ˆâ–„
wandb:                PPO_1330/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1330/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1330/rollout/ep_rew_mean â–„â–ƒâ–ƒâ–†â–„â–â–ƒâ–„â–†â–†â–†â–ˆ
wandb:                   PPO_1330/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1330/train/approx_kl â–„â–‚â–â–ˆâ–ƒâ–ˆâ–…â–…â–„â–…â–‚
wandb:        PPO_1330/train/clip_fraction â–…â–ƒâ–â–ˆâ–‚â–ˆâ–†â–…â–„â–ˆâ–
wandb:           PPO_1330/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1330/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1330/train/explained_variance â–†â–…â–ˆâ–„â–‚â–…â–â–‡â–„â–ˆâ–
wandb:        PPO_1330/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1330/train/loss â–â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–ˆ
wandb: PPO_1330/train/policy_gradient_loss â–â–‚â–‡â–ƒâ–ƒâ–ƒâ–„â–…â–â–ˆâ–„
wandb:                  PPO_1330/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1330/train/value_loss â–â–ƒâ–…â–‚â–…â–†â–â–„â–‡â–ƒâ–ˆ
wandb:                PPO_1341/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1341/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1341/rollout/ep_rew_mean â–…â–„â–ƒâ–ƒâ–ƒâ–â–…â–„â–„â–„â–ƒâ–ˆ
wandb:                   PPO_1341/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1341/train/approx_kl â–ˆâ–„â–â–…â–…â–…â–‚â–â–â–‚â–†
wandb:        PPO_1341/train/clip_fraction â–„â–ˆâ–â–†â–ƒâ–„â–„â–‚â–‚â–„â–„
wandb:           PPO_1341/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1341/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–ˆ
wandb:   PPO_1341/train/explained_variance â–…â–†â–â–„â–„â–‡â–†â–†â–‡â–ˆâ–ˆ
wandb:        PPO_1341/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1341/train/loss â–ƒâ–‚â–â–…â–ƒâ–ˆâ–â–„â–ˆâ–ƒâ–ƒ
wandb: PPO_1341/train/policy_gradient_loss â–ƒâ–ˆâ–‡â–â–â–ƒâ–†â–„â–â–‚â–ƒ
wandb:                  PPO_1341/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1341/train/value_loss â–…â–†â–‡â–â–…â–„â–‡â–„â–„â–„â–ˆ
wandb:                PPO_1351/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1351/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1351/rollout/ep_rew_mean â–…â–â–‚â–„â–†â–‡â–ƒâ–‡â–†â–†â–ˆâ–ƒ
wandb:                   PPO_1351/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1351/train/approx_kl â–‡â–‡â–‚â–†â–‚â–„â–‚â–ˆâ–â–„â–†
wandb:        PPO_1351/train/clip_fraction â–ƒâ–â–„â–…â–ƒâ–ƒâ–„â–ˆâ–‚â–†â–†
wandb:           PPO_1351/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1351/train/entropy_loss â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:   PPO_1351/train/explained_variance â–‚â–â–…â–…â–‚â–…â–„â–â–ƒâ–†â–ˆ
wandb:        PPO_1351/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1351/train/loss â–ƒâ–ˆâ–†â–ƒâ–„â–â–ˆâ–ƒâ–ƒâ–„â–…
wandb: PPO_1351/train/policy_gradient_loss â–„â–â–ƒâ–‚â–ƒâ–ˆâ–â–…â–â–…â–‚
wandb:                  PPO_1351/train/std â–‡â–ˆâ–‡â–†â–†â–†â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1351/train/value_loss â–â–…â–…â–„â–…â–ƒâ–‡â–‚â–ˆâ–‚â–
wandb:                PPO_1360/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1360/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1360/rollout/ep_rew_mean â–†â–„â–ƒâ–‚â–‚â–‚â–…â–„â–‚â–‡â–ˆâ–
wandb:                   PPO_1360/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1360/train/approx_kl â–ƒâ–„â–ˆâ–…â–„â–†â–‚â–‚â–ƒâ–â–ˆ
wandb:        PPO_1360/train/clip_fraction â–„â–†â–ˆâ–â–„â–†â–ƒâ–…â–„â–‚â–ˆ
wandb:           PPO_1360/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1360/train/entropy_loss â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–‡â–ˆ
wandb:   PPO_1360/train/explained_variance â–â–„â–†â–„â–ƒâ–†â–‡â–„â–ˆâ–ƒâ–†
wandb:        PPO_1360/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1360/train/loss â–â–‚â–„â–†â–…â–„â–ˆâ–…â–ƒâ–„â–†
wandb: PPO_1360/train/policy_gradient_loss â–†â–ˆâ–†â–â–†â–…â–…â–…â–‡â–ƒâ–„
wandb:                  PPO_1360/train/std â–ˆâ–‡â–†â–†â–†â–…â–…â–ƒâ–ƒâ–‚â–
wandb:           PPO_1360/train/value_loss â–‚â–ƒâ–â–ˆâ–…â–„â–…â–‡â–„â–…â–†
wandb:                PPO_1370/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1370/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1370/rollout/ep_rew_mean â–†â–…â–†â–†â–†â–†â–†â–…â–â–ƒâ–…â–ˆ
wandb:                   PPO_1370/time/fps â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1370/train/approx_kl â–‚â–‚â–„â–„â–‚â–â–†â–„â–‡â–ˆâ–ƒ
wandb:        PPO_1370/train/clip_fraction â–‚â–ƒâ–†â–…â–„â–â–ˆâ–‡â–…â–†â–…
wandb:           PPO_1370/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1370/train/entropy_loss â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ˆ
wandb:   PPO_1370/train/explained_variance â–…â–†â–ƒâ–‡â–‡â–ƒâ–â–„â–ˆâ–„â–†
wandb:        PPO_1370/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1370/train/loss â–‚â–ˆâ–‚â–â–…â–„â–ƒâ–‚â–‚â–‚â–†
wandb: PPO_1370/train/policy_gradient_loss â–â–„â–†â–†â–„â–…â–†â–„â–†â–‡â–ˆ
wandb:                  PPO_1370/train/std â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–†â–‡â–„â–
wandb:           PPO_1370/train/value_loss â–ƒâ–…â–ƒâ–ƒâ–â–ˆâ–‡â–„â–â–…â–†
wandb:                PPO_1380/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1380/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1380/rollout/ep_rew_mean â–â–ƒâ–„â–‡â–…â–â–†â–†â–‚â–…â–â–ˆ
wandb:                   PPO_1380/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1380/train/approx_kl â–ƒâ–â–†â–â–ˆâ–ƒâ–†â–†â–‡â–‚â–„
wandb:        PPO_1380/train/clip_fraction â–â–ƒâ–†â–„â–ˆâ–ƒâ–ˆâ–†â–ƒâ–„â–…
wandb:           PPO_1380/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1380/train/entropy_loss â–â–â–‚â–„â–„â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1380/train/explained_variance â–„â–…â–‡â–‚â–ƒâ–â–â–‡â–…â–ˆâ–…
wandb:        PPO_1380/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1380/train/loss â–ˆâ–„â–„â–„â–„â–‡â–‚â–„â–ƒâ–â–‚
wandb: PPO_1380/train/policy_gradient_loss â–ƒâ–„â–…â–„â–ˆâ–ƒâ–†â–„â–…â–â–…
wandb:                  PPO_1380/train/std â–ˆâ–ˆâ–‡â–…â–…â–„â–ƒâ–‚â–‚â–â–
wandb:           PPO_1380/train/value_loss â–‡â–…â–…â–ˆâ–„â–ˆâ–ƒâ–â–ƒâ–ƒâ–…
wandb:                    global_mean_eval â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–…â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_10 â–â–…â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–…â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_12 â–â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_13 â–â–…â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_14 â–â–…â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_15 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_18 â–â–„â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_19 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_2 â–â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_20 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_21 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_23 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_24 â–â–…â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_25 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_26 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_27 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_28 â–â–„â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_29 â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                       mean_reward_3 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_30 â–â–…â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_31 â–â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_32 â–â–…â–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_33 â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_35 â–â–„â–†â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                       mean_reward_5 â–â–„â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                       mean_reward_6 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_8 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                       mean_reward_9 â–â–„â–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–„â–„â–†â–‡â–‡â–ˆ
wandb:                        std_reward_0 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–†â–‡
wandb:                        std_reward_1 â–ƒâ–â–â–‚â–ƒâ–„â–„â–ˆâ–…â–‡
wandb:                       std_reward_10 â–„â–â–â–ƒâ–ƒâ–†â–„â–ˆâ–‡â–ˆ
wandb:                       std_reward_11 â–ƒâ–â–â–‚â–ƒâ–„â–ƒâ–ˆâ–‡â–‡
wandb:                       std_reward_12 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–‡â–‡
wandb:                       std_reward_13 â–ƒâ–â–â–ƒâ–ƒâ–…â–„â–ˆâ–‡â–†
wandb:                       std_reward_14 â–ƒâ–â–â–‚â–ƒâ–„â–„â–‡â–†â–ˆ
wandb:                       std_reward_15 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–†â–ˆ
wandb:                       std_reward_16 â–ƒâ–â–‚â–‚â–ƒâ–…â–„â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_17 â–ƒâ–â–â–‚â–ƒâ–…â–…â–ˆâ–ˆâ–‡
wandb:                       std_reward_18 â–ƒâ–â–â–‚â–‚â–„â–„â–ˆâ–‡â–…
wandb:                       std_reward_19 â–ƒâ–â–â–‚â–ƒâ–…â–ƒâ–ˆâ–†â–‡
wandb:                        std_reward_2 â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–ˆâ–‡â–†
wandb:                       std_reward_20 â–ƒâ–â–â–‚â–ƒâ–†â–„â–ˆâ–‡â–‡
wandb:                       std_reward_21 â–„â–â–‚â–ƒâ–ƒâ–†â–„â–ˆâ–ˆâ–‡
wandb:                       std_reward_22 â–ƒâ–â–â–ƒâ–ƒâ–…â–„â–ˆâ–‡â–‡
wandb:                       std_reward_23 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–ˆâ–‡
wandb:                       std_reward_24 â–ƒâ–â–â–ƒâ–‚â–„â–„â–ˆâ–‡â–†
wandb:                       std_reward_25 â–ƒâ–â–â–‚â–ƒâ–„â–„â–ˆâ–‡â–ˆ
wandb:                       std_reward_26 â–ƒâ–â–â–ƒâ–ƒâ–„â–„â–ˆâ–†â–‡
wandb:                       std_reward_27 â–ƒâ–â–â–ƒâ–ƒâ–†â–„â–ˆâ–ˆâ–‡
wandb:                       std_reward_28 â–ƒâ–â–â–ƒâ–ƒâ–„â–ƒâ–ˆâ–‡â–‡
wandb:                       std_reward_29 â–ƒâ–â–‚â–‚â–ƒâ–…â–„â–ˆâ–‡â–‡
wandb:                        std_reward_3 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–†â–ˆ
wandb:                       std_reward_30 â–ƒâ–â–â–‚â–‚â–„â–ƒâ–ˆâ–‡â–‡
wandb:                       std_reward_31 â–ƒâ–â–â–‚â–ƒâ–†â–„â–ˆâ–ˆâ–‡
wandb:                       std_reward_32 â–ƒâ–â–â–ƒâ–ƒâ–…â–„â–ˆâ–ˆâ–‡
wandb:                       std_reward_33 â–ƒâ–â–â–ƒâ–„â–†â–„â–ˆâ–†â–ˆ
wandb:                       std_reward_34 â–„â–â–‚â–ƒâ–ƒâ–†â–„â–ˆâ–‡â–ˆ
wandb:                       std_reward_35 â–ƒâ–â–â–‚â–ƒâ–„â–„â–ˆâ–†â–‡
wandb:                        std_reward_4 â–ƒâ–â–â–ƒâ–ƒâ–…â–„â–ˆâ–‡â–‡
wandb:                        std_reward_5 â–„â–â–‚â–ƒâ–ƒâ–…â–…â–‡â–†â–ˆ
wandb:                        std_reward_6 â–ƒâ–â–â–‚â–ƒâ–‡â–„â–‡â–‡â–ˆ
wandb:                        std_reward_7 â–ƒâ–â–â–‚â–ƒâ–…â–ƒâ–ˆâ–†â–ˆ
wandb:                        std_reward_8 â–ƒâ–â–‚â–ƒâ–ƒâ–…â–„â–ˆâ–ˆâ–ˆ
wandb:                        std_reward_9 â–ƒâ–â–â–‚â–ƒâ–…â–„â–ˆâ–‡â–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–â–‚â–ƒâ–ˆâ–†â–‚â–â–ƒâ–ƒâ–…â–„â–„
wandb:                 train/clip_fraction â–„â–„â–„â–…â–…â–‚â–â–„â–‡â–ˆâ–ˆâ–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–‚â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–…â–…â–…â–ˆâ–ˆâ–†â–„â–‚â–â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1299/global_step 212992
wandb:        PPO_1299/rollout/ep_len_mean 200.0
wandb:        PPO_1299/rollout/ep_rew_mean -816.10785
wandb:                   PPO_1299/time/fps 605.0
wandb:            PPO_1299/train/approx_kl 0.01152
wandb:        PPO_1299/train/clip_fraction 0.14532
wandb:           PPO_1299/train/clip_range 0.2
wandb:         PPO_1299/train/entropy_loss -7.74537
wandb:   PPO_1299/train/explained_variance 0.95942
wandb:        PPO_1299/train/learning_rate 0.0003
wandb:                 PPO_1299/train/loss 26.27252
wandb: PPO_1299/train/policy_gradient_loss -0.00723
wandb:                  PPO_1299/train/std 0.73185
wandb:           PPO_1299/train/value_loss 104.42182
wandb:                PPO_1310/global_step 212992
wandb:        PPO_1310/rollout/ep_len_mean 200.0
wandb:        PPO_1310/rollout/ep_rew_mean -680.54364
wandb:                   PPO_1310/time/fps 601.0
wandb:            PPO_1310/train/approx_kl 0.01628
wandb:        PPO_1310/train/clip_fraction 0.22734
wandb:           PPO_1310/train/clip_range 0.2
wandb:         PPO_1310/train/entropy_loss -6.83583
wandb:   PPO_1310/train/explained_variance 0.97101
wandb:        PPO_1310/train/learning_rate 0.0003
wandb:                 PPO_1310/train/loss 22.12281
wandb: PPO_1310/train/policy_gradient_loss -0.00618
wandb:                  PPO_1310/train/std 0.64236
wandb:           PPO_1310/train/value_loss 46.54818
wandb:                PPO_1320/global_step 212992
wandb:        PPO_1320/rollout/ep_len_mean 200.0
wandb:        PPO_1320/rollout/ep_rew_mean -594.95007
wandb:                   PPO_1320/time/fps 599.0
wandb:            PPO_1320/train/approx_kl 0.01647
wandb:        PPO_1320/train/clip_fraction 0.2158
wandb:           PPO_1320/train/clip_range 0.2
wandb:         PPO_1320/train/entropy_loss -5.9362
wandb:   PPO_1320/train/explained_variance 0.98002
wandb:        PPO_1320/train/learning_rate 0.0003
wandb:                 PPO_1320/train/loss 8.30973
wandb: PPO_1320/train/policy_gradient_loss -0.00115
wandb:                  PPO_1320/train/std 0.56422
wandb:           PPO_1320/train/value_loss 37.94209
wandb:                PPO_1330/global_step 212992
wandb:        PPO_1330/rollout/ep_len_mean 200.0
wandb:        PPO_1330/rollout/ep_rew_mean -563.10492
wandb:                   PPO_1330/time/fps 601.0
wandb:            PPO_1330/train/approx_kl 0.01572
wandb:        PPO_1330/train/clip_fraction 0.20475
wandb:           PPO_1330/train/clip_range 0.2
wandb:         PPO_1330/train/entropy_loss -5.29397
wandb:   PPO_1330/train/explained_variance 0.96393
wandb:        PPO_1330/train/learning_rate 0.0003
wandb:                 PPO_1330/train/loss 66.08321
wandb: PPO_1330/train/policy_gradient_loss -0.00238
wandb:                  PPO_1330/train/std 0.51643
wandb:           PPO_1330/train/value_loss 71.11455
wandb:                PPO_1341/global_step 212992
wandb:        PPO_1341/rollout/ep_len_mean 200.0
wandb:        PPO_1341/rollout/ep_rew_mean -512.79059
wandb:                   PPO_1341/time/fps 599.0
wandb:            PPO_1341/train/approx_kl 0.01851
wandb:        PPO_1341/train/clip_fraction 0.22601
wandb:           PPO_1341/train/clip_range 0.2
wandb:         PPO_1341/train/entropy_loss -4.78268
wandb:   PPO_1341/train/explained_variance 0.97956
wandb:        PPO_1341/train/learning_rate 0.0003
wandb:                 PPO_1341/train/loss 29.97879
wandb: PPO_1341/train/policy_gradient_loss -0.00188
wandb:                  PPO_1341/train/std 0.47902
wandb:           PPO_1341/train/value_loss 82.59895
wandb:                PPO_1351/global_step 212992
wandb:        PPO_1351/rollout/ep_len_mean 200.0
wandb:        PPO_1351/rollout/ep_rew_mean -540.96838
wandb:                   PPO_1351/time/fps 601.0
wandb:            PPO_1351/train/approx_kl 0.0173
wandb:        PPO_1351/train/clip_fraction 0.23205
wandb:           PPO_1351/train/clip_range 0.2
wandb:         PPO_1351/train/entropy_loss -4.39432
wandb:   PPO_1351/train/explained_variance 0.98789
wandb:        PPO_1351/train/learning_rate 0.0003
wandb:                 PPO_1351/train/loss 44.4884
wandb: PPO_1351/train/policy_gradient_loss -0.00265
wandb:                  PPO_1351/train/std 0.45321
wandb:           PPO_1351/train/value_loss 71.21587
wandb:                PPO_1360/global_step 212992
wandb:        PPO_1360/rollout/ep_len_mean 200.0
wandb:        PPO_1360/rollout/ep_rew_mean -528.23511
wandb:                   PPO_1360/time/fps 598.0
wandb:            PPO_1360/train/approx_kl 0.02029
wandb:        PPO_1360/train/clip_fraction 0.2513
wandb:           PPO_1360/train/clip_range 0.2
wandb:         PPO_1360/train/entropy_loss -3.97252
wandb:   PPO_1360/train/explained_variance 0.98611
wandb:        PPO_1360/train/learning_rate 0.0003
wandb:                 PPO_1360/train/loss 49.81297
wandb: PPO_1360/train/policy_gradient_loss -0.0015
wandb:                  PPO_1360/train/std 0.42787
wandb:           PPO_1360/train/value_loss 95.94772
wandb:                PPO_1370/global_step 212992
wandb:        PPO_1370/rollout/ep_len_mean 200.0
wandb:        PPO_1370/rollout/ep_rew_mean -492.89557
wandb:                   PPO_1370/time/fps 599.0
wandb:            PPO_1370/train/approx_kl 0.01753
wandb:        PPO_1370/train/clip_fraction 0.2366
wandb:           PPO_1370/train/clip_range 0.2
wandb:         PPO_1370/train/entropy_loss -3.71181
wandb:   PPO_1370/train/explained_variance 0.98843
wandb:        PPO_1370/train/learning_rate 0.0003
wandb:                 PPO_1370/train/loss 80.57842
wandb: PPO_1370/train/policy_gradient_loss 0.00111
wandb:                  PPO_1370/train/std 0.41132
wandb:           PPO_1370/train/value_loss 147.70277
wandb:                PPO_1380/global_step 212992
wandb:        PPO_1380/rollout/ep_len_mean 200.0
wandb:        PPO_1380/rollout/ep_rew_mean -482.48633
wandb:                   PPO_1380/time/fps 596.0
wandb:            PPO_1380/train/approx_kl 0.02061
wandb:        PPO_1380/train/clip_fraction 0.25441
wandb:           PPO_1380/train/clip_range 0.2
wandb:         PPO_1380/train/entropy_loss -3.35942
wandb:   PPO_1380/train/explained_variance 0.98871
wandb:        PPO_1380/train/learning_rate 0.0003
wandb:                 PPO_1380/train/loss 35.15711
wandb: PPO_1380/train/policy_gradient_loss 0.00143
wandb:                  PPO_1380/train/std 0.39148
wandb:           PPO_1380/train/value_loss 116.11802
wandb:                    global_mean_eval -464.28211
wandb:                         global_step 212992
wandb:                       mean_reward_0 -460.80676
wandb:                       mean_reward_1 -461.12579
wandb:                      mean_reward_10 -465.05369
wandb:                      mean_reward_11 -456.77135
wandb:                      mean_reward_12 -476.54181
wandb:                      mean_reward_13 -450.8529
wandb:                      mean_reward_14 -489.85206
wandb:                      mean_reward_15 -460.63691
wandb:                      mean_reward_16 -469.58486
wandb:                      mean_reward_17 -465.87663
wandb:                      mean_reward_18 -445.5069
wandb:                      mean_reward_19 -474.94796
wandb:                       mean_reward_2 -444.96009
wandb:                      mean_reward_20 -448.07496
wandb:                      mean_reward_21 -457.49113
wandb:                      mean_reward_22 -458.86729
wandb:                      mean_reward_23 -480.83348
wandb:                      mean_reward_24 -464.34645
wandb:                      mean_reward_25 -475.13636
wandb:                      mean_reward_26 -461.86032
wandb:                      mean_reward_27 -448.89439
wandb:                      mean_reward_28 -449.94301
wandb:                      mean_reward_29 -453.9734
wandb:                       mean_reward_3 -491.07002
wandb:                      mean_reward_30 -472.49038
wandb:                      mean_reward_31 -453.51761
wandb:                      mean_reward_32 -452.37608
wandb:                      mean_reward_33 -472.60163
wandb:                      mean_reward_34 -485.7428
wandb:                      mean_reward_35 -448.83999
wandb:                       mean_reward_4 -452.46611
wandb:                       mean_reward_5 -479.88679
wandb:                       mean_reward_6 -479.83903
wandb:                       mean_reward_7 -469.27658
wandb:                       mean_reward_8 -473.25627
wandb:                       mean_reward_9 -460.85434
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -901.89819
wandb:                        std_reward_0 159.53119
wandb:                        std_reward_1 166.317
wandb:                       std_reward_10 153.81947
wandb:                       std_reward_11 154.90922
wandb:                       std_reward_12 164.37992
wandb:                       std_reward_13 142.59854
wandb:                       std_reward_14 178.98849
wandb:                       std_reward_15 161.97997
wandb:                       std_reward_16 158.02886
wandb:                       std_reward_17 140.80068
wandb:                       std_reward_18 130.13637
wandb:                       std_reward_19 169.21654
wandb:                        std_reward_2 147.5925
wandb:                       std_reward_20 146.42237
wandb:                       std_reward_21 142.84923
wandb:                       std_reward_22 150.58497
wandb:                       std_reward_23 155.59811
wandb:                       std_reward_24 153.05012
wandb:                       std_reward_25 162.11926
wandb:                       std_reward_26 159.20288
wandb:                       std_reward_27 150.72958
wandb:                       std_reward_28 154.99191
wandb:                       std_reward_29 151.97536
wandb:                        std_reward_3 168.29096
wandb:                       std_reward_30 173.93184
wandb:                       std_reward_31 154.58948
wandb:                       std_reward_32 150.74663
wandb:                       std_reward_33 171.37473
wandb:                       std_reward_34 157.08061
wandb:                       std_reward_35 155.64454
wandb:                        std_reward_4 157.66341
wandb:                        std_reward_5 165.05926
wandb:                        std_reward_6 164.45607
wandb:                        std_reward_7 169.36916
wandb:                        std_reward_8 157.92744
wandb:                        std_reward_9 170.54831
wandb:                            time/fps 597.0
wandb:                     train/approx_kl 0.0106
wandb:                 train/clip_fraction 0.13875
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.80915
wandb:            train/explained_variance 0.95603
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 9.91018
wandb:          train/policy_gradient_loss -0.00981
wandb:                           train/std 0.84977
wandb:                    train/value_loss 25.25248
wandb: 
wandb: Synced lyric-morning-48: https://wandb.ai/tidiane/meta_rl_context/runs/1gp8uu9i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-1gp8uu9i/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1298/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1298/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1298/rollout/ep_rew_mean â–â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆ
wandb:                   PPO_1298/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1298/train/approx_kl â–ƒâ–â–…â–„â–†â–…â–†â–„â–†â–ˆâ–†
wandb:        PPO_1298/train/clip_fraction â–ƒâ–â–…â–„â–…â–„â–†â–…â–…â–ˆâ–†
wandb:           PPO_1298/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1298/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1298/train/explained_variance â–â–ˆâ–†â–‡â–„â–ƒâ–…â–‡â–…â–„â–
wandb:        PPO_1298/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1298/train/loss â–…â–„â–‚â–ƒâ–ƒâ–ˆâ–…â–â–„â–â–‚
wandb: PPO_1298/train/policy_gradient_loss â–…â–‡â–ƒâ–…â–„â–…â–„â–†â–†â–â–ˆ
wandb:                  PPO_1298/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1298/train/value_loss â–â–„â–‚â–„â–„â–ˆâ–ƒâ–ƒâ–„â–‚â–„
wandb:                PPO_1309/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1309/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1309/rollout/ep_rew_mean â–â–â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–ˆ
wandb:                   PPO_1309/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1309/train/approx_kl â–„â–ƒâ–ƒâ–‚â–â–„â–‚â–ˆâ–…â–…â–‡
wandb:        PPO_1309/train/clip_fraction â–‚â–â–‚â–ƒâ–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–ˆ
wandb:           PPO_1309/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1309/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1309/train/explained_variance â–â–„â–‚â–…â–ƒâ–„â–„â–†â–ƒâ–‡â–ˆ
wandb:        PPO_1309/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1309/train/loss â–…â–ƒâ–ˆâ–ˆâ–‚â–„â–‡â–‡â–â–„â–‚
wandb: PPO_1309/train/policy_gradient_loss â–ƒâ–ƒâ–â–„â–ˆâ–…â–ˆâ–‡â–ˆâ–†â–ˆ
wandb:                  PPO_1309/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1309/train/value_loss â–‡â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–…â–…â–‚â–ƒâ–
wandb:                PPO_1319/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1319/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1319/rollout/ep_rew_mean â–â–‚â–‚â–ƒâ–„â–ƒâ–…â–†â–‡â–†â–‡â–ˆ
wandb:                   PPO_1319/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1319/train/approx_kl â–„â–ƒâ–ƒâ–„â–‚â–…â–â–ƒâ–â–ˆâ–ƒ
wandb:        PPO_1319/train/clip_fraction â–†â–„â–ˆâ–‡â–‚â–†â–â–ˆâ–ƒâ–‡â–ƒ
wandb:           PPO_1319/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1319/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1319/train/explained_variance â–„â–…â–ˆâ–ˆâ–ƒâ–…â–…â–‡â–â–‚â–
wandb:        PPO_1319/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1319/train/loss â–‚â–„â–†â–ƒâ–†â–‚â–…â–ˆâ–â–‡â–…
wandb: PPO_1319/train/policy_gradient_loss â–â–‚â–â–ƒâ–…â–ƒâ–…â–ˆâ–„â–…â–„
wandb:                  PPO_1319/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1319/train/value_loss â–…â–â–â–‚â–„â–…â–ˆâ–ƒâ–„â–ˆâ–‡
wandb:                PPO_1329/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1329/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1329/rollout/ep_rew_mean â–â–„â–ƒâ–…â–†â–ˆâ–„â–‚â–†â–ˆâ–„â–„
wandb:                   PPO_1329/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1329/train/approx_kl â–‚â–…â–ƒâ–…â–ƒâ–ˆâ–ƒâ–â–ƒâ–‚â–ƒ
wandb:        PPO_1329/train/clip_fraction â–‚â–ˆâ–â–ˆâ–„â–ƒâ–ƒâ–â–‚â–„â–„
wandb:           PPO_1329/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1329/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1329/train/explained_variance â–ˆâ–‡â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–…â–‡
wandb:        PPO_1329/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1329/train/loss â–…â–â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚
wandb: PPO_1329/train/policy_gradient_loss â–â–„â–ˆâ–†â–â–…â–„â–…â–„â–„â–…
wandb:                  PPO_1329/train/std â–ˆâ–‡â–‡â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1329/train/value_loss â–„â–â–…â–‚â–„â–ƒâ–†â–†â–ˆâ–†â–‡
wandb:                PPO_1339/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1339/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1339/rollout/ep_rew_mean â–ƒâ–ƒâ–…â–…â–…â–…â–ƒâ–â–†â–ˆâ–‚â–…
wandb:                   PPO_1339/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1339/train/approx_kl â–…â–„â–†â–ˆâ–‡â–„â–„â–â–…â–†â–†
wandb:        PPO_1339/train/clip_fraction â–â–ˆâ–…â–ˆâ–„â–â–†â–…â–„â–‡â–…
wandb:           PPO_1339/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1339/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1339/train/explained_variance â–„â–â–…â–†â–†â–‡â–…â–‡â–‚â–„â–ˆ
wandb:        PPO_1339/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1339/train/loss â–…â–â–ƒâ–â–‚â–‡â–…â–„â–ˆâ–‚â–‚
wandb: PPO_1339/train/policy_gradient_loss â–‚â–â–ˆâ–†â–‚â–ƒâ–‡â–†â–…â–ƒâ–ƒ
wandb:                  PPO_1339/train/std â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1339/train/value_loss â–„â–â–„â–‚â–ƒâ–†â–‡â–†â–ˆâ–‡â–„
wandb:                PPO_1350/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1350/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1350/rollout/ep_rew_mean â–ˆâ–„â–†â–‡â–…â–…â–â–…â–ˆâ–„â–â–ˆ
wandb:                   PPO_1350/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1350/train/approx_kl â–‡â–ƒâ–†â–‡â–†â–„â–†â–‚â–ˆâ–…â–
wandb:        PPO_1350/train/clip_fraction â–…â–‚â–ˆâ–ƒâ–„â–„â–â–ƒâ–…â–â–‚
wandb:           PPO_1350/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1350/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1350/train/explained_variance â–‡â–†â–ˆâ–…â–â–†â–‡â–ƒâ–†â–†â–‡
wandb:        PPO_1350/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1350/train/loss â–„â–ƒâ–‚â–ˆâ–ƒâ–â–‚â–„â–‚â–„â–‚
wandb: PPO_1350/train/policy_gradient_loss â–‚â–‚â–…â–„â–â–â–â–ˆâ–‡â–ƒâ–†
wandb:                  PPO_1350/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–…â–„â–„â–‚â–
wandb:           PPO_1350/train/value_loss â–â–‚â–â–„â–…â–‚â–…â–…â–ƒâ–ˆâ–†
wandb:                PPO_1361/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1361/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1361/rollout/ep_rew_mean â–…â–†â–ˆâ–†â–…â–‚â–…â–ˆâ–ˆâ–‡â–â–ˆ
wandb:                   PPO_1361/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1361/train/approx_kl â–ƒâ–‚â–‚â–‚â–â–ˆâ–â–ƒâ–„â–â–‚
wandb:        PPO_1361/train/clip_fraction â–ƒâ–„â–‡â–„â–‚â–‡â–ƒâ–ˆâ–†â–â–…
wandb:           PPO_1361/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1361/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1361/train/explained_variance â–ƒâ–‚â–†â–‡â–ƒâ–ˆâ–†â–„â–†â–â–†
wandb:        PPO_1361/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1361/train/loss â–ƒâ–â–â–ƒâ–ˆâ–‚â–‚â–„â–â–…â–ƒ
wandb: PPO_1361/train/policy_gradient_loss â–…â–†â–â–‡â–…â–…â–†â–ˆâ–†â–ƒâ–‡
wandb:                  PPO_1361/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1361/train/value_loss â–ƒâ–„â–â–‚â–…â–â–ƒâ–‚â–ƒâ–ˆâ–…
wandb:                PPO_1371/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1371/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1371/rollout/ep_rew_mean â–…â–…â–ˆâ–„â–„â–…â–â–â–â–â–ƒâ–ƒ
wandb:                   PPO_1371/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1371/train/approx_kl â–…â–ƒâ–…â–‚â–‚â–ˆâ–„â–„â–‚â–ƒâ–
wandb:        PPO_1371/train/clip_fraction â–ˆâ–ˆâ–ˆâ–ƒâ–…â–‡â–‡â–†â–â–†â–‚
wandb:           PPO_1371/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1371/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1371/train/explained_variance â–ƒâ–…â–…â–„â–â–„â–‡â–ˆâ–„â–ƒâ–„
wandb:        PPO_1371/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1371/train/loss â–â–‚â–„â–†â–â–ƒâ–ƒâ–ƒâ–„â–ˆâ–ƒ
wandb: PPO_1371/train/policy_gradient_loss â–ˆâ–…â–†â–„â–â–†â–…â–†â–‚â–ƒâ–‚
wandb:                  PPO_1371/train/std â–ˆâ–ˆâ–‡â–†â–…â–…â–„â–…â–ƒâ–ƒâ–
wandb:           PPO_1371/train/value_loss â–â–‚â–â–„â–„â–…â–ƒâ–ƒâ–ˆâ–‡â–ˆ
wandb:                PPO_1381/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1381/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1381/rollout/ep_rew_mean â–ˆâ–†â–…â–„â–‚â–‚â–„â–„â–ˆâ–‚â–‚â–
wandb:                   PPO_1381/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1381/train/approx_kl â–‚â–‚â–ˆâ–ƒâ–â–‚â–…â–…â–‚â–‚â–‚
wandb:        PPO_1381/train/clip_fraction â–ˆâ–ƒâ–„â–â–‚â–ƒâ–„â–…â–„â–ƒâ–
wandb:           PPO_1381/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1381/train/entropy_loss â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–‡â–ˆ
wandb:   PPO_1381/train/explained_variance â–…â–…â–†â–…â–â–‡â–„â–„â–†â–ˆâ–‡
wandb:        PPO_1381/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1381/train/loss â–â–‚â–â–†â–„â–„â–ˆâ–‚â–â–„â–ƒ
wandb: PPO_1381/train/policy_gradient_loss â–ˆâ–‚â–†â–â–…â–…â–„â–„â–†â–ƒâ–ƒ
wandb:                  PPO_1381/train/std â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–‚â–‚â–
wandb:           PPO_1381/train/value_loss â–‚â–…â–ƒâ–†â–ˆâ–„â–†â–ˆâ–â–â–†
wandb:                    global_mean_eval â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–„â–ˆ
wandb:                       mean_reward_1 â–â–ƒâ–†â–‡â–‡â–ˆâ–†â–ˆâ–„â–‡
wandb:                      mean_reward_10 â–â–ƒâ–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†
wandb:                      mean_reward_11 â–â–„â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_12 â–â–ƒâ–†â–ˆâ–‡â–‡â–†â–ˆâ–‡â–‡
wandb:                      mean_reward_13 â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–†â–ˆ
wandb:                      mean_reward_14 â–â–„â–†â–‡â–ˆâ–‡â–ˆâ–‡â–†â–ˆ
wandb:                      mean_reward_15 â–â–„â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–â–„â–†â–ˆâ–‡â–ˆâ–†â–‡â–‡â–ˆ
wandb:                      mean_reward_17 â–â–„â–†â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆ
wandb:                      mean_reward_18 â–â–„â–†â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡
wandb:                      mean_reward_19 â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†
wandb:                       mean_reward_2 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_20 â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_21 â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†
wandb:                      mean_reward_22 â–â–ƒâ–…â–‡â–ˆâ–‡â–†â–†â–‡â–†
wandb:                      mean_reward_23 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_24 â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_25 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_26 â–â–ƒâ–†â–‡â–‡â–ˆâ–†â–†â–„â–‡
wandb:                      mean_reward_27 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–ˆ
wandb:                      mean_reward_28 â–â–ƒâ–†â–‡â–‡â–‡â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_29 â–â–„â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_3 â–â–ƒâ–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–…â–†
wandb:                      mean_reward_30 â–â–ƒâ–†â–ˆâ–ˆâ–‡â–†â–‡â–†â–ˆ
wandb:                      mean_reward_31 â–â–„â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–‡
wandb:                      mean_reward_32 â–â–ƒâ–…â–‡â–‡â–ˆâ–ˆâ–‡â–„â–‡
wandb:                      mean_reward_33 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_34 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_35 â–â–ƒâ–†â–‡â–‡â–ˆâ–†â–ˆâ–…â–‡
wandb:                       mean_reward_4 â–â–„â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_5 â–â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–†â–…â–…
wandb:                       mean_reward_6 â–â–„â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡
wandb:                       mean_reward_7 â–â–ƒâ–†â–ˆâ–ˆâ–ˆâ–†â–†â–‡â–‡
wandb:                       mean_reward_8 â–â–„â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–‡
wandb:                       mean_reward_9 â–â–„â–†â–ˆâ–ˆâ–‡â–†â–‡â–†â–‡
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–‡â–‡â–‡â–ˆâ–†
wandb:                        std_reward_0 â–‚â–â–â–â–ƒâ–„â–…â–†â–ˆâ–†
wandb:                        std_reward_1 â–ƒâ–â–â–‚â–„â–„â–…â–…â–ˆâ–†
wandb:                       std_reward_10 â–ƒâ–â–â–‚â–„â–…â–‡â–†â–ˆâ–ˆ
wandb:                       std_reward_11 â–ƒâ–â–â–â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_12 â–ƒâ–â–â–‚â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb:                       std_reward_13 â–‚â–â–â–‚â–ƒâ–„â–…â–†â–ˆâ–‡
wandb:                       std_reward_14 â–ƒâ–â–â–‚â–ƒâ–…â–…â–†â–ˆâ–†
wandb:                       std_reward_15 â–ƒâ–â–â–‚â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:                       std_reward_16 â–ƒâ–â–â–‚â–„â–…â–‡â–‡â–ˆâ–‡
wandb:                       std_reward_17 â–ƒâ–â–â–‚â–ƒâ–…â–…â–†â–ˆâ–‡
wandb:                       std_reward_18 â–ƒâ–â–â–â–ƒâ–„â–†â–†â–ˆâ–‡
wandb:                       std_reward_19 â–ƒâ–â–â–‚â–ƒâ–„â–†â–†â–ˆâ–‡
wandb:                        std_reward_2 â–ƒâ–â–â–‚â–„â–…â–†â–‡â–‡â–ˆ
wandb:                       std_reward_20 â–ƒâ–â–â–‚â–ƒâ–…â–†â–†â–‡â–ˆ
wandb:                       std_reward_21 â–ƒâ–â–â–‚â–„â–„â–†â–…â–ˆâ–ˆ
wandb:                       std_reward_22 â–ƒâ–â–â–‚â–ƒâ–„â–‡â–‡â–‡â–ˆ
wandb:                       std_reward_23 â–‚â–â–â–â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb:                       std_reward_24 â–ƒâ–â–â–‚â–„â–…â–‡â–†â–ˆâ–‡
wandb:                       std_reward_25 â–ƒâ–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                       std_reward_26 â–ƒâ–â–â–‚â–ƒâ–„â–†â–†â–ˆâ–†
wandb:                       std_reward_27 â–ƒâ–â–â–‚â–ƒâ–„â–†â–†â–ˆâ–†
wandb:                       std_reward_28 â–ƒâ–â–â–‚â–„â–…â–‡â–†â–ˆâ–‡
wandb:                       std_reward_29 â–ƒâ–â–â–‚â–ƒâ–…â–‡â–‡â–ˆâ–‡
wandb:                        std_reward_3 â–‚â–â–â–â–ƒâ–„â–…â–…â–ˆâ–‡
wandb:                       std_reward_30 â–ƒâ–â–â–â–ƒâ–„â–†â–†â–ˆâ–†
wandb:                       std_reward_31 â–ƒâ–â–â–â–„â–…â–†â–†â–ˆâ–ˆ
wandb:                       std_reward_32 â–ƒâ–â–â–â–ƒâ–„â–„â–†â–ˆâ–†
wandb:                       std_reward_33 â–ƒâ–â–â–‚â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb:                       std_reward_34 â–ƒâ–â–â–‚â–ƒâ–„â–†â–†â–ˆâ–†
wandb:                       std_reward_35 â–ƒâ–â–â–‚â–„â–„â–†â–…â–ˆâ–‡
wandb:                        std_reward_4 â–ƒâ–â–â–‚â–…â–…â–‡â–‡â–ˆâ–ˆ
wandb:                        std_reward_5 â–‚â–â–â–‚â–„â–„â–…â–†â–ˆâ–ˆ
wandb:                        std_reward_6 â–ƒâ–â–â–‚â–„â–„â–…â–†â–ˆâ–‡
wandb:                        std_reward_7 â–ƒâ–â–â–‚â–ƒâ–…â–‡â–‡â–‡â–ˆ
wandb:                        std_reward_8 â–ƒâ–â–â–‚â–„â–…â–†â–†â–ˆâ–‡
wandb:                        std_reward_9 â–ƒâ–â–â–‚â–ƒâ–…â–†â–†â–ˆâ–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–ƒâ–‚â–ƒâ–ˆâ–‡â–‚â–â–ƒâ–ƒâ–„â–„â–…
wandb:                 train/clip_fraction â–…â–„â–„â–…â–…â–‚â–â–…â–†â–ˆâ–‡â–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:                           train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1298/global_step 212992
wandb:        PPO_1298/rollout/ep_len_mean 200.0
wandb:        PPO_1298/rollout/ep_rew_mean -789.26703
wandb:                   PPO_1298/time/fps 598.0
wandb:            PPO_1298/train/approx_kl 0.012
wandb:        PPO_1298/train/clip_fraction 0.1514
wandb:           PPO_1298/train/clip_range 0.2
wandb:         PPO_1298/train/entropy_loss -7.75913
wandb:   PPO_1298/train/explained_variance 0.94998
wandb:        PPO_1298/train/learning_rate 0.0003
wandb:                 PPO_1298/train/loss 30.58978
wandb: PPO_1298/train/policy_gradient_loss -0.00627
wandb:                  PPO_1298/train/std 0.73354
wandb:           PPO_1298/train/value_loss 91.47829
wandb:                PPO_1309/global_step 212992
wandb:        PPO_1309/rollout/ep_len_mean 200.0
wandb:        PPO_1309/rollout/ep_rew_mean -649.00568
wandb:                   PPO_1309/time/fps 597.0
wandb:            PPO_1309/train/approx_kl 0.01503
wandb:        PPO_1309/train/clip_fraction 0.20412
wandb:           PPO_1309/train/clip_range 0.2
wandb:         PPO_1309/train/entropy_loss -6.84929
wandb:   PPO_1309/train/explained_variance 0.97387
wandb:        PPO_1309/train/learning_rate 0.0003
wandb:                 PPO_1309/train/loss 16.96134
wandb: PPO_1309/train/policy_gradient_loss -0.00501
wandb:                  PPO_1309/train/std 0.64469
wandb:           PPO_1309/train/value_loss 44.50845
wandb:                PPO_1319/global_step 212992
wandb:        PPO_1319/rollout/ep_len_mean 200.0
wandb:        PPO_1319/rollout/ep_rew_mean -560.24048
wandb:                   PPO_1319/time/fps 596.0
wandb:            PPO_1319/train/approx_kl 0.01604
wandb:        PPO_1319/train/clip_fraction 0.19731
wandb:           PPO_1319/train/clip_range 0.2
wandb:         PPO_1319/train/entropy_loss -5.96349
wandb:   PPO_1319/train/explained_variance 0.96896
wandb:        PPO_1319/train/learning_rate 0.0003
wandb:                 PPO_1319/train/loss 27.1461
wandb: PPO_1319/train/policy_gradient_loss -0.00414
wandb:                  PPO_1319/train/std 0.56806
wandb:           PPO_1319/train/value_loss 55.77895
wandb:                PPO_1329/global_step 212992
wandb:        PPO_1329/rollout/ep_len_mean 200.0
wandb:        PPO_1329/rollout/ep_rew_mean -543.48138
wandb:                   PPO_1329/time/fps 596.0
wandb:            PPO_1329/train/approx_kl 0.01561
wandb:        PPO_1329/train/clip_fraction 0.20561
wandb:           PPO_1329/train/clip_range 0.2
wandb:         PPO_1329/train/entropy_loss -5.45199
wandb:   PPO_1329/train/explained_variance 0.97
wandb:        PPO_1329/train/learning_rate 0.0003
wandb:                 PPO_1329/train/loss 23.32735
wandb: PPO_1329/train/policy_gradient_loss -0.00232
wandb:                  PPO_1329/train/std 0.52782
wandb:           PPO_1329/train/value_loss 64.57671
wandb:                PPO_1339/global_step 212992
wandb:        PPO_1339/rollout/ep_len_mean 200.0
wandb:        PPO_1339/rollout/ep_rew_mean -524.93781
wandb:                   PPO_1339/time/fps 596.0
wandb:            PPO_1339/train/approx_kl 0.01591
wandb:        PPO_1339/train/clip_fraction 0.20477
wandb:           PPO_1339/train/clip_range 0.2
wandb:         PPO_1339/train/entropy_loss -5.02296
wandb:   PPO_1339/train/explained_variance 0.98691
wandb:        PPO_1339/train/learning_rate 0.0003
wandb:                 PPO_1339/train/loss 16.10193
wandb: PPO_1339/train/policy_gradient_loss -0.0029
wandb:                  PPO_1339/train/std 0.4968
wandb:           PPO_1339/train/value_loss 74.32899
wandb:                PPO_1350/global_step 212992
wandb:        PPO_1350/rollout/ep_len_mean 200.0
wandb:        PPO_1350/rollout/ep_rew_mean -500.02206
wandb:                   PPO_1350/time/fps 595.0
wandb:            PPO_1350/train/approx_kl 0.01301
wandb:        PPO_1350/train/clip_fraction 0.19689
wandb:           PPO_1350/train/clip_range 0.2
wandb:         PPO_1350/train/entropy_loss -4.60574
wandb:   PPO_1350/train/explained_variance 0.98417
wandb:        PPO_1350/train/learning_rate 0.0003
wandb:                 PPO_1350/train/loss 35.27217
wandb: PPO_1350/train/policy_gradient_loss -0.00092
wandb:                  PPO_1350/train/std 0.46683
wandb:           PPO_1350/train/value_loss 155.52771
wandb:                PPO_1361/global_step 212992
wandb:        PPO_1361/rollout/ep_len_mean 200.0
wandb:        PPO_1361/rollout/ep_rew_mean -521.40625
wandb:                   PPO_1361/time/fps 595.0
wandb:            PPO_1361/train/approx_kl 0.0159
wandb:        PPO_1361/train/clip_fraction 0.21661
wandb:           PPO_1361/train/clip_range 0.2
wandb:         PPO_1361/train/entropy_loss -4.05229
wandb:   PPO_1361/train/explained_variance 0.98442
wandb:        PPO_1361/train/learning_rate 0.0003
wandb:                 PPO_1361/train/loss 106.86045
wandb: PPO_1361/train/policy_gradient_loss 0.00013
wandb:                  PPO_1361/train/std 0.43137
wandb:           PPO_1361/train/value_loss 239.77217
wandb:                PPO_1371/global_step 212992
wandb:        PPO_1371/rollout/ep_len_mean 200.0
wandb:        PPO_1371/rollout/ep_rew_mean -540.02673
wandb:                   PPO_1371/time/fps 594.0
wandb:            PPO_1371/train/approx_kl 0.01366
wandb:        PPO_1371/train/clip_fraction 0.19235
wandb:           PPO_1371/train/clip_range 0.2
wandb:         PPO_1371/train/entropy_loss -3.55667
wandb:   PPO_1371/train/explained_variance 0.98474
wandb:        PPO_1371/train/learning_rate 0.0003
wandb:                 PPO_1371/train/loss 78.27966
wandb: PPO_1371/train/policy_gradient_loss 0.00032
wandb:                  PPO_1371/train/std 0.40121
wandb:           PPO_1371/train/value_loss 503.16641
wandb:                PPO_1381/global_step 212992
wandb:        PPO_1381/rollout/ep_len_mean 200.0
wandb:        PPO_1381/rollout/ep_rew_mean -559.88934
wandb:                   PPO_1381/time/fps 593.0
wandb:            PPO_1381/train/approx_kl 0.01819
wandb:        PPO_1381/train/clip_fraction 0.22167
wandb:           PPO_1381/train/clip_range 0.2
wandb:         PPO_1381/train/entropy_loss -3.23325
wandb:   PPO_1381/train/explained_variance 0.98886
wandb:        PPO_1381/train/learning_rate 0.0003
wandb:                 PPO_1381/train/loss 123.14413
wandb: PPO_1381/train/policy_gradient_loss 0.00215
wandb:                  PPO_1381/train/std 0.38456
wandb:           PPO_1381/train/value_loss 376.5278
wandb:                    global_mean_eval -507.62096
wandb:                         global_step 212992
wandb:                       mean_reward_0 -499.84509
wandb:                       mean_reward_1 -494.29691
wandb:                      mean_reward_10 -545.75579
wandb:                      mean_reward_11 -516.13558
wandb:                      mean_reward_12 -526.31916
wandb:                      mean_reward_13 -485.00342
wandb:                      mean_reward_14 -486.66346
wandb:                      mean_reward_15 -474.91907
wandb:                      mean_reward_16 -476.54013
wandb:                      mean_reward_17 -477.06116
wandb:                      mean_reward_18 -505.72214
wandb:                      mean_reward_19 -534.49261
wandb:                       mean_reward_2 -508.94209
wandb:                      mean_reward_20 -525.46092
wandb:                      mean_reward_21 -539.07505
wandb:                      mean_reward_22 -549.48697
wandb:                      mean_reward_23 -518.43757
wandb:                      mean_reward_24 -497.82359
wandb:                      mean_reward_25 -511.77544
wandb:                      mean_reward_26 -509.94706
wandb:                      mean_reward_27 -486.69103
wandb:                      mean_reward_28 -476.60605
wandb:                      mean_reward_29 -485.41667
wandb:                       mean_reward_3 -534.80124
wandb:                      mean_reward_30 -484.91984
wandb:                      mean_reward_31 -526.51338
wandb:                      mean_reward_32 -486.67105
wandb:                      mean_reward_33 -497.92519
wandb:                      mean_reward_34 -481.39933
wandb:                      mean_reward_35 -511.88123
wandb:                       mean_reward_4 -487.77
wandb:                       mean_reward_5 -565.40151
wandb:                       mean_reward_6 -511.02496
wandb:                       mean_reward_7 -510.64272
wandb:                       mean_reward_8 -510.06075
wandb:                       mean_reward_9 -532.92651
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -939.39148
wandb:                        std_reward_0 238.69484
wandb:                        std_reward_1 227.70209
wandb:                       std_reward_10 261.35704
wandb:                       std_reward_11 243.93707
wandb:                       std_reward_12 250.47308
wandb:                       std_reward_13 226.07459
wandb:                       std_reward_14 220.90594
wandb:                       std_reward_15 232.93795
wandb:                       std_reward_16 229.53977
wandb:                       std_reward_17 216.84647
wandb:                       std_reward_18 240.49634
wandb:                       std_reward_19 266.03957
wandb:                        std_reward_2 245.88755
wandb:                       std_reward_20 261.89467
wandb:                       std_reward_21 262.17493
wandb:                       std_reward_22 260.0502
wandb:                       std_reward_23 243.1021
wandb:                       std_reward_24 233.4831
wandb:                       std_reward_25 244.40637
wandb:                       std_reward_26 239.73297
wandb:                       std_reward_27 234.06861
wandb:                       std_reward_28 210.2979
wandb:                       std_reward_29 231.9969
wandb:                        std_reward_3 253.80178
wandb:                       std_reward_30 216.10045
wandb:                       std_reward_31 251.32535
wandb:                       std_reward_32 230.16073
wandb:                       std_reward_33 242.60988
wandb:                       std_reward_34 213.60104
wandb:                       std_reward_35 250.87809
wandb:                        std_reward_4 223.49169
wandb:                        std_reward_5 276.38193
wandb:                        std_reward_6 249.95968
wandb:                        std_reward_7 254.53081
wandb:                        std_reward_8 244.64127
wandb:                        std_reward_9 258.64639
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01128
wandb:                 train/clip_fraction 0.12654
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7942
wandb:            train/explained_variance 0.92484
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.3112
wandb:          train/policy_gradient_loss -0.0089
wandb:                           train/std 0.84816
wandb:                    train/value_loss 56.39774
wandb: 
wandb: Synced zany-fire-50: https://wandb.ai/tidiane/meta_rl_context/runs/2uae6ict
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 14 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-2uae6ict/logs
wandb: 
wandb: Run history:
wandb:                PPO_1302/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1302/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1302/rollout/ep_rew_mean â–‚â–‚â–â–‚â–„â–…â–„â–…â–‡â–†â–‡â–ˆ
wandb:                   PPO_1302/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1302/train/approx_kl â–ƒâ–â–„â–‚â–‚â–‡â–…â–†â–‚â–ˆâ–ˆ
wandb:        PPO_1302/train/clip_fraction â–‚â–…â–„â–ƒâ–â–ˆâ–†â–ˆâ–†â–‡â–‡
wandb:           PPO_1302/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1302/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1302/train/explained_variance â–†â–†â–‡â–ˆâ–ˆâ–†â–ˆâ–†â–ƒâ–„â–
wandb:        PPO_1302/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1302/train/loss â–â–‚â–â–â–„â–„â–„â–„â–ˆâ–„â–ƒ
wandb: PPO_1302/train/policy_gradient_loss â–ƒâ–ƒâ–ƒâ–‡â–‡â–â–‚â–…â–ˆâ–„â–‡
wandb:                  PPO_1302/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1302/train/value_loss â–â–â–‚â–‚â–‡â–ƒâ–„â–…â–ˆâ–‡â–†
wandb:                PPO_1312/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1312/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1312/rollout/ep_rew_mean â–â–‚â–â–ƒâ–„â–ƒâ–†â–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                   PPO_1312/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1312/train/approx_kl â–ƒâ–„â–„â–„â–ƒâ–„â–‡â–ˆâ–â–‡â–†
wandb:        PPO_1312/train/clip_fraction â–â–„â–ƒâ–†â–â–ƒâ–†â–‡â–‚â–ˆâ–‡
wandb:           PPO_1312/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1312/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1312/train/explained_variance â–â–…â–‡â–ˆâ–‡â–…â–„â–‡â–†â–‚â–…
wandb:        PPO_1312/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1312/train/loss â–ƒâ–…â–ƒâ–â–ˆâ–‚â–‚â–†â–„â–‚â–
wandb: PPO_1312/train/policy_gradient_loss â–ƒâ–â–‚â–ƒâ–†â–ƒâ–ƒâ–„â–ˆâ–ƒâ–†
wandb:                  PPO_1312/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1312/train/value_loss â–ˆâ–„â–ƒâ–â–‡â–‚â–ƒâ–ƒâ–…â–‚â–
wandb:                PPO_1322/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1322/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1322/rollout/ep_rew_mean â–â–‚â–â–‚â–„â–ƒâ–ƒâ–„â–…â–†â–‡â–ˆ
wandb:                   PPO_1322/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1322/train/approx_kl â–„â–‚â–ƒâ–â–†â–ˆâ–„â–…â–â–ƒâ–ˆ
wandb:        PPO_1322/train/clip_fraction â–„â–â–ƒâ–â–‚â–ˆâ–…â–â–â–ƒâ–†
wandb:           PPO_1322/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1322/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1322/train/explained_variance â–‚â–ˆâ–‡â–…â–‚â–â–‡â–„â–„â–…â–‚
wandb:        PPO_1322/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1322/train/loss â–…â–ƒâ–ƒâ–ƒâ–†â–‚â–â–ƒâ–‚â–ƒâ–ˆ
wandb: PPO_1322/train/policy_gradient_loss â–„â–…â–ˆâ–…â–ƒâ–†â–ˆâ–ƒâ–ˆâ–ƒâ–
wandb:                  PPO_1322/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1322/train/value_loss â–„â–„â–ƒâ–‡â–‡â–ƒâ–â–„â–„â–…â–ˆ
wandb:                PPO_1332/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1332/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1332/rollout/ep_rew_mean â–‚â–‚â–‚â–â–„â–…â–ƒâ–ƒâ–ˆâ–ˆâ–†â–„
wandb:                   PPO_1332/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1332/train/approx_kl â–ƒâ–…â–â–ˆâ–â–ƒâ–„â–‚â–‚â–†â–‡
wandb:        PPO_1332/train/clip_fraction â–…â–ƒâ–„â–„â–â–‚â–ƒâ–‚â–„â–ˆâ–ƒ
wandb:           PPO_1332/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1332/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1332/train/explained_variance â–„â–†â–†â–‚â–ƒâ–†â–‚â–â–ˆâ–…â–
wandb:        PPO_1332/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1332/train/loss â–â–‡â–‚â–â–„â–„â–ƒâ–„â–„â–†â–ˆ
wandb: PPO_1332/train/policy_gradient_loss â–†â–†â–ˆâ–‡â–…â–‚â–â–‚â–‡â–…â–‡
wandb:                  PPO_1332/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1332/train/value_loss â–‚â–â–â–‚â–„â–ƒâ–„â–…â–‚â–‚â–ˆ
wandb:                PPO_1342/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1342/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1342/rollout/ep_rew_mean â–ƒâ–ƒâ–ƒâ–„â–â–„â–ˆâ–„â–ƒâ–ƒâ–ˆâ–…
wandb:                   PPO_1342/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1342/train/approx_kl â–‡â–†â–‚â–ˆâ–â–ˆâ–‚â–„â–†â–ƒâ–†
wandb:        PPO_1342/train/clip_fraction â–ƒâ–„â–ƒâ–†â–â–ˆâ–…â–ƒâ–ƒâ–‚â–†
wandb:           PPO_1342/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1342/train/entropy_loss â–â–â–â–‚â–ƒâ–„â–…â–‡â–‡â–‡â–ˆ
wandb:   PPO_1342/train/explained_variance â–â–ƒâ–‚â–ˆâ–…â–‡â–‡â–‡â–†â–ˆâ–ˆ
wandb:        PPO_1342/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1342/train/loss â–„â–â–ˆâ–ƒâ–â–â–ƒâ–„â–‚â–†â–„
wandb: PPO_1342/train/policy_gradient_loss â–‚â–„â–â–ƒâ–‡â–ƒâ–ƒâ–ˆâ–ˆâ–‡â–ˆ
wandb:                  PPO_1342/train/std â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1342/train/value_loss â–ƒâ–„â–†â–‚â–†â–ƒâ–â–…â–…â–ˆâ–…
wandb:                PPO_1352/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1352/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1352/rollout/ep_rew_mean â–‡â–‡â–†â–…â–‡â–â–„â–…â–…â–†â–…â–ˆ
wandb:                   PPO_1352/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1352/train/approx_kl â–‚â–„â–…â–†â–ˆâ–â–„â–†â–…â–…â–„
wandb:        PPO_1352/train/clip_fraction â–ƒâ–ˆâ–â–†â–‡â–â–†â–…â–‚â–†â–†
wandb:           PPO_1352/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1352/train/entropy_loss â–â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1352/train/explained_variance â–„â–â–…â–…â–„â–†â–ˆâ–…â–†â–„â–†
wandb:        PPO_1352/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1352/train/loss â–‚â–â–‚â–â–‚â–â–ˆâ–‚â–ƒâ–„â–
wandb: PPO_1352/train/policy_gradient_loss â–ƒâ–„â–ƒâ–â–‡â–â–…â–ˆâ–â–‚â–ƒ
wandb:                  PPO_1352/train/std â–ˆâ–ˆâ–‡â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–â–
wandb:           PPO_1352/train/value_loss â–…â–â–…â–„â–„â–ˆâ–â–„â–†â–…â–…
wandb:                PPO_1362/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1362/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1362/rollout/ep_rew_mean â–†â–‡â–‡â–ˆâ–†â–ˆâ–…â–‚â–â–…â–…â–†
wandb:                   PPO_1362/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1362/train/approx_kl â–†â–…â–„â–ˆâ–…â–„â–ƒâ–‚â–ƒâ–â–„
wandb:        PPO_1362/train/clip_fraction â–…â–†â–…â–ˆâ–â–„â–…â–‚â–ƒâ–‚â–‡
wandb:           PPO_1362/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1362/train/entropy_loss â–â–‚â–ƒâ–„â–„â–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1362/train/explained_variance â–„â–â–ƒâ–†â–…â–„â–ƒâ–†â–‡â–„â–ˆ
wandb:        PPO_1362/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1362/train/loss â–â–â–‚â–ƒâ–…â–ƒâ–ƒâ–†â–ˆâ–ƒâ–‚
wandb: PPO_1362/train/policy_gradient_loss â–„â–†â–†â–ˆâ–„â–…â–…â–â–…â–„â–‡
wandb:                  PPO_1362/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1362/train/value_loss â–ƒâ–ƒâ–ƒâ–â–„â–†â–‡â–ˆâ–‡â–ˆâ–‚
wandb:                PPO_1372/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1372/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1372/rollout/ep_rew_mean â–‚â–â–…â–ƒâ–â–ƒâ–„â–…â–„â–ƒâ–ˆâ–
wandb:                   PPO_1372/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1372/train/approx_kl â–ƒâ–ƒâ–‡â–â–ˆâ–„â–†â–„â–‡â–†â–‡
wandb:        PPO_1372/train/clip_fraction â–…â–†â–ˆâ–â–‡â–„â–ˆâ–‡â–ƒâ–‡â–…
wandb:           PPO_1372/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1372/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆâ–‡
wandb:   PPO_1372/train/explained_variance â–…â–ˆâ–â–„â–‡â–…â–ˆâ–†â–…â–†â–‡
wandb:        PPO_1372/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1372/train/loss â–ˆâ–‚â–ƒâ–â–‚â–‚â–â–ƒâ–‚â–â–
wandb: PPO_1372/train/policy_gradient_loss â–†â–‡â–‡â–â–„â–ƒâ–ˆâ–†â–„â–…â–…
wandb:                  PPO_1372/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–â–‚
wandb:           PPO_1372/train/value_loss â–„â–ƒâ–ƒâ–ˆâ–„â–…â–â–ƒâ–„â–„â–
wandb:                PPO_1382/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1382/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1382/rollout/ep_rew_mean â–„â–‡â–„â–„â–â–†â–‡â–„â–ˆâ–†â–ˆâ–„
wandb:                   PPO_1382/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1382/train/approx_kl â–ƒâ–‡â–„â–â–ƒâ–‡â–ˆâ–„â–„â–‡â–†
wandb:        PPO_1382/train/clip_fraction â–†â–ˆâ–…â–‚â–‚â–ˆâ–†â–â–‡â–‚â–‡
wandb:           PPO_1382/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1382/train/entropy_loss â–â–â–â–‚â–„â–…â–‡â–‡â–†â–†â–ˆ
wandb:   PPO_1382/train/explained_variance â–ˆâ–â–…â–‚â–…â–…â–…â–…â–„â–â–…
wandb:        PPO_1382/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1382/train/loss â–â–â–‚â–‚â–„â–„â–‚â–ˆâ–â–†â–‚
wandb: PPO_1382/train/policy_gradient_loss â–†â–ƒâ–†â–ƒâ–â–ˆâ–†â–„â–‡â–‡â–‡
wandb:                  PPO_1382/train/std â–ˆâ–‡â–ˆâ–‡â–…â–„â–‚â–‚â–ƒâ–ƒâ–
wandb:           PPO_1382/train/value_loss â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–„
wandb:                    global_mean_eval â–â–‚â–…â–‡â–ˆâ–‡â–ˆâ–†â–†â–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–…â–‡â–‡â–‡â–‡â–†â–ˆâ–‡
wandb:                       mean_reward_1 â–â–‚â–„â–‡â–ˆâ–‡â–†â–…â–†â–ˆ
wandb:                      mean_reward_10 â–â–‚â–…â–‡â–‡â–‡â–ˆâ–…â–ˆâ–ˆ
wandb:                      mean_reward_11 â–â–‚â–„â–‡â–†â–†â–ˆâ–†â–†â–†
wandb:                      mean_reward_12 â–â–‚â–…â–‡â–ˆâ–†â–ˆâ–…â–‡â–†
wandb:                      mean_reward_13 â–â–‚â–…â–‡â–ˆâ–†â–†â–†â–‡â–„
wandb:                      mean_reward_14 â–â–‚â–…â–‡â–ˆâ–‡â–‡â–…â–‡â–„
wandb:                      mean_reward_15 â–â–‚â–„â–‡â–ˆâ–†â–ˆâ–†â–†â–‡
wandb:                      mean_reward_16 â–â–‚â–…â–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–…
wandb:                      mean_reward_17 â–â–‚â–…â–‡â–‡â–‡â–‡â–†â–†â–ˆ
wandb:                      mean_reward_18 â–â–‚â–…â–ˆâ–ˆâ–†â–‡â–‚â–‡â–†
wandb:                      mean_reward_19 â–â–â–„â–‡â–ˆâ–‡â–‡â–‡â–„â–ˆ
wandb:                       mean_reward_2 â–â–‚â–„â–‡â–‡â–†â–‡â–…â–…â–ˆ
wandb:                      mean_reward_20 â–â–‚â–…â–‡â–†â–ˆâ–†â–ˆâ–†â–…
wandb:                      mean_reward_21 â–â–‚â–…â–‡â–ˆâ–‡â–ˆâ–†â–…â–†
wandb:                      mean_reward_22 â–â–‚â–…â–‡â–ˆâ–‡â–ˆâ–…â–„â–„
wandb:                      mean_reward_23 â–â–‚â–…â–‡â–‡â–‡â–ˆâ–…â–…â–…
wandb:                      mean_reward_24 â–â–â–„â–†â–ˆâ–†â–…â–†â–ƒâ–‡
wandb:                      mean_reward_25 â–â–‚â–…â–‡â–ˆâ–†â–‡â–†â–†â–‡
wandb:                      mean_reward_26 â–â–‚â–…â–†â–‡â–…â–ˆâ–…â–…â–‡
wandb:                      mean_reward_27 â–â–‚â–…â–‡â–ˆâ–†â–‡â–†â–‡â–ˆ
wandb:                      mean_reward_28 â–â–‚â–…â–‡â–ˆâ–†â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_29 â–â–ƒâ–…â–‡â–‡â–ˆâ–‡â–†â–…â–†
wandb:                       mean_reward_3 â–â–ƒâ–…â–‡â–ˆâ–†â–‡â–†â–†â–ˆ
wandb:                      mean_reward_30 â–â–‚â–…â–‡â–ˆâ–‡â–‡â–…â–†â–ˆ
wandb:                      mean_reward_31 â–â–‚â–…â–ˆâ–‡â–‡â–ˆâ–…â–‡â–„
wandb:                      mean_reward_32 â–â–‚â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–„
wandb:                      mean_reward_33 â–â–ƒâ–…â–‡â–ˆâ–†â–‡â–…â–‡â–‡
wandb:                      mean_reward_34 â–â–â–„â–‡â–ˆâ–†â–ˆâ–…â–ˆâ–‡
wandb:                      mean_reward_35 â–â–â–…â–‡â–ˆâ–†â–ˆâ–…â–ˆâ–‡
wandb:                       mean_reward_4 â–â–‚â–…â–‡â–ˆâ–‡â–‡â–†â–…â–ˆ
wandb:                       mean_reward_5 â–â–‚â–…â–†â–ˆâ–†â–‡â–„â–†â–†
wandb:                       mean_reward_6 â–â–‚â–…â–‡â–ˆâ–‡â–ˆâ–„â–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–â–„â–‡â–‡â–‡â–ˆâ–‡â–†â–†
wandb:                       mean_reward_8 â–â–‚â–…â–‡â–ˆâ–…â–†â–„â–†â–†
wandb:                       mean_reward_9 â–â–‚â–…â–‡â–ˆâ–†â–ˆâ–†â–†â–„
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–„â–„â–†â–‡â–‡â–ˆ
wandb:                        std_reward_0 â–‚â–â–â–‚â–…â–…â–†â–ˆâ–‡â–‡
wandb:                        std_reward_1 â–‚â–â–â–‚â–„â–…â–†â–ˆâ–‡â–…
wandb:                       std_reward_10 â–‚â–â–â–‚â–…â–…â–…â–ˆâ–†â–†
wandb:                       std_reward_11 â–‚â–â–â–‚â–…â–†â–…â–ˆâ–ˆâ–‡
wandb:                       std_reward_12 â–ƒâ–â–â–‚â–„â–…â–…â–ˆâ–†â–‡
wandb:                       std_reward_13 â–‚â–â–â–‚â–ƒâ–†â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_14 â–‚â–â–â–‚â–„â–…â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_15 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–‡â–†
wandb:                       std_reward_16 â–ƒâ–â–â–‚â–„â–…â–…â–ˆâ–‡â–ˆ
wandb:                       std_reward_17 â–‚â–â–â–‚â–„â–„â–…â–ˆâ–‡â–†
wandb:                       std_reward_18 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–†â–†
wandb:                       std_reward_19 â–‚â–â–â–‚â–„â–…â–…â–‡â–ˆâ–‡
wandb:                        std_reward_2 â–ƒâ–â–â–‚â–…â–…â–…â–ˆâ–‡â–†
wandb:                       std_reward_20 â–ƒâ–â–‚â–‚â–…â–…â–†â–†â–ˆâ–ˆ
wandb:                       std_reward_21 â–‚â–â–â–‚â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                       std_reward_22 â–‚â–â–â–‚â–ƒâ–…â–…â–‡â–ˆâ–‡
wandb:                       std_reward_23 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–‡â–ˆ
wandb:                       std_reward_24 â–‚â–â–â–â–ƒâ–…â–†â–‡â–ˆâ–…
wandb:                       std_reward_25 â–ƒâ–â–â–‚â–„â–†â–…â–ˆâ–‡â–‡
wandb:                       std_reward_26 â–ƒâ–â–â–‚â–…â–†â–…â–ˆâ–ˆâ–†
wandb:                       std_reward_27 â–ƒâ–â–‚â–‚â–„â–†â–…â–ˆâ–‡â–†
wandb:                       std_reward_28 â–ƒâ–â–â–‚â–„â–†â–‡â–ˆâ–ˆâ–‡
wandb:                       std_reward_29 â–‚â–â–â–‚â–…â–„â–†â–ˆâ–ˆâ–ˆ
wandb:                        std_reward_3 â–ƒâ–â–‚â–‚â–„â–†â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_30 â–ƒâ–â–â–‚â–ƒâ–…â–…â–ˆâ–‡â–†
wandb:                       std_reward_31 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–†â–ˆ
wandb:                       std_reward_32 â–‚â–â–â–‚â–„â–…â–…â–‡â–†â–ˆ
wandb:                       std_reward_33 â–ƒâ–â–â–‚â–„â–…â–…â–ˆâ–†â–†
wandb:                       std_reward_34 â–‚â–â–â–‚â–„â–…â–„â–ˆâ–†â–†
wandb:                       std_reward_35 â–‚â–â–â–â–„â–…â–…â–ˆâ–†â–†
wandb:                        std_reward_4 â–ƒâ–â–‚â–‚â–„â–…â–…â–ˆâ–ˆâ–†
wandb:                        std_reward_5 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–‡â–†
wandb:                        std_reward_6 â–‚â–â–â–‚â–„â–…â–…â–ˆâ–…â–†
wandb:                        std_reward_7 â–‚â–â–â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆ
wandb:                        std_reward_8 â–‚â–â–â–â–ƒâ–†â–…â–ˆâ–‡â–‡
wandb:                        std_reward_9 â–‚â–â–â–‚â–„â–…â–…â–‡â–ˆâ–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–â–‚â–ƒâ–ˆâ–†â–‚â–â–ƒâ–ƒâ–…â–„â–„
wandb:                 train/clip_fraction â–„â–„â–„â–…â–…â–‚â–â–„â–‡â–ˆâ–ˆâ–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–‚â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–…â–…â–…â–ˆâ–ˆâ–†â–„â–‚â–â–â–‚
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1302/global_step 212992
wandb:        PPO_1302/rollout/ep_len_mean 200.0
wandb:        PPO_1302/rollout/ep_rew_mean -830.51654
wandb:                   PPO_1302/time/fps 598.0
wandb:            PPO_1302/train/approx_kl 0.01242
wandb:        PPO_1302/train/clip_fraction 0.1532
wandb:           PPO_1302/train/clip_range 0.2
wandb:         PPO_1302/train/entropy_loss -7.61768
wandb:   PPO_1302/train/explained_variance 0.94702
wandb:        PPO_1302/train/learning_rate 0.0003
wandb:                 PPO_1302/train/loss 24.45832
wandb: PPO_1302/train/policy_gradient_loss -0.00692
wandb:                  PPO_1302/train/std 0.71719
wandb:           PPO_1302/train/value_loss 72.70901
wandb:                PPO_1312/global_step 212992
wandb:        PPO_1312/rollout/ep_len_mean 200.0
wandb:        PPO_1312/rollout/ep_rew_mean -777.71552
wandb:                   PPO_1312/time/fps 598.0
wandb:            PPO_1312/train/approx_kl 0.01367
wandb:        PPO_1312/train/clip_fraction 0.189
wandb:           PPO_1312/train/clip_range 0.2
wandb:         PPO_1312/train/entropy_loss -6.62419
wandb:   PPO_1312/train/explained_variance 0.95369
wandb:        PPO_1312/train/learning_rate 0.0003
wandb:                 PPO_1312/train/loss 15.92439
wandb: PPO_1312/train/policy_gradient_loss -0.00423
wandb:                  PPO_1312/train/std 0.62174
wandb:           PPO_1312/train/value_loss 54.53857
wandb:                PPO_1322/global_step 212992
wandb:        PPO_1322/rollout/ep_len_mean 200.0
wandb:        PPO_1322/rollout/ep_rew_mean -665.87018
wandb:                   PPO_1322/time/fps 598.0
wandb:            PPO_1322/train/approx_kl 0.01675
wandb:        PPO_1322/train/clip_fraction 0.21343
wandb:           PPO_1322/train/clip_range 0.2
wandb:         PPO_1322/train/entropy_loss -5.77933
wandb:   PPO_1322/train/explained_variance 0.94581
wandb:        PPO_1322/train/learning_rate 0.0003
wandb:                 PPO_1322/train/loss 47.98217
wandb: PPO_1322/train/policy_gradient_loss -0.00499
wandb:                  PPO_1322/train/std 0.55201
wandb:           PPO_1322/train/value_loss 68.78239
wandb:                PPO_1332/global_step 212992
wandb:        PPO_1332/rollout/ep_len_mean 200.0
wandb:        PPO_1332/rollout/ep_rew_mean -626.44946
wandb:                   PPO_1332/time/fps 597.0
wandb:            PPO_1332/train/approx_kl 0.01683
wandb:        PPO_1332/train/clip_fraction 0.20101
wandb:           PPO_1332/train/clip_range 0.2
wandb:         PPO_1332/train/entropy_loss -5.22177
wandb:   PPO_1332/train/explained_variance 0.93654
wandb:        PPO_1332/train/learning_rate 0.0003
wandb:                 PPO_1332/train/loss 77.13206
wandb: PPO_1332/train/policy_gradient_loss -0.0036
wandb:                  PPO_1332/train/std 0.51085
wandb:           PPO_1332/train/value_loss 171.57169
wandb:                PPO_1342/global_step 212992
wandb:        PPO_1342/rollout/ep_len_mean 200.0
wandb:        PPO_1342/rollout/ep_rew_mean -595.92737
wandb:                   PPO_1342/time/fps 600.0
wandb:            PPO_1342/train/approx_kl 0.01616
wandb:        PPO_1342/train/clip_fraction 0.22092
wandb:           PPO_1342/train/clip_range 0.2
wandb:         PPO_1342/train/entropy_loss -4.86229
wandb:   PPO_1342/train/explained_variance 0.96823
wandb:        PPO_1342/train/learning_rate 0.0003
wandb:                 PPO_1342/train/loss 92.20898
wandb: PPO_1342/train/policy_gradient_loss -0.00278
wandb:                  PPO_1342/train/std 0.48414
wandb:           PPO_1342/train/value_loss 286.28943
wandb:                PPO_1352/global_step 212992
wandb:        PPO_1352/rollout/ep_len_mean 200.0
wandb:        PPO_1352/rollout/ep_rew_mean -559.29108
wandb:                   PPO_1352/time/fps 600.0
wandb:            PPO_1352/train/approx_kl 0.0155
wandb:        PPO_1352/train/clip_fraction 0.22002
wandb:           PPO_1352/train/clip_range 0.2
wandb:         PPO_1352/train/entropy_loss -4.59053
wandb:   PPO_1352/train/explained_variance 0.97515
wandb:        PPO_1352/train/learning_rate 0.0003
wandb:                 PPO_1352/train/loss 38.11616
wandb: PPO_1352/train/policy_gradient_loss -0.00216
wandb:                  PPO_1352/train/std 0.46785
wandb:           PPO_1352/train/value_loss 406.86066
wandb:                PPO_1362/global_step 212992
wandb:        PPO_1362/rollout/ep_len_mean 200.0
wandb:        PPO_1362/rollout/ep_rew_mean -600.82312
wandb:                   PPO_1362/time/fps 598.0
wandb:            PPO_1362/train/approx_kl 0.01552
wandb:        PPO_1362/train/clip_fraction 0.23214
wandb:           PPO_1362/train/clip_range 0.2
wandb:         PPO_1362/train/entropy_loss -4.19592
wandb:   PPO_1362/train/explained_variance 0.98257
wandb:        PPO_1362/train/learning_rate 0.0003
wandb:                 PPO_1362/train/loss 107.57084
wandb: PPO_1362/train/policy_gradient_loss -0.00033
wandb:                  PPO_1362/train/std 0.44265
wandb:           PPO_1362/train/value_loss 522.73517
wandb:                PPO_1372/global_step 212992
wandb:        PPO_1372/rollout/ep_len_mean 200.0
wandb:        PPO_1372/rollout/ep_rew_mean -634.30829
wandb:                   PPO_1372/time/fps 597.0
wandb:            PPO_1372/train/approx_kl 0.01748
wandb:        PPO_1372/train/clip_fraction 0.21818
wandb:           PPO_1372/train/clip_range 0.2
wandb:         PPO_1372/train/entropy_loss -3.9742
wandb:   PPO_1372/train/explained_variance 0.98105
wandb:        PPO_1372/train/learning_rate 0.0003
wandb:                 PPO_1372/train/loss 83.88232
wandb: PPO_1372/train/policy_gradient_loss -0.00021
wandb:                  PPO_1372/train/std 0.42904
wandb:           PPO_1372/train/value_loss 443.22116
wandb:                PPO_1382/global_step 212992
wandb:        PPO_1382/rollout/ep_len_mean 200.0
wandb:        PPO_1382/rollout/ep_rew_mean -627.68494
wandb:                   PPO_1382/time/fps 596.0
wandb:            PPO_1382/train/approx_kl 0.01769
wandb:        PPO_1382/train/clip_fraction 0.2298
wandb:           PPO_1382/train/clip_range 0.2
wandb:         PPO_1382/train/entropy_loss -3.75819
wandb:   PPO_1382/train/explained_variance 0.98132
wandb:        PPO_1382/train/learning_rate 0.0003
wandb:                 PPO_1382/train/loss 181.98555
wandb: PPO_1382/train/policy_gradient_loss -0.00012
wandb:                  PPO_1382/train/std 0.41581
wandb:           PPO_1382/train/value_loss 805.42407
wandb:                    global_mean_eval -583.10884
wandb:                         global_step 212992
wandb:                       mean_reward_0 -556.71758
wandb:                       mean_reward_1 -509.79422
wandb:                      mean_reward_10 -541.01072
wandb:                      mean_reward_11 -565.69051
wandb:                      mean_reward_12 -596.8119
wandb:                      mean_reward_13 -658.96323
wandb:                      mean_reward_14 -654.61454
wandb:                      mean_reward_15 -545.9936
wandb:                      mean_reward_16 -621.37119
wandb:                      mean_reward_17 -531.23221
wandb:                      mean_reward_18 -610.54982
wandb:                      mean_reward_19 -553.10044
wandb:                       mean_reward_2 -509.96856
wandb:                      mean_reward_20 -628.16637
wandb:                      mean_reward_21 -601.08938
wandb:                      mean_reward_22 -666.65913
wandb:                      mean_reward_23 -645.19448
wandb:                      mean_reward_24 -542.30735
wandb:                      mean_reward_25 -570.13942
wandb:                      mean_reward_26 -569.66261
wandb:                      mean_reward_27 -528.10234
wandb:                      mean_reward_28 -536.38496
wandb:                      mean_reward_29 -589.38904
wandb:                       mean_reward_3 -534.75899
wandb:                      mean_reward_30 -548.60144
wandb:                      mean_reward_31 -674.76846
wandb:                      mean_reward_32 -657.54041
wandb:                      mean_reward_33 -567.2976
wandb:                      mean_reward_34 -562.8785
wandb:                      mean_reward_35 -575.2194
wandb:                       mean_reward_4 -540.14267
wandb:                       mean_reward_5 -582.86471
wandb:                       mean_reward_6 -548.75614
wandb:                       mean_reward_7 -589.7865
wandb:                       mean_reward_8 -599.1141
wandb:                       mean_reward_9 -677.27589
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -901.89819
wandb:                        std_reward_0 344.00432
wandb:                        std_reward_1 248.07375
wandb:                       std_reward_10 324.11768
wandb:                       std_reward_11 351.48783
wandb:                       std_reward_12 365.05555
wandb:                       std_reward_13 433.82913
wandb:                       std_reward_14 419.41952
wandb:                       std_reward_15 346.03262
wandb:                       std_reward_16 420.34458
wandb:                       std_reward_17 304.7396
wandb:                       std_reward_18 383.03174
wandb:                       std_reward_19 354.80183
wandb:                        std_reward_2 300.02853
wandb:                       std_reward_20 402.1015
wandb:                       std_reward_21 372.01305
wandb:                       std_reward_22 437.39454
wandb:                       std_reward_23 438.90014
wandb:                       std_reward_24 306.49355
wandb:                       std_reward_25 360.21894
wandb:                       std_reward_26 346.52261
wandb:                       std_reward_27 304.34492
wandb:                       std_reward_28 303.09708
wandb:                       std_reward_29 405.86749
wandb:                        std_reward_3 318.8117
wandb:                       std_reward_30 350.8371
wandb:                       std_reward_31 426.09956
wandb:                       std_reward_32 421.3285
wandb:                       std_reward_33 334.95115
wandb:                       std_reward_34 345.89845
wandb:                       std_reward_35 353.40064
wandb:                        std_reward_4 323.72266
wandb:                        std_reward_5 346.32182
wandb:                        std_reward_6 329.05109
wandb:                        std_reward_7 375.62316
wandb:                        std_reward_8 377.02261
wandb:                        std_reward_9 435.11132
wandb:                            time/fps 597.0
wandb:                     train/approx_kl 0.0106
wandb:                 train/clip_fraction 0.13875
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.80915
wandb:            train/explained_variance 0.95603
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 9.91018
wandb:          train/policy_gradient_loss -0.00981
wandb:                           train/std 0.84977
wandb:                    train/value_loss 25.25248
wandb: 
wandb: Synced kind-terrain-50: https://wandb.ai/tidiane/meta_rl_context/runs/2ow35t7w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-2ow35t7w/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1303/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1303/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1303/rollout/ep_rew_mean â–â–â–‚â–ƒâ–‚â–‚â–„â–…â–†â–†â–†â–ˆ
wandb:                   PPO_1303/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1303/train/approx_kl â–„â–ˆâ–‚â–ƒâ–‚â–†â–‚â–â–…â–ƒâ–‚
wandb:        PPO_1303/train/clip_fraction â–‡â–†â–„â–â–ƒâ–‡â–ƒâ–ƒâ–†â–ˆâ–„
wandb:           PPO_1303/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1303/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1303/train/explained_variance â–â–ƒâ–‡â–„â–†â–‡â–…â–‡â–‡â–…â–ˆ
wandb:        PPO_1303/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1303/train/loss â–‚â–â–â–…â–‚â–„â–ˆâ–ƒâ–…â–‡â–…
wandb: PPO_1303/train/policy_gradient_loss â–‚â–â–‚â–…â–‡â–…â–‡â–…â–„â–„â–ˆ
wandb:                  PPO_1303/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1303/train/value_loss â–â–â–â–ƒâ–„â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                PPO_1314/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1314/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1314/rollout/ep_rew_mean â–â–â–‚â–ƒâ–ƒâ–…â–…â–…â–…â–†â–ˆâ–ˆ
wandb:                   PPO_1314/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1314/train/approx_kl â–‚â–â–ˆâ–†â–†â–„â–ƒâ–†â–ˆâ–†â–…
wandb:        PPO_1314/train/clip_fraction â–„â–â–…â–†â–„â–†â–„â–„â–…â–ˆâ–…
wandb:           PPO_1314/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1314/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1314/train/explained_variance â–‡â–„â–†â–†â–…â–„â–‡â–†â–ˆâ–ƒâ–
wandb:        PPO_1314/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1314/train/loss â–ˆâ–‚â–„â–…â–…â–„â–â–ƒâ–ƒâ–ƒâ–
wandb: PPO_1314/train/policy_gradient_loss â–‚â–ˆâ–â–„â–ƒâ–…â–‡â–†â–†â–†â–†
wandb:                  PPO_1314/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1314/train/value_loss â–ˆâ–†â–„â–…â–ˆâ–ƒâ–ƒâ–…â–‡â–â–…
wandb:                PPO_1324/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1324/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1324/rollout/ep_rew_mean â–â–…â–†â–…â–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–ˆ
wandb:                   PPO_1324/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1324/train/approx_kl â–â–…â–‚â–…â–†â–ƒâ–ˆâ–ˆâ–…â–†â–‡
wandb:        PPO_1324/train/clip_fraction â–â–…â–„â–…â–†â–„â–ˆâ–…â–„â–‡â–„
wandb:           PPO_1324/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1324/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–ˆ
wandb:   PPO_1324/train/explained_variance â–ˆâ–„â–…â–ˆâ–â–‡â–‡â–ˆâ–ˆâ–†â–‡
wandb:        PPO_1324/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1324/train/loss â–ˆâ–‚â–â–‚â–‚â–ƒâ–â–…â–‚â–„â–„
wandb: PPO_1324/train/policy_gradient_loss â–ƒâ–…â–‡â–â–„â–…â–ƒâ–ˆâ–ˆâ–†â–‡
wandb:                  PPO_1324/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:           PPO_1324/train/value_loss â–ˆâ–ƒâ–„â–ƒâ–„â–„â–â–„â–„â–ƒâ–„
wandb:                PPO_1334/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1334/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1334/rollout/ep_rew_mean â–†â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–ˆ
wandb:                   PPO_1334/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1334/train/approx_kl â–ƒâ–â–ƒâ–â–ƒâ–†â–…â–„â–…â–ˆâ–„
wandb:        PPO_1334/train/clip_fraction â–‚â–ƒâ–„â–â–„â–ˆâ–ˆâ–…â–†â–ˆâ–‡
wandb:           PPO_1334/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1334/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1334/train/explained_variance â–â–…â–…â–„â–„â–„â–„â–‡â–…â–‡â–ˆ
wandb:        PPO_1334/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1334/train/loss â–‡â–‚â–†â–‡â–ˆâ–‚â–‚â–„â–â–‚â–‚
wandb: PPO_1334/train/policy_gradient_loss â–„â–„â–â–„â–‚â–‚â–ƒâ–‚â–„â–ˆâ–„
wandb:                  PPO_1334/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1334/train/value_loss â–ˆâ–…â–‡â–ˆâ–ˆâ–„â–ƒâ–…â–…â–â–‚
wandb:                PPO_1344/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1344/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1344/rollout/ep_rew_mean â–†â–ƒâ–‚â–„â–„â–…â–â–ƒâ–…â–…â–ˆâ–‡
wandb:                   PPO_1344/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1344/train/approx_kl â–ˆâ–„â–„â–‡â–†â–‡â–â–ˆâ–„â–‚â–„
wandb:        PPO_1344/train/clip_fraction â–ƒâ–†â–„â–ˆâ–ƒâ–„â–â–„â–„â–â–„
wandb:           PPO_1344/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1344/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1344/train/explained_variance â–â–ƒâ–„â–„â–…â–„â–„â–‡â–†â–†â–ˆ
wandb:        PPO_1344/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1344/train/loss â–â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–â–…â–ˆâ–ƒ
wandb: PPO_1344/train/policy_gradient_loss â–†â–‡â–…â–„â–‚â–‚â–ƒâ–„â–â–ˆâ–ƒ
wandb:                  PPO_1344/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1344/train/value_loss â–â–â–ƒâ–‚â–„â–„â–†â–…â–„â–ˆâ–†
wandb:                PPO_1354/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1354/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1354/rollout/ep_rew_mean â–…â–â–„â–…â–‡â–ˆâ–‡â–‚â–‡â–‡â–…â–„
wandb:                   PPO_1354/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1354/train/approx_kl â–„â–„â–â–…â–‚â–ˆâ–„â–„â–„â–„â–†
wandb:        PPO_1354/train/clip_fraction â–â–â–‚â–…â–ƒâ–ˆâ–ƒâ–‚â–‚â–…â–„
wandb:           PPO_1354/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1354/train/entropy_loss â–â–â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–ˆ
wandb:   PPO_1354/train/explained_variance â–‡â–‡â–†â–ƒâ–‡â–‡â–…â–‡â–ˆâ–…â–
wandb:        PPO_1354/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1354/train/loss â–…â–…â–‚â–‚â–„â–â–‚â–„â–‚â–â–ˆ
wandb: PPO_1354/train/policy_gradient_loss â–‚â–â–‚â–„â–ƒâ–ˆâ–…â–â–ƒâ–‡â–„
wandb:                  PPO_1354/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–
wandb:           PPO_1354/train/value_loss â–‚â–‚â–‚â–„â–ƒâ–â–„â–†â–ƒâ–…â–ˆ
wandb:                PPO_1364/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1364/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1364/rollout/ep_rew_mean â–â–„â–ˆâ–‡â–…â–…â–†â–…â–‡â–…â–ƒâ–„
wandb:                   PPO_1364/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1364/train/approx_kl â–„â–…â–â–‚â–…â–…â–†â–„â–ˆâ–†â–†
wandb:        PPO_1364/train/clip_fraction â–ƒâ–…â–‡â–â–‡â–ˆâ–…â–…â–…â–†â–ˆ
wandb:           PPO_1364/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1364/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1364/train/explained_variance â–‚â–â–…â–„â–†â–ƒâ–„â–ˆâ–‡â–â–…
wandb:        PPO_1364/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1364/train/loss â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–‚â–‚â–†â–‚
wandb: PPO_1364/train/policy_gradient_loss â–ƒâ–‚â–ƒâ–â–„â–„â–‡â–„â–ƒâ–ˆâ–ˆ
wandb:                  PPO_1364/train/std â–ˆâ–ˆâ–†â–†â–†â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1364/train/value_loss â–ˆâ–…â–‚â–‡â–„â–â–‚â–ƒâ–†â–…â–ƒ
wandb:                PPO_1373/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1373/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1373/rollout/ep_rew_mean â–…â–…â–ˆâ–…â–â–‚â–†â–‡â–†â–ˆâ–…â–ˆ
wandb:                   PPO_1373/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1373/train/approx_kl â–‚â–â–ˆâ–ƒâ–ƒâ–‚â–„â–„â–ˆâ–„â–„
wandb:        PPO_1373/train/clip_fraction â–‚â–„â–‡â–â–‚â–„â–…â–…â–ˆâ–ˆâ–‡
wandb:           PPO_1373/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1373/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1373/train/explained_variance â–â–‡â–‚â–‚â–†â–ƒâ–‡â–…â–„â–ˆâ–‡
wandb:        PPO_1373/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1373/train/loss â–ƒâ–‚â–â–„â–‚â–â–ˆâ–‚â–â–†â–ƒ
wandb: PPO_1373/train/policy_gradient_loss â–‚â–‡â–‡â–â–â–â–…â–‡â–ˆâ–†â–†
wandb:                  PPO_1373/train/std â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1373/train/value_loss â–‡â–„â–ƒâ–‡â–†â–ˆâ–†â–…â–ƒâ–â–ƒ
wandb:                PPO_1383/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1383/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1383/rollout/ep_rew_mean â–„â–‚â–†â–ƒâ–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–…â–
wandb:                   PPO_1383/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1383/train/approx_kl â–„â–„â–‚â–â–ˆâ–‚â–ƒâ–‚â–ƒâ–…â–„
wandb:        PPO_1383/train/clip_fraction â–ˆâ–â–…â–â–‡â–†â–†â–†â–ˆâ–ˆâ–‡
wandb:           PPO_1383/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1383/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1383/train/explained_variance â–†â–†â–ƒâ–ˆâ–ˆâ–…â–â–†â–‚â–…â–‡
wandb:        PPO_1383/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1383/train/loss â–â–â–‚â–ƒâ–â–â–â–„â–„â–ƒâ–ˆ
wandb: PPO_1383/train/policy_gradient_loss â–…â–‚â–„â–â–„â–…â–†â–†â–†â–†â–ˆ
wandb:                  PPO_1383/train/std â–ˆâ–‡â–†â–†â–„â–„â–„â–„â–ƒâ–‚â–
wandb:           PPO_1383/train/value_loss â–â–‡â–ƒâ–†â–ƒâ–„â–ˆâ–‡â–‡â–…â–„
wandb:                    global_mean_eval â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_1 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_10 â–â–„â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_11 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                      mean_reward_12 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_13 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_14 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_15 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_16 â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_17 â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_18 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_19 â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_2 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_20 â–â–„â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_21 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_22 â–â–„â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆ
wandb:                      mean_reward_23 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_24 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_25 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_26 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_27 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_28 â–â–„â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_3 â–â–„â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_30 â–â–„â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_31 â–â–„â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_32 â–â–„â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_33 â–â–„â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                      mean_reward_34 â–â–„â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_35 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡
wandb:                       mean_reward_5 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_6 â–â–„â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_7 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                       mean_reward_8 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–‡â–‡â–‡â–ˆâ–†
wandb:                        std_reward_0 â–â–â–‚â–â–‚â–…â–…â–ˆâ–‡â–ˆ
wandb:                        std_reward_1 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_10 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–‡
wandb:                       std_reward_11 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_12 â–â–â–‚â–â–‚â–„â–…â–‡â–†â–ˆ
wandb:                       std_reward_13 â–â–â–‚â–â–‚â–…â–…â–ˆâ–‡â–ˆ
wandb:                       std_reward_14 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–‡
wandb:                       std_reward_15 â–â–â–‚â–â–‚â–…â–…â–ˆâ–†â–‡
wandb:                       std_reward_16 â–â–â–ƒâ–â–‚â–…â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_17 â–â–â–‚â–â–‚â–…â–†â–ˆâ–†â–‡
wandb:                       std_reward_18 â–â–â–‚â–â–‚â–…â–†â–‡â–†â–ˆ
wandb:                       std_reward_19 â–‚â–â–‚â–â–‚â–†â–‡â–ˆâ–‡â–‡
wandb:                        std_reward_2 â–â–â–‚â–â–‚â–…â–‡â–ˆâ–‡â–ˆ
wandb:                       std_reward_20 â–â–â–‚â–â–‚â–…â–†â–‡â–‡â–ˆ
wandb:                       std_reward_21 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–ˆ
wandb:                       std_reward_22 â–â–â–‚â–â–‚â–ƒâ–…â–ˆâ–†â–‡
wandb:                       std_reward_23 â–â–â–‚â–â–‚â–…â–†â–‡â–‡â–ˆ
wandb:                       std_reward_24 â–â–â–‚â–â–‚â–„â–†â–ˆâ–†â–ˆ
wandb:                       std_reward_25 â–â–â–‚â–â–‚â–…â–…â–‡â–†â–ˆ
wandb:                       std_reward_26 â–â–â–‚â–â–‚â–…â–†â–ˆâ–‡â–‡
wandb:                       std_reward_27 â–â–â–‚â–â–‚â–…â–…â–‡â–†â–ˆ
wandb:                       std_reward_28 â–â–â–‚â–â–‚â–…â–†â–ˆâ–†â–ˆ
wandb:                       std_reward_29 â–â–â–‚â–â–‚â–„â–…â–†â–†â–ˆ
wandb:                        std_reward_3 â–â–â–‚â–â–‚â–„â–‡â–‡â–‡â–ˆ
wandb:                       std_reward_30 â–â–â–‚â–‚â–‚â–„â–†â–ˆâ–†â–ˆ
wandb:                       std_reward_31 â–â–â–‚â–â–‚â–„â–†â–ˆâ–†â–ˆ
wandb:                       std_reward_32 â–â–â–‚â–â–‚â–„â–†â–ˆâ–†â–‡
wandb:                       std_reward_33 â–â–â–‚â–â–‚â–…â–†â–ˆâ–…â–‡
wandb:                       std_reward_34 â–â–â–‚â–â–‚â–†â–…â–ˆâ–†â–‡
wandb:                       std_reward_35 â–â–â–‚â–â–‚â–„â–†â–ˆâ–†â–ˆ
wandb:                        std_reward_4 â–â–â–‚â–â–‚â–…â–†â–ˆâ–†â–ˆ
wandb:                        std_reward_5 â–‚â–â–‚â–â–‚â–„â–†â–‡â–‡â–ˆ
wandb:                        std_reward_6 â–â–‚â–‚â–â–ƒâ–†â–ˆâ–ˆâ–‡â–ˆ
wandb:                        std_reward_7 â–â–â–‚â–â–‚â–„â–…â–‡â–†â–ˆ
wandb:                        std_reward_8 â–â–â–‚â–â–â–…â–‡â–‡â–‡â–ˆ
wandb:                        std_reward_9 â–â–â–‚â–â–‚â–…â–…â–ˆâ–…â–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–ƒâ–‚â–ƒâ–ˆâ–‡â–‚â–â–ƒâ–ƒâ–„â–„â–…
wandb:                 train/clip_fraction â–…â–„â–„â–…â–…â–‚â–â–…â–†â–ˆâ–‡â–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:                           train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1303/global_step 212992
wandb:        PPO_1303/rollout/ep_len_mean 200.0
wandb:        PPO_1303/rollout/ep_rew_mean -729.87524
wandb:                   PPO_1303/time/fps 589.0
wandb:            PPO_1303/train/approx_kl 0.01015
wandb:        PPO_1303/train/clip_fraction 0.12627
wandb:           PPO_1303/train/clip_range 0.2
wandb:         PPO_1303/train/entropy_loss -7.61006
wandb:   PPO_1303/train/explained_variance 0.96932
wandb:        PPO_1303/train/learning_rate 0.0003
wandb:                 PPO_1303/train/loss 48.82642
wandb: PPO_1303/train/policy_gradient_loss -0.00575
wandb:                  PPO_1303/train/std 0.71597
wandb:           PPO_1303/train/value_loss 151.464
wandb:                PPO_1314/global_step 212992
wandb:        PPO_1314/rollout/ep_len_mean 200.0
wandb:        PPO_1314/rollout/ep_rew_mean -590.4024
wandb:                   PPO_1314/time/fps 587.0
wandb:            PPO_1314/train/approx_kl 0.01192
wandb:        PPO_1314/train/clip_fraction 0.16514
wandb:           PPO_1314/train/clip_range 0.2
wandb:         PPO_1314/train/entropy_loss -6.7463
wandb:   PPO_1314/train/explained_variance 0.95574
wandb:        PPO_1314/train/learning_rate 0.0003
wandb:                 PPO_1314/train/loss 22.26704
wandb: PPO_1314/train/policy_gradient_loss -0.0042
wandb:                  PPO_1314/train/std 0.63511
wandb:           PPO_1314/train/value_loss 89.26234
wandb:                PPO_1324/global_step 212992
wandb:        PPO_1324/rollout/ep_len_mean 200.0
wandb:        PPO_1324/rollout/ep_rew_mean -554.02301
wandb:                   PPO_1324/time/fps 587.0
wandb:            PPO_1324/train/approx_kl 0.01508
wandb:        PPO_1324/train/clip_fraction 0.1814
wandb:           PPO_1324/train/clip_range 0.2
wandb:         PPO_1324/train/entropy_loss -5.9861
wandb:   PPO_1324/train/explained_variance 0.96865
wandb:        PPO_1324/train/learning_rate 0.0003
wandb:                 PPO_1324/train/loss 44.40052
wandb: PPO_1324/train/policy_gradient_loss -0.00294
wandb:                  PPO_1324/train/std 0.56856
wandb:           PPO_1324/train/value_loss 84.94218
wandb:                PPO_1334/global_step 212992
wandb:        PPO_1334/rollout/ep_len_mean 200.0
wandb:        PPO_1334/rollout/ep_rew_mean -518.61517
wandb:                   PPO_1334/time/fps 597.0
wandb:            PPO_1334/train/approx_kl 0.01527
wandb:        PPO_1334/train/clip_fraction 0.21785
wandb:           PPO_1334/train/clip_range 0.2
wandb:         PPO_1334/train/entropy_loss -5.36873
wandb:   PPO_1334/train/explained_variance 0.98388
wandb:        PPO_1334/train/learning_rate 0.0003
wandb:                 PPO_1334/train/loss 15.58491
wandb: PPO_1334/train/policy_gradient_loss -0.00171
wandb:                  PPO_1334/train/std 0.52063
wandb:           PPO_1334/train/value_loss 41.41672
wandb:                PPO_1344/global_step 212992
wandb:        PPO_1344/rollout/ep_len_mean 200.0
wandb:        PPO_1344/rollout/ep_rew_mean -498.4812
wandb:                   PPO_1344/time/fps 596.0
wandb:            PPO_1344/train/approx_kl 0.01573
wandb:        PPO_1344/train/clip_fraction 0.20959
wandb:           PPO_1344/train/clip_range 0.2
wandb:         PPO_1344/train/entropy_loss -4.73924
wandb:   PPO_1344/train/explained_variance 0.98957
wandb:        PPO_1344/train/learning_rate 0.0003
wandb:                 PPO_1344/train/loss 29.30214
wandb: PPO_1344/train/policy_gradient_loss -0.00185
wandb:                  PPO_1344/train/std 0.47563
wandb:           PPO_1344/train/value_loss 74.98966
wandb:                PPO_1354/global_step 212992
wandb:        PPO_1354/rollout/ep_len_mean 200.0
wandb:        PPO_1354/rollout/ep_rew_mean -523.10956
wandb:                   PPO_1354/time/fps 596.0
wandb:            PPO_1354/train/approx_kl 0.01792
wandb:        PPO_1354/train/clip_fraction 0.22192
wandb:           PPO_1354/train/clip_range 0.2
wandb:         PPO_1354/train/entropy_loss -4.35645
wandb:   PPO_1354/train/explained_variance 0.98308
wandb:        PPO_1354/train/learning_rate 0.0003
wandb:                 PPO_1354/train/loss 95.87229
wandb: PPO_1354/train/policy_gradient_loss 0.00017
wandb:                  PPO_1354/train/std 0.44936
wandb:           PPO_1354/train/value_loss 164.11676
wandb:                PPO_1364/global_step 212992
wandb:        PPO_1364/rollout/ep_len_mean 200.0
wandb:        PPO_1364/rollout/ep_rew_mean -503.55756
wandb:                   PPO_1364/time/fps 595.0
wandb:            PPO_1364/train/approx_kl 0.0187
wandb:        PPO_1364/train/clip_fraction 0.24369
wandb:           PPO_1364/train/clip_range 0.2
wandb:         PPO_1364/train/entropy_loss -3.96428
wandb:   PPO_1364/train/explained_variance 0.98934
wandb:        PPO_1364/train/learning_rate 0.0003
wandb:                 PPO_1364/train/loss 30.67681
wandb: PPO_1364/train/policy_gradient_loss 0.0019
wandb:                  PPO_1364/train/std 0.42651
wandb:           PPO_1364/train/value_loss 103.77716
wandb:                PPO_1373/global_step 212992
wandb:        PPO_1373/rollout/ep_len_mean 200.0
wandb:        PPO_1373/rollout/ep_rew_mean -477.10565
wandb:                   PPO_1373/time/fps 596.0
wandb:            PPO_1373/train/approx_kl 0.01806
wandb:        PPO_1373/train/clip_fraction 0.26616
wandb:           PPO_1373/train/clip_range 0.2
wandb:         PPO_1373/train/entropy_loss -3.56929
wandb:   PPO_1373/train/explained_variance 0.99102
wandb:        PPO_1373/train/learning_rate 0.0003
wandb:                 PPO_1373/train/loss 38.72242
wandb: PPO_1373/train/policy_gradient_loss 0.00249
wandb:                  PPO_1373/train/std 0.40233
wandb:           PPO_1373/train/value_loss 97.44786
wandb:                PPO_1383/global_step 212992
wandb:        PPO_1383/rollout/ep_len_mean 200.0
wandb:        PPO_1383/rollout/ep_rew_mean -503.21542
wandb:                   PPO_1383/time/fps 595.0
wandb:            PPO_1383/train/approx_kl 0.02173
wandb:        PPO_1383/train/clip_fraction 0.27009
wandb:           PPO_1383/train/clip_range 0.2
wandb:         PPO_1383/train/entropy_loss -3.24381
wandb:   PPO_1383/train/explained_variance 0.99134
wandb:        PPO_1383/train/learning_rate 0.0003
wandb:                 PPO_1383/train/loss 176.81693
wandb: PPO_1383/train/policy_gradient_loss 0.00635
wandb:                  PPO_1383/train/std 0.38493
wandb:           PPO_1383/train/value_loss 99.35527
wandb:                    global_mean_eval -469.68518
wandb:                         global_step 212992
wandb:                       mean_reward_0 -469.0825
wandb:                       mean_reward_1 -468.90241
wandb:                      mean_reward_10 -439.88034
wandb:                      mean_reward_11 -472.95026
wandb:                      mean_reward_12 -490.65933
wandb:                      mean_reward_13 -483.50297
wandb:                      mean_reward_14 -461.42197
wandb:                      mean_reward_15 -458.44783
wandb:                      mean_reward_16 -465.2554
wandb:                      mean_reward_17 -470.8239
wandb:                      mean_reward_18 -475.7963
wandb:                      mean_reward_19 -427.71997
wandb:                       mean_reward_2 -451.66911
wandb:                      mean_reward_20 -464.32432
wandb:                      mean_reward_21 -465.34111
wandb:                      mean_reward_22 -452.51189
wandb:                      mean_reward_23 -507.41685
wandb:                      mean_reward_24 -493.90084
wandb:                      mean_reward_25 -513.96866
wandb:                      mean_reward_26 -446.45033
wandb:                      mean_reward_27 -490.27893
wandb:                      mean_reward_28 -456.52139
wandb:                      mean_reward_29 -490.36753
wandb:                       mean_reward_3 -453.19812
wandb:                      mean_reward_30 -474.38043
wandb:                      mean_reward_31 -481.93046
wandb:                      mean_reward_32 -462.75584
wandb:                      mean_reward_33 -462.18531
wandb:                      mean_reward_34 -452.85683
wandb:                      mean_reward_35 -474.24394
wandb:                       mean_reward_4 -488.05901
wandb:                       mean_reward_5 -471.30355
wandb:                       mean_reward_6 -433.14696
wandb:                       mean_reward_7 -478.00187
wandb:                       mean_reward_8 -479.09058
wandb:                       mean_reward_9 -480.31945
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -939.39148
wandb:                        std_reward_0 198.18216
wandb:                        std_reward_1 194.95411
wandb:                       std_reward_10 168.72266
wandb:                       std_reward_11 201.80472
wandb:                       std_reward_12 226.40378
wandb:                       std_reward_13 206.73302
wandb:                       std_reward_14 181.93964
wandb:                       std_reward_15 189.0107
wandb:                       std_reward_16 194.28409
wandb:                       std_reward_17 188.2336
wandb:                       std_reward_18 207.28729
wandb:                       std_reward_19 157.30751
wandb:                        std_reward_2 200.63611
wandb:                       std_reward_20 181.49755
wandb:                       std_reward_21 194.26099
wandb:                       std_reward_22 187.68408
wandb:                       std_reward_23 212.84965
wandb:                       std_reward_24 201.03211
wandb:                       std_reward_25 221.75476
wandb:                       std_reward_26 179.04361
wandb:                       std_reward_27 205.5408
wandb:                       std_reward_28 194.51403
wandb:                       std_reward_29 207.32605
wandb:                        std_reward_3 191.92639
wandb:                       std_reward_30 190.15393
wandb:                       std_reward_31 200.12858
wandb:                       std_reward_32 180.5598
wandb:                       std_reward_33 184.30964
wandb:                       std_reward_34 172.64872
wandb:                       std_reward_35 195.63763
wandb:                        std_reward_4 192.32128
wandb:                        std_reward_5 192.35446
wandb:                        std_reward_6 158.45726
wandb:                        std_reward_7 210.66693
wandb:                        std_reward_8 195.53172
wandb:                        std_reward_9 206.97628
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01128
wandb:                 train/clip_fraction 0.12654
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7942
wandb:            train/explained_variance 0.92484
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.3112
wandb:          train/policy_gradient_loss -0.0089
wandb:                           train/std 0.84816
wandb:                    train/value_loss 56.39774
wandb: 
wandb: Synced logical-forest-46: https://wandb.ai/tidiane/meta_rl_context/runs/2gfbf78j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 14 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-2gfbf78j/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1304/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1304/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1304/rollout/ep_rew_mean â–‚â–â–ƒâ–ƒâ–„â–…â–…â–…â–‡â–†â–‡â–ˆ
wandb:                   PPO_1304/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1304/train/approx_kl â–â–ƒâ–…â–‚â–…â–„â–„â–ƒâ–„â–ˆâ–ˆ
wandb:        PPO_1304/train/clip_fraction â–‚â–â–…â–ƒâ–…â–„â–„â–ƒâ–…â–‡â–ˆ
wandb:           PPO_1304/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1304/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1304/train/explained_variance â–‡â–ƒâ–ˆâ–…â–‡â–†â–â–†â–†â–†â–†
wandb:        PPO_1304/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1304/train/loss â–â–‚â–„â–…â–ˆâ–‚â–ƒâ–…â–‡â–…â–ƒ
wandb: PPO_1304/train/policy_gradient_loss â–„â–ƒâ–â–†â–‚â–ƒâ–‚â–†â–ˆâ–ˆâ–„
wandb:                  PPO_1304/train/std â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1304/train/value_loss â–â–â–â–†â–„â–ˆâ–†â–…â–†â–…â–‡
wandb:                PPO_1313/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1313/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1313/rollout/ep_rew_mean â–ƒâ–‚â–â–„â–ƒâ–„â–ƒâ–ƒâ–„â–†â–ˆâ–ˆ
wandb:                   PPO_1313/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1313/train/approx_kl â–‚â–â–„â–…â–†â–„â–…â–„â–‡â–ˆâ–ˆ
wandb:        PPO_1313/train/clip_fraction â–â–‚â–„â–…â–„â–„â–‚â–…â–‡â–‡â–ˆ
wandb:           PPO_1313/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1313/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1313/train/explained_variance â–‡â–„â–†â–„â–…â–„â–„â–â–…â–†â–ˆ
wandb:        PPO_1313/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1313/train/loss â–†â–‚â–ƒâ–â–ˆâ–â–†â–â–â–â–„
wandb: PPO_1313/train/policy_gradient_loss â–ƒâ–„â–‚â–â–‡â–ˆâ–ˆâ–‡â–…â–â–‚
wandb:                  PPO_1313/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1313/train/value_loss â–†â–ˆâ–…â–†â–†â–„â–…â–„â–â–‚â–
wandb:                PPO_1323/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1323/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1323/rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–„â–…â–†â–„â–…â–†â–ˆ
wandb:                   PPO_1323/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1323/train/approx_kl â–‚â–â–ƒâ–â–ƒâ–ƒâ–â–„â–‚â–„â–ˆ
wandb:        PPO_1323/train/clip_fraction â–â–‚â–‚â–…â–†â–†â–„â–ˆâ–‚â–‡â–ˆ
wandb:           PPO_1323/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1323/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1323/train/explained_variance â–†â–†â–â–…â–…â–†â–„â–†â–†â–ƒâ–ˆ
wandb:        PPO_1323/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1323/train/loss â–‚â–‚â–‚â–ˆâ–â–„â–‚â–â–‚â–‚â–‚
wandb: PPO_1323/train/policy_gradient_loss â–„â–ƒâ–â–…â–„â–ƒâ–†â–‡â–ˆâ–†â–†
wandb:                  PPO_1323/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1323/train/value_loss â–…â–…â–†â–ˆâ–ƒâ–…â–„â–â–†â–ƒâ–ƒ
wandb:                PPO_1333/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1333/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1333/rollout/ep_rew_mean â–‚â–â–â–â–„â–„â–„â–…â–†â–†â–ˆâ–ˆ
wandb:                   PPO_1333/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1333/train/approx_kl â–â–‚â–‚â–ƒâ–â–„â–†â–…â–ˆâ–…â–‚
wandb:        PPO_1333/train/clip_fraction â–ƒâ–â–ƒâ–‚â–ƒâ–†â–‡â–‡â–ˆâ–‡â–…
wandb:           PPO_1333/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1333/train/entropy_loss â–â–‚â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–ˆ
wandb:   PPO_1333/train/explained_variance â–â–‚â–ƒâ–„â–ƒâ–…â–„â–…â–…â–ˆâ–…
wandb:        PPO_1333/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1333/train/loss â–ƒâ–„â–â–„â–ˆâ–„â–â–ˆâ–ƒâ–â–
wandb: PPO_1333/train/policy_gradient_loss â–„â–â–‚â–„â–ƒâ–‚â–‚â–ˆâ–„â–‚â–„
wandb:                  PPO_1333/train/std â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–
wandb:           PPO_1333/train/value_loss â–„â–†â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‚â–â–…
wandb:                PPO_1343/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1343/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1343/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–ˆâ–ˆ
wandb:                   PPO_1343/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1343/train/approx_kl â–„â–ƒâ–„â–†â–†â–‡â–…â–â–‚â–…â–ˆ
wandb:        PPO_1343/train/clip_fraction â–„â–„â–…â–ƒâ–â–ˆâ–†â–‚â–†â–…â–„
wandb:           PPO_1343/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1343/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1343/train/explained_variance â–…â–ƒâ–†â–ˆâ–…â–†â–…â–…â–ƒâ–ƒâ–
wandb:        PPO_1343/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1343/train/loss â–ˆâ–â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–…â–†
wandb: PPO_1343/train/policy_gradient_loss â–…â–„â–†â–…â–…â–…â–…â–ˆâ–ƒâ–â–ˆ
wandb:                  PPO_1343/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1343/train/value_loss â–…â–ˆâ–‚â–â–…â–ƒâ–‚â–ƒâ–†â–‡â–‡
wandb:                PPO_1353/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1353/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1353/rollout/ep_rew_mean â–â–„â–„â–…â–†â–…â–†â–‡â–‡â–ˆâ–†â–†
wandb:                   PPO_1353/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1353/train/approx_kl â–†â–„â–ƒâ–‡â–ƒâ–ˆâ–„â–„â–‚â–â–„
wandb:        PPO_1353/train/clip_fraction â–†â–†â–…â–‡â–â–†â–…â–ˆâ–‚â–…â–‚
wandb:           PPO_1353/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1353/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1353/train/explained_variance â–‡â–†â–ˆâ–‡â–†â–‡â–…â–†â–…â–…â–
wandb:        PPO_1353/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1353/train/loss â–‚â–„â–…â–â–ˆâ–…â–ƒâ–‚â–‚â–â–ƒ
wandb: PPO_1353/train/policy_gradient_loss â–â–…â–ƒâ–ˆâ–ƒâ–ˆâ–‡â–†â–…â–†â–„
wandb:                  PPO_1353/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–‚â–
wandb:           PPO_1353/train/value_loss â–…â–†â–„â–â–†â–„â–…â–‚â–†â–‡â–ˆ
wandb:                PPO_1363/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1363/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1363/rollout/ep_rew_mean â–ƒâ–â–â–ƒâ–ƒâ–†â–ˆâ–‡â–„â–ˆâ–„â–†
wandb:                   PPO_1363/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1363/train/approx_kl â–…â–ƒâ–„â–…â–‚â–„â–ˆâ–ƒâ–â–…â–‚
wandb:        PPO_1363/train/clip_fraction â–ˆâ–‡â–…â–‡â–„â–ˆâ–ƒâ–â–â–ˆâ–„
wandb:           PPO_1363/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1363/train/entropy_loss â–â–â–â–ƒâ–ƒâ–„â–„â–„â–…â–‡â–ˆ
wandb:   PPO_1363/train/explained_variance â–„â–…â–ˆâ–ˆâ–â–ˆâ–ˆâ–†â–…â–…â–‡
wandb:        PPO_1363/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1363/train/loss â–‚â–‚â–â–ˆâ–‚â–‚â–â–‚â–†â–‚â–‚
wandb: PPO_1363/train/policy_gradient_loss â–ˆâ–†â–â–ƒâ–†â–ˆâ–ˆâ–‚â–„â–…â–ƒ
wandb:                  PPO_1363/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–…â–…â–ƒâ–‚â–
wandb:           PPO_1363/train/value_loss â–‚â–ƒâ–†â–†â–ˆâ–â–„â–‚â–…â–‚â–…
wandb:                PPO_1374/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1374/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1374/rollout/ep_rew_mean â–ƒâ–â–ƒâ–„â–…â–„â–‡â–‡â–‚â–†â–ˆâ–†
wandb:                   PPO_1374/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1374/train/approx_kl â–ˆâ–‡â–‡â–â–†â–…â–ƒâ–â–…â–â–„
wandb:        PPO_1374/train/clip_fraction â–†â–ƒâ–ˆâ–â–‡â–†â–„â–â–â–‚â–…
wandb:           PPO_1374/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1374/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1374/train/explained_variance â–â–ƒâ–…â–‚â–†â–…â–ˆâ–‡â–…â–‡â–…
wandb:        PPO_1374/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1374/train/loss â–ƒâ–…â–â–…â–‡â–â–â–‚â–ˆâ–‚â–‚
wandb: PPO_1374/train/policy_gradient_loss â–„â–â–ˆâ–â–„â–ƒâ–‡â–†â–ƒâ–ˆâ–‚
wandb:                  PPO_1374/train/std â–ˆâ–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–
wandb:           PPO_1374/train/value_loss â–â–†â–â–„â–ƒâ–ƒâ–â–‚â–ˆâ–†â–ƒ
wandb:                PPO_1384/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1384/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1384/rollout/ep_rew_mean â–ˆâ–…â–ƒâ–„â–†â–‡â–ˆâ–ƒâ–â–â–…â–…
wandb:                   PPO_1384/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1384/train/approx_kl â–â–…â–ƒâ–„â–â–ƒâ–ˆâ–â–„â–‡â–†
wandb:        PPO_1384/train/clip_fraction â–†â–‡â–„â–…â–„â–‡â–‡â–â–ƒâ–†â–ˆ
wandb:           PPO_1384/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1384/train/entropy_loss â–â–‚â–ƒâ–„â–„â–†â–†â–…â–…â–…â–ˆ
wandb:   PPO_1384/train/explained_variance â–â–„â–†â–†â–…â–†â–…â–ˆâ–ˆâ–†â–ˆ
wandb:        PPO_1384/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1384/train/loss â–…â–â–â–„â–‚â–‡â–ƒâ–â–ˆâ–‡â–ƒ
wandb: PPO_1384/train/policy_gradient_loss â–ƒâ–‚â–„â–â–…â–…â–…â–â–„â–‚â–ˆ
wandb:                  PPO_1384/train/std â–ˆâ–‡â–†â–…â–„â–‚â–ƒâ–ƒâ–…â–ƒâ–
wandb:           PPO_1384/train/value_loss â–â–‚â–‚â–ƒâ–„â–‚â–‚â–…â–†â–ˆâ–…
wandb:                    global_mean_eval â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–‡
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–†
wandb:                       mean_reward_1 â–â–‚â–ƒâ–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_10 â–â–‚â–‚â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_11 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_12 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_13 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–†
wandb:                      mean_reward_14 â–â–‚â–‚â–„â–†â–‡â–‡â–ˆâ–ˆâ–†
wandb:                      mean_reward_15 â–â–‚â–ƒâ–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_16 â–â–‚â–‚â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_17 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–†
wandb:                      mean_reward_18 â–â–‚â–‚â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–†
wandb:                      mean_reward_19 â–â–‚â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆâ–†
wandb:                       mean_reward_2 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_20 â–â–‚â–‚â–„â–†â–†â–ˆâ–‡â–ˆâ–‡
wandb:                      mean_reward_21 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_22 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_23 â–â–‚â–ƒâ–…â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_24 â–â–‚â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_25 â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–†
wandb:                      mean_reward_26 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–†
wandb:                      mean_reward_27 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_28 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_29 â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–†
wandb:                       mean_reward_3 â–â–‚â–‚â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_30 â–â–‚â–ƒâ–„â–†â–†â–ˆâ–ˆâ–ˆâ–†
wandb:                      mean_reward_31 â–â–‚â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆâ–‡
wandb:                      mean_reward_32 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_33 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_34 â–â–‚â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆâ–†
wandb:                      mean_reward_35 â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–‡
wandb:                       mean_reward_4 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–‡
wandb:                       mean_reward_5 â–â–‚â–‚â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:                       mean_reward_6 â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–†
wandb:                       mean_reward_7 â–â–‚â–ƒâ–„â–†â–†â–‡â–ˆâ–ˆâ–†
wandb:                       mean_reward_8 â–â–‚â–‚â–„â–†â–†â–‡â–ˆâ–ˆâ–‡
wandb:                       mean_reward_9 â–â–‚â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆâ–‡
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–‡â–‡â–‡â–ˆâ–†
wandb:                        std_reward_0 â–ƒâ–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                        std_reward_1 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_10 â–„â–â–‚â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_11 â–ƒâ–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_12 â–ƒâ–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_13 â–ƒâ–â–‚â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_14 â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                       std_reward_15 â–„â–â–‚â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                       std_reward_16 â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                       std_reward_17 â–„â–‚â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_18 â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                       std_reward_19 â–„â–â–‚â–‚â–â–‚â–‚â–â–„â–ˆ
wandb:                        std_reward_2 â–…â–â–â–â–â–ƒâ–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_20 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_21 â–ƒâ–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_22 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_23 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_24 â–…â–â–‚â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_25 â–ƒâ–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_26 â–ƒâ–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_27 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_28 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_29 â–ƒâ–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                        std_reward_3 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_30 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_31 â–„â–â–â–‚â–â–ƒâ–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_32 â–„â–‚â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                       std_reward_33 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                       std_reward_34 â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                       std_reward_35 â–ƒâ–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                        std_reward_4 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                        std_reward_5 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                        std_reward_6 â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–ˆ
wandb:                        std_reward_7 â–ƒâ–â–â–â–â–â–‚â–â–‚â–ˆ
wandb:                        std_reward_8 â–„â–â–â–â–â–‚â–‚â–â–ƒâ–ˆ
wandb:                        std_reward_9 â–„â–â–â–â–â–‚â–ƒâ–â–ƒâ–ˆ
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–ƒâ–‚â–ƒâ–ˆâ–‡â–‚â–â–ƒâ–ƒâ–„â–„â–…
wandb:                 train/clip_fraction â–…â–„â–„â–…â–…â–‚â–â–…â–†â–ˆâ–‡â–‡
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–‚â–
wandb:          train/policy_gradient_loss â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:                           train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1304/global_step 212992
wandb:        PPO_1304/rollout/ep_len_mean 200.0
wandb:        PPO_1304/rollout/ep_rew_mean -825.61829
wandb:                   PPO_1304/time/fps 590.0
wandb:            PPO_1304/train/approx_kl 0.01303
wandb:        PPO_1304/train/clip_fraction 0.15875
wandb:           PPO_1304/train/clip_range 0.2
wandb:         PPO_1304/train/entropy_loss -7.67415
wandb:   PPO_1304/train/explained_variance 0.95915
wandb:        PPO_1304/train/learning_rate 0.0003
wandb:                 PPO_1304/train/loss 25.13453
wandb: PPO_1304/train/policy_gradient_loss -0.00829
wandb:                  PPO_1304/train/std 0.72256
wandb:           PPO_1304/train/value_loss 90.12502
wandb:                PPO_1313/global_step 212992
wandb:        PPO_1313/rollout/ep_len_mean 200.0
wandb:        PPO_1313/rollout/ep_rew_mean -781.992
wandb:                   PPO_1313/time/fps 594.0
wandb:            PPO_1313/train/approx_kl 0.01517
wandb:        PPO_1313/train/clip_fraction 0.19214
wandb:           PPO_1313/train/clip_range 0.2
wandb:         PPO_1313/train/entropy_loss -6.8544
wandb:   PPO_1313/train/explained_variance 0.9694
wandb:        PPO_1313/train/learning_rate 0.0003
wandb:                 PPO_1313/train/loss 34.24713
wandb: PPO_1313/train/policy_gradient_loss -0.00699
wandb:                  PPO_1313/train/std 0.64396
wandb:           PPO_1313/train/value_loss 45.7892
wandb:                PPO_1323/global_step 212992
wandb:        PPO_1323/rollout/ep_len_mean 200.0
wandb:        PPO_1323/rollout/ep_rew_mean -683.82178
wandb:                   PPO_1323/time/fps 595.0
wandb:            PPO_1323/train/approx_kl 0.01802
wandb:        PPO_1323/train/clip_fraction 0.21071
wandb:           PPO_1323/train/clip_range 0.2
wandb:         PPO_1323/train/entropy_loss -6.00281
wandb:   PPO_1323/train/explained_variance 0.98076
wandb:        PPO_1323/train/learning_rate 0.0003
wandb:                 PPO_1323/train/loss 14.66159
wandb: PPO_1323/train/policy_gradient_loss -0.0043
wandb:                  PPO_1323/train/std 0.57005
wandb:           PPO_1323/train/value_loss 36.12022
wandb:                PPO_1333/global_step 212992
wandb:        PPO_1333/rollout/ep_len_mean 200.0
wandb:        PPO_1333/rollout/ep_rew_mean -612.38165
wandb:                   PPO_1333/time/fps 594.0
wandb:            PPO_1333/train/approx_kl 0.01716
wandb:        PPO_1333/train/clip_fraction 0.2358
wandb:           PPO_1333/train/clip_range 0.2
wandb:         PPO_1333/train/entropy_loss -5.13992
wandb:   PPO_1333/train/explained_variance 0.97937
wandb:        PPO_1333/train/learning_rate 0.0003
wandb:                 PPO_1333/train/loss 9.9293
wandb: PPO_1333/train/policy_gradient_loss -0.00156
wandb:                  PPO_1333/train/std 0.50512
wandb:           PPO_1333/train/value_loss 35.01083
wandb:                PPO_1343/global_step 212992
wandb:        PPO_1343/rollout/ep_len_mean 200.0
wandb:        PPO_1343/rollout/ep_rew_mean -545.94513
wandb:                   PPO_1343/time/fps 593.0
wandb:            PPO_1343/train/approx_kl 0.02241
wandb:        PPO_1343/train/clip_fraction 0.24805
wandb:           PPO_1343/train/clip_range 0.2
wandb:         PPO_1343/train/entropy_loss -4.2777
wandb:   PPO_1343/train/explained_variance 0.97935
wandb:        PPO_1343/train/learning_rate 0.0003
wandb:                 PPO_1343/train/loss 15.17304
wandb: PPO_1343/train/policy_gradient_loss 0.00031
wandb:                  PPO_1343/train/std 0.44535
wandb:           PPO_1343/train/value_loss 24.3054
wandb:                PPO_1353/global_step 212992
wandb:        PPO_1353/rollout/ep_len_mean 200.0
wandb:        PPO_1353/rollout/ep_rew_mean -520.36609
wandb:                   PPO_1353/time/fps 592.0
wandb:            PPO_1353/train/approx_kl 0.01942
wandb:        PPO_1353/train/clip_fraction 0.23073
wandb:           PPO_1353/train/clip_range 0.2
wandb:         PPO_1353/train/entropy_loss -3.59917
wandb:   PPO_1353/train/explained_variance 0.95691
wandb:        PPO_1353/train/learning_rate 0.0003
wandb:                 PPO_1353/train/loss 15.02359
wandb: PPO_1353/train/policy_gradient_loss -0.00049
wandb:                  PPO_1353/train/std 0.40558
wandb:           PPO_1353/train/value_loss 44.73174
wandb:                PPO_1363/global_step 212992
wandb:        PPO_1363/rollout/ep_len_mean 200.0
wandb:        PPO_1363/rollout/ep_rew_mean -496.90869
wandb:                   PPO_1363/time/fps 592.0
wandb:            PPO_1363/train/approx_kl 0.01688
wandb:        PPO_1363/train/clip_fraction 0.24883
wandb:           PPO_1363/train/clip_range 0.2
wandb:         PPO_1363/train/entropy_loss -3.2356
wandb:   PPO_1363/train/explained_variance 0.97046
wandb:        PPO_1363/train/learning_rate 0.0003
wandb:                 PPO_1363/train/loss 15.45499
wandb: PPO_1363/train/policy_gradient_loss 6e-05
wandb:                  PPO_1363/train/std 0.38502
wandb:           PPO_1363/train/value_loss 38.0761
wandb:                PPO_1374/global_step 212992
wandb:        PPO_1374/rollout/ep_len_mean 200.0
wandb:        PPO_1374/rollout/ep_rew_mean -485.74792
wandb:                   PPO_1374/time/fps 592.0
wandb:            PPO_1374/train/approx_kl 0.0179
wandb:        PPO_1374/train/clip_fraction 0.24866
wandb:           PPO_1374/train/clip_range 0.2
wandb:         PPO_1374/train/entropy_loss -2.89897
wandb:   PPO_1374/train/explained_variance 0.97372
wandb:        PPO_1374/train/learning_rate 0.0003
wandb:                 PPO_1374/train/loss 19.54455
wandb: PPO_1374/train/policy_gradient_loss -0.00219
wandb:                  PPO_1374/train/std 0.3668
wandb:           PPO_1374/train/value_loss 46.46445
wandb:                PPO_1384/global_step 212992
wandb:        PPO_1384/rollout/ep_len_mean 200.0
wandb:        PPO_1384/rollout/ep_rew_mean -480.82297
wandb:                   PPO_1384/time/fps 591.0
wandb:            PPO_1384/train/approx_kl 0.01931
wandb:        PPO_1384/train/clip_fraction 0.25494
wandb:           PPO_1384/train/clip_range 0.2
wandb:         PPO_1384/train/entropy_loss -2.75321
wandb:   PPO_1384/train/explained_variance 0.98528
wandb:        PPO_1384/train/learning_rate 0.0003
wandb:                 PPO_1384/train/loss 26.17315
wandb: PPO_1384/train/policy_gradient_loss 0.00173
wandb:                  PPO_1384/train/std 0.35956
wandb:           PPO_1384/train/value_loss 108.80746
wandb:                    global_mean_eval -507.78991
wandb:                         global_step 212992
wandb:                       mean_reward_0 -511.51568
wandb:                       mean_reward_1 -497.87986
wandb:                      mean_reward_10 -510.46751
wandb:                      mean_reward_11 -502.57238
wandb:                      mean_reward_12 -501.22193
wandb:                      mean_reward_13 -509.67781
wandb:                      mean_reward_14 -535.44281
wandb:                      mean_reward_15 -502.0353
wandb:                      mean_reward_16 -516.18479
wandb:                      mean_reward_17 -511.6722
wandb:                      mean_reward_18 -526.46983
wandb:                      mean_reward_19 -528.06455
wandb:                       mean_reward_2 -490.37684
wandb:                      mean_reward_20 -503.54361
wandb:                      mean_reward_21 -506.29872
wandb:                      mean_reward_22 -482.59067
wandb:                      mean_reward_23 -512.90185
wandb:                      mean_reward_24 -496.60101
wandb:                      mean_reward_25 -532.98952
wandb:                      mean_reward_26 -522.12761
wandb:                      mean_reward_27 -502.5623
wandb:                      mean_reward_28 -487.95103
wandb:                      mean_reward_29 -518.99264
wandb:                       mean_reward_3 -491.63877
wandb:                      mean_reward_30 -527.68284
wandb:                      mean_reward_31 -495.30967
wandb:                      mean_reward_32 -491.83305
wandb:                      mean_reward_33 -485.17886
wandb:                      mean_reward_34 -518.85056
wandb:                      mean_reward_35 -492.18701
wandb:                       mean_reward_4 -503.22699
wandb:                       mean_reward_5 -499.31828
wandb:                       mean_reward_6 -533.75959
wandb:                       mean_reward_7 -549.54032
wandb:                       mean_reward_8 -492.72774
wandb:                       mean_reward_9 -489.04267
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -939.39148
wandb:                        std_reward_0 174.79256
wandb:                        std_reward_1 146.00595
wandb:                       std_reward_10 155.32738
wandb:                       std_reward_11 148.84504
wandb:                       std_reward_12 166.53231
wandb:                       std_reward_13 164.60903
wandb:                       std_reward_14 180.57267
wandb:                       std_reward_15 153.83455
wandb:                       std_reward_16 174.26685
wandb:                       std_reward_17 159.04655
wandb:                       std_reward_18 178.26579
wandb:                       std_reward_19 172.85496
wandb:                        std_reward_2 135.96934
wandb:                       std_reward_20 149.56059
wandb:                       std_reward_21 170.08227
wandb:                       std_reward_22 138.37993
wandb:                       std_reward_23 163.5463
wandb:                       std_reward_24 142.14255
wandb:                       std_reward_25 179.01717
wandb:                       std_reward_26 175.61365
wandb:                       std_reward_27 159.91723
wandb:                       std_reward_28 134.26925
wandb:                       std_reward_29 158.92809
wandb:                        std_reward_3 143.88105
wandb:                       std_reward_30 177.4682
wandb:                       std_reward_31 137.30183
wandb:                       std_reward_32 134.93941
wandb:                       std_reward_33 138.96079
wandb:                       std_reward_34 165.73718
wandb:                       std_reward_35 149.30883
wandb:                        std_reward_4 154.18777
wandb:                        std_reward_5 143.13039
wandb:                        std_reward_6 182.92919
wandb:                        std_reward_7 188.95228
wandb:                        std_reward_8 145.0767
wandb:                        std_reward_9 149.14571
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01128
wandb:                 train/clip_fraction 0.12654
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.7942
wandb:            train/explained_variance 0.92484
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 12.3112
wandb:          train/policy_gradient_loss -0.0089
wandb:                           train/std 0.84816
wandb:                    train/value_loss 56.39774
wandb: 
wandb: Synced stellar-yogurt-48: https://wandb.ai/tidiane/meta_rl_context/runs/tyuqum18
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 14 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-tyuqum18/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1305/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1305/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1305/rollout/ep_rew_mean â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–ˆ
wandb:                   PPO_1305/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1305/train/approx_kl â–â–‚â–‚â–â–ƒâ–…â–â–†â–ˆâ–„â–
wandb:        PPO_1305/train/clip_fraction â–ƒâ–„â–…â–â–„â–„â–…â–ˆâ–ˆâ–…â–„
wandb:           PPO_1305/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1305/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:   PPO_1305/train/explained_variance â–…â–…â–ˆâ–‡â–…â–…â–‡â–‚â–…â–â–
wandb:        PPO_1305/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1305/train/loss â–â–â–â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‡â–…
wandb: PPO_1305/train/policy_gradient_loss â–ƒâ–„â–…â–‡â–‡â–†â–‡â–â–‚â–…â–ˆ
wandb:                  PPO_1305/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1305/train/value_loss â–‚â–‚â–â–„â–ƒâ–„â–…â–†â–…â–ˆâ–‡
wandb:                PPO_1315/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1315/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1315/rollout/ep_rew_mean â–â–‚â–ƒâ–ƒâ–…â–…â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                   PPO_1315/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1315/train/approx_kl â–†â–‡â–â–„â–ˆâ–…â–„â–†â–„â–„â–…
wandb:        PPO_1315/train/clip_fraction â–„â–†â–‚â–ˆâ–†â–„â–‡â–„â–†â–â–†
wandb:           PPO_1315/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1315/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1315/train/explained_variance â–ƒâ–‚â–…â–â–‚â–…â–…â–ƒâ–†â–ƒâ–ˆ
wandb:        PPO_1315/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1315/train/loss â–ˆâ–‡â–ƒâ–„â–â–ƒâ–‚â–†â–â–ƒâ–‚
wandb: PPO_1315/train/policy_gradient_loss â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–…â–†â–‡â–‡â–ˆ
wandb:                  PPO_1315/train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1315/train/value_loss â–ˆâ–…â–…â–…â–„â–„â–â–ƒâ–â–ƒâ–‚
wandb:                PPO_1325/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1325/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1325/rollout/ep_rew_mean â–…â–…â–…â–†â–ˆâ–†â–…â–…â–„â–â–ƒâ–„
wandb:                   PPO_1325/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1325/train/approx_kl â–…â–ˆâ–…â–‡â–‡â–„â–„â–‡â–‚â–â–ƒ
wandb:        PPO_1325/train/clip_fraction â–…â–ˆâ–…â–‡â–„â–†â–†â–„â–‚â–â–„
wandb:           PPO_1325/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1325/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1325/train/explained_variance â–„â–ˆâ–†â–†â–…â–†â–„â–â–†â–‡â–†
wandb:        PPO_1325/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1325/train/loss â–‚â–â–‚â–â–ˆâ–‚â–…â–„â–†â–‡â–ˆ
wandb: PPO_1325/train/policy_gradient_loss â–â–‚â–‚â–â–‚â–„â–ƒâ–„â–ˆâ–†â–„
wandb:                  PPO_1325/train/std â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1325/train/value_loss â–‚â–â–‚â–‚â–‚â–ƒâ–…â–…â–‡â–ˆâ–ˆ
wandb:                PPO_1335/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1335/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1335/rollout/ep_rew_mean â–„â–„â–ƒâ–„â–†â–…â–ˆâ–‡â–â–…â–„â–„
wandb:                   PPO_1335/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1335/train/approx_kl â–â–„â–ƒâ–„â–ƒâ–„â–ˆâ–‚â–…â–„â–‚
wandb:        PPO_1335/train/clip_fraction â–ƒâ–ƒâ–â–…â–„â–„â–ˆâ–â–‚â–„â–‚
wandb:           PPO_1335/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1335/train/entropy_loss â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–ˆ
wandb:   PPO_1335/train/explained_variance â–â–…â–„â–ˆâ–…â–…â–‚â–„â–„â–†â–ˆ
wandb:        PPO_1335/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1335/train/loss â–‚â–ˆâ–„â–â–…â–†â–‚â–ƒâ–‡â–ƒâ–ˆ
wandb: PPO_1335/train/policy_gradient_loss â–…â–‡â–‡â–‚â–†â–…â–‡â–ˆâ–â–‚â–†
wandb:                  PPO_1335/train/std â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1335/train/value_loss â–„â–„â–†â–„â–…â–‡â–â–„â–ˆâ–†â–ˆ
wandb:                PPO_1345/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1345/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1345/rollout/ep_rew_mean â–…â–„â–â–„â–…â–ˆâ–ƒâ–‚â–…â–…â–ƒâ–
wandb:                   PPO_1345/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1345/train/approx_kl â–â–†â–ƒâ–„â–‡â–ˆâ–‚â–…â–â–â–‡
wandb:        PPO_1345/train/clip_fraction â–„â–‡â–‚â–‚â–ˆâ–‡â–„â–â–‚â–‚â–‡
wandb:           PPO_1345/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1345/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:   PPO_1345/train/explained_variance â–ƒâ–†â–ˆâ–…â–‚â–ƒâ–„â–ƒâ–‚â–„â–
wandb:        PPO_1345/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1345/train/loss â–ƒâ–ƒâ–†â–ƒâ–‚â–â–†â–‡â–ˆâ–†â–„
wandb: PPO_1345/train/policy_gradient_loss â–„â–ƒâ–…â–‚â–†â–ˆâ–ƒâ–…â–â–…â–†
wandb:                  PPO_1345/train/std â–ˆâ–†â–†â–…â–„â–„â–„â–‚â–‚â–‚â–
wandb:           PPO_1345/train/value_loss â–ƒâ–â–„â–…â–ƒâ–‚â–…â–ˆâ–ˆâ–…â–ƒ
wandb:                PPO_1355/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1355/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1355/rollout/ep_rew_mean â–â–…â–ƒâ–‡â–…â–‡â–ˆâ–†â–…â–ˆâ–„â–†
wandb:                   PPO_1355/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1355/train/approx_kl â–â–„â–‚â–‚â–…â–…â–„â–„â–…â–ƒâ–ˆ
wandb:        PPO_1355/train/clip_fraction â–â–„â–‚â–ƒâ–„â–‡â–ˆâ–ƒâ–ƒâ–„â–‡
wandb:           PPO_1355/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1355/train/entropy_loss â–â–â–â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1355/train/explained_variance â–†â–ˆâ–‡â–†â–…â–†â–â–‡â–ˆâ–„â–‡
wandb:        PPO_1355/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1355/train/loss â–‚â–‚â–â–â–ƒâ–â–â–â–ˆâ–‚â–
wandb: PPO_1355/train/policy_gradient_loss â–…â–„â–â–„â–„â–‚â–ˆâ–ƒâ–†â–‚â–ˆ
wandb:                  PPO_1355/train/std â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1355/train/value_loss â–…â–ƒâ–ˆâ–…â–ˆâ–ƒâ–„â–…â–ƒâ–„â–
wandb:                PPO_1365/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1365/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1365/rollout/ep_rew_mean â–„â–ƒâ–ƒâ–â–ƒâ–…â–â–‡â–ˆâ–ƒâ–‚â–ƒ
wandb:                   PPO_1365/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1365/train/approx_kl â–â–†â–„â–†â–„â–†â–…â–…â–ˆâ–â–…
wandb:        PPO_1365/train/clip_fraction â–‚â–†â–„â–…â–ƒâ–ƒâ–ƒâ–…â–ˆâ–â–…
wandb:           PPO_1365/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1365/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1365/train/explained_variance â–…â–†â–â–‡â–‡â–ƒâ–ˆâ–ˆâ–ˆâ–…â–‡
wandb:        PPO_1365/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1365/train/loss â–â–‚â–…â–‚â–‚â–ˆâ–ˆâ–‚â–‡â–‚â–„
wandb: PPO_1365/train/policy_gradient_loss â–„â–ƒâ–…â–„â–ƒâ–…â–‚â–‚â–ˆâ–â–†
wandb:                  PPO_1365/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1365/train/value_loss â–…â–ƒâ–ˆâ–ƒâ–„â–…â–…â–ƒâ–â–ˆâ–‚
wandb:                PPO_1375/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1375/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1375/rollout/ep_rew_mean â–†â–ƒâ–†â–ˆâ–ˆâ–…â–‡â–…â–„â–â–†â–†
wandb:                   PPO_1375/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1375/train/approx_kl â–„â–ƒâ–â–ˆâ–ƒâ–ƒâ–‚â–†â–‚â–â–‚
wandb:        PPO_1375/train/clip_fraction â–…â–…â–„â–‡â–†â–‚â–…â–ˆâ–‚â–â–ƒ
wandb:           PPO_1375/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1375/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1375/train/explained_variance â–ƒâ–†â–â–†â–ˆâ–ƒâ–„â–…â–ƒâ–†â–‡
wandb:        PPO_1375/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1375/train/loss â–‚â–†â–ˆâ–ƒâ–ˆâ–â–‚â–ƒâ–…â–„â–†
wandb: PPO_1375/train/policy_gradient_loss â–‡â–…â–†â–ˆâ–†â–„â–ƒâ–†â–â–‚â–†
wandb:                  PPO_1375/train/std â–ˆâ–‡â–†â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1375/train/value_loss â–„â–†â–†â–â–‚â–†â–…â–ƒâ–†â–ˆâ–„
wandb:                PPO_1385/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1385/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1385/rollout/ep_rew_mean â–‡â–…â–‚â–…â–‡â–†â–‡â–†â–â–…â–ˆâ–…
wandb:                   PPO_1385/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–
wandb:            PPO_1385/train/approx_kl â–â–‚â–‚â–…â–â–„â–„â–„â–‚â–„â–ˆ
wandb:        PPO_1385/train/clip_fraction â–â–‚â–â–‚â–ƒâ–…â–„â–‚â–â–„â–ˆ
wandb:           PPO_1385/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1385/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1385/train/explained_variance â–‡â–‡â–‡â–†â–„â–â–†â–„â–ˆâ–‡â–†
wandb:        PPO_1385/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1385/train/loss â–‚â–ˆâ–â–â–â–‚â–…â–‚â–†â–ƒâ–ƒ
wandb: PPO_1385/train/policy_gradient_loss â–‚â–ƒâ–ƒâ–„â–ƒâ–â–…â–ƒâ–‚â–â–ˆ
wandb:                  PPO_1385/train/std â–ˆâ–‡â–†â–…â–„â–„â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1385/train/value_loss â–†â–…â–ˆâ–‡â–‡â–†â–†â–ˆâ–ˆâ–…â–
wandb:                    global_mean_eval â–â–…â–ˆâ–‡â–†â–†â–†â–‡â–‡â–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–†â–ˆâ–‡â–†â–…â–‡â–‡â–‡â–‡
wandb:                       mean_reward_1 â–â–…â–ˆâ–‡â–…â–…â–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_10 â–â–…â–ˆâ–‡â–†â–‡â–†â–†â–‡â–ˆ
wandb:                      mean_reward_11 â–â–…â–ˆâ–ˆâ–†â–†â–…â–‡â–†â–‡
wandb:                      mean_reward_12 â–â–†â–ˆâ–ˆâ–…â–…â–…â–‡â–ˆâ–ˆ
wandb:                      mean_reward_13 â–â–…â–‡â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_14 â–â–…â–ˆâ–‡â–…â–†â–†â–‡â–†â–‡
wandb:                      mean_reward_15 â–â–…â–ˆâ–†â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–â–…â–ˆâ–†â–…â–…â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_17 â–â–…â–ˆâ–‡â–†â–†â–…â–‡â–‡â–‡
wandb:                      mean_reward_18 â–â–…â–ˆâ–†â–†â–…â–†â–ˆâ–‡â–‡
wandb:                      mean_reward_19 â–â–…â–ˆâ–‡â–…â–†â–†â–†â–‡â–‡
wandb:                       mean_reward_2 â–â–…â–‡â–†â–„â–…â–†â–†â–‡â–ˆ
wandb:                      mean_reward_20 â–â–…â–ˆâ–ˆâ–…â–…â–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_21 â–â–…â–ˆâ–‡â–†â–‡â–…â–†â–ˆâ–‡
wandb:                      mean_reward_22 â–â–…â–ˆâ–†â–…â–†â–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_23 â–â–…â–ˆâ–‡â–†â–„â–†â–‡â–ˆâ–‡
wandb:                      mean_reward_24 â–â–…â–ˆâ–‡â–…â–…â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_25 â–â–…â–ˆâ–‡â–†â–…â–†â–†â–‡â–ˆ
wandb:                      mean_reward_26 â–â–…â–ˆâ–†â–…â–†â–†â–†â–‡â–ˆ
wandb:                      mean_reward_27 â–â–…â–ˆâ–†â–†â–…â–†â–‡â–‡â–ˆ
wandb:                      mean_reward_28 â–â–…â–ˆâ–†â–†â–…â–†â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_29 â–â–…â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_3 â–â–…â–ˆâ–‡â–…â–„â–†â–ˆâ–‡â–ˆ
wandb:                      mean_reward_30 â–â–…â–ˆâ–‡â–…â–„â–†â–‡â–ˆâ–‡
wandb:                      mean_reward_31 â–â–†â–ˆâ–‡â–†â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_32 â–â–…â–ˆâ–ˆâ–„â–†â–†â–†â–‡â–‡
wandb:                      mean_reward_33 â–â–…â–ˆâ–‡â–‡â–…â–…â–ˆâ–ˆâ–‡
wandb:                      mean_reward_34 â–â–†â–ˆâ–ˆâ–…â–†â–‡â–†â–‡â–ˆ
wandb:                      mean_reward_35 â–â–…â–‡â–†â–…â–…â–‡â–†â–‡â–ˆ
wandb:                       mean_reward_4 â–â–…â–ˆâ–ˆâ–…â–…â–†â–ˆâ–‡â–ˆ
wandb:                       mean_reward_5 â–â–…â–ˆâ–ˆâ–†â–‡â–†â–‡â–‡â–ˆ
wandb:                       mean_reward_6 â–â–…â–ˆâ–‡â–„â–†â–…â–‡â–ˆâ–‡
wandb:                       mean_reward_7 â–â–…â–ˆâ–†â–…â–†â–‡â–†â–‡â–‡
wandb:                       mean_reward_8 â–â–…â–ˆâ–ˆâ–…â–…â–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_9 â–â–…â–ˆâ–…â–‡â–‡â–…â–‡â–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–…â–†â–ˆ
wandb:                        std_reward_0 â–‚â–â–ƒâ–†â–‡â–ˆâ–†â–†â–…â–„
wandb:                        std_reward_1 â–‚â–â–‚â–…â–ˆâ–ˆâ–†â–„â–…â–„
wandb:                       std_reward_10 â–‚â–â–ƒâ–†â–ˆâ–‡â–‡â–†â–…â–„
wandb:                       std_reward_11 â–‚â–â–‚â–…â–ˆâ–‡â–ˆâ–†â–†â–…
wandb:                       std_reward_12 â–‚â–â–‚â–…â–ˆâ–‡â–‡â–…â–„â–„
wandb:                       std_reward_13 â–‚â–â–ƒâ–ˆâ–ˆâ–ˆâ–†â–…â–…â–„
wandb:                       std_reward_14 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–‡â–…â–†â–…
wandb:                       std_reward_15 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_16 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–‡â–†â–…â–„
wandb:                       std_reward_17 â–‚â–â–‚â–†â–ˆâ–‡â–ˆâ–†â–…â–„
wandb:                       std_reward_18 â–‚â–â–‚â–‡â–‡â–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_19 â–‚â–â–‚â–†â–ˆâ–‡â–‡â–…â–…â–„
wandb:                        std_reward_2 â–‚â–â–‚â–‡â–ˆâ–ˆâ–†â–…â–„â–ƒ
wandb:                       std_reward_20 â–‚â–â–‚â–…â–ˆâ–ˆâ–†â–…â–…â–„
wandb:                       std_reward_21 â–‚â–â–ƒâ–‡â–ˆâ–‡â–ˆâ–‡â–„â–…
wandb:                       std_reward_22 â–‚â–â–ƒâ–‡â–ˆâ–‡â–†â–„â–…â–…
wandb:                       std_reward_23 â–‚â–â–ƒâ–†â–‡â–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_24 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–†â–…â–…â–…
wandb:                       std_reward_25 â–‚â–â–‚â–†â–‡â–ˆâ–†â–…â–…â–ƒ
wandb:                       std_reward_26 â–‚â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–†â–†â–„
wandb:                       std_reward_27 â–‚â–â–ƒâ–‡â–‡â–ˆâ–‡â–…â–†â–„
wandb:                       std_reward_28 â–‚â–â–ƒâ–‡â–ˆâ–ˆâ–‡â–…â–„â–„
wandb:                       std_reward_29 â–‚â–â–ƒâ–‡â–ˆâ–‡â–‡â–†â–…â–„
wandb:                        std_reward_3 â–‚â–â–‚â–†â–ˆâ–ˆâ–‡â–…â–…â–„
wandb:                       std_reward_30 â–‚â–â–‚â–†â–ˆâ–ˆâ–‡â–…â–„â–„
wandb:                       std_reward_31 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–†â–…â–…â–…
wandb:                       std_reward_32 â–‚â–â–‚â–…â–ˆâ–†â–†â–…â–„â–ƒ
wandb:                       std_reward_33 â–‚â–â–‚â–‡â–‡â–ˆâ–ˆâ–…â–…â–…
wandb:                       std_reward_34 â–‚â–â–‚â–…â–ˆâ–ˆâ–‡â–†â–…â–„
wandb:                       std_reward_35 â–‚â–â–‚â–†â–ˆâ–ˆâ–†â–†â–…â–ƒ
wandb:                        std_reward_4 â–‚â–â–ƒâ–…â–ˆâ–ˆâ–‡â–…â–…â–„
wandb:                        std_reward_5 â–‚â–â–‚â–†â–ˆâ–‡â–ˆâ–…â–…â–„
wandb:                        std_reward_6 â–‚â–â–‚â–…â–ˆâ–†â–‡â–…â–„â–„
wandb:                        std_reward_7 â–‚â–â–‚â–†â–ˆâ–‡â–†â–…â–„â–„
wandb:                        std_reward_8 â–‚â–â–ƒâ–†â–ˆâ–ˆâ–†â–…â–„â–„
wandb:                        std_reward_9 â–‚â–â–ƒâ–‡â–‡â–‡â–ˆâ–…â–…â–„
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–„â–ˆâ–‡â–†â–„â–ƒâ–â–‚â–„â–„
wandb:                 train/clip_fraction â–‚â–ƒâ–ƒâ–„â–‡â–‚â–â–‚â–â–‚â–…â–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–â–â–â–†â–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–„â–…â–…â–ˆâ–†â–‡â–†â–…â–ƒâ–‚â–
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1305/global_step 212992
wandb:        PPO_1305/rollout/ep_len_mean 200.0
wandb:        PPO_1305/rollout/ep_rew_mean -754.05072
wandb:                   PPO_1305/time/fps 585.0
wandb:            PPO_1305/train/approx_kl 0.01095
wandb:        PPO_1305/train/clip_fraction 0.14146
wandb:           PPO_1305/train/clip_range 0.2
wandb:         PPO_1305/train/entropy_loss -7.84264
wandb:   PPO_1305/train/explained_variance 0.95934
wandb:        PPO_1305/train/learning_rate 0.0003
wandb:                 PPO_1305/train/loss 64.63321
wandb: PPO_1305/train/policy_gradient_loss -0.00728
wandb:                  PPO_1305/train/std 0.74042
wandb:           PPO_1305/train/value_loss 119.40968
wandb:                PPO_1315/global_step 212992
wandb:        PPO_1315/rollout/ep_len_mean 200.0
wandb:        PPO_1315/rollout/ep_rew_mean -570.17004
wandb:                   PPO_1315/time/fps 584.0
wandb:            PPO_1315/train/approx_kl 0.0133
wandb:        PPO_1315/train/clip_fraction 0.18489
wandb:           PPO_1315/train/clip_range 0.2
wandb:         PPO_1315/train/entropy_loss -6.91847
wandb:   PPO_1315/train/explained_variance 0.9743
wandb:        PPO_1315/train/learning_rate 0.0003
wandb:                 PPO_1315/train/loss 32.27102
wandb: PPO_1315/train/policy_gradient_loss -0.00325
wandb:                  PPO_1315/train/std 0.64978
wandb:           PPO_1315/train/value_loss 62.22541
wandb:                PPO_1325/global_step 212992
wandb:        PPO_1325/rollout/ep_len_mean 200.0
wandb:        PPO_1325/rollout/ep_rew_mean -570.44965
wandb:                   PPO_1325/time/fps 581.0
wandb:            PPO_1325/train/approx_kl 0.01123
wandb:        PPO_1325/train/clip_fraction 0.15079
wandb:           PPO_1325/train/clip_range 0.2
wandb:         PPO_1325/train/entropy_loss -6.39968
wandb:   PPO_1325/train/explained_variance 0.96527
wandb:        PPO_1325/train/learning_rate 0.0003
wandb:                 PPO_1325/train/loss 185.74689
wandb: PPO_1325/train/policy_gradient_loss -0.00286
wandb:                  PPO_1325/train/std 0.60361
wandb:           PPO_1325/train/value_loss 359.63986
wandb:                PPO_1335/global_step 212992
wandb:        PPO_1335/rollout/ep_len_mean 200.0
wandb:        PPO_1335/rollout/ep_rew_mean -590.05994
wandb:                   PPO_1335/time/fps 581.0
wandb:            PPO_1335/train/approx_kl 0.01018
wandb:        PPO_1335/train/clip_fraction 0.13958
wandb:           PPO_1335/train/clip_range 0.2
wandb:         PPO_1335/train/entropy_loss -5.94907
wandb:   PPO_1335/train/explained_variance 0.98168
wandb:        PPO_1335/train/learning_rate 0.0003
wandb:                 PPO_1335/train/loss 342.42581
wandb: PPO_1335/train/policy_gradient_loss -0.0029
wandb:                  PPO_1335/train/std 0.56392
wandb:           PPO_1335/train/value_loss 624.52924
wandb:                PPO_1345/global_step 212992
wandb:        PPO_1345/rollout/ep_len_mean 200.0
wandb:        PPO_1345/rollout/ep_rew_mean -667.07281
wandb:                   PPO_1345/time/fps 582.0
wandb:            PPO_1345/train/approx_kl 0.01255
wandb:        PPO_1345/train/clip_fraction 0.16456
wandb:           PPO_1345/train/clip_range 0.2
wandb:         PPO_1345/train/entropy_loss -5.45646
wandb:   PPO_1345/train/explained_variance 0.97724
wandb:        PPO_1345/train/learning_rate 0.0003
wandb:                 PPO_1345/train/loss 235.27417
wandb: PPO_1345/train/policy_gradient_loss -0.00265
wandb:                  PPO_1345/train/std 0.52709
wandb:           PPO_1345/train/value_loss 561.5968
wandb:                PPO_1355/global_step 212992
wandb:        PPO_1355/rollout/ep_len_mean 200.0
wandb:        PPO_1355/rollout/ep_rew_mean -606.81573
wandb:                   PPO_1355/time/fps 581.0
wandb:            PPO_1355/train/approx_kl 0.01235
wandb:        PPO_1355/train/clip_fraction 0.16294
wandb:           PPO_1355/train/clip_range 0.2
wandb:         PPO_1355/train/entropy_loss -5.07466
wandb:   PPO_1355/train/explained_variance 0.98407
wandb:        PPO_1355/train/learning_rate 0.0003
wandb:                 PPO_1355/train/loss 156.7691
wandb: PPO_1355/train/policy_gradient_loss -0.0011
wandb:                  PPO_1355/train/std 0.49843
wandb:           PPO_1355/train/value_loss 550.8316
wandb:                PPO_1365/global_step 212992
wandb:        PPO_1365/rollout/ep_len_mean 200.0
wandb:        PPO_1365/rollout/ep_rew_mean -594.99756
wandb:                   PPO_1365/time/fps 581.0
wandb:            PPO_1365/train/approx_kl 0.0116
wandb:        PPO_1365/train/clip_fraction 0.15532
wandb:           PPO_1365/train/clip_range 0.2
wandb:         PPO_1365/train/entropy_loss -4.76682
wandb:   PPO_1365/train/explained_variance 0.98298
wandb:        PPO_1365/train/learning_rate 0.0003
wandb:                 PPO_1365/train/loss 458.62384
wandb: PPO_1365/train/policy_gradient_loss -0.00141
wandb:                  PPO_1365/train/std 0.47891
wandb:           PPO_1365/train/value_loss 581.40631
wandb:                PPO_1375/global_step 212992
wandb:        PPO_1375/rollout/ep_len_mean 200.0
wandb:        PPO_1375/rollout/ep_rew_mean -572.96521
wandb:                   PPO_1375/time/fps 581.0
wandb:            PPO_1375/train/approx_kl 0.01151
wandb:        PPO_1375/train/clip_fraction 0.1495
wandb:           PPO_1375/train/clip_range 0.2
wandb:         PPO_1375/train/entropy_loss -4.41916
wandb:   PPO_1375/train/explained_variance 0.98357
wandb:        PPO_1375/train/learning_rate 0.0003
wandb:                 PPO_1375/train/loss 277.89746
wandb: PPO_1375/train/policy_gradient_loss -0.00022
wandb:                  PPO_1375/train/std 0.45546
wandb:           PPO_1375/train/value_loss 592.44708
wandb:                PPO_1385/global_step 212992
wandb:        PPO_1385/rollout/ep_len_mean 200.0
wandb:        PPO_1385/rollout/ep_rew_mean -563.78027
wandb:                   PPO_1385/time/fps 579.0
wandb:            PPO_1385/train/approx_kl 0.01688
wandb:        PPO_1385/train/clip_fraction 0.209
wandb:           PPO_1385/train/clip_range 0.2
wandb:         PPO_1385/train/entropy_loss -4.112
wandb:   PPO_1385/train/explained_variance 0.98328
wandb:        PPO_1385/train/learning_rate 0.0003
wandb:                 PPO_1385/train/loss 334.57947
wandb: PPO_1385/train/policy_gradient_loss 0.00207
wandb:                  PPO_1385/train/std 0.43632
wandb:           PPO_1385/train/value_loss 358.54614
wandb:                    global_mean_eval -489.50983
wandb:                         global_step 212992
wandb:                       mean_reward_0 -514.48819
wandb:                       mean_reward_1 -481.04265
wandb:                      mean_reward_10 -497.39665
wandb:                      mean_reward_11 -494.10886
wandb:                      mean_reward_12 -496.71401
wandb:                      mean_reward_13 -448.92244
wandb:                      mean_reward_14 -492.59468
wandb:                      mean_reward_15 -463.86185
wandb:                      mean_reward_16 -472.57368
wandb:                      mean_reward_17 -509.47084
wandb:                      mean_reward_18 -532.46186
wandb:                      mean_reward_19 -506.57901
wandb:                       mean_reward_2 -444.46261
wandb:                      mean_reward_20 -487.11064
wandb:                      mean_reward_21 -488.95723
wandb:                      mean_reward_22 -529.75678
wandb:                      mean_reward_23 -516.08127
wandb:                      mean_reward_24 -524.08613
wandb:                      mean_reward_25 -463.41541
wandb:                      mean_reward_26 -489.70427
wandb:                      mean_reward_27 -485.5725
wandb:                      mean_reward_28 -492.30739
wandb:                      mean_reward_29 -479.94762
wandb:                       mean_reward_3 -477.9851
wandb:                      mean_reward_30 -494.01578
wandb:                      mean_reward_31 -499.89792
wandb:                      mean_reward_32 -492.09565
wandb:                      mean_reward_33 -499.12007
wandb:                      mean_reward_34 -480.59567
wandb:                      mean_reward_35 -428.78819
wandb:                       mean_reward_4 -488.96287
wandb:                       mean_reward_5 -492.05985
wandb:                       mean_reward_6 -498.78517
wandb:                       mean_reward_7 -491.63813
wandb:                       mean_reward_8 -495.71076
wandb:                       mean_reward_9 -471.08202
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -935.32892
wandb:                        std_reward_0 217.07336
wandb:                        std_reward_1 199.24149
wandb:                       std_reward_10 193.84336
wandb:                       std_reward_11 220.42389
wandb:                       std_reward_12 216.09829
wandb:                       std_reward_13 157.60935
wandb:                       std_reward_14 213.47707
wandb:                       std_reward_15 184.84948
wandb:                       std_reward_16 185.44002
wandb:                       std_reward_17 195.59267
wandb:                       std_reward_18 216.91978
wandb:                       std_reward_19 207.83127
wandb:                        std_reward_2 151.85514
wandb:                       std_reward_20 192.24181
wandb:                       std_reward_21 210.4755
wandb:                       std_reward_22 233.73616
wandb:                       std_reward_23 204.41619
wandb:                       std_reward_24 226.74668
wandb:                       std_reward_25 165.91779
wandb:                       std_reward_26 210.69303
wandb:                       std_reward_27 185.50719
wandb:                       std_reward_28 198.50791
wandb:                       std_reward_29 199.7123
wandb:                        std_reward_3 198.25532
wandb:                       std_reward_30 216.86648
wandb:                       std_reward_31 214.17662
wandb:                       std_reward_32 182.91711
wandb:                       std_reward_33 215.0763
wandb:                       std_reward_34 205.27147
wandb:                       std_reward_35 145.91546
wandb:                        std_reward_4 202.73808
wandb:                        std_reward_5 202.46485
wandb:                        std_reward_6 210.18573
wandb:                        std_reward_7 196.26885
wandb:                        std_reward_8 177.92859
wandb:                        std_reward_9 175.97682
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01017
wandb:                 train/clip_fraction 0.12781
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.67882
wandb:            train/explained_variance 0.87368
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 7.2388
wandb:          train/policy_gradient_loss -0.01025
wandb:                           train/std 0.83444
wandb:                    train/value_loss 20.95161
wandb: 
wandb: Synced glowing-glitter-45: https://wandb.ai/tidiane/meta_rl_context/runs/2if2cb72
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-2if2cb72/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                PPO_1306/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1306/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1306/rollout/ep_rew_mean â–â–ƒâ–„â–‚â–ƒâ–…â–…â–†â–†â–†â–†â–ˆ
wandb:                   PPO_1306/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1306/train/approx_kl â–„â–â–†â–ƒâ–…â–†â–…â–…â–ˆâ–…â–…
wandb:        PPO_1306/train/clip_fraction â–…â–â–†â–ƒâ–…â–†â–†â–„â–‡â–†â–ˆ
wandb:           PPO_1306/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1306/train/entropy_loss â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1306/train/explained_variance â–†â–…â–ˆâ–ˆâ–†â–†â–‡â–„â–„â–â–ƒ
wandb:        PPO_1306/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1306/train/loss â–‚â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–…â–ˆâ–ƒ
wandb: PPO_1306/train/policy_gradient_loss â–â–‡â–‚â–‡â–ƒâ–„â–â–ˆâ–„â–„â–ƒ
wandb:                  PPO_1306/train/std â–ˆâ–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1306/train/value_loss â–â–‚â–‚â–‚â–„â–„â–…â–ˆâ–ˆâ–†â–…
wandb:                PPO_1316/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1316/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1316/rollout/ep_rew_mean â–â–â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–†â–ˆ
wandb:                   PPO_1316/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1316/train/approx_kl â–ƒâ–‚â–„â–ƒâ–â–ƒâ–…â–„â–„â–‡â–ˆ
wandb:        PPO_1316/train/clip_fraction â–â–‚â–…â–â–„â–„â–„â–…â–†â–†â–ˆ
wandb:           PPO_1316/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1316/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1316/train/explained_variance â–â–â–…â–„â–„â–„â–ƒâ–…â–†â–‡â–ˆ
wandb:        PPO_1316/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1316/train/loss â–‚â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚â–â–â–â–
wandb: PPO_1316/train/policy_gradient_loss â–†â–„â–â–ˆâ–…â–…â–ƒâ–‡â–†â–ˆâ–‡
wandb:                  PPO_1316/train/std â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–‚â–
wandb:           PPO_1316/train/value_loss â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–ƒâ–â–â–ƒ
wandb:                PPO_1326/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1326/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1326/rollout/ep_rew_mean â–â–ƒâ–ƒâ–…â–…â–…â–‡â–†â–‡â–†â–†â–ˆ
wandb:                   PPO_1326/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1326/train/approx_kl â–‚â–‡â–ƒâ–ˆâ–ˆâ–…â–„â–â–„â–â–‡
wandb:        PPO_1326/train/clip_fraction â–…â–‡â–‡â–†â–†â–†â–ˆâ–…â–„â–â–†
wandb:           PPO_1326/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1326/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:   PPO_1326/train/explained_variance â–‡â–â–…â–†â–‚â–‡â–†â–ˆâ–†â–…â–…
wandb:        PPO_1326/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1326/train/loss â–‚â–ƒâ–„â–…â–ˆâ–‚â–â–‚â–‚â–†â–ƒ
wandb: PPO_1326/train/policy_gradient_loss â–„â–‚â–„â–‚â–â–ƒâ–†â–â–†â–‡â–ˆ
wandb:                  PPO_1326/train/std â–ˆâ–‡â–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–
wandb:           PPO_1326/train/value_loss â–‚â–„â–â–ƒâ–‡â–†â–â–„â–…â–ˆâ–„
wandb:                PPO_1336/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1336/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1336/rollout/ep_rew_mean â–â–„â–†â–…â–â–„â–‡â–‚â–‡â–‚â–†â–ˆ
wandb:                   PPO_1336/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1336/train/approx_kl â–ƒâ–ˆâ–„â–„â–„â–â–ˆâ–‡â–â–â–†
wandb:        PPO_1336/train/clip_fraction â–â–ˆâ–…â–…â–ƒâ–‡â–ƒâ–†â–†â–…â–„
wandb:           PPO_1336/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1336/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆ
wandb:   PPO_1336/train/explained_variance â–‚â–„â–…â–‚â–â–†â–‚â–‡â–†â–ˆâ–ˆ
wandb:        PPO_1336/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1336/train/loss â–„â–…â–â–‚â–ˆâ–„â–‚â–‚â–â–ƒâ–‚
wandb: PPO_1336/train/policy_gradient_loss â–â–ˆâ–†â–ƒâ–†â–…â–ˆâ–†â–„â–†â–…
wandb:                  PPO_1336/train/std â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–
wandb:           PPO_1336/train/value_loss â–†â–â–â–„â–†â–„â–‡â–‡â–…â–†â–ˆ
wandb:                PPO_1346/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1346/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1346/rollout/ep_rew_mean â–„â–…â–…â–â–…â–†â–„â–ˆâ–‚â–…â–ˆâ–‡
wandb:                   PPO_1346/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1346/train/approx_kl â–†â–ˆâ–‚â–ˆâ–‡â–‡â–‚â–â–…â–ƒâ–…
wandb:        PPO_1346/train/clip_fraction â–ˆâ–ˆâ–ƒâ–„â–‡â–ˆâ–‚â–ƒâ–ˆâ–â–ƒ
wandb:           PPO_1346/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1346/train/entropy_loss â–â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:   PPO_1346/train/explained_variance â–â–…â–ƒâ–â–„â–‡â–…â–ˆâ–…â–‡â–‡
wandb:        PPO_1346/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1346/train/loss â–ƒâ–‚â–„â–ˆâ–ƒâ–â–ƒâ–…â–‚â–ˆâ–ƒ
wandb: PPO_1346/train/policy_gradient_loss â–â–‚â–„â–‚â–†â–ˆâ–†â–‡â–„â–‚â–†
wandb:                  PPO_1346/train/std â–ˆâ–‡â–‡â–†â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:           PPO_1346/train/value_loss â–ƒâ–‚â–…â–†â–â–â–‡â–„â–„â–ˆâ–…
wandb:                PPO_1356/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1356/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1356/rollout/ep_rew_mean â–…â–ƒâ–â–„â–†â–‡â–‚â–„â–‡â–†â–ˆâ–‡
wandb:                   PPO_1356/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1356/train/approx_kl â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–†â–â–ˆ
wandb:        PPO_1356/train/clip_fraction â–†â–‚â–ƒâ–„â–ƒâ–‡â–„â–â–†â–…â–ˆ
wandb:           PPO_1356/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1356/train/entropy_loss â–â–â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–ˆ
wandb:   PPO_1356/train/explained_variance â–â–â–†â–„â–‚â–‚â–†â–â–ˆâ–ˆâ–ˆ
wandb:        PPO_1356/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1356/train/loss â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‡â–â–ƒâ–‚
wandb: PPO_1356/train/policy_gradient_loss â–ƒâ–ƒâ–‚â–â–â–ƒâ–„â–â–ˆâ–„â–…
wandb:                  PPO_1356/train/std â–ˆâ–ˆâ–‡â–†â–‡â–†â–„â–„â–ƒâ–ƒâ–
wandb:           PPO_1356/train/value_loss â–â–…â–‚â–ƒâ–…â–ƒâ–†â–ˆâ–‚â–„â–„
wandb:                PPO_1366/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1366/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1366/rollout/ep_rew_mean â–‡â–ˆâ–ˆâ–ˆâ–†â–„â–†â–…â–ƒâ–â–†â–ƒ
wandb:                   PPO_1366/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1366/train/approx_kl â–‚â–…â–ˆâ–…â–†â–â–†â–…â–‚â–ˆâ–ƒ
wandb:        PPO_1366/train/clip_fraction â–‚â–„â–„â–…â–…â–ƒâ–…â–…â–â–ˆâ–ƒ
wandb:           PPO_1366/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1366/train/entropy_loss â–â–â–‚â–‚â–â–‚â–ƒâ–„â–…â–‡â–ˆ
wandb:   PPO_1366/train/explained_variance â–†â–ˆâ–†â–„â–ˆâ–…â–†â–ˆâ–â–…â–†
wandb:        PPO_1366/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1366/train/loss â–â–ƒâ–â–â–…â–†â–…â–…â–ˆâ–ƒâ–ˆ
wandb: PPO_1366/train/policy_gradient_loss â–ƒâ–„â–†â–ˆâ–ˆâ–…â–†â–†â–â–ˆâ–‚
wandb:                  PPO_1366/train/std â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–„â–„â–‚â–
wandb:           PPO_1366/train/value_loss â–‚â–â–‚â–‚â–â–…â–‚â–‚â–ˆâ–ƒâ–…
wandb:                PPO_1376/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1376/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1376/rollout/ep_rew_mean â–ƒâ–…â–…â–‡â–…â–…â–ˆâ–ˆâ–â–„â–…â–ƒ
wandb:                   PPO_1376/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1376/train/approx_kl â–â–â–‚â–‚â–‚â–ˆâ–†â–â–â–‚â–
wandb:        PPO_1376/train/clip_fraction â–‚â–ƒâ–…â–‡â–„â–†â–ˆâ–â–…â–†â–†
wandb:           PPO_1376/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1376/train/entropy_loss â–â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–‡â–ˆ
wandb:   PPO_1376/train/explained_variance â–…â–„â–ƒâ–‚â–â–…â–ˆâ–…â–…â–†â–…
wandb:        PPO_1376/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1376/train/loss â–‚â–‚â–‚â–â–‚â–„â–ƒâ–â–ƒâ–ˆâ–ˆ
wandb: PPO_1376/train/policy_gradient_loss â–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–‡â–ƒâ–†â–…â–ˆ
wandb:                  PPO_1376/train/std â–ˆâ–‡â–‡â–†â–…â–…â–…â–ƒâ–ƒâ–‚â–
wandb:           PPO_1376/train/value_loss â–…â–…â–„â–„â–ˆâ–…â–â–†â–†â–„â–‡
wandb:                PPO_1386/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆ
wandb:        PPO_1386/rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        PPO_1386/rollout/ep_rew_mean â–ˆâ–…â–„â–â–ƒâ–‚â–‡â–‡â–‡â–ˆâ–†â–…
wandb:                   PPO_1386/time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:            PPO_1386/train/approx_kl â–â–‡â–†â–…â–…â–„â–„â–…â–„â–ˆâ–†
wandb:        PPO_1386/train/clip_fraction â–â–†â–„â–…â–ƒâ–â–ƒâ–„â–„â–ˆâ–ƒ
wandb:           PPO_1386/train/clip_range â–â–â–â–â–â–â–â–â–â–â–
wandb:         PPO_1386/train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–†â–‡â–‡â–ˆ
wandb:   PPO_1386/train/explained_variance â–ƒâ–†â–ˆâ–†â–‡â–†â–â–ˆâ–…â–…â–‡
wandb:        PPO_1386/train/learning_rate â–â–â–â–â–â–â–â–â–â–â–
wandb:                 PPO_1386/train/loss â–ƒâ–…â–‚â–‚â–â–ˆâ–…â–â–â–ˆâ–‚
wandb: PPO_1386/train/policy_gradient_loss â–„â–…â–ƒâ–„â–„â–‚â–â–†â–…â–ˆâ–„
wandb:                  PPO_1386/train/std â–ˆâ–ˆâ–‡â–†â–†â–†â–„â–ƒâ–‚â–‚â–
wandb:           PPO_1386/train/value_loss â–ƒâ–…â–‚â–…â–‚â–ƒâ–ˆâ–ƒâ–…â–â–‚
wandb:                    global_mean_eval â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                         global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_0 â–â–„â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_1 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_10 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_11 â–â–„â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_12 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_13 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                      mean_reward_14 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_15 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                      mean_reward_16 â–â–„â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:                      mean_reward_17 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_18 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                      mean_reward_19 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_2 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_20 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_21 â–â–„â–†â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_22 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡
wandb:                      mean_reward_23 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_24 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡
wandb:                      mean_reward_25 â–â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–ˆ
wandb:                      mean_reward_26 â–â–„â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_27 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                      mean_reward_28 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_29 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_3 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡
wandb:                      mean_reward_30 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_31 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡
wandb:                      mean_reward_32 â–â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆ
wandb:                      mean_reward_33 â–â–„â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:                      mean_reward_34 â–â–„â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:                      mean_reward_35 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       mean_reward_4 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                       mean_reward_5 â–â–„â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆ
wandb:                       mean_reward_6 â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_7 â–â–„â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡
wandb:                       mean_reward_8 â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:                       mean_reward_9 â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                 rollout/ep_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 rollout/ep_rew_mean â–â–â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–„â–…â–†â–ˆ
wandb:                        std_reward_0 â–‚â–â–â–‚â–‚â–…â–†â–ˆâ–‡â–‡
wandb:                        std_reward_1 â–‚â–â–‚â–‚â–‚â–…â–†â–ˆâ–‡â–‡
wandb:                       std_reward_10 â–‚â–â–‚â–‚â–‚â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_11 â–‚â–â–‚â–‚â–ƒâ–„â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_12 â–‚â–â–â–â–‚â–…â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_13 â–‚â–â–â–â–‚â–…â–…â–‡â–ˆâ–‡
wandb:                       std_reward_14 â–‚â–â–‚â–‚â–‚â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_15 â–‚â–â–â–‚â–‚â–…â–†â–‡â–ˆâ–†
wandb:                       std_reward_16 â–‚â–â–‚â–‚â–‚â–…â–‡â–‡â–ˆâ–‡
wandb:                       std_reward_17 â–‚â–â–â–‚â–‚â–„â–…â–ˆâ–ˆâ–†
wandb:                       std_reward_18 â–‚â–â–â–â–‚â–…â–†â–‡â–ˆâ–‡
wandb:                       std_reward_19 â–‚â–â–â–‚â–‚â–„â–†â–ˆâ–ˆâ–‡
wandb:                        std_reward_2 â–‚â–â–â–‚â–‚â–…â–†â–ˆâ–‡â–†
wandb:                       std_reward_20 â–‚â–â–â–â–‚â–„â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_21 â–‚â–â–â–â–â–†â–‡â–ˆâ–ˆâ–‡
wandb:                       std_reward_22 â–‚â–â–â–â–‚â–„â–†â–ˆâ–‡â–†
wandb:                       std_reward_23 â–‚â–â–â–â–‚â–„â–†â–‡â–ˆâ–†
wandb:                       std_reward_24 â–‚â–â–â–‚â–‚â–„â–…â–ˆâ–†â–†
wandb:                       std_reward_25 â–‚â–â–‚â–‚â–‚â–…â–†â–ˆâ–ˆâ–†
wandb:                       std_reward_26 â–‚â–â–â–‚â–ƒâ–…â–‡â–‡â–ˆâ–‡
wandb:                       std_reward_27 â–‚â–â–â–‚â–‚â–…â–‡â–ˆâ–‡â–‡
wandb:                       std_reward_28 â–ƒâ–â–‚â–‚â–ƒâ–†â–†â–ˆâ–ˆâ–‡
wandb:                       std_reward_29 â–‚â–â–â–‚â–‚â–…â–…â–ˆâ–‡â–†
wandb:                        std_reward_3 â–‚â–â–‚â–‚â–‚â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:                       std_reward_30 â–â–â–â–‚â–‚â–…â–†â–‡â–ˆâ–‡
wandb:                       std_reward_31 â–‚â–â–â–‚â–‚â–…â–†â–‡â–ˆâ–†
wandb:                       std_reward_32 â–‚â–â–â–â–‚â–…â–†â–†â–ˆâ–…
wandb:                       std_reward_33 â–‚â–â–â–â–‚â–…â–…â–ˆâ–ˆâ–†
wandb:                       std_reward_34 â–‚â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–‡
wandb:                       std_reward_35 â–‚â–â–‚â–‚â–‚â–†â–†â–ˆâ–ˆâ–‡
wandb:                        std_reward_4 â–‚â–â–â–‚â–‚â–…â–…â–ˆâ–‡â–†
wandb:                        std_reward_5 â–ƒâ–â–â–‚â–‚â–„â–…â–ˆâ–‡â–„
wandb:                        std_reward_6 â–‚â–â–‚â–â–‚â–…â–…â–ˆâ–‡â–‡
wandb:                        std_reward_7 â–‚â–â–â–‚â–‚â–…â–…â–ˆâ–ˆâ–‡
wandb:                        std_reward_8 â–‚â–â–‚â–‚â–‚â–…â–†â–ˆâ–ˆâ–†
wandb:                        std_reward_9 â–â–â–â–â–‚â–†â–†â–‡â–ˆâ–‡
wandb:                            time/fps â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                     train/approx_kl â–‚â–ƒâ–„â–ˆâ–‡â–†â–„â–ƒâ–â–‚â–„â–„
wandb:                 train/clip_fraction â–‚â–ƒâ–ƒâ–„â–‡â–‚â–â–‚â–â–‚â–…â–ˆ
wandb:                    train/clip_range â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  train/entropy_loss â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            train/explained_variance â–â–â–â–â–â–â–â–â–â–†â–ˆâ–ˆ
wandb:                 train/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train/loss â–ˆâ–‡â–„â–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:          train/policy_gradient_loss â–†â–„â–…â–…â–ˆâ–†â–‡â–†â–…â–ƒâ–‚â–
wandb:                           train/std â–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:                    train/value_loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                PPO_1306/global_step 212992
wandb:        PPO_1306/rollout/ep_len_mean 200.0
wandb:        PPO_1306/rollout/ep_rew_mean -816.2121
wandb:                   PPO_1306/time/fps 581.0
wandb:            PPO_1306/train/approx_kl 0.01167
wandb:        PPO_1306/train/clip_fraction 0.16325
wandb:           PPO_1306/train/clip_range 0.2
wandb:         PPO_1306/train/entropy_loss -7.76121
wandb:   PPO_1306/train/explained_variance 0.94796
wandb:        PPO_1306/train/learning_rate 0.0003
wandb:                 PPO_1306/train/loss 36.41696
wandb: PPO_1306/train/policy_gradient_loss -0.00852
wandb:                  PPO_1306/train/std 0.73255
wandb:           PPO_1306/train/value_loss 99.7776
wandb:                PPO_1316/global_step 212992
wandb:        PPO_1316/rollout/ep_len_mean 200.0
wandb:        PPO_1316/rollout/ep_rew_mean -593.1886
wandb:                   PPO_1316/time/fps 579.0
wandb:            PPO_1316/train/approx_kl 0.01533
wandb:        PPO_1316/train/clip_fraction 0.1949
wandb:           PPO_1316/train/clip_range 0.2
wandb:         PPO_1316/train/entropy_loss -6.76734
wandb:   PPO_1316/train/explained_variance 0.97072
wandb:        PPO_1316/train/learning_rate 0.0003
wandb:                 PPO_1316/train/loss 18.46652
wandb: PPO_1316/train/policy_gradient_loss -0.00647
wandb:                  PPO_1316/train/std 0.63549
wandb:           PPO_1316/train/value_loss 58.5304
wandb:                PPO_1326/global_step 212992
wandb:        PPO_1326/rollout/ep_len_mean 200.0
wandb:        PPO_1326/rollout/ep_rew_mean -555.27991
wandb:                   PPO_1326/time/fps 577.0
wandb:            PPO_1326/train/approx_kl 0.01508
wandb:        PPO_1326/train/clip_fraction 0.19344
wandb:           PPO_1326/train/clip_range 0.2
wandb:         PPO_1326/train/entropy_loss -5.9572
wandb:   PPO_1326/train/explained_variance 0.96809
wandb:        PPO_1326/train/learning_rate 0.0003
wandb:                 PPO_1326/train/loss 22.88289
wandb: PPO_1326/train/policy_gradient_loss -0.00291
wandb:                  PPO_1326/train/std 0.56608
wandb:           PPO_1326/train/value_loss 62.91434
wandb:                PPO_1336/global_step 212992
wandb:        PPO_1336/rollout/ep_len_mean 200.0
wandb:        PPO_1336/rollout/ep_rew_mean -533.91345
wandb:                   PPO_1336/time/fps 577.0
wandb:            PPO_1336/train/approx_kl 0.01591
wandb:        PPO_1336/train/clip_fraction 0.19395
wandb:           PPO_1336/train/clip_range 0.2
wandb:         PPO_1336/train/entropy_loss -5.37655
wandb:   PPO_1336/train/explained_variance 0.98087
wandb:        PPO_1336/train/learning_rate 0.0003
wandb:                 PPO_1336/train/loss 17.70603
wandb: PPO_1336/train/policy_gradient_loss -0.00251
wandb:                  PPO_1336/train/std 0.52185
wandb:           PPO_1336/train/value_loss 77.82939
wandb:                PPO_1346/global_step 212992
wandb:        PPO_1346/rollout/ep_len_mean 200.0
wandb:        PPO_1346/rollout/ep_rew_mean -513.32068
wandb:                   PPO_1346/time/fps 577.0
wandb:            PPO_1346/train/approx_kl 0.01511
wandb:        PPO_1346/train/clip_fraction 0.18688
wandb:           PPO_1346/train/clip_range 0.2
wandb:         PPO_1346/train/entropy_loss -4.8728
wandb:   PPO_1346/train/explained_variance 0.98526
wandb:        PPO_1346/train/learning_rate 0.0003
wandb:                 PPO_1346/train/loss 33.21234
wandb: PPO_1346/train/policy_gradient_loss -0.00157
wandb:                  PPO_1346/train/std 0.48605
wandb:           PPO_1346/train/value_loss 88.65797
wandb:                PPO_1356/global_step 212992
wandb:        PPO_1356/rollout/ep_len_mean 200.0
wandb:        PPO_1356/rollout/ep_rew_mean -490.77365
wandb:                   PPO_1356/time/fps 576.0
wandb:            PPO_1356/train/approx_kl 0.021
wandb:        PPO_1356/train/clip_fraction 0.23682
wandb:           PPO_1356/train/clip_range 0.2
wandb:         PPO_1356/train/entropy_loss -4.30835
wandb:   PPO_1356/train/explained_variance 0.98901
wandb:        PPO_1356/train/learning_rate 0.0003
wandb:                 PPO_1356/train/loss 25.06101
wandb: PPO_1356/train/policy_gradient_loss -0.00016
wandb:                  PPO_1356/train/std 0.44732
wandb:           PPO_1356/train/value_loss 135.26982
wandb:                PPO_1366/global_step 212992
wandb:        PPO_1366/rollout/ep_len_mean 200.0
wandb:        PPO_1366/rollout/ep_rew_mean -537.90881
wandb:                   PPO_1366/time/fps 575.0
wandb:            PPO_1366/train/approx_kl 0.0144
wandb:        PPO_1366/train/clip_fraction 0.21248
wandb:           PPO_1366/train/clip_range 0.2
wandb:         PPO_1366/train/entropy_loss -4.02454
wandb:   PPO_1366/train/explained_variance 0.98803
wandb:        PPO_1366/train/learning_rate 0.0003
wandb:                 PPO_1366/train/loss 210.2908
wandb: PPO_1366/train/policy_gradient_loss -0.00063
wandb:                  PPO_1366/train/std 0.43117
wandb:           PPO_1366/train/value_loss 250.72
wandb:                PPO_1376/global_step 212992
wandb:        PPO_1376/rollout/ep_len_mean 200.0
wandb:        PPO_1376/rollout/ep_rew_mean -533.86444
wandb:                   PPO_1376/time/fps 576.0
wandb:            PPO_1376/train/approx_kl 0.01732
wandb:        PPO_1376/train/clip_fraction 0.2508
wandb:           PPO_1376/train/clip_range 0.2
wandb:         PPO_1376/train/entropy_loss -3.67376
wandb:   PPO_1376/train/explained_variance 0.98863
wandb:        PPO_1376/train/learning_rate 0.0003
wandb:                 PPO_1376/train/loss 266.7616
wandb: PPO_1376/train/policy_gradient_loss 0.00451
wandb:                  PPO_1376/train/std 0.40918
wandb:           PPO_1376/train/value_loss 309.63828
wandb:                PPO_1386/global_step 212992
wandb:        PPO_1386/rollout/ep_len_mean 200.0
wandb:        PPO_1386/rollout/ep_rew_mean -533.75421
wandb:                   PPO_1386/time/fps 575.0
wandb:            PPO_1386/train/approx_kl 0.02263
wandb:        PPO_1386/train/clip_fraction 0.25818
wandb:           PPO_1386/train/clip_range 0.2
wandb:         PPO_1386/train/entropy_loss -3.40334
wandb:   PPO_1386/train/explained_variance 0.99083
wandb:        PPO_1386/train/learning_rate 0.0003
wandb:                 PPO_1386/train/loss 67.47871
wandb: PPO_1386/train/policy_gradient_loss 0.00432
wandb:                  PPO_1386/train/std 0.39404
wandb:           PPO_1386/train/value_loss 247.91537
wandb:                    global_mean_eval -482.746
wandb:                         global_step 212992
wandb:                       mean_reward_0 -505.87851
wandb:                       mean_reward_1 -491.24766
wandb:                      mean_reward_10 -489.77542
wandb:                      mean_reward_11 -456.60061
wandb:                      mean_reward_12 -463.00189
wandb:                      mean_reward_13 -510.02652
wandb:                      mean_reward_14 -504.92905
wandb:                      mean_reward_15 -453.62503
wandb:                      mean_reward_16 -481.0767
wandb:                      mean_reward_17 -476.78736
wandb:                      mean_reward_18 -477.20529
wandb:                      mean_reward_19 -494.5621
wandb:                       mean_reward_2 -467.34303
wandb:                      mean_reward_20 -485.70781
wandb:                      mean_reward_21 -498.25618
wandb:                      mean_reward_22 -510.37371
wandb:                      mean_reward_23 -484.44498
wandb:                      mean_reward_24 -478.70604
wandb:                      mean_reward_25 -479.67113
wandb:                      mean_reward_26 -469.28269
wandb:                      mean_reward_27 -452.36965
wandb:                      mean_reward_28 -518.60769
wandb:                      mean_reward_29 -493.48027
wandb:                       mean_reward_3 -492.95853
wandb:                      mean_reward_30 -478.01261
wandb:                      mean_reward_31 -490.53171
wandb:                      mean_reward_32 -461.418
wandb:                      mean_reward_33 -457.17745
wandb:                      mean_reward_34 -507.74206
wandb:                      mean_reward_35 -484.39386
wandb:                       mean_reward_4 -474.73281
wandb:                       mean_reward_5 -416.98461
wandb:                       mean_reward_6 -491.69007
wandb:                       mean_reward_7 -519.60827
wandb:                       mean_reward_8 -477.79412
wandb:                       mean_reward_9 -482.85264
wandb:                 rollout/ep_len_mean 200.0
wandb:                 rollout/ep_rew_mean -935.32892
wandb:                        std_reward_0 214.892
wandb:                        std_reward_1 209.94877
wandb:                       std_reward_10 212.38388
wandb:                       std_reward_11 187.73337
wandb:                       std_reward_12 181.50613
wandb:                       std_reward_13 202.32466
wandb:                       std_reward_14 220.48591
wandb:                       std_reward_15 181.41019
wandb:                       std_reward_16 186.58904
wandb:                       std_reward_17 189.21552
wandb:                       std_reward_18 204.18918
wandb:                       std_reward_19 212.42168
wandb:                        std_reward_2 195.172
wandb:                       std_reward_20 198.1157
wandb:                       std_reward_21 202.62617
wandb:                       std_reward_22 205.94127
wandb:                       std_reward_23 188.11047
wandb:                       std_reward_24 198.05163
wandb:                       std_reward_25 197.40839
wandb:                       std_reward_26 196.95958
wandb:                       std_reward_27 194.78675
wandb:                       std_reward_28 210.32273
wandb:                       std_reward_29 208.39657
wandb:                        std_reward_3 214.71036
wandb:                       std_reward_30 213.36954
wandb:                       std_reward_31 186.4194
wandb:                       std_reward_32 175.02686
wandb:                       std_reward_33 180.86097
wandb:                       std_reward_34 224.51973
wandb:                       std_reward_35 185.28109
wandb:                        std_reward_4 191.83129
wandb:                        std_reward_5 144.78827
wandb:                        std_reward_6 219.26964
wandb:                        std_reward_7 221.37707
wandb:                        std_reward_8 195.34294
wandb:                        std_reward_9 205.98363
wandb:                            time/fps 600.0
wandb:                     train/approx_kl 0.01017
wandb:                 train/clip_fraction 0.12781
wandb:                    train/clip_range 0.2
wandb:                  train/entropy_loss -8.67882
wandb:            train/explained_variance 0.87368
wandb:                 train/learning_rate 0.0003
wandb:                          train/loss 7.2388
wandb:          train/policy_gradient_loss -0.01025
wandb:                           train/std 0.83444
wandb:                    train/value_loss 20.95161
wandb: 
wandb: Synced deft-thunder-45: https://wandb.ai/tidiane/meta_rl_context/runs/2y87u8r8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 13 other file(s)
wandb: Find logs at: ./wandb/run-20230626_052650-2y87u8r8/logs

real	252m31.971s
user	2467m34.648s
sys	8m57.267s
